{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z51a5GUFjdUI",
        "outputId": "ba3d45e0-8b02-4bc4-bc8b-4055f4d196c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZJL1sB6iBD1"
      },
      "source": [
        "##Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0ZGv_CLGhzrr"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# !pip install torch==1.8.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install transformers\n",
        "!pip install nltk spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4VCvfIGtr9q",
        "outputId": "9dcb7fbe-9ad7-46ad-fb2a-8ff2cc137bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_scatter-2.1.2%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_sparse-0.6.18%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu121/torch_cluster-1.6.3%2Bpt21cu121-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.23.5)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt21cu121\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-sqxm0ybp\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-sqxm0ybp\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 025ef209ee57d56cb9e736fe0d0ed076e13c5ad4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.4.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.4.0-py3-none-any.whl size=1094340 sha256=cdfb6a2b0200d34e1069d5ea0f9777c6bd1954e6426a79bed4715cc653588ba6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0patv8ia/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "!pip uninstall torch-sparse  --y\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GNJ4gJNiSvg"
      },
      "source": [
        "#Download Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm0LWGpylPaD"
      },
      "source": [
        "<h3><font color=lightgreen>ConceptNet Full KnowledgeGraph (including none english data)</font></h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsdtWFThsP0n"
      },
      "outputs": [],
      "source": [
        "# download ConceptNet\n",
        "%mkdir -p data/\n",
        "%mkdir -p data/cpnet/\n",
        "!wget -nc -P data/cpnet/ https://s3.amazonaws.com/conceptnet/downloads/2018/edges/conceptnet-assertions-5.6.0.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A4Sdfcxic3i"
      },
      "outputs": [],
      "source": [
        "%cd data/cpnet/\n",
        "!yes n | gzip -d conceptnet-assertions-5.6.0.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR3e9D4YsRsB"
      },
      "outputs": [],
      "source": [
        "# download ConceptNet entity embedding\n",
        "!wget https://csr.s3-us-west-1.amazonaws.com/tzw.ent.npy\n",
        "%cd ../../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3djGO1F6lQ5P"
      },
      "source": [
        "<h3><font color=Hotpink>CommensenseQA datset</font></h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT5TpWNZiqNM"
      },
      "outputs": [],
      "source": [
        "# download CommensenseQA dataset\n",
        "%mkdir -p data/csqa/\n",
        "!wget -nc -P data/csqa/ https://s3.amazonaws.com/commensenseqa/train_rand_split.jsonl\n",
        "!wget -nc -P data/csqa/ https://s3.amazonaws.com/commensenseqa/dev_rand_split.jsonl\n",
        "!wget -nc -P data/csqa/ https://s3.amazonaws.com/commensenseqa/test_rand_split_no_answers.jsonl\n",
        "\n",
        "# create output folders\n",
        "%mkdir -p data/csqa/grounded/\n",
        "%mkdir -p data/csqa/graph/\n",
        "%mkdir -p data/csqa/statement/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ3eLOv2lGS5"
      },
      "source": [
        "<font color=yellow>OBQA datset</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeND74UshzHS"
      },
      "outputs": [],
      "source": [
        "# # download OpenBookQA dataset\n",
        "# !wget -nc -P data/obqa/ https://s3-us-west-2.amazonaws.com/ai2-website/data/OpenBookQA-V1-Sep2018.zip\n",
        "# !yes n | unzip data/obqa/OpenBookQA-V1-Sep2018.zip -d data/obqa/\n",
        "\n",
        "# # create output folders\n",
        "# %mkdir -p data/obqa/fairseq/official/\n",
        "# %mkdir -p data/obqa/grounded/\n",
        "# %mkdir -p data/obqa/graph/\n",
        "# %mkdir -p data/obqa/statement/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3OESkpwSnZo"
      },
      "source": [
        "#Download Preprocessed data (ConceptNet and CommonsenseQA and OBQA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mqQMVBGSqc1",
        "outputId": "162283c7-36fe-4ebf-d7d9-c6a312394e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'data': No such file or directory\n",
            "--2023-12-12 14:59:58--  https://nlp.stanford.edu/projects/myasu/QAGNN/data_preprocessed_release.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4226838278 (3.9G) [application/zip]\n",
            "Saving to: ‘data_preprocessed_release.zip’\n",
            "\n",
            "data_preprocessed_r 100%[===================>]   3.94G  40.1MB/s    in 2m 11s  \n",
            "\n",
            "2023-12-12 15:02:09 (30.8 MB/s) - ‘data_preprocessed_release.zip’ saved [4226838278/4226838278]\n",
            "\n",
            "Archive:  data_preprocessed_release.zip\n",
            "   creating: data_preprocessed_release/\n",
            "   creating: data_preprocessed_release/cpnet/\n",
            "  inflating: data_preprocessed_release/cpnet/conceptnet.en.unpruned.graph  \n",
            "  inflating: data_preprocessed_release/cpnet/conceptnet.en.csv  \n",
            "  inflating: data_preprocessed_release/cpnet/matcher_patterns.json  \n",
            "  inflating: data_preprocessed_release/cpnet/conceptnet-assertions-5.6.0.csv  \n",
            "  inflating: data_preprocessed_release/cpnet/conceptnet.en.pruned.graph  \n",
            "  inflating: data_preprocessed_release/cpnet/tzw.ent.npy  \n",
            "  inflating: data_preprocessed_release/cpnet/concept.txt  \n",
            "   creating: data_preprocessed_release/obqa/\n",
            "   creating: data_preprocessed_release/obqa/statement/\n",
            "  inflating: data_preprocessed_release/obqa/statement/train.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/statement/dev-fact.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/statement/dev.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/statement/test-fact.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/statement/train-fact.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/statement/test.statement.jsonl  \n",
            "   creating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/\n",
            "   creating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/\n",
            "   creating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/\n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/dev.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/openbook.txt  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/test.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/train.tsv  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/train.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/test.tsv  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Main/dev.tsv  \n",
            "   creating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Additional/\n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Additional/test_complete.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Additional/train_complete.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Additional/crowdsourced-facts.txt  \n",
            "  inflating: data_preprocessed_release/obqa/OpenBookQA-V1-Sep2018/Data/Additional/dev_complete.jsonl  \n",
            "   creating: data_preprocessed_release/obqa/grounded/\n",
            "  inflating: data_preprocessed_release/obqa/grounded/train.grounded.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/grounded/test.grounded.jsonl  \n",
            "  inflating: data_preprocessed_release/obqa/grounded/dev.grounded.jsonl  \n",
            "   creating: data_preprocessed_release/obqa/graph/\n",
            "  inflating: data_preprocessed_release/obqa/graph/train.graph.adj.pk  \n",
            "  inflating: data_preprocessed_release/obqa/graph/train.graph.adj.pk.loaded_cache  \n",
            "  inflating: data_preprocessed_release/obqa/graph/dev.graph.adj.pk.loaded_cache  \n",
            "  inflating: data_preprocessed_release/obqa/graph/test.graph.adj.pk.loaded_cache  \n",
            "  inflating: data_preprocessed_release/obqa/graph/dev.graph.adj.pk  \n",
            "  inflating: data_preprocessed_release/obqa/graph/test.graph.adj.pk  \n",
            "   creating: data_preprocessed_release/csqa/\n",
            "   creating: data_preprocessed_release/csqa/grounded/\n",
            "  inflating: data_preprocessed_release/csqa/grounded/test.grounded.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/grounded/train.grounded.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/grounded/dev.grounded.jsonl  \n",
            "   creating: data_preprocessed_release/csqa/graph/\n",
            "  inflating: data_preprocessed_release/csqa/graph/test.graph.adj.pk  \n",
            "  inflating: data_preprocessed_release/csqa/graph/dev.graph.adj.pk.loaded_cache  \n",
            "  inflating: data_preprocessed_release/csqa/graph/train.graph.adj.pk  \n",
            "  inflating: data_preprocessed_release/csqa/graph/test.graph.adj.pk.loaded_cache  \n",
            "  inflating: data_preprocessed_release/csqa/graph/dev.graph.adj.pk  \n",
            "  inflating: data_preprocessed_release/csqa/graph/train.graph.adj.pk.loaded_cache  \n",
            "   creating: data_preprocessed_release/csqa/statement/\n",
            "  inflating: data_preprocessed_release/csqa/statement/dev.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/statement/train.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/statement/test.statement.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/train_rand_split.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/dev_rand_split.jsonl  \n",
            "  inflating: data_preprocessed_release/csqa/inhouse_split_qids.txt  \n",
            "  inflating: data_preprocessed_release/csqa/test_rand_split_no_answers.jsonl  \n"
          ]
        }
      ],
      "source": [
        "!mv data data_old\n",
        "\n",
        "!wget https://nlp.stanford.edu/projects/myasu/QAGNN/data_preprocessed_release.zip\n",
        "!unzip data_preprocessed_release.zip\n",
        "!mv data_preprocessed_release  data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBidYjbXkACn"
      },
      "source": [
        "#Preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHFKwLTQzoCE"
      },
      "source": [
        "###from utils.convert_csqa import convert_to_entailment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69TQQeIqzolR"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Script to convert the retrieved HITS into an entailment dataset\n",
        "USAGE:\n",
        " python convert_csqa.py input_file output_file\n",
        "\n",
        "JSONL format of files\n",
        " 1. input_file:\n",
        " {\n",
        "   \"id\": \"d3b479933e716fb388dfb297e881054c\",\n",
        "   \"question\": {\n",
        "      \"stem\": \"If a lantern is not for sale, where is it likely to be?\"\n",
        "      \"choices\": [{\"label\": \"A\", \"text\": \"antique shop\"}, {\"label\": \"B\", \"text\": \"house\"}, {\"label\": \"C\", \"text\": \"dark place\"}]\n",
        "    },\n",
        "     \"answerKey\":\"B\"\n",
        "  }\n",
        "\n",
        " 2. output_file:\n",
        "   {\n",
        "   \"id\": \"d3b479933e716fb388dfb297e881054c\",\n",
        "   \"question\": {\n",
        "      \"stem\": \"If a lantern is not for sale, where is it likely to be?\"\n",
        "      \"choices\": [{\"label\": \"A\", \"text\": \"antique shop\"}, {\"label\": \"B\", \"text\": \"house\"}, {\"label\": \"C\", \"text\": \"dark place\"}]\n",
        "    },\n",
        "    \"answerKey\":\"B\",\n",
        "\n",
        "    \"statements\":[\n",
        "        {label:true, stem: \"If a lantern is not for sale, it likely to be at house\"},\n",
        "        {label:false, stem: \"If a lantern is not for sale, it likely to be at antique shop\"},\n",
        "        {label:false, stem: \"If a lantern is not for sale, it likely to be at dark place\"}\n",
        "        ]\n",
        "  }\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "import re\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "__all__ = ['convert_to_entailment']\n",
        "\n",
        "# String used to indicate a blank\n",
        "BLANK_STR = \"___\"\n",
        "\n",
        "\n",
        "def convert_to_entailment(qa_file: str, output_file: str, ans_pos: bool=False):\n",
        "    print(f'converting {qa_file} to entailment dataset...')\n",
        "    nrow = sum(1 for _ in open(qa_file, 'r'))\n",
        "    with open(output_file, 'w') as output_handle, open(qa_file, 'r') as qa_handle:\n",
        "        # print(\"Writing to {} from {}\".format(output_file, qa_file))\n",
        "        for line in tqdm(qa_handle, total=nrow):\n",
        "            json_line = json.loads(line)\n",
        "            output_dict = convert_qajson_to_entailment(json_line, ans_pos)\n",
        "            output_handle.write(json.dumps(output_dict))\n",
        "            output_handle.write(\"\\n\")\n",
        "    print(f'converted statements saved to {output_file}')\n",
        "    print()\n",
        "\n",
        "\n",
        "# Convert the QA file json to output dictionary containing premise and hypothesis\n",
        "def convert_qajson_to_entailment(qa_json: dict, ans_pos: bool):\n",
        "    question_text = qa_json[\"question\"][\"stem\"]\n",
        "    choices = qa_json[\"question\"][\"choices\"]\n",
        "    for choice in choices:\n",
        "        choice_text = choice[\"text\"]\n",
        "        pos = None\n",
        "        if not ans_pos:\n",
        "            statement = create_hypothesis(get_fitb_from_question(question_text), choice_text, ans_pos)\n",
        "        else:\n",
        "            statement, pos = create_hypothesis(get_fitb_from_question(question_text), choice_text, ans_pos)\n",
        "        create_output_dict(qa_json, statement,  choice[\"label\"] == qa_json.get(\"answerKey\", \"A\"), ans_pos, pos)\n",
        "\n",
        "    return qa_json\n",
        "\n",
        "\n",
        "# Get a Fill-In-The-Blank (FITB) statement from the question text. E.g. \"George wants to warm his\n",
        "# hands quickly by rubbing them. Which skin surface will produce the most heat?\" ->\n",
        "# \"George wants to warm his hands quickly by rubbing them. ___ skin surface will produce the most\n",
        "# heat?\n",
        "def get_fitb_from_question(question_text: str) -> str:\n",
        "    fitb = replace_wh_word_with_blank(question_text)\n",
        "    if not re.match(\".*_+.*\", fitb):\n",
        "        # print(\"Can't create hypothesis from: '{}'. Appending {} !\".format(question_text, BLANK_STR))\n",
        "        # Strip space, period and question mark at the end of the question and add a blank\n",
        "        fitb = re.sub(r\"[\\.\\? ]*$\", \"\", question_text.strip()) + \" \" + BLANK_STR\n",
        "    return fitb\n",
        "\n",
        "\n",
        "# Create a hypothesis statement from the the input fill-in-the-blank statement and answer choice.\n",
        "def create_hypothesis(fitb: str, choice: str, ans_pos: bool) -> str:\n",
        "\n",
        "    if \". \" + BLANK_STR in fitb or fitb.startswith(BLANK_STR):\n",
        "        choice = choice[0].upper() + choice[1:]\n",
        "    else:\n",
        "        choice = choice.lower()\n",
        "    # Remove period from the answer choice, if the question doesn't end with the blank\n",
        "    if not fitb.endswith(BLANK_STR):\n",
        "        choice = choice.rstrip(\".\")\n",
        "    # Some questions already have blanks indicated with 2+ underscores\n",
        "    if not ans_pos:\n",
        "        try:\n",
        "            hypothesis = re.sub(\"__+\", choice, fitb)\n",
        "        except:\n",
        "            print (choice, fitb)\n",
        "        return hypothesis\n",
        "    choice = choice.strip()\n",
        "    m = re.search(\"__+\", fitb)\n",
        "    start = m.start()\n",
        "\n",
        "    length = (len(choice) - 1) if fitb.endswith(BLANK_STR) and choice[-1] in ['.', '?', '!'] else len(choice)\n",
        "    hypothesis = re.sub(\"__+\", choice, fitb)\n",
        "\n",
        "    return hypothesis, (start, start + length)\n",
        "\n",
        "\n",
        "# Identify the wh-word in the question and replace with a blank\n",
        "def replace_wh_word_with_blank(question_str: str):\n",
        "    # if \"What is the name of the government building that houses the U.S. Congress?\" in question_str:\n",
        "    #     print()\n",
        "    question_str = question_str.replace(\"What's\", \"What is\")\n",
        "    question_str = question_str.replace(\"whats\", \"what\")\n",
        "    question_str = question_str.replace(\"U.S.\", \"US\")\n",
        "    wh_word_offset_matches = []\n",
        "    wh_words = [\"which\", \"what\", \"where\", \"when\", \"how\", \"who\", \"why\"]\n",
        "    for wh in wh_words:\n",
        "        # Some Turk-authored SciQ questions end with wh-word\n",
        "        # E.g. The passing of traits from parents to offspring is done through what?\n",
        "\n",
        "        if wh == \"who\" and \"people who\" in question_str:\n",
        "            continue\n",
        "\n",
        "        m = re.search(wh + r\"\\?[^\\.]*[\\. ]*$\", question_str.lower())\n",
        "        if m:\n",
        "            wh_word_offset_matches = [(wh, m.start())]\n",
        "            break\n",
        "        else:\n",
        "            # Otherwise, find the wh-word in the last sentence\n",
        "            m = re.search(wh + r\"[ ,][^\\.]*[\\. ]*$\", question_str.lower())\n",
        "            if m:\n",
        "                wh_word_offset_matches.append((wh, m.start()))\n",
        "            # else:\n",
        "            #     wh_word_offset_matches.append((wh, question_str.index(wh)))\n",
        "\n",
        "    # If a wh-word is found\n",
        "    if len(wh_word_offset_matches):\n",
        "        # Pick the first wh-word as the word to be replaced with BLANK\n",
        "        # E.g. Which is most likely needed when describing the change in position of an object?\n",
        "        wh_word_offset_matches.sort(key=lambda x: x[1])\n",
        "        wh_word_found = wh_word_offset_matches[0][0]\n",
        "        wh_word_start_offset = wh_word_offset_matches[0][1]\n",
        "        # Replace the last question mark with period.\n",
        "        question_str = re.sub(r\"\\?$\", \".\", question_str.strip())\n",
        "        # Introduce the blank in place of the wh-word\n",
        "        fitb_question = (question_str[:wh_word_start_offset] + BLANK_STR +\n",
        "                         question_str[wh_word_start_offset + len(wh_word_found):])\n",
        "        # Drop \"of the following\" as it doesn't make sense in the absence of a multiple-choice\n",
        "        # question. E.g. \"Which of the following force ...\" -> \"___ force ...\"\n",
        "        final = fitb_question.replace(BLANK_STR + \" of the following\", BLANK_STR)\n",
        "        final = final.replace(BLANK_STR + \" of these\", BLANK_STR)\n",
        "        return final\n",
        "\n",
        "    elif \" them called?\" in question_str:\n",
        "        return question_str.replace(\" them called?\", \" \" + BLANK_STR + \".\")\n",
        "    elif \" meaning he was not?\" in question_str:\n",
        "        return question_str.replace(\" meaning he was not?\", \" he was not \" + BLANK_STR + \".\")\n",
        "    elif \" one of these?\" in question_str:\n",
        "        return question_str.replace(\" one of these?\", \" \" + BLANK_STR + \".\")\n",
        "    elif re.match(r\".*[^\\.\\?] *$\", question_str):\n",
        "        # If no wh-word is found and the question ends without a period/question, introduce a\n",
        "        # blank at the end. e.g. The gravitational force exerted by an object depends on its\n",
        "        return question_str + \" \" + BLANK_STR\n",
        "    else:\n",
        "        # If all else fails, assume \"this ?\" indicates the blank. Used in Turk-authored questions\n",
        "        # e.g. Virtually every task performed by living organisms requires this?\n",
        "        return re.sub(r\" this[ \\?]\", \" ___ \", question_str)\n",
        "\n",
        "\n",
        "# Create the output json dictionary from the input json, premise and hypothesis statement\n",
        "def create_output_dict(input_json: dict, statement: str, label: bool, ans_pos: bool, pos=None) -> dict:\n",
        "    if \"statements\" not in input_json:\n",
        "        input_json[\"statements\"] = []\n",
        "    if not ans_pos:\n",
        "        input_json[\"statements\"].append({\"label\": label, \"statement\": statement})\n",
        "    else:\n",
        "        input_json[\"statements\"].append({\"label\": label, \"statement\": statement, \"ans_pos\": pos})\n",
        "    return input_json\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     if len(sys.argv) < 3:\n",
        "#         raise ValueError(\"Provide at least two arguments: \"\n",
        "#                          \"json file with hits, output file name\")\n",
        "#     convert_to_entailment(sys.argv[1], sys.argv[2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEkPdryQz2Bp"
      },
      "source": [
        "###from utils.convert_obqa import convert_to_obqa_statement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn_0mGfaz25X"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "__all__ = ['convert_to_obqa_statement']\n",
        "\n",
        "# String used to indicate a blank\n",
        "BLANK_STR = \"___\"\n",
        "\n",
        "\n",
        "def convert_to_obqa_statement(qa_file: str, output_file1: str, output_file2: str):\n",
        "    print(f'converting {qa_file} to entailment dataset...')\n",
        "    nrow = sum(1 for _ in open(qa_file, 'r'))\n",
        "    with open(output_file1, 'w') as output_handle1, open(output_file2, 'w') as output_handle2, open(qa_file, 'r') as qa_handle:\n",
        "        # print(\"Writing to {} from {}\".format(output_file, qa_file))\n",
        "        for line in tqdm(qa_handle, total=nrow):\n",
        "            json_line = json.loads(line)\n",
        "            output_dict = convert_qajson_to_entailment(json_line)\n",
        "            output_handle1.write(json.dumps(output_dict))\n",
        "            output_handle1.write(\"\\n\")\n",
        "            output_handle2.write(json.dumps(output_dict))\n",
        "            output_handle2.write(\"\\n\")\n",
        "    print(f'converted statements saved to {output_file1}, {output_file2}')\n",
        "    print()\n",
        "\n",
        "\n",
        "# Convert the QA file json to output dictionary containing premise and hypothesis\n",
        "def convert_obqa_convert_qajson_to_entailment(qa_json: dict):\n",
        "    question_text = qa_json[\"question\"][\"stem\"]\n",
        "    choices = qa_json[\"question\"][\"choices\"]\n",
        "    for choice in choices:\n",
        "        choice_text = choice[\"text\"]\n",
        "        statement = question_text + ' ' + choice_text\n",
        "        create_output_dict(qa_json, statement, choice[\"label\"] == qa_json.get(\"answerKey\", \"A\"))\n",
        "\n",
        "    return qa_json\n",
        "\n",
        "\n",
        "# Create the output json dictionary from the input json, premise and hypothesis statement\n",
        "def convert_obqa_create_output_dict(input_json: dict, statement: str, label: bool) -> dict:\n",
        "    if \"statements\" not in input_json:\n",
        "        input_json[\"statements\"] = []\n",
        "    input_json[\"statements\"].append({\"label\": label, \"statement\": statement})\n",
        "    return input_json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzWaS2419YSv"
      },
      "source": [
        "###from utils.conceptnet import extract_english, construct_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIZpDCQiPwpr"
      },
      "source": [
        "from .utils import check_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2NEfnz_PwaS"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "\n",
        "# def bool_flag(v):\n",
        "#     if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "#         return True\n",
        "#     elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "#         return False\n",
        "#     else:\n",
        "#         raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "\n",
        "# def check_path(path):\n",
        "#     d = os.path.dirname(path)\n",
        "#     if not os.path.exists(d):\n",
        "#         os.makedirs(d)\n",
        "\n",
        "\n",
        "def check_file(file):\n",
        "    return os.path.isfile(file)\n",
        "\n",
        "\n",
        "# def export_config(config, path):\n",
        "#     param_dict = dict(vars(config))\n",
        "#     check_path(path)\n",
        "#     with open(path, 'w') as fout:\n",
        "#         json.dump(param_dict, fout, indent=4)\n",
        "\n",
        "\n",
        "# def freeze_net(module):\n",
        "#     for p in module.parameters():\n",
        "#         p.requires_grad = False\n",
        "\n",
        "\n",
        "# def unfreeze_net(module):\n",
        "#     for p in module.parameters():\n",
        "#         p.requires_grad = True\n",
        "\n",
        "\n",
        "# def test_data_loader_ms_per_batch(data_loader, max_steps=10000):\n",
        "#     start = time.time()\n",
        "#     n_batch = sum(1 for batch, _ in zip(data_loader, range(max_steps)))\n",
        "#     return (time.time() - start) * 1000 / n_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNcDd8Qv2AkA"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from networkx.utils import open_file\n",
        "\n",
        "try:\n",
        "    import cPickle as pickle\n",
        "except ImportError:\n",
        "    import pickle\n",
        "\n",
        "\n",
        "@open_file(1, mode='wb')\n",
        "def write_gpickle(G, path, protocol=pickle.HIGHEST_PROTOCOL):\n",
        "    \"\"\"Write graph in Python pickle format.\n",
        "\n",
        "    Pickles are a serialized byte stream of a Python object [1]_.\n",
        "    This format will preserve Python objects used as nodes or edges.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    G : graph\n",
        "       A NetworkX graph\n",
        "\n",
        "    path : file or string\n",
        "       File or filename to write.\n",
        "       Filenames ending in .gz or .bz2 will be compressed.\n",
        "\n",
        "    protocol : integer\n",
        "        Pickling protocol to use. Default value: ``pickle.HIGHEST_PROTOCOL``.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> G = nx.path_graph(4)\n",
        "    >>> nx.write_gpickle(G, \"test.gpickle\")\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] https://docs.python.org/2/library/pickle.html\n",
        "    \"\"\"\n",
        "    pickle.dump(G, path, protocol)\n",
        "\n",
        "\n",
        "@open_file(0, mode='rb')\n",
        "def read_gpickle(path):\n",
        "    \"\"\"Read graph object in Python pickle format.\n",
        "\n",
        "    Pickles are a serialized byte stream of a Python object [1]_.\n",
        "    This format will preserve Python objects used as nodes or edges.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : file or string\n",
        "       File or filename to write.\n",
        "       Filenames ending in .gz or .bz2 will be uncompressed.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    G : graph\n",
        "       A NetworkX graph\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> G = nx.path_graph(4)\n",
        "    >>> nx.write_gpickle(G, \"test.gpickle\")\n",
        "    >>> G = nx.read_gpickle(\"test.gpickle\")\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] https://docs.python.org/2/library/pickle.html\n",
        "    \"\"\"\n",
        "    return pickle.load(path)\n",
        "\n",
        "# fixture for nose tests\n",
        "\n",
        "\n",
        "def teardown_module(module):\n",
        "    import os\n",
        "    os.unlink('test.gpickle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFtDzf989aqN"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import nltk\n",
        "import json\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import sys\n",
        "import codecs\n",
        "\n",
        "\n",
        "# try:\n",
        "#     from .utils import check_file\n",
        "# except ImportError:\n",
        "#     from utils import check_file\n",
        "\n",
        "__all__ = ['extract_english', 'construct_graph', 'merged_relations']\n",
        "\n",
        "relation_groups = [\n",
        "    'atlocation/locatednear',\n",
        "    'capableof',\n",
        "    'causes/causesdesire/*motivatedbygoal',\n",
        "    'createdby',\n",
        "    'desires',\n",
        "    'antonym/distinctfrom',\n",
        "    'hascontext',\n",
        "    'hasproperty',\n",
        "    'hassubevent/hasfirstsubevent/haslastsubevent/hasprerequisite/entails/mannerof',\n",
        "    'isa/instanceof/definedas',\n",
        "    'madeof',\n",
        "    'notcapableof',\n",
        "    'notdesires',\n",
        "    'partof/*hasa',\n",
        "    'relatedto/similarto/synonym',\n",
        "    'usedfor',\n",
        "    'receivesaction',\n",
        "]\n",
        "\n",
        "merged_relations = [\n",
        "    'antonym',\n",
        "    'atlocation',\n",
        "    'capableof',\n",
        "    'causes',\n",
        "    'createdby',\n",
        "    'isa',\n",
        "    'desires',\n",
        "    'hassubevent',\n",
        "    'partof',\n",
        "    'hascontext',\n",
        "    'hasproperty',\n",
        "    'madeof',\n",
        "    'notcapableof',\n",
        "    'notdesires',\n",
        "    'receivesaction',\n",
        "    'relatedto',\n",
        "    'usedfor',\n",
        "]\n",
        "\n",
        "relation_text = [\n",
        "    'is the antonym of',\n",
        "    'is at location of',\n",
        "    'is capable of',\n",
        "    'causes',\n",
        "    'is created by',\n",
        "    'is a kind of',\n",
        "    'desires',\n",
        "    'has subevent',\n",
        "    'is part of',\n",
        "    'has context',\n",
        "    'has property',\n",
        "    'is made of',\n",
        "    'is not capable of',\n",
        "    'does not desires',\n",
        "    'is',\n",
        "    'is related to',\n",
        "    'is used for',\n",
        "]\n",
        "\n",
        "\n",
        "def load_merge_relation():\n",
        "    relation_mapping = dict()\n",
        "    for line in relation_groups:\n",
        "        ls = line.strip().split('/')\n",
        "        rel = ls[0]\n",
        "        for l in ls:\n",
        "            if l.startswith(\"*\"):\n",
        "                relation_mapping[l[1:]] = \"*\" + rel\n",
        "            else:\n",
        "                relation_mapping[l] = rel\n",
        "    return relation_mapping\n",
        "\n",
        "\n",
        "def del_pos(s):\n",
        "    \"\"\"\n",
        "    Deletes part-of-speech encoding from an entity string, if present.\n",
        "    :param s: Entity string.\n",
        "    :return: Entity string with part-of-speech encoding removed.\n",
        "    \"\"\"\n",
        "    if s.endswith(\"/n\") or s.endswith(\"/a\") or s.endswith(\"/v\") or s.endswith(\"/r\"):\n",
        "        s = s[:-2]\n",
        "    return s\n",
        "\n",
        "\n",
        "def extract_english(conceptnet_path, output_csv_path, output_vocab_path):\n",
        "    \"\"\"\n",
        "    Reads original conceptnet csv file and extracts all English relations (head and tail are both English entities) into\n",
        "    a new file, with the following format for each line: <relation> <head> <tail> <weight>.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    print('extracting English concepts and relations from ConceptNet...')\n",
        "    relation_mapping = load_merge_relation()\n",
        "    num_lines = sum(1 for line in open(conceptnet_path, 'r', encoding='utf-8'))\n",
        "    cpnet_vocab = []\n",
        "    concepts_seen = set()\n",
        "    with open(conceptnet_path, 'r', encoding=\"utf8\") as fin, \\\n",
        "            open(output_csv_path, 'w', encoding=\"utf8\") as fout:\n",
        "        for line in tqdm(fin, total=num_lines):\n",
        "            toks = line.strip().split('\\t')\n",
        "            if toks[2].startswith('/c/en/') and toks[3].startswith('/c/en/'):\n",
        "                \"\"\"\n",
        "                Some preprocessing:\n",
        "                    - Remove part-of-speech encoding.\n",
        "                    - Split(\"/\")[-1] to trim the \"/c/en/\" and just get the entity name, convert all to\n",
        "                    - Lowercase for uniformity.\n",
        "                \"\"\"\n",
        "                rel = toks[1].split(\"/\")[-1].lower()\n",
        "                head = del_pos(toks[2]).split(\"/\")[-1].lower()\n",
        "                tail = del_pos(toks[3]).split(\"/\")[-1].lower()\n",
        "\n",
        "                if not head.replace(\"_\", \"\").replace(\"-\", \"\").isalpha():\n",
        "                    continue\n",
        "                if not tail.replace(\"_\", \"\").replace(\"-\", \"\").isalpha():\n",
        "                    continue\n",
        "                if rel not in relation_mapping:\n",
        "                    continue\n",
        "\n",
        "                rel = relation_mapping[rel]\n",
        "                if rel.startswith(\"*\"):\n",
        "                    head, tail, rel = tail, head, rel[1:]\n",
        "\n",
        "                data = json.loads(toks[4])\n",
        "\n",
        "                fout.write('\\t'.join([rel, head, tail, str(data[\"weight\"])]) + '\\n')\n",
        "\n",
        "                for w in [head, tail]:\n",
        "                    if w not in concepts_seen:\n",
        "                        concepts_seen.add(w)\n",
        "                        cpnet_vocab.append(w)\n",
        "\n",
        "    with codecs.open(output_vocab_path, 'w', \"utf-8\") as fout:\n",
        "        for word in cpnet_vocab:\n",
        "            fout.write(word+\"\\n\")\n",
        "\n",
        "    print(f'extracted ConceptNet csv file saved to {output_csv_path}')\n",
        "    print(f'extracted concept vocabulary saved to {output_vocab_path}')\n",
        "    print()\n",
        "\n",
        "\n",
        "def construct_graph(cpnet_csv_path, cpnet_vocab_path, output_path, prune=True):\n",
        "    print('generating ConceptNet graph file...')\n",
        "\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
        "    nltk_stopwords += [\"like\", \"gone\", \"did\", \"going\", \"would\", \"could\",\n",
        "                       \"get\", \"in\", \"up\", \"may\", \"wanter\"]  # issue: mismatch with the stop words in grouding.py\n",
        "\n",
        "    blacklist = set([\"uk\", \"us\", \"take\", \"make\", \"object\", \"person\", \"people\"])  # issue: mismatch with the blacklist in grouding.py\n",
        "\n",
        "    concept2id = {}\n",
        "    id2concept = {}\n",
        "    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n",
        "        id2concept = [w.strip() for w in fin]\n",
        "    concept2id = {w: i for i, w in enumerate(id2concept)}\n",
        "\n",
        "    id2relation = merged_relations\n",
        "    relation2id = {r: i for i, r in enumerate(id2relation)}\n",
        "\n",
        "    graph = nx.MultiDiGraph()\n",
        "    nrow = sum(1 for _ in open(cpnet_csv_path, 'r', encoding='utf-8'))\n",
        "    with open(cpnet_csv_path, \"r\", encoding=\"utf8\") as fin:\n",
        "\n",
        "        def not_save(cpt):\n",
        "            if cpt in blacklist:\n",
        "                return True\n",
        "            '''originally phrases like \"branch out\" would not be kept in the graph'''\n",
        "            # for t in cpt.split(\"_\"):\n",
        "            #     if t in nltk_stopwords:\n",
        "            #         return True\n",
        "            return False\n",
        "\n",
        "        attrs = set()\n",
        "\n",
        "        for line in tqdm(fin, total=nrow):\n",
        "            ls = line.strip().split('\\t')\n",
        "            rel = relation2id[ls[0]]\n",
        "            subj = concept2id[ls[1]]\n",
        "            obj = concept2id[ls[2]]\n",
        "            weight = float(ls[3])\n",
        "            if prune and (not_save(ls[1]) or not_save(ls[2]) or id2relation[rel] == \"hascontext\"):\n",
        "                continue\n",
        "            # if id2relation[rel] == \"relatedto\" or id2relation[rel] == \"antonym\":\n",
        "            # weight -= 0.3\n",
        "            # continue\n",
        "            if subj == obj:  # delete loops\n",
        "                continue\n",
        "            # weight = 1 + float(math.exp(1 - weight))  # issue: ???\n",
        "\n",
        "            if (subj, obj, rel) not in attrs:\n",
        "                graph.add_edge(subj, obj, rel=rel, weight=weight)\n",
        "                attrs.add((subj, obj, rel))\n",
        "                graph.add_edge(obj, subj, rel=rel + len(relation2id), weight=weight)\n",
        "                attrs.add((obj, subj, rel + len(relation2id)))\n",
        "\n",
        "    # nx.write_gpickle(graph, output_path)\n",
        "    write_gpickle(graph, output_path)\n",
        "    print(f\"graph file saved to {output_path}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "def glove_init(input, output, concept_file):\n",
        "    embeddings_file = output + '.npy'\n",
        "    vocabulary_file = output.split('.')[0] + '.vocab.txt'\n",
        "    output_dir = '/'.join(output.split('/')[:-1])\n",
        "    output_prefix = output.split('/')[-1]\n",
        "\n",
        "    words = []\n",
        "    vectors = []\n",
        "    vocab_exist = check_file(vocabulary_file)\n",
        "    print(\"loading embedding\")\n",
        "    with open(input, 'rb') as f:\n",
        "        for line in f:\n",
        "            fields = line.split()\n",
        "            if len(fields) <= 2:\n",
        "                continue\n",
        "            if not vocab_exist:\n",
        "                word = fields[0].decode('utf-8')\n",
        "                words.append(word)\n",
        "            vector = np.fromiter((float(x) for x in fields[1:]), dtype=np.float)\n",
        "\n",
        "            vectors.append(vector)\n",
        "        dim = vector.shape[0]\n",
        "    print(\"converting\")\n",
        "    matrix = np.array(vectors, dtype=\"float32\")\n",
        "    print(\"writing\")\n",
        "    np.save(embeddings_file, matrix)\n",
        "    text = '\\n'.join(words)\n",
        "    if not vocab_exist:\n",
        "        with open(vocabulary_file, 'wb') as f:\n",
        "            f.write(text.encode('utf-8'))\n",
        "\n",
        "    def load_glove_from_npy(glove_vec_path, glove_vocab_path):\n",
        "        vectors = np.load(glove_vec_path)\n",
        "        with open(glove_vocab_path, \"r\", encoding=\"utf8\") as f:\n",
        "            vocab = [l.strip() for l in f.readlines()]\n",
        "\n",
        "        assert (len(vectors) == len(vocab))\n",
        "\n",
        "        glove_embeddings = {}\n",
        "        for i in range(0, len(vectors)):\n",
        "            glove_embeddings[vocab[i]] = vectors[i]\n",
        "        print(\"Read \" + str(len(glove_embeddings)) + \" glove vectors.\")\n",
        "        return glove_embeddings\n",
        "\n",
        "    def weighted_average(avg, new, n):\n",
        "        # TODO: maybe a better name for this function?\n",
        "        return ((n - 1) / n) * avg + (new / n)\n",
        "\n",
        "    def max_pooling(old, new):\n",
        "        # TODO: maybe a better name for this function?\n",
        "        return np.maximum(old, new)\n",
        "\n",
        "    def write_embeddings_npy(embeddings, embeddings_cnt, npy_path, vocab_path):\n",
        "        words = []\n",
        "        vectors = []\n",
        "        for key, vec in embeddings.items():\n",
        "            words.append(key)\n",
        "            vectors.append(vec)\n",
        "\n",
        "        matrix = np.array(vectors, dtype=\"float32\")\n",
        "        print(matrix.shape)\n",
        "\n",
        "        print(\"Writing embeddings matrix to \" + npy_path, flush=True)\n",
        "        np.save(npy_path, matrix)\n",
        "        print(\"Finished writing embeddings matrix to \" + npy_path, flush=True)\n",
        "\n",
        "        if not check_file(vocab_path):\n",
        "            print(\"Writing vocab file to \" + vocab_path, flush=True)\n",
        "            to_write = [\"\\t\".join([w, str(embeddings_cnt[w])]) for w in words]\n",
        "            with open(vocab_path, \"w\", encoding=\"utf8\") as f:\n",
        "                f.write(\"\\n\".join(to_write))\n",
        "            print(\"Finished writing vocab file to \" + vocab_path, flush=True)\n",
        "\n",
        "    def create_embeddings_glove(pooling=\"max\", dim=100):\n",
        "        print(\"Pooling: \" + pooling)\n",
        "\n",
        "        with open(concept_file, \"r\", encoding=\"utf8\") as f:\n",
        "            triple_str_json = json.load(f)\n",
        "        print(\"Loaded \" + str(len(triple_str_json)) + \" triple strings.\")\n",
        "\n",
        "        glove_embeddings = load_glove_from_npy(embeddings_file, vocabulary_file)\n",
        "        print(\"Loaded glove.\", flush=True)\n",
        "\n",
        "        concept_embeddings = {}\n",
        "        concept_embeddings_cnt = {}\n",
        "        rel_embeddings = {}\n",
        "        rel_embeddings_cnt = {}\n",
        "\n",
        "        for i in tqdm(range(len(triple_str_json))):\n",
        "            data = triple_str_json[i]\n",
        "\n",
        "            words = data[\"string\"].strip().split(\" \")\n",
        "\n",
        "            rel = data[\"rel\"]\n",
        "            subj_start = data[\"subj_start\"]\n",
        "            subj_end = data[\"subj_end\"]\n",
        "            obj_start = data[\"obj_start\"]\n",
        "            obj_end = data[\"obj_end\"]\n",
        "\n",
        "            subj_words = words[subj_start:subj_end]\n",
        "            obj_words = words[obj_start:obj_end]\n",
        "\n",
        "            subj = \" \".join(subj_words)\n",
        "            obj = \" \".join(obj_words)\n",
        "\n",
        "            # counting the frequency (only used for the avg pooling)\n",
        "            if subj not in concept_embeddings:\n",
        "                concept_embeddings[subj] = np.zeros((dim,))\n",
        "                concept_embeddings_cnt[subj] = 0\n",
        "            concept_embeddings_cnt[subj] += 1\n",
        "\n",
        "            if obj not in concept_embeddings:\n",
        "                concept_embeddings[obj] = np.zeros((dim,))\n",
        "                concept_embeddings_cnt[obj] = 0\n",
        "            concept_embeddings_cnt[obj] += 1\n",
        "\n",
        "            if rel not in rel_embeddings:\n",
        "                rel_embeddings[rel] = np.zeros((dim,))\n",
        "                rel_embeddings_cnt[rel] = 0\n",
        "            rel_embeddings_cnt[rel] += 1\n",
        "\n",
        "            if pooling == \"avg\":\n",
        "                subj_encoding_sum = sum([glove_embeddings.get(word, np.zeros((dim,))) for word in subj])\n",
        "                obj_encoding_sum = sum([glove_embeddings.get(word, np.zeros((dim,))) for word in obj])\n",
        "\n",
        "                if rel in [\"relatedto\", \"antonym\"]:\n",
        "                    # Symmetric relation.\n",
        "                    rel_encoding_sum = sum([glove_embeddings.get(word, np.zeros((dim,))) for word in words]) - subj_encoding_sum - obj_encoding_sum\n",
        "                else:\n",
        "                    # Asymmetrical relation.\n",
        "                    rel_encoding_sum = obj_encoding_sum - subj_encoding_sum\n",
        "\n",
        "                subj_len = subj_end - subj_start\n",
        "                obj_len = obj_end - obj_start\n",
        "\n",
        "                subj_encoding = subj_encoding_sum / subj_len\n",
        "                obj_encoding = obj_encoding_sum / obj_len\n",
        "                rel_encoding = rel_encoding_sum / (len(words) - subj_len - obj_len)\n",
        "\n",
        "                concept_embeddings[subj] = subj_encoding\n",
        "                concept_embeddings[obj] = obj_encoding\n",
        "                rel_embeddings[rel] = weighted_average(rel_embeddings[rel], rel_encoding, rel_embeddings_cnt[rel])\n",
        "\n",
        "            elif pooling == \"max\":\n",
        "                subj_encoding = np.amax([glove_embeddings.get(word, np.zeros((dim,))) for word in subj_words], axis=0)\n",
        "                obj_encoding = np.amax([glove_embeddings.get(word, np.zeros((dim,))) for word in obj_words], axis=0)\n",
        "\n",
        "                mask_rel = []\n",
        "                for j in range(len(words)):\n",
        "                    if subj_start <= j < subj_end or obj_start <= j < obj_end:\n",
        "                        continue\n",
        "                    mask_rel.append(j)\n",
        "                rel_vecs = [glove_embeddings.get(words[i], np.zeros((dim,))) for i in mask_rel]\n",
        "                rel_encoding = np.amax(rel_vecs, axis=0)\n",
        "\n",
        "                # here it is actually avg over max for relation\n",
        "                concept_embeddings[subj] = max_pooling(concept_embeddings[subj], subj_encoding)\n",
        "                concept_embeddings[obj] = max_pooling(concept_embeddings[obj], obj_encoding)\n",
        "                rel_embeddings[rel] = weighted_average(rel_embeddings[rel], rel_encoding, rel_embeddings_cnt[rel])\n",
        "\n",
        "        print(str(len(concept_embeddings)) + \" concept embeddings\")\n",
        "        print(str(len(rel_embeddings)) + \" relation embeddings\")\n",
        "\n",
        "        write_embeddings_npy(concept_embeddings, concept_embeddings_cnt, f'{output_dir}/concept.{output_prefix}.{pooling}.npy',\n",
        "                             f'{output_dir}/concept.glove.{pooling}.txt')\n",
        "        write_embeddings_npy(rel_embeddings, rel_embeddings_cnt, f'{output_dir}/relation.{output_prefix}.{pooling}.npy',\n",
        "                             f'{output_dir}/relation.glove.{pooling}.txt')\n",
        "\n",
        "    create_embeddings_glove(dim=dim)\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     glove_init(\"../data/glove/glove.6B.200d.txt\", \"../data/glove/glove.200d\", '../data/glove/tp_str_corpus.json')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvkQQajd9jE4"
      },
      "source": [
        "###from utils.grounding import create_matcher_patterns, ground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J9kobeg9j0Q"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import Pool\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "import json\n",
        "import string\n",
        "\n",
        "\n",
        "__all__ = ['create_matcher_patterns', 'ground']\n",
        "\n",
        "\n",
        "# the lemma of it/them/mine/.. is -PRON-\n",
        "\n",
        "blacklist = set([\"-PRON-\", \"actually\", \"likely\", \"possibly\", \"want\",\n",
        "                 \"make\", \"my\", \"someone\", \"sometimes_people\", \"sometimes\", \"would\", \"want_to\",\n",
        "                 \"one\", \"something\", \"sometimes\", \"everybody\", \"somebody\", \"could\", \"could_be\"\n",
        "                 ])\n",
        "\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# CHUNK_SIZE = 1\n",
        "\n",
        "CPNET_VOCAB = None\n",
        "PATTERN_PATH = None\n",
        "nlp = None\n",
        "matcher = None\n",
        "\n",
        "\n",
        "def load_cpnet_vocab(cpnet_vocab_path):\n",
        "    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n",
        "        cpnet_vocab = [l.strip() for l in fin]\n",
        "    cpnet_vocab = [c.replace(\"_\", \" \") for c in cpnet_vocab]\n",
        "    return cpnet_vocab\n",
        "\n",
        "\n",
        "def create_pattern(nlp, doc, debug=False):\n",
        "    pronoun_list = set([\"my\", \"you\", \"it\", \"its\", \"your\", \"i\", \"he\", \"she\", \"his\", \"her\", \"they\", \"them\", \"their\", \"our\", \"we\"])\n",
        "    # Filtering concepts consisting of all stop words and longer than four words.\n",
        "    if len(doc) >= 5 or doc[0].text in pronoun_list or doc[-1].text in pronoun_list or \\\n",
        "            all([(token.text in nltk_stopwords or token.lemma_ in nltk_stopwords or token.lemma_ in blacklist) for token in doc]):\n",
        "        if debug:\n",
        "            return False, doc.text\n",
        "        return None  # ignore this concept as pattern\n",
        "\n",
        "    pattern = []\n",
        "    for token in doc:  # a doc is a concept\n",
        "        pattern.append({\"LEMMA\": token.lemma_})\n",
        "    if debug:\n",
        "        return True, doc.text\n",
        "    return pattern\n",
        "\n",
        "\n",
        "def create_matcher_patterns(cpnet_vocab_path, output_path, debug=False):\n",
        "    cpnet_vocab = load_cpnet_vocab(cpnet_vocab_path)\n",
        "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner', 'textcat'])\n",
        "    docs = nlp.pipe(cpnet_vocab)\n",
        "    all_patterns = {}\n",
        "\n",
        "    if debug:\n",
        "        f = open(\"filtered_concept.txt\", \"w\")\n",
        "\n",
        "    for doc in tqdm(docs, total=len(cpnet_vocab)):\n",
        "\n",
        "        pattern = create_pattern(nlp, doc, debug)\n",
        "        if debug:\n",
        "            if not pattern[0]:\n",
        "                f.write(pattern[1] + '\\n')\n",
        "\n",
        "        if pattern is None:\n",
        "            continue\n",
        "        all_patterns[\"_\".join(doc.text.split(\" \"))] = pattern\n",
        "\n",
        "    print(\"Created \" + str(len(all_patterns)) + \" patterns.\")\n",
        "    with open(output_path, \"w\", encoding=\"utf8\") as fout:\n",
        "        json.dump(all_patterns, fout)\n",
        "    if debug:\n",
        "        f.close()\n",
        "\n",
        "\n",
        "def lemmatize(nlp, concept):\n",
        "\n",
        "    doc = nlp(concept.replace(\"_\", \" \"))\n",
        "    lcs = set()\n",
        "    # for i in range(len(doc)):\n",
        "    #     lemmas = []\n",
        "    #     for j, token in enumerate(doc):\n",
        "    #         if j == i:\n",
        "    #             lemmas.append(token.lemma_)\n",
        "    #         else:\n",
        "    #             lemmas.append(token.text)\n",
        "    #     lc = \"_\".join(lemmas)\n",
        "    #     lcs.add(lc)\n",
        "    lcs.add(\"_\".join([token.lemma_ for token in doc]))  # all lemma\n",
        "    return lcs\n",
        "\n",
        "\n",
        "def load_matcher(nlp, pattern_path):\n",
        "    with open(pattern_path, \"r\", encoding=\"utf8\") as fin:\n",
        "        all_patterns = json.load(fin)\n",
        "\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    for concept, pattern in all_patterns.items():\n",
        "        # matcher.add(concept, None, pattern)\n",
        "        matcher.add(concept, [pattern])\n",
        "    return matcher\n",
        "\n",
        "\n",
        "def ground_qa_pair(qa_pair):\n",
        "    global nlp, matcher\n",
        "    if nlp is None or matcher is None:\n",
        "        nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'textcat'])\n",
        "        # nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "        nlp.add_pipe('sentencizer')\n",
        "        matcher = load_matcher(nlp, PATTERN_PATH)\n",
        "\n",
        "    s, a = qa_pair\n",
        "    all_concepts = ground_mentioned_concepts(nlp, matcher, s, a)\n",
        "    answer_concepts = ground_mentioned_concepts(nlp, matcher, a)\n",
        "    question_concepts = all_concepts - answer_concepts\n",
        "    if len(question_concepts) == 0:\n",
        "        question_concepts = hard_ground(nlp, s, CPNET_VOCAB)  # not very possible\n",
        "\n",
        "    if len(answer_concepts) == 0:\n",
        "        answer_concepts = hard_ground(nlp, a, CPNET_VOCAB)  # some case\n",
        "\n",
        "    # question_concepts = question_concepts -  answer_concepts\n",
        "    question_concepts = sorted(list(question_concepts))\n",
        "    answer_concepts = sorted(list(answer_concepts))\n",
        "    return {\"sent\": s, \"ans\": a, \"qc\": question_concepts, \"ac\": answer_concepts}\n",
        "\n",
        "\n",
        "def ground_mentioned_concepts(nlp, matcher, s, ans=None):\n",
        "\n",
        "    s = s.lower()\n",
        "    doc = nlp(s)\n",
        "    matches = matcher(doc)\n",
        "\n",
        "    mentioned_concepts = set()\n",
        "    span_to_concepts = {}\n",
        "\n",
        "    if ans is not None:\n",
        "        ans_matcher = Matcher(nlp.vocab)\n",
        "        ans_words = nlp(ans)\n",
        "        # print(ans_words)\n",
        "        ans_matcher.add(ans, [[{'TEXT': token.text.lower()}] for token in ans_words])\n",
        "\n",
        "        ans_match = ans_matcher(doc)\n",
        "        ans_mentions = set()\n",
        "        for _, ans_start, ans_end in ans_match:\n",
        "            ans_mentions.add((ans_start, ans_end))\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        if ans is not None:\n",
        "            if (start, end) in ans_mentions:\n",
        "                continue\n",
        "\n",
        "        span = doc[start:end].text  # the matched span\n",
        "\n",
        "        # a word that appears in answer is not considered as a mention in the question\n",
        "        # if len(set(span.split(\" \")).intersection(set(ans.split(\" \")))) > 0:\n",
        "        #     continue\n",
        "        original_concept = nlp.vocab.strings[match_id]\n",
        "        original_concept_set = set()\n",
        "        original_concept_set.add(original_concept)\n",
        "\n",
        "        # print(\"span\", span)\n",
        "        # print(\"concept\", original_concept)\n",
        "        # print(\"Matched '\" + span + \"' to the rule '\" + string_id)\n",
        "\n",
        "        # why do you lemmatize a mention whose len == 1?\n",
        "\n",
        "        if len(original_concept.split(\"_\")) == 1:\n",
        "            # tag = doc[start].tag_\n",
        "            # if tag in ['VBN', 'VBG']:\n",
        "\n",
        "            original_concept_set.update(lemmatize(nlp, nlp.vocab.strings[match_id]))\n",
        "\n",
        "        if span not in span_to_concepts:\n",
        "            span_to_concepts[span] = set()\n",
        "\n",
        "        span_to_concepts[span].update(original_concept_set)\n",
        "\n",
        "    for span, concepts in span_to_concepts.items():\n",
        "        concepts_sorted = list(concepts)\n",
        "        # print(\"span:\")\n",
        "        # print(span)\n",
        "        # print(\"concept_sorted:\")\n",
        "        # print(concepts_sorted)\n",
        "        concepts_sorted.sort(key=len)\n",
        "\n",
        "        # mentioned_concepts.update(concepts_sorted[0:2])\n",
        "\n",
        "        shortest = concepts_sorted[0:3]\n",
        "\n",
        "        for c in shortest:\n",
        "            if c in blacklist:\n",
        "                continue\n",
        "\n",
        "            # a set with one string like: set(\"like_apples\")\n",
        "            lcs = lemmatize(nlp, c)\n",
        "            intersect = lcs.intersection(shortest)\n",
        "            if len(intersect) > 0:\n",
        "                mentioned_concepts.add(list(intersect)[0])\n",
        "            else:\n",
        "                mentioned_concepts.add(c)\n",
        "\n",
        "        # if a mention exactly matches with a concept\n",
        "\n",
        "        exact_match = set([concept for concept in concepts_sorted if concept.replace(\"_\", \" \").lower() == span.lower()])\n",
        "        # print(\"exact match:\")\n",
        "        # print(exact_match)\n",
        "        assert len(exact_match) < 2\n",
        "        mentioned_concepts.update(exact_match)\n",
        "\n",
        "    return mentioned_concepts\n",
        "\n",
        "\n",
        "def hard_ground(nlp, sent, cpnet_vocab):\n",
        "    sent = sent.lower()\n",
        "    doc = nlp(sent)\n",
        "    res = set()\n",
        "    for t in doc:\n",
        "        if t.lemma_ in cpnet_vocab:\n",
        "            res.add(t.lemma_)\n",
        "    sent = \" \".join([t.text for t in doc])\n",
        "    if sent in cpnet_vocab:\n",
        "        res.add(sent)\n",
        "    try:\n",
        "        assert len(res) > 0\n",
        "    except Exception:\n",
        "        print(f\"for {sent}, concept not found in hard grounding.\")\n",
        "    return res\n",
        "\n",
        "\n",
        "def match_mentioned_concepts(sents, answers, num_processes):\n",
        "    res = []\n",
        "    with Pool(num_processes) as p:\n",
        "        res = list(tqdm(p.imap(ground_qa_pair, zip(sents, answers)), total=len(sents)))\n",
        "    return res\n",
        "\n",
        "\n",
        "# To-do: examine prune\n",
        "def prune(data, cpnet_vocab_path):\n",
        "    # reload cpnet_vocab\n",
        "    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n",
        "        cpnet_vocab = [l.strip() for l in fin]\n",
        "\n",
        "    prune_data = []\n",
        "    for item in tqdm(data):\n",
        "        qc = item[\"qc\"]\n",
        "        prune_qc = []\n",
        "        for c in qc:\n",
        "            if c[-2:] == \"er\" and c[:-2] in qc:\n",
        "                continue\n",
        "            if c[-1:] == \"e\" and c[:-1] in qc:\n",
        "                continue\n",
        "            have_stop = False\n",
        "            # remove all concepts having stopwords, including hard-grounded ones\n",
        "            for t in c.split(\"_\"):\n",
        "                if t in nltk_stopwords:\n",
        "                    have_stop = True\n",
        "            if not have_stop and c in cpnet_vocab:\n",
        "                prune_qc.append(c)\n",
        "\n",
        "        ac = item[\"ac\"]\n",
        "        prune_ac = []\n",
        "        for c in ac:\n",
        "            if c[-2:] == \"er\" and c[:-2] in ac:\n",
        "                continue\n",
        "            if c[-1:] == \"e\" and c[:-1] in ac:\n",
        "                continue\n",
        "            all_stop = True\n",
        "            for t in c.split(\"_\"):\n",
        "                if t not in nltk_stopwords:\n",
        "                    all_stop = False\n",
        "            if not all_stop and c in cpnet_vocab:\n",
        "                prune_ac.append(c)\n",
        "\n",
        "        try:\n",
        "            assert len(prune_ac) > 0 and len(prune_qc) > 0\n",
        "        except Exception as e:\n",
        "            pass\n",
        "            # print(\"In pruning\")\n",
        "            # print(prune_qc)\n",
        "            # print(prune_ac)\n",
        "            # print(\"original:\")\n",
        "            # print(qc)\n",
        "            # print(ac)\n",
        "            # print()\n",
        "        item[\"qc\"] = prune_qc\n",
        "        item[\"ac\"] = prune_ac\n",
        "\n",
        "        prune_data.append(item)\n",
        "    return prune_data\n",
        "\n",
        "\n",
        "def ground(statement_path, cpnet_vocab_path, pattern_path, output_path, num_processes=1, debug=False):\n",
        "    global PATTERN_PATH, CPNET_VOCAB\n",
        "    if PATTERN_PATH is None:\n",
        "        PATTERN_PATH = pattern_path\n",
        "        CPNET_VOCAB = load_cpnet_vocab(cpnet_vocab_path)\n",
        "\n",
        "    sents = []\n",
        "    answers = []\n",
        "    with open(statement_path, 'r') as fin:\n",
        "        lines = [line for line in fin]\n",
        "\n",
        "    if debug:\n",
        "        lines = lines[192:195]\n",
        "        print(len(lines))\n",
        "    for line in lines:\n",
        "        if line == \"\":\n",
        "            continue\n",
        "        j = json.loads(line)\n",
        "        # {'answerKey': 'B',\n",
        "        #   'id': 'b8c0a4703079cf661d7261a60a1bcbff',\n",
        "        #   'question': {'question_concept': 'magazines',\n",
        "        #                 'choices': [{'label': 'A', 'text': 'doctor'}, {'label': 'B', 'text': 'bookstore'}, {'label': 'C', 'text': 'market'}, {'label': 'D', 'text': 'train station'}, {'label': 'E', 'text': 'mortuary'}],\n",
        "        #                 'stem': 'Where would you find magazines along side many other printed works?'},\n",
        "        #   'statements': [{'label': False, 'statement': 'Doctor would you find magazines along side many other printed works.'}, {'label': True, 'statement': 'Bookstore would you find magazines along side many other printed works.'}, {'label': False, 'statement': 'Market would you find magazines along side many other printed works.'}, {'label': False, 'statement': 'Train station would you find magazines along side many other printed works.'}, {'label': False, 'statement': 'Mortuary would you find magazines along side many other printed works.'}]}\n",
        "\n",
        "        for statement in j[\"statements\"]:\n",
        "            sents.append(statement[\"statement\"])\n",
        "\n",
        "        for answer in j[\"question\"][\"choices\"]:\n",
        "            ans = answer['text']\n",
        "            # ans = \" \".join(answer['text'].split(\"_\"))\n",
        "            try:\n",
        "                assert all([i != \"_\" for i in ans])\n",
        "            except Exception:\n",
        "                print(ans)\n",
        "            answers.append(ans)\n",
        "\n",
        "    res = match_mentioned_concepts(sents, answers, num_processes)\n",
        "    res = prune(res, cpnet_vocab_path)\n",
        "\n",
        "    # check_path(output_path)\n",
        "    with open(output_path, 'w') as fout:\n",
        "        for dic in res:\n",
        "            fout.write(json.dumps(dic) + '\\n')\n",
        "\n",
        "    print(f'grounded concepts saved to {output_path}')\n",
        "    print()\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     create_matcher_patterns(\"../data/cpnet/concept.txt\", \"./matcher_res.txt\", True)\n",
        "\n",
        "    # ground(\"../data/statement/dev.statement.jsonl\", \"../data/cpnet/concept.txt\", \"../data/cpnet/matcher_patterns.json\", \"./ground_res.jsonl\", 10, True)\n",
        "\n",
        "    # s = \"a revolving door is convenient for two direction travel, but it also serves as a security measure at a bank.\"\n",
        "    # a = \"bank\"\n",
        "    # nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'textcat'])\n",
        "    # nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "    # ans_words = nlp(a)\n",
        "    # doc = nlp(s)\n",
        "    # ans_matcher = Matcher(nlp.vocab)\n",
        "    # print([{'TEXT': token.text.lower()} for token in ans_words])\n",
        "    # ans_matcher.add(\"ok\", None, [{'TEXT': token.text.lower()} for token in ans_words])\n",
        "    #\n",
        "    # matches = ans_matcher(doc)\n",
        "    # for a, b, c in matches:\n",
        "    #     print(a, b, c)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPhvEjtb9uUL"
      },
      "source": [
        "###from utils.graph import generate_adj_data_from_grounded_concepts__use_LM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yKitfz5QMuU"
      },
      "source": [
        "math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHZouUV_S-48"
      },
      "outputs": [],
      "source": [
        "concept2id = None\n",
        "id2concept = None\n",
        "relation2id = None\n",
        "id2relation = None\n",
        "\n",
        "cpnet = None\n",
        "cpnet_all = None\n",
        "cpnet_simple = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212,
          "referenced_widgets": [
            "d32b2a401d4e4c0b9496948a027c8fe6",
            "596645eda20f4b91a8323de570854203",
            "f6730ce233fd4b3aa9833c02fa0e86e1",
            "c69e1d273d694ba5a912da20eece5b10",
            "22098da9de01452c9a114eaba2460fa4",
            "403ce0e6f0dd4d1f8f9943fcac101032",
            "942dd3f6fd754b18956f9424be66ce51",
            "a568a5851fba4fe7bd0998b8f7919e9f",
            "7093cabbcbc3455b977c6902e974c949",
            "86221f9c690f4e7089db3db12994cc65",
            "27239faf493841c1994c7ee70eaae5e5",
            "13b189ebc05a425398c90e14290bb2b1",
            "aeb32f54f0464262b77937675b00c95a",
            "75c978ddaf48488e8fccab426aff11ef",
            "fc694e117e8241c6a13d16cf4b9c33f6",
            "92d4d0d7ed45448f91c891c2692eeded",
            "0e02e5d622b140959818e6e23f482e0e",
            "73ced5e57db54217a51c0ec93f2db19d",
            "5c642e70ae7045b7a73527a72ba31e24",
            "66085a2ab1964bc1a0a7e8716c740ae8",
            "a56f44e83d5e4df49533d9d2e8990550",
            "9161e72b7c524b2385206123913153a3",
            "48e421f7f8414bc4b7e8dbd79ad50fe0",
            "d0bc5ba7e16e4818a998137066c1d6ef",
            "97eb08aed9b042f68d73e65e24a00e08",
            "0cda20db7de64c0ca7844afde465d77b",
            "b42932735b6b494f8b27f3cb745333c2",
            "4df4c5cc0a494a57a41c4616c97dc42d",
            "4a5f86ff185c4cfba33ff2998a82d2e3",
            "49b91dfd059645cca58b1b4177991aff",
            "dfaa6cb5d31046d4957c4253d2b61c7c",
            "1c060951707a48b1a4682a5f5445a30f",
            "525d925ac8a84b3587136a96edcada6a",
            "39d16970b4994b42802dff8a739149b0",
            "cca53dec484449b58ec184e205f9808c",
            "df9892c7bf804e1c884eeccece200a78",
            "ee03d39fca184c98b884f49bdf7e7a83",
            "e5b2545485014a6393d06a07fa9988ad",
            "cc6949948cd74909b1d530f48ad94c31",
            "ff057385f27f47d9adf0b5c3cd8adba8",
            "772df8c2cd0447619ced3acdd0046c24",
            "00ea5426180f4abdab48246b35b91b0d",
            "b7ce631d8d8f42a9b950673d21eb503b",
            "37e5d8ad303f42a6b73492ce6226f59d",
            "c929dc3239114c479ecd9ff450092cec",
            "45f084d7edfa4f989aad34a64dd9b2b8",
            "438284f546864d6dbcb55c54a8d97275",
            "7999b7ab4bc54326ae6ffa736e52712b",
            "3d57d8934c914660a6e5973ae97f8bce",
            "aa9a2d6c33b64504bdc0b31f964787e1",
            "452172f204f44b299a4277ee99b4d6a7",
            "3e0e04ea663643998c2bdd9efd2ba4c6",
            "2254211f20c144caa95f4074072981a4",
            "c499589d90fc45619f656fb10a5bf962",
            "fb685baeaf9643309fe48a61c5c06fcc"
          ]
        },
        "id": "7TywLK3w9vIw",
        "outputId": "3316909e-d23e-4dca-a70e-3f360b607d90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading pre-trained LM...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d32b2a401d4e4c0b9496948a027c8fe6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13b189ebc05a425398c90e14290bb2b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48e421f7f8414bc4b7e8dbd79ad50fe0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39d16970b4994b42802dff8a739149b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c929dc3239114c479ecd9ff450092cec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading done\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "import itertools\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "# from .conceptnet import merged_relations\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "import pickle\n",
        "from scipy.sparse import csr_matrix, coo_matrix\n",
        "from multiprocessing import Pool\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "# from .maths import *\n",
        "\n",
        "__all__ = ['generate_graph']\n",
        "\n",
        "\n",
        "def load_resources(cpnet_vocab_path):\n",
        "    global concept2id, id2concept, relation2id, id2relation\n",
        "\n",
        "    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n",
        "        id2concept = [w.strip() for w in fin]\n",
        "    concept2id = {w: i for i, w in enumerate(id2concept)}\n",
        "\n",
        "    id2relation = merged_relations\n",
        "    relation2id = {r: i for i, r in enumerate(id2relation)}\n",
        "\n",
        "\n",
        "def load_cpnet(cpnet_graph_path):\n",
        "    global cpnet, cpnet_simple\n",
        "    # cpnet = nx.read_gpickle(cpnet_graph_path)\n",
        "    cpnet = read_gpickle(cpnet_graph_path)\n",
        "    cpnet_simple = nx.Graph()\n",
        "    for u, v, data in cpnet.edges(data=True):\n",
        "        w = data['weight'] if 'weight' in data else 1.0\n",
        "        if cpnet_simple.has_edge(u, v):\n",
        "            cpnet_simple[u][v]['weight'] += w\n",
        "        else:\n",
        "            cpnet_simple.add_edge(u, v, weight=w)\n",
        "\n",
        "\n",
        "def relational_graph_generation(qcs, acs, paths, rels):\n",
        "    raise NotImplementedError()  # TODO\n",
        "\n",
        "\n",
        "# plain graph generation\n",
        "def plain_graph_generation(qcs, acs, paths, rels):\n",
        "    global cpnet, concept2id, relation2id, id2relation, id2concept, cpnet_simple\n",
        "\n",
        "    graph = nx.Graph()\n",
        "    for p in paths:\n",
        "        for c_index in range(len(p) - 1):\n",
        "            h = p[c_index]\n",
        "            t = p[c_index + 1]\n",
        "            # TODO: the weight can computed by concept embeddings and relation embeddings of TransE\n",
        "            graph.add_edge(h, t, weight=1.0)\n",
        "\n",
        "    for qc1, qc2 in list(itertools.combinations(qcs, 2)):\n",
        "        if cpnet_simple.has_edge(qc1, qc2):\n",
        "            graph.add_edge(qc1, qc2, weight=1.0)\n",
        "\n",
        "    for ac1, ac2 in list(itertools.combinations(acs, 2)):\n",
        "        if cpnet_simple.has_edge(ac1, ac2):\n",
        "            graph.add_edge(ac1, ac2, weight=1.0)\n",
        "\n",
        "    if len(qcs) == 0:\n",
        "        qcs.append(-1)\n",
        "\n",
        "    if len(acs) == 0:\n",
        "        acs.append(-1)\n",
        "\n",
        "    if len(paths) == 0:\n",
        "        for qc in qcs:\n",
        "            for ac in acs:\n",
        "                graph.add_edge(qc, ac, rel=-1, weight=0.1)\n",
        "\n",
        "    g = nx.convert_node_labels_to_integers(graph, label_attribute='cid')  # re-index\n",
        "    return nx.node_link_data(g)\n",
        "\n",
        "\n",
        "def generate_adj_matrix_per_inst(nxg_str):\n",
        "    global id2relation\n",
        "    n_rel = len(id2relation)\n",
        "\n",
        "    nxg = nx.node_link_graph(json.loads(nxg_str))\n",
        "    n_node = len(nxg.nodes)\n",
        "    cids = np.zeros(n_node, dtype=np.int32)\n",
        "    for node_id, node_attr in nxg.nodes(data=True):\n",
        "        cids[node_id] = node_attr['cid']\n",
        "\n",
        "    adj = np.zeros((n_rel, n_node, n_node), dtype=np.uint8)\n",
        "    for s in range(n_node):\n",
        "        for t in range(n_node):\n",
        "            s_c, t_c = cids[s], cids[t]\n",
        "            if cpnet_all.has_edge(s_c, t_c):\n",
        "                for e_attr in cpnet_all[s_c][t_c].values():\n",
        "                    if e_attr['rel'] >= 0 and e_attr['rel'] < n_rel:\n",
        "                        adj[e_attr['rel']][s][t] = 1\n",
        "    cids += 1\n",
        "    adj = coo_matrix(adj.reshape(-1, n_node))\n",
        "    return (adj, cids)\n",
        "\n",
        "\n",
        "def concepts2adj(node_ids):\n",
        "    global id2relation\n",
        "    cids = np.array(node_ids, dtype=np.int32)\n",
        "    n_rel = len(id2relation)\n",
        "    n_node = cids.shape[0]\n",
        "    adj = np.zeros((n_rel, n_node, n_node), dtype=np.uint8)\n",
        "    for s in range(n_node):\n",
        "        for t in range(n_node):\n",
        "            s_c, t_c = cids[s], cids[t]\n",
        "            if cpnet.has_edge(s_c, t_c):\n",
        "                for e_attr in cpnet[s_c][t_c].values():\n",
        "                    if e_attr['rel'] >= 0 and e_attr['rel'] < n_rel:\n",
        "                        adj[e_attr['rel']][s][t] = 1\n",
        "    # cids += 1  # note!!! index 0 is reserved for padding\n",
        "    # try:\n",
        "    adj = coo_matrix(adj.reshape(-1, n_node))\n",
        "    # except:\n",
        "      # print(\"corrupted data\")\n",
        "    return adj, cids\n",
        "\n",
        "\n",
        "def concepts_to_adj_matrices_1hop_neighbours(data):\n",
        "    qc_ids, ac_ids = data\n",
        "    qa_nodes = set(qc_ids) | set(ac_ids)\n",
        "    extra_nodes = set()\n",
        "    for u in set(qc_ids) | set(ac_ids):\n",
        "        if u in cpnet.nodes:\n",
        "            extra_nodes |= set(cpnet[u])\n",
        "    extra_nodes = extra_nodes - qa_nodes\n",
        "    schema_graph = sorted(qc_ids) + sorted(ac_ids) + sorted(extra_nodes)\n",
        "    arange = np.arange(len(schema_graph))\n",
        "    qmask = arange < len(qc_ids)\n",
        "    amask = (arange >= len(qc_ids)) & (arange < (len(qc_ids) + len(ac_ids)))\n",
        "    adj, concepts = concepts2adj(schema_graph)\n",
        "    return adj, concepts, qmask, amask\n",
        "\n",
        "\n",
        "def concepts_to_adj_matrices_1hop_neighbours_without_relatedto(data):\n",
        "    qc_ids, ac_ids = data\n",
        "    qa_nodes = set(qc_ids) | set(ac_ids)\n",
        "    extra_nodes = set()\n",
        "    for u in set(qc_ids) | set(ac_ids):\n",
        "        if u in cpnet.nodes:\n",
        "            for v in cpnet[u]:\n",
        "                for data in cpnet[u][v].values():\n",
        "                    if data['rel'] not in (15, 32):\n",
        "                        extra_nodes.add(v)\n",
        "    extra_nodes = extra_nodes - qa_nodes\n",
        "    schema_graph = sorted(qc_ids) + sorted(ac_ids) + sorted(extra_nodes)\n",
        "    arange = np.arange(len(schema_graph))\n",
        "    qmask = arange < len(qc_ids)\n",
        "    amask = (arange >= len(qc_ids)) & (arange < (len(qc_ids) + len(ac_ids)))\n",
        "    adj, concepts = concepts2adj(schema_graph)\n",
        "    return adj, concepts, qmask, amask\n",
        "\n",
        "\n",
        "def concepts_to_adj_matrices_2hop_qa_pair(data):\n",
        "    qc_ids, ac_ids = data\n",
        "    qa_nodes = set(qc_ids) | set(ac_ids)\n",
        "    extra_nodes = set()\n",
        "    for qid in qc_ids:\n",
        "        for aid in ac_ids:\n",
        "            if qid != aid and qid in cpnet_simple.nodes and aid in cpnet_simple.nodes:\n",
        "                extra_nodes |= set(cpnet_simple[qid]) & set(cpnet_simple[aid])\n",
        "    extra_nodes = extra_nodes - qa_nodes\n",
        "    schema_graph = sorted(qc_ids) + sorted(ac_ids) + sorted(extra_nodes)\n",
        "    arange = np.arange(len(schema_graph))\n",
        "    qmask = arange < len(qc_ids)\n",
        "    amask = (arange >= len(qc_ids)) & (arange < (len(qc_ids) + len(ac_ids)))\n",
        "    adj, concepts = concepts2adj(schema_graph)\n",
        "    return adj, concepts, qmask, amask\n",
        "\n",
        "\n",
        "def concepts_to_adj_matrices_2hop_all_pair(data):\n",
        "    qc_ids, ac_ids = data\n",
        "    qa_nodes = set(qc_ids) | set(ac_ids)\n",
        "    extra_nodes = set()\n",
        "    for qid in qa_nodes:\n",
        "        for aid in qa_nodes:\n",
        "            if qid != aid and qid in cpnet_simple.nodes and aid in cpnet_simple.nodes:\n",
        "                extra_nodes |= set(cpnet_simple[qid]) & set(cpnet_simple[aid])\n",
        "    extra_nodes = extra_nodes - qa_nodes\n",
        "    schema_graph = sorted(qc_ids) + sorted(ac_ids) + sorted(extra_nodes)\n",
        "    arange = np.arange(len(schema_graph))\n",
        "    qmask = arange < len(qc_ids)\n",
        "    amask = (arange >= len(qc_ids)) & (arange < (len(qc_ids) + len(ac_ids)))\n",
        "    adj, concepts = concepts2adj(schema_graph)\n",
        "    return adj, concepts, qmask, amask\n",
        "\n",
        "\n",
        "def concepts_to_adj_matrices_2step_relax_all_pair(data):\n",
        "    qc_ids, ac_ids = data\n",
        "    qa_nodes = set(qc_ids) | set(ac_ids)\n",
        "    extra_nodes = set()\n",
        "    for qid in qc_ids:\n",
        "        for aid in ac_ids:\n",
        "            if qid != aid and qid in cpnet_simple.nodes and aid in cpnet_simple.nodes:\n",
        "                extra_nodes |= set(cpnet_simple[qid]) & set(cpnet_simple[aid])\n",
        "    intermediate_ids = extra_nodes - qa_nodes\n",
        "    for qid in intermediate_ids:\n",
        "        for aid in ac_ids:\n",
        "            if qid != aid and qid in cpnet_simple.nodes and aid in cpnet_simple.nodes:\n",
        "                extra_nodes |= set(cpnet_simple[qid]) & set(cpnet_simple[aid])\n",
        "    for qid in qc_ids:\n",
        "        for aid in intermediate_ids:\n",
        "            if qid != aid and qid in cpnet_simple.nodes and aid in cpnet_simple.nodes:\n",
        "                extra_nodes |= set(cpnet_simple[qid]) & set(cpnet_simple[aid])\n",
        "    extra_nodes = extra_nodes - qa_nodes\n",
        "    schema_graph = sorted(qc_ids) + sorted(ac_ids) + sorted(extra_nodes)\n",
        "    arange = np.arange(len(schema_graph))\n",
        "    qmask = arange < len(qc_ids)\n",
        "    amask = (arange >= len(qc_ids)) & (arange < (len(qc_ids) + len(ac_ids)))\n",
        "    adj, concepts = concepts2adj(schema_graph)\n",
        "    return adj, concepts, qmask, amask\n",
        "\n",
        "\n",
        "def concepts_to_adj_matrices_3hop_qa_pair(data):\n",
        "    qc_ids, ac_ids = data\n",
        "    qa_nodes = set(qc_ids) | set(ac_ids)\n",
        "    extra_nodes = set()\n",
        "    for qid in qc_ids:\n",
        "        for aid in ac_ids:\n",
        "            if qid != aid and qid in cpnet_simple.nodes and aid in cpnet_simple.nodes:\n",
        "                for u in cpnet_simple[qid]:\n",
        "                    for v in cpnet_simple[aid]:\n",
        "                        if cpnet_simple.has_edge(u, v):  # ac is a 3-hop neighbour of qc\n",
        "                            extra_nodes.add(u)\n",
        "                            extra_nodes.add(v)\n",
        "                        if u == v:  # ac is a 2-hop neighbour of qc\n",
        "                            extra_nodes.add(u)\n",
        "    extra_nodes = extra_nodes - qa_nodes\n",
        "    schema_graph = sorted(qc_ids) + sorted(ac_ids) + sorted(extra_nodes)\n",
        "    arange = np.arange(len(schema_graph))\n",
        "    qmask = arange < len(qc_ids)\n",
        "    amask = (arange >= len(qc_ids)) & (arange < (len(qc_ids) + len(ac_ids)))\n",
        "    adj, concepts = concepts2adj(schema_graph)\n",
        "    return adj, concepts, qmask, amask\n",
        "\n",
        "\n",
        "\n",
        "######################################################################\n",
        "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
        "\n",
        "class RobertaForMaskedLMwithLoss(RobertaForMaskedLM):\n",
        "    #\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "    #\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, masked_lm_labels=None):\n",
        "        #\n",
        "        assert attention_mask is not None\n",
        "        outputs = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask)\n",
        "        sequence_output = outputs[0] #hidden_states of final layer (batch_size, sequence_length, hidden_size)\n",
        "        prediction_scores = self.lm_head(sequence_output)\n",
        "        outputs = (prediction_scores, sequence_output) + outputs[2:]\n",
        "        if masked_lm_labels is not None:\n",
        "            loss_fct = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "            bsize, seqlen = input_ids.size()\n",
        "            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), masked_lm_labels.view(-1)).view(bsize, seqlen)\n",
        "            masked_lm_loss = (masked_lm_loss * attention_mask).sum(dim=1)\n",
        "            outputs = (masked_lm_loss,) + outputs\n",
        "            # (masked_lm_loss), prediction_scores, sequence_output, (hidden_states), (attentions)\n",
        "        return outputs\n",
        "\n",
        "print ('loading pre-trained LM...')\n",
        "TOKENIZER = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "LM_MODEL = RobertaForMaskedLMwithLoss.from_pretrained('roberta-large')\n",
        "LM_MODEL.cuda(); LM_MODEL.eval()\n",
        "print ('loading done')\n",
        "\n",
        "def get_LM_score(cids, question):\n",
        "    cids = cids[:]\n",
        "    cids.insert(0, -1) #QAcontext node\n",
        "    sents, scores = [], []\n",
        "    for cid in cids:\n",
        "        if cid==-1:\n",
        "            sent = question.lower()\n",
        "        else:\n",
        "            sent = '{} {}.'.format(question.lower(), ' '.join(id2concept[cid].split('_')))\n",
        "        sent = TOKENIZER.encode(sent, add_special_tokens=True)\n",
        "        sents.append(sent)\n",
        "    n_cids = len(cids)\n",
        "    cur_idx = 0\n",
        "    batch_size = 50\n",
        "    while cur_idx < n_cids:\n",
        "        #Prepare batch\n",
        "        input_ids = sents[cur_idx: cur_idx+batch_size]\n",
        "        max_len = max([len(seq) for seq in input_ids])\n",
        "        for j, seq in enumerate(input_ids):\n",
        "            seq += [TOKENIZER.pad_token_id] * (max_len-len(seq))\n",
        "            input_ids[j] = seq\n",
        "        input_ids = torch.tensor(input_ids).cuda() #[B, seqlen]\n",
        "        mask = (input_ids!=1).long() #[B, seq_len]\n",
        "        #Get LM score\n",
        "        with torch.no_grad():\n",
        "            outputs = LM_MODEL(input_ids, attention_mask=mask, masked_lm_labels=input_ids)\n",
        "            loss = outputs[0] #[B, ]\n",
        "            _scores = list(-loss.detach().cpu().numpy()) #list of float\n",
        "        scores += _scores\n",
        "        cur_idx += batch_size\n",
        "    assert len(sents) == len(scores) == len(cids)\n",
        "    cid2score = OrderedDict(sorted(list(zip(cids, scores)), key=lambda x: -x[1])) #score: from high to low\n",
        "    return cid2score\n",
        "\n",
        "def concepts_to_adj_matrices_2hop_all_pair__use_LM__Part1(data):\n",
        "    qc_ids, ac_ids, question = data\n",
        "    qa_nodes = set(qc_ids) | set(ac_ids)\n",
        "    extra_nodes = set()\n",
        "    for qid in qa_nodes:\n",
        "        for aid in qa_nodes:\n",
        "            if qid != aid and qid in cpnet_simple.nodes and aid in cpnet_simple.nodes:\n",
        "                extra_nodes |= set(cpnet_simple[qid]) & set(cpnet_simple[aid])\n",
        "    extra_nodes = extra_nodes - qa_nodes\n",
        "    return (sorted(qc_ids), sorted(ac_ids), question, sorted(extra_nodes))\n",
        "\n",
        "def concepts_to_adj_matrices_2hop_all_pair__use_LM__Part2(data):\n",
        "    qc_ids, ac_ids, question, extra_nodes = data\n",
        "    cid2score = get_LM_score(qc_ids+ac_ids+extra_nodes, question)\n",
        "    return (qc_ids, ac_ids, question, extra_nodes, cid2score)\n",
        "\n",
        "def concepts_to_adj_matrices_2hop_all_pair__use_LM__Part3(data):\n",
        "    qc_ids, ac_ids, question, extra_nodes, cid2score = data\n",
        "    schema_graph = qc_ids + ac_ids + sorted(extra_nodes, key=lambda x: -cid2score[x]) #score: from high to low\n",
        "    arange = np.arange(len(schema_graph))\n",
        "    qmask = arange < len(qc_ids)\n",
        "    amask = (arange >= len(qc_ids)) & (arange < (len(qc_ids) + len(ac_ids)))\n",
        "    adj, concepts = concepts2adj(schema_graph)\n",
        "    return {'adj': adj, 'concepts': concepts, 'qmask': qmask, 'amask': amask, 'cid2score': cid2score}\n",
        "\n",
        "################################################################################\n",
        "\n",
        "\n",
        "\n",
        "#####################################################################################################\n",
        "#                     functions below this line will be called by preprocess.py                     #\n",
        "#####################################################################################################\n",
        "\n",
        "\n",
        "def generate_graph(grounded_path, pruned_paths_path, cpnet_vocab_path, cpnet_graph_path, output_path):\n",
        "    print(f'generating schema graphs for {grounded_path} and {pruned_paths_path}...')\n",
        "\n",
        "    global concept2id, id2concept, relation2id, id2relation\n",
        "    if any(x is None for x in [concept2id, id2concept, relation2id, id2relation]):\n",
        "        load_resources(cpnet_vocab_path)\n",
        "\n",
        "    global cpnet, cpnet_simple\n",
        "    if cpnet is None or cpnet_simple is None:\n",
        "        load_cpnet(cpnet_graph_path)\n",
        "\n",
        "    nrow = sum(1 for _ in open(grounded_path, 'r'))\n",
        "    with open(grounded_path, 'r') as fin_gr, \\\n",
        "            open(pruned_paths_path, 'r') as fin_pf, \\\n",
        "            open(output_path, 'w') as fout:\n",
        "        for line_gr, line_pf in tqdm(zip(fin_gr, fin_pf), total=nrow):\n",
        "            mcp = json.loads(line_gr)\n",
        "            qa_pairs = json.loads(line_pf)\n",
        "\n",
        "            statement_paths = []\n",
        "            statement_rel_list = []\n",
        "            for qas in qa_pairs:\n",
        "                if qas[\"pf_res\"] is None:\n",
        "                    cur_paths = []\n",
        "                    cur_rels = []\n",
        "                else:\n",
        "                    cur_paths = [item[\"path\"] for item in qas[\"pf_res\"]]\n",
        "                    cur_rels = [item[\"rel\"] for item in qas[\"pf_res\"]]\n",
        "                statement_paths.extend(cur_paths)\n",
        "                statement_rel_list.extend(cur_rels)\n",
        "\n",
        "            qcs = [concept2id[c] for c in mcp[\"qc\"]]\n",
        "            acs = [concept2id[c] for c in mcp[\"ac\"]]\n",
        "\n",
        "            gobj = plain_graph_generation(qcs=qcs, acs=acs,\n",
        "                                          paths=statement_paths,\n",
        "                                          rels=statement_rel_list)\n",
        "            fout.write(json.dumps(gobj) + '\\n')\n",
        "\n",
        "    print(f'schema graphs saved to {output_path}')\n",
        "    print()\n",
        "\n",
        "\n",
        "def generate_adj_matrices(ori_schema_graph_path, cpnet_graph_path, cpnet_vocab_path, output_path, num_processes, num_rels=34, debug=False):\n",
        "    print(f'generating adjacency matrices for {ori_schema_graph_path} and {cpnet_graph_path}...')\n",
        "\n",
        "    global concept2id, id2concept, relation2id, id2relation\n",
        "    if any(x is None for x in [concept2id, id2concept, relation2id, id2relation]):\n",
        "        load_resources(cpnet_vocab_path)\n",
        "\n",
        "    global cpnet_all\n",
        "    if cpnet_all is None:\n",
        "        # cpnet_all = nx.read_gpickle(cpnet_graph_path)\n",
        "        cpnet_all = read_gpickle(cpnet_graph_path)\n",
        "\n",
        "    with open(ori_schema_graph_path, 'r') as fin:\n",
        "        nxg_strs = [line for line in fin]\n",
        "\n",
        "    if debug:\n",
        "        nxgs = nxgs[:1]\n",
        "\n",
        "    with Pool(num_processes) as p:\n",
        "        res = list(tqdm(p.imap(generate_adj_matrix_per_inst, nxg_strs), total=len(nxg_strs)))\n",
        "\n",
        "    with open(output_path, 'wb') as fout:\n",
        "        pickle.dump(res, fout)\n",
        "\n",
        "    print(f'adjacency matrices saved to {output_path}')\n",
        "    print()\n",
        "\n",
        "\n",
        "def generate_adj_data_from_grounded_concepts(grounded_path, cpnet_graph_path, cpnet_vocab_path, output_path, num_processes):\n",
        "    \"\"\"\n",
        "    This function will save\n",
        "        (1) adjacency matrics (each in the form of a (R*N, N) coo sparse matrix)\n",
        "        (2) concepts ids\n",
        "        (3) qmask that specifices whether a node is a question concept\n",
        "        (4) amask that specifices whether a node is a answer concept\n",
        "    to the output path in python pickle format\n",
        "\n",
        "    grounded_path: str\n",
        "    cpnet_graph_path: str\n",
        "    cpnet_vocab_path: str\n",
        "    output_path: str\n",
        "    num_processes: int\n",
        "    \"\"\"\n",
        "    print(f'generating adj data for {grounded_path}...')\n",
        "\n",
        "    global concept2id, id2concept, relation2id, id2relation, cpnet_simple, cpnet\n",
        "    if any(x is None for x in [concept2id, id2concept, relation2id, id2relation]):\n",
        "        load_resources(cpnet_vocab_path)\n",
        "    if cpnet is None or cpnet_simple is None:\n",
        "        load_cpnet(cpnet_graph_path)\n",
        "\n",
        "    qa_data = []\n",
        "    with open(grounded_path, 'r', encoding='utf-8') as fin:\n",
        "        for line in fin:\n",
        "            dic = json.loads(line)\n",
        "            q_ids = set(concept2id[c] for c in dic['qc'])\n",
        "            a_ids = set(concept2id[c] for c in dic['ac'])\n",
        "            q_ids = q_ids - a_ids\n",
        "            qa_data.append((q_ids, a_ids))\n",
        "\n",
        "    with Pool(num_processes) as p:\n",
        "        res = list(tqdm(p.imap(concepts_to_adj_matrices_2hop_all_pair, qa_data), total=len(qa_data)))\n",
        "\n",
        "    # res is a list of tuples, each tuple consists of four elements (adj, concepts, qmask, amask)\n",
        "    with open(output_path, 'wb') as fout:\n",
        "        pickle.dump(res, fout)\n",
        "\n",
        "    print(f'adj data saved to {output_path}')\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "def generate_adj_data_from_grounded_concepts__use_LM(grounded_path, cpnet_graph_path, cpnet_vocab_path, output_path, num_processes):\n",
        "    \"\"\"\n",
        "    This function will save\n",
        "        (1) adjacency matrics (each in the form of a (R*N, N) coo sparse matrix)\n",
        "        (2) concepts ids\n",
        "        (3) qmask that specifices whether a node is a question concept\n",
        "        (4) amask that specifices whether a node is a answer concept\n",
        "        (5) cid2score that maps a concept id to its relevance score given the QA context\n",
        "    to the output path in python pickle format\n",
        "\n",
        "    grounded_path: str\n",
        "    cpnet_graph_path: str\n",
        "    cpnet_vocab_path: str\n",
        "    output_path: str\n",
        "    num_processes: int\n",
        "    \"\"\"\n",
        "    print(f'generating adj data for {grounded_path}...')\n",
        "\n",
        "    global concept2id, id2concept, relation2id, id2relation, cpnet_simple, cpnet\n",
        "    if any(x is None for x in [concept2id, id2concept, relation2id, id2relation]):\n",
        "        load_resources(cpnet_vocab_path)\n",
        "    if cpnet is None or cpnet_simple is None:\n",
        "        load_cpnet(cpnet_graph_path)\n",
        "\n",
        "    qa_data = []\n",
        "    statement_path = grounded_path.replace('grounded', 'statement')\n",
        "    with open(grounded_path, 'r', encoding='utf-8') as fin_ground, open(statement_path, 'r', encoding='utf-8') as fin_state:\n",
        "        lines_ground = fin_ground.readlines()\n",
        "        lines_state  = fin_state.readlines()\n",
        "        assert len(lines_ground) % len(lines_state) == 0\n",
        "        n_choices = len(lines_ground) // len(lines_state)\n",
        "        for j, line in enumerate(lines_ground):\n",
        "            dic = json.loads(line)\n",
        "            q_ids = set(concept2id[c] for c in dic['qc'])\n",
        "            a_ids = set(concept2id[c] for c in dic['ac'])\n",
        "            q_ids = q_ids - a_ids\n",
        "            statement_obj = json.loads(lines_state[j//n_choices])\n",
        "            QAcontext = \"{} {}.\".format(statement_obj['question']['stem'], dic['ans'])\n",
        "            qa_data.append((q_ids, a_ids, QAcontext))\n",
        "\n",
        "    with Pool(num_processes) as p:\n",
        "        res1 = list(tqdm(p.imap(concepts_to_adj_matrices_2hop_all_pair__use_LM__Part1, qa_data), total=len(qa_data)))\n",
        "\n",
        "    return res1\n",
        "\n",
        "    # res2 = []\n",
        "    # for j, _data in enumerate(res1):\n",
        "    #     if j % 100 == 0: print (j)\n",
        "    #     res2.append(concepts_to_adj_matrices_2hop_all_pair__use_LM__Part2(_data))\n",
        "\n",
        "    # with Pool(num_processes) as p:\n",
        "    #     res3 = list(tqdm(p.imap(concepts_to_adj_matrices_2hop_all_pair__use_LM__Part3, res2), total=len(res2)))\n",
        "\n",
        "    # # res is a list of responses\n",
        "    # with open(output_path, 'wb') as fout:\n",
        "    #     pickle.dump(res3, fout)\n",
        "\n",
        "    # print(f'adj data saved to {output_path}')\n",
        "    # print()\n",
        "\n",
        "\n",
        "def do_part2(data_index_range, res1):\n",
        "\n",
        "  res2 = []\n",
        "  questions_with_problem=[]\n",
        "  # for j, _data in enumerate(res1):\n",
        "  for j in range(data_index_range[0], data_index_range[1]):\n",
        "    _data = res1[j]\n",
        "    if j % 10 == 0: print (j)\n",
        "    try:\n",
        "      res2.append(concepts_to_adj_matrices_2hop_all_pair__use_LM__Part2(_data))\n",
        "    except:\n",
        "      print(f\"q index with problem: {j}\")\n",
        "      questions_with_problem.append(j)\n",
        "\n",
        "  return res2, questions_with_problem\n",
        "\n",
        "\n",
        "def do_part3(res2, num_processes, cpnet_graph_path, cpnet_vocab_path, output_path):\n",
        "  global concept2id, id2concept, relation2id, id2relation, cpnet_simple, cpnet\n",
        "  if any(x is None for x in [concept2id, id2concept, relation2id, id2relation]):\n",
        "      load_resources(cpnet_vocab_path)\n",
        "  if cpnet is None or cpnet_simple is None:\n",
        "      load_cpnet(cpnet_graph_path)\n",
        "\n",
        "  with Pool(num_processes) as p:\n",
        "    res3 = list(tqdm(p.imap(concepts_to_adj_matrices_2hop_all_pair__use_LM__Part3, res2), total=len(res2)))\n",
        "\n",
        "  # res is a list of responses\n",
        "  with open(output_path, 'wb') as fout:\n",
        "      pickle.dump(res3, fout)\n",
        "\n",
        "  print(f'adj data saved to {output_path}')\n",
        "  print()\n",
        "\n",
        "\n",
        "\n",
        "#################### adj to sparse ####################\n",
        "\n",
        "# def coo_to_normalized_per_inst(data):\n",
        "#     adj, concepts, qm, am, max_node_num = data\n",
        "#     ori_adj_len = len(concepts)\n",
        "#     concepts = torch.tensor(concepts[:min(len(concepts), max_node_num)])\n",
        "#     adj_len = len(concepts)\n",
        "#     qm = torch.tensor(qm[:adj_len], dtype=torch.uint8)\n",
        "#     am = torch.tensor(am[:adj_len], dtype=torch.uint8)\n",
        "#     ij = adj.row\n",
        "#     k = adj.col\n",
        "#     n_node = adj.shape[1]\n",
        "#     n_rel = 2 * adj.shape[0] // n_node\n",
        "#     i, j = ij // n_node, ij % n_node\n",
        "#     mask = (j < max_node_num) & (k < max_node_num)\n",
        "#     i, j, k = i[mask], j[mask], k[mask]\n",
        "#     i, j, k = np.concatenate((i, i + n_rel // 2), 0), np.concatenate((j, k), 0), np.concatenate((k, j), 0)  # add inverse relations\n",
        "#     adj_list = []\n",
        "#     for r in range(n_rel):\n",
        "#         mask = i == r\n",
        "#         ones = np.ones(mask.sum(), dtype=np.float32)\n",
        "#         A = sparse.csr_matrix((ones, (k[mask], j[mask])), shape=(max_node_num, max_node_num))  # A is transposed by exchanging the order of j and k\n",
        "#         adj_list.append(normalize_sparse_adj(A, 'coo'))\n",
        "#     adj_list.append(sparse.identity(max_node_num, dtype=np.float32, format='coo'))\n",
        "#     return ori_adj_len, adj_len, concepts, adj_list, qm, am\n",
        "\n",
        "\n",
        "# def coo_to_normalized(adj_path, output_path, max_node_num, num_processes):\n",
        "#     print(f'converting {adj_path} to normalized adj')\n",
        "\n",
        "#     with open(adj_path, 'rb') as fin:\n",
        "#         adj_data = pickle.load(fin)\n",
        "#     data = [(adj, concepts, qmask, amask, max_node_num) for adj, concepts, qmask, amask in adj_data]\n",
        "\n",
        "#     ori_adj_lengths = torch.zeros((len(data),), dtype=torch.int64)\n",
        "#     adj_lengths = torch.zeros((len(data),), dtype=torch.int64)\n",
        "#     concepts_ids = torch.zeros((len(data), max_node_num), dtype=torch.int64)\n",
        "#     qmask = torch.zeros((len(data), max_node_num), dtype=torch.uint8)\n",
        "#     amask = torch.zeros((len(data), max_node_num), dtype=torch.uint8)\n",
        "\n",
        "#     adj_data = []\n",
        "#     with Pool(num_processes) as p:\n",
        "#         for i, (ori_adj_len, adj_len, concepts, adj_list, qm, am) in tqdm(enumerate(p.imap(coo_to_normalized_per_inst, data)), total=len(data)):\n",
        "#             ori_adj_lengths[i] = ori_adj_len\n",
        "#             adj_lengths[i] = adj_len\n",
        "#             concepts_ids[i][:adj_len] = concepts\n",
        "#             qmask[i][:adj_len] = qm\n",
        "#             amask[i][:adj_len] = am\n",
        "#             adj_list = [(torch.LongTensor(np.stack((adj.row, adj.col), 0)),\n",
        "#                          torch.FloatTensor(adj.data)) for adj in adj_list]\n",
        "#             adj_data.append(adj_list)\n",
        "\n",
        "#     torch.save((ori_adj_lengths, adj_lengths, concepts_ids, adj_data), output_path)\n",
        "\n",
        "#     print(f'normalized adj saved to {output_path}')\n",
        "#     print()\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     generate_adj_matrices_from_grounded_concepts('./data/csqa/grounded/train.grounded.jsonl',\n",
        "#                                                  './data/cpnet/conceptnet.en.pruned.graph',\n",
        "#                                                  './data/cpnet/concept.txt',\n",
        "#                                                  '/tmp/asdf', 40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuA8Vzig9ZtW"
      },
      "source": [
        "###ConceptNet Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLMwobLwkCMf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "from multiprocessing import cpu_count\n",
        "# from utils.convert_csqa import convert_to_entailment\n",
        "# from utils.convert_obqa import convert_to_obqa_statement\n",
        "# from utils.conceptnet import extract_english, construct_graph\n",
        "# from utils.grounding import create_matcher_patterns, ground\n",
        "# from utils.graph import generate_adj_data_from_grounded_concepts__use_LM\n",
        "\n",
        "input_paths = {\n",
        "    'cpnet': {\n",
        "        'csv': './data/cpnet/conceptnet-assertions-5.6.0.csv',\n",
        "    },\n",
        "    'csqa': {\n",
        "        'train': './data/csqa/train_rand_split.jsonl',\n",
        "        'dev': './data/csqa/dev_rand_split.jsonl',\n",
        "        'test': './data/csqa/test_rand_split_no_answers.jsonl',\n",
        "    },\n",
        "    'riddle_sense':{\n",
        "        'train': '/content/drive/MyDrive/brain_teaser/datasets/rs_train_preprocessed_pruned.jsonl',\n",
        "        'dev': '/content/drive/MyDrive/brain_teaser/datasets/rs_dev_preprocessed_pruned.jsonl',\n",
        "    },\n",
        "    'brain_teaser_ds':{\n",
        "        'SP_train': '/content/drive/MyDrive/brain_teaser/datasets/SP_train_preprocessed_pruned.jsonl',\n",
        "        'SP_dev': '/content/drive/MyDrive/brain_teaser/datasets/SP_dev_preprocessed_pruned.jsonl',\n",
        "        'WP_train': '/content/drive/MyDrive/brain_teaser/datasets/WP_train_preprocessed_pruned.jsonl',\n",
        "        'WP_dev': '/content/drive/MyDrive/brain_teaser/datasets/WP_dev_preprocessed_pruned.jsonl',\n",
        "    }\n",
        "}\n",
        "\n",
        "output_paths = {\n",
        "    'cpnet': {\n",
        "        'csv': './data/cpnet/conceptnet.en.csv',\n",
        "        'vocab': './data/cpnet/concept.txt',\n",
        "        'patterns': './data/cpnet/matcher_patterns.json',\n",
        "        'unpruned-graph': './data/cpnet/conceptnet.en.unpruned.graph',\n",
        "        'pruned-graph': './data/cpnet/conceptnet.en.pruned.graph',\n",
        "    },\n",
        "    'csqa': {\n",
        "        'statement': {\n",
        "            'train': './data/csqa/statement/train.statement.jsonl',\n",
        "            'dev': './data/csqa/statement/dev.statement.jsonl',\n",
        "            'test': './data/csqa/statement/test.statement.jsonl',\n",
        "        },\n",
        "        'grounded': {\n",
        "            'train': './data/csqa/grounded/train.grounded.jsonl',\n",
        "            'dev': './data/csqa/grounded/dev.grounded.jsonl',\n",
        "            'test': './data/csqa/grounded/test.grounded.jsonl',\n",
        "        },\n",
        "        'graph': {\n",
        "            'adj-train': './data/csqa/graph/train.graph.adj.pk',\n",
        "            'adj-dev': './data/csqa/graph/dev.graph.adj.pk',\n",
        "            'adj-test': './data/csqa/graph/test.graph.adj.pk',\n",
        "        },\n",
        "    },\n",
        "    'riddle_sense': {\n",
        "        'statement': {\n",
        "            'train': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl',\n",
        "            'dev': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/dev.statement.jsonl',\n",
        "            # 'test': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/test.statement.jsonl',\n",
        "        },\n",
        "        'grounded': {\n",
        "            'train': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/grounded/train.grounded.jsonl',\n",
        "            'dev': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/grounded/dev.grounded.jsonl',\n",
        "            # 'test': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/grounded/test.grounded.jsonl',\n",
        "        },\n",
        "        'graph': {\n",
        "            'adj-train': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/train.graph.adj.pk',\n",
        "            'adj-dev': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/dev.graph.adj.pk',\n",
        "            # 'adj-test': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/test.graph.adj.pk',\n",
        "        },\n",
        "    },\n",
        "    'brain_teaser_ds':{\n",
        "         'statement': {\n",
        "            'SP_train': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl',\n",
        "            'SP_dev': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_dev.statement.jsonl',\n",
        "            'WP_train': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl',\n",
        "            'WP_dev': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_dev.statement.jsonl',\n",
        "            # 'test': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/test.statement.jsonl',\n",
        "        },\n",
        "        'grounded': {\n",
        "            'SP_train': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/SP_train.grounded.jsonl',\n",
        "            'SP_dev': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/SP_dev.grounded.jsonl',\n",
        "            'WP_train': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/WP_train.grounded.jsonl',\n",
        "            'WP_dev': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/WP_dev.grounded.jsonl',\n",
        "            # 'test': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/test.grounded.jsonl',\n",
        "        },\n",
        "        'graph': {\n",
        "            'adj-SP_train': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_train.graph.adj.pk',\n",
        "            'adj-SP_dev': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_dev.graph.adj.pk',\n",
        "            'adj-WP_train': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_train.graph.adj.pk',\n",
        "            'adj-WP_dev': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_dev.graph.adj.pk',\n",
        "            # 'adj-test': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/test.graph.adj.pk',\n",
        "        },\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_func(args, routines):\n",
        "\n",
        "    for rt in args[\"run\"]:\n",
        "        print(rt)\n",
        "        for rt_dic in routines[rt]:\n",
        "            print(rt_dic)\n",
        "            rt_dic['func'](*rt_dic['args'])\n",
        "\n",
        "    print('Successfully run {}'.format(' '.join(args[\"run\"])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMQzlslSxT0I"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "def getlocale():\n",
        "  return \"UTF-8\"\n",
        "locale.getpreferredencoding=getlocale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgBprUypwWCo"
      },
      "outputs": [],
      "source": [
        "# routines = {\n",
        "#     'common': [\n",
        "#         {'func': extract_english, 'args': (input_paths['cpnet']['csv'], output_paths['cpnet']['csv'], output_paths['cpnet']['vocab'])},\n",
        "#         {'func': construct_graph, 'args': (output_paths['cpnet']['csv'], output_paths['cpnet']['vocab'],\n",
        "#                                             output_paths['cpnet']['unpruned-graph'], False)},\n",
        "#         {'func': construct_graph, 'args': (output_paths['cpnet']['csv'], output_paths['cpnet']['vocab'],\n",
        "#                                             output_paths['cpnet']['pruned-graph'], True)},\n",
        "#         {'func': create_matcher_patterns, 'args': (output_paths['cpnet']['vocab'], output_paths['cpnet']['patterns'])},\n",
        "#     ],\n",
        "# }\n",
        "\n",
        "\n",
        "# args=dict()\n",
        "# args[\"run\"]=[\"common\"]\n",
        "# args[\"path_prune_threshold\"]=0.12\n",
        "# args[\"max_node_num\"]=200\n",
        "# args[\"nprocs\"]=cpu_count()\n",
        "# args[\"seed\"]=0\n",
        "# args[\"debug\"]=False\n",
        "\n",
        "# preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvPbRU_Yv7AP"
      },
      "source": [
        "##CSQA and Riddle-sense preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVjdHIbbv-yn"
      },
      "source": [
        "### CSQA Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUU0sg8Zugcr"
      },
      "source": [
        "<h3>Run convert_to_entailment func</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPlS8rTt5dok"
      },
      "outputs": [],
      "source": [
        "args=dict()\n",
        "args[\"run\"]=[\"csqa\"]\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q272ITYYvK5V"
      },
      "outputs": [],
      "source": [
        "routines = {\n",
        "    'csqa': [\n",
        "        {'func': convert_to_entailment, 'args': (input_paths['csqa']['train'], output_paths['csqa']['statement']['train'])},\n",
        "        {'func': convert_to_entailment, 'args': (input_paths['csqa']['dev'], output_paths['csqa']['statement']['dev'])},\n",
        "        {'func': convert_to_entailment, 'args': (input_paths['csqa']['test'], output_paths['csqa']['statement']['test'])},\n",
        "    ],\n",
        "}\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEEAeputunLU"
      },
      "source": [
        "<h3>Run ground func</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NebmHJrcwr8j"
      },
      "outputs": [],
      "source": [
        "routines = {\n",
        "    'csqa': [\n",
        "        {'func': ground, 'args': (output_paths['csqa']['statement']['train'], output_paths['cpnet']['vocab'],\n",
        "                                  output_paths['cpnet']['patterns'], output_paths['csqa']['grounded']['train'], args[\"nprocs\"])},\n",
        "    ],\n",
        "}\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkgBeE8qwcOR"
      },
      "outputs": [],
      "source": [
        "routines = {\n",
        "    'csqa': [\n",
        "        {'func': ground, 'args': (output_paths['csqa']['statement']['dev'], output_paths['cpnet']['vocab'],\n",
        "                                  output_paths['cpnet']['patterns'], output_paths['csqa']['grounded']['dev'], args[\"nprocs\"])},\n",
        "    ],\n",
        "}\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w9ITJ0OwcFw",
        "outputId": "5cc7ce6b-b9f6-4807-dc8e-de42f28817a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "csqa\n",
            "{'func': <function ground at 0x7f9ede204dc0>, 'args': ('./data/csqa/statement/test.statement.jsonl', './data/cpnet/concept.txt', './data/cpnet/matcher_patterns.json', './data/csqa/grounded/test.grounded.jsonl', 2)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 1444/5700 [15:39<27:35,  2.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for mzzleloader, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 1750/5700 [18:27<53:09,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for piramid, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 2114/5700 [21:42<22:33,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for loniliness, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 3042/5700 [29:59<31:20,  1.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for stubhub, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 4680/5700 [44:44<08:48,  1.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for accomadable, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 5449/5700 [51:41<02:56,  1.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for stds, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5700/5700 [54:05<00:00,  1.76it/s]\n",
            "100%|██████████| 5700/5700 [01:19<00:00, 71.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grounded concepts saved to ./data/csqa/grounded/test.grounded.jsonl\n",
            "\n",
            "Successfully run csqa\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "routines = {\n",
        "      'csqa': [\n",
        "          {'func': ground, 'args': (output_paths['csqa']['statement']['test'], output_paths['cpnet']['vocab'],\n",
        "                                    output_paths['cpnet']['patterns'], output_paths['csqa']['grounded']['test'], args[\"nprocs\"])},\n",
        "      ],\n",
        "  }\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yySKAPcRuwjv"
      },
      "source": [
        "<h3>Run generate_adj_data_from_grounded_concepts__use_LM func</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ielutuGHw7z2"
      },
      "outputs": [],
      "source": [
        "routines = {\n",
        "        'csqa': [\n",
        "            {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['csqa']['grounded']['train'], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['csqa']['graph']['adj-train'], args[\"nprocs\"])},\n",
        "        ],\n",
        "    }\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az589ggOw2IN"
      },
      "outputs": [],
      "source": [
        "routines = {\n",
        "        'csqa': [\n",
        "            {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['csqa']['grounded']['dev'], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['csqa']['graph']['adj-dev'], args[\"nprocs\"])},\n",
        "        ],\n",
        "    }\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjAAGBXtv9r5"
      },
      "outputs": [],
      "source": [
        "routines = {\n",
        "    'csqa': [\n",
        "        {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['csqa']['grounded']['test'], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['csqa']['graph']['adj-test'], args[\"nprocs\"])},\n",
        "    ],\n",
        "}\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQY_0LsYZ2bv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-mowULYmxf6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbYeETmRoZPB"
      },
      "source": [
        "###Riddle_Sense Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4OI9lggSpvW"
      },
      "source": [
        "####convert_to_entailment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv-W1wyAlXiH",
        "outputId": "8e696ce0-453b-49e8-8ccc-f4188185d88c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "riddle_sense\n",
            "{'func': <function convert_to_entailment at 0x7ebc1c77a050>, 'args': ('/content/drive/MyDrive/brain_teaser/datasets/rs_dev_preprocessed_pruned.jsonl', '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/dev.statement.jsonl')}\n",
            "converting /content/drive/MyDrive/brain_teaser/datasets/rs_dev_preprocessed_pruned.jsonl to entailment dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1021/1021 [00:00<00:00, 6567.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "converted statements saved to /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/dev.statement.jsonl\n",
            "\n",
            "Successfully run riddle_sense\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "routines = {\n",
        "    'riddle_sense': [\n",
        "        {'func': convert_to_entailment, 'args': (input_paths['riddle_sense']['dev'], output_paths['riddle_sense']['statement']['dev'])},\n",
        "    ],\n",
        "}\n",
        "\n",
        "args=dict()\n",
        "# args[\"run\"]=[\"common\"]\n",
        "args[\"run\"]=['riddle_sense']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M50vxyHr3f8j",
        "outputId": "447d74bb-3e80-432e-f4ad-553ce2bac197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "riddle_sense\n",
            "{'func': <function convert_to_entailment at 0x7ebc1c77a050>, 'args': ('/content/drive/MyDrive/brain_teaser/datasets/rs_train_preprocessed_pruned.jsonl', '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl')}\n",
            "converting /content/drive/MyDrive/brain_teaser/datasets/rs_train_preprocessed_pruned.jsonl to entailment dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3510/3510 [00:00<00:00, 6188.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "converted statements saved to /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl\n",
            "\n",
            "Successfully run riddle_sense\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "routines = {\n",
        "    'riddle_sense': [\n",
        "        {'func': convert_to_entailment, 'args': (input_paths['riddle_sense']['train'], output_paths['riddle_sense']['statement']['train'])},\n",
        "    ],\n",
        "}\n",
        "\n",
        "args=dict()\n",
        "args[\"run\"]=['riddle_sense']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgUHf2vgSt8E"
      },
      "source": [
        "####ground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsKRiHhMnfaX",
        "outputId": "2f755de5-1e1b-4263-ca4a-472028736455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "riddle_sense\n",
            "{'func': <function ground at 0x7eba779cdd80>, 'args': ('/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/dev.statement.jsonl', './data/cpnet/concept.txt', './data/cpnet/matcher_patterns.json', '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/grounded/dev.grounded.jsonl', 2)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▎        | 701/5105 [09:43<51:58,  1.41it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for xray, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 764/5105 [10:11<29:21,  2.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for i.q, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 852/5105 [11:12<1:16:35,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 21, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 941/5105 [12:05<39:47,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for yourword, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▊        | 948/5105 [12:08<31:51,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for yourword, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▊        | 955/5105 [12:10<19:42,  3.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for reportcard, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 979/5105 [12:19<21:29,  3.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fieldgoal, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 1246/5105 [15:26<1:05:19,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for axies, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 1502/5105 [18:54<1:09:53,  1.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for iny, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▋     | 2364/5105 [30:35<38:34,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tailcatcher, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 2765/5105 [35:53<23:39,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 2, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 2828/5105 [36:31<20:36,  1.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for forwardward, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 3912/5105 [50:43<11:53,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for mosphere, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 3918/5105 [50:47<11:55,  1.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for xray, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 3994/5105 [51:53<28:38,  1.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for beetbeat, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 4738/5105 [1:01:26<03:57,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 21, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 5014/5105 [1:05:01<01:47,  1.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for sitan, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5105/5105 [1:06:10<00:00,  1.29it/s]\n",
            "100%|██████████| 5105/5105 [01:19<00:00, 64.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grounded concepts saved to /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/grounded/dev.grounded.jsonl\n",
            "\n",
            "Successfully run riddle_sense\n"
          ]
        }
      ],
      "source": [
        "routines = {\n",
        "    'riddle_sense': [\n",
        "        {'func': ground, 'args': (output_paths['riddle_sense']['statement']['dev'], output_paths['cpnet']['vocab'],\n",
        "                                  output_paths['cpnet']['patterns'], output_paths['riddle_sense']['grounded']['dev'], args[\"nprocs\"])},\n",
        "    ],\n",
        "}\n",
        "\n",
        "args=dict()\n",
        "args[\"run\"]=['riddle_sense']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0U3ichgSwkS"
      },
      "source": [
        "####generate_adj_data_from_grounded_concepts__use_LM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHKNT38O402r",
        "outputId": "9efc7cab-2c14-47c5-8662-0855fe687a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating adj data for /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/grounded/dev.grounded.jsonl...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5105/5105 [00:32<00:00, 156.36it/s]\n"
          ]
        }
      ],
      "source": [
        "# routines = {\n",
        "#         'riddle_sense': [\n",
        "#             {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['riddle_sense']['grounded']['dev'],\n",
        "#                   output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['riddle_sense']['graph']['adj-dev'], args[\"nprocs\"])},\n",
        "#         ],\n",
        "#     }\n",
        "# preprocess_func(args, routines)\n",
        "args=dict()\n",
        "args[\"run\"]=['riddle_sense']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "res1=generate_adj_data_from_grounded_concepts__use_LM(output_paths['riddle_sense']['grounded']['dev'],\n",
        "                  output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['riddle_sense']['graph']['adj-dev'], args[\"nprocs\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRM_n2o7U43f"
      },
      "source": [
        "#####do part2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kgM63cWjvqX",
        "outputId": "a473d4cd-b476-4314-8832-945d42c355a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n"
          ]
        }
      ],
      "source": [
        "data_range_to_process=[0,1000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm40GijaXt7Y",
        "outputId": "7b11975a-2a15-487b-ee8c-5bcbf89d1949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[1000,2000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BWiNaIHbkTZ",
        "outputId": "f94a5a63-8de3-428c-cd35-26b653c8e758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "CPU times: user 37min 5s, sys: 3.15 s, total: 37min 8s\n",
            "Wall time: 37min 57s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[2000, 3000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU8_rYhGkudd",
        "outputId": "cc6c99c2-d14b-4ba4-83dd-a0ce8417b1c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "CPU times: user 46min 37s, sys: 3.92 s, total: 46min 41s\n",
            "Wall time: 47min 12s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[3000, 4000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4p7HMZH4dvu",
        "outputId": "c46c2f77-ca24-48b5-ca2e-9b84f7b2bcac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "CPU times: user 43min 37s, sys: 4.22 s, total: 43min 42s\n",
            "Wall time: 44min 2s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[4000, 5105]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J48ndOxbU72V"
      },
      "source": [
        "#####combine parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPngYyA9Shg4"
      },
      "outputs": [],
      "source": [
        "args=dict()\n",
        "# args[\"run\"]=[\"common\"]\n",
        "args[\"run\"]=['riddle_sense']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35Pov3rBRppR",
        "outputId": "90006132-cbff-4688-e418-5ea0eaee8c70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_res2=[]\n",
        "i=1000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fpl9KVJBSJ-B",
        "outputId": "89f82b29-3dbb-4256-b72e-9bc674e407ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=2000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQBMLE8PRkw9",
        "outputId": "98c881be-205d-4de1-c10b-b9a94c57c5c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=3000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDXSgK9uTN8z",
        "outputId": "0f720e7a-a099-4b73-a6c1-da69a449a9fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=4000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuWy-e-NSnFJ",
        "outputId": "33154356-7123-48c4-f830-40af07e0832d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5105"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=5105\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlhHUUUfU-ai"
      },
      "source": [
        "#####do part 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDkGflHOjvmo",
        "outputId": "dde63dfe-8bd9-4971-a156-cbc471307285"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5105/5105 [18:37<00:00,  4.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "adj data saved to /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/dev.graph.adj.pk\n",
            "\n"
          ]
        }
      ],
      "source": [
        "do_part3(temp_res2, args[\"nprocs\"], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['riddle_sense']['graph']['adj-dev'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhFZp_mDjvi6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykGP-hd4jvff"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCXov-G7g24j"
      },
      "source": [
        "####train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfhWt9ggPKjY"
      },
      "source": [
        "#####ground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6ROmnLFZu9o",
        "outputId": "e2d8f2f4-3802-4c62-eacc-88261ba50345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "riddle_sense\n",
            "{'func': <function ground at 0x79f3d0f46680>, 'args': ('/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl', './data/cpnet/concept.txt', './data/cpnet/matcher_patterns.json', '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/grounded/train.grounded.jsonl', 2)}\n",
            "nothing n_n\n",
            "ice_cream\n",
            "towel_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 333/17550 [06:50<5:07:07,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for ong, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 569/17550 [10:08<4:45:07,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 20, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▎         | 658/17550 [11:10<4:59:57,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for pacman, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 1055/17550 [15:57<1:55:43,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for cabde, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 1317/17550 [19:29<3:02:15,  1.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for blackboardchalkboard, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 1345/17550 [20:00<3:59:30,  1.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for inkpen, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 1401/17550 [21:18<8:49:54,  1.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for writeright, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 1455/17550 [22:20<3:24:23,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for readreed, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 1487/17550 [22:47<3:57:09,  1.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for screwscrewdriver, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▊         | 1535/17550 [23:26<3:44:28,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for doormouse, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 1644/17550 [24:52<2:28:28,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for seceret, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 1648/17550 [24:54<2:13:10,  1.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for riott, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|▉         | 1732/17550 [25:36<1:33:07,  2.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for pronounciation, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 1881/17550 [27:05<2:46:27,  1.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 378, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 1928/17550 [27:28<1:32:58,  2.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for rudeolph, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█▏        | 1990/17550 [28:04<2:49:04,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for lobstar, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 2068/17550 [28:43<2:19:20,  1.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fiiiish, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 2217/17550 [30:37<1:46:17,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 18, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 2224/17550 [30:40<1:33:12,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 18, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 2228/17550 [30:43<4:03:08,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 18, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 2249/17550 [30:56<1:40:35,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for caskit, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 2287/17550 [31:20<1:56:00,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for toothhurty, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2443/17550 [32:44<3:11:21,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 12, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2530/17550 [33:30<2:10:09,  1.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for piñata, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 2539/17550 [33:33<1:12:11,  3.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for elephino, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 2940/17550 [37:16<2:35:11,  1.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for graaains, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 2970/17550 [37:28<1:13:36,  3.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 6 25, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 3182/17550 [39:37<4:13:35,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 12345678x9100, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 3214/17550 [39:51<1:07:22,  3.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 5050, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 3326/17550 [41:16<3:09:30,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for ringbox, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 3598/17550 [45:22<6:40:42,  1.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for shaddow, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 3713/17550 [46:42<3:49:04,  1.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 3717/17550 [46:47<4:02:13,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 3722/17550 [46:51<3:05:43,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 3724/17550 [46:53<3:12:25,  1.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 3777/17550 [47:38<3:25:01,  1.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for arive, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 3819/17550 [48:09<2:13:35,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 9 30, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 3839/17550 [48:23<2:17:11,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1986, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 3840/17550 [48:24<2:39:00,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1961, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 3854/17550 [48:33<4:08:26,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 0, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 3878/17550 [48:55<8:26:51,  2.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 74658, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 3907/17550 [49:13<1:22:03,  2.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for crabtree, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▎       | 4166/17550 [52:53<1:34:00,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1974, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 4282/17550 [54:27<3:45:56,  1.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for toedsloth, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 4440/17550 [56:22<4:33:41,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1694, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 4455/17550 [56:44<4:38:17,  1.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for coffinolbiously, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 4674/17550 [1:00:18<1:49:37,  1.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for shawdow, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 4710/17550 [1:00:45<1:37:51,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for linerick, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 4834/17550 [1:02:23<2:05:51,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for umbrellabelt, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 4917/17550 [1:03:26<2:16:42,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for candel, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 4923/17550 [1:03:29<2:05:02,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for candel, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 5054/17550 [1:05:22<1:32:53,  2.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tebag, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 5055/17550 [1:05:23<1:28:31,  2.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tebag, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|██▉       | 5259/17550 [1:08:42<3:51:56,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 9999100, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 5319/17550 [1:09:42<1:38:10,  2.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 9000, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 5323/17550 [1:09:46<2:53:29,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 12345678x9   100, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 5478/17550 [1:11:58<2:43:13,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 9999, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 5482/17550 [1:12:01<2:26:30,  1.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for yellowskin, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 5578/17550 [1:13:21<1:23:39,  2.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for rajivia, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 5592/17550 [1:13:27<2:22:44,  1.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for coffen, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 5593/17550 [1:13:29<2:53:59,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for essor, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 5679/17550 [1:14:34<1:05:13,  3.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for raindeer, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 5808/17550 [1:16:25<4:28:33,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tencows toote toote, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 5833/17550 [1:16:54<3:44:25,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for cano, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 5853/17550 [1:17:14<1:14:22,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for iddl, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▎      | 5915/17550 [1:17:49<1:27:55,  2.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for thunderdome, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 5936/17550 [1:17:58<2:00:56,  1.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for sixarmed, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 5938/17550 [1:18:00<2:05:55,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for sixsix, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 6069/17550 [1:19:53<3:22:20,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 9, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 6078/17550 [1:19:58<1:50:00,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 9, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 6143/17550 [1:20:47<1:35:07,  2.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for animalant, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 6160/17550 [1:21:01<2:28:40,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 9918 189, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 6173/17550 [1:21:06<1:13:07,  2.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for liraffe, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 6257/17550 [1:22:15<1:32:56,  2.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for pinkwall, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 6357/17550 [1:23:27<1:12:59,  2.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for rubberbands, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▋      | 6369/17550 [1:23:33<2:01:39,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for pastdrainer, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 6420/17550 [1:24:14<2:08:43,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fficer, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 6435/17550 [1:24:26<2:00:47,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for elegirre, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 6594/17550 [1:26:27<3:44:31,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for beingseen, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 6634/17550 [1:27:07<2:01:16,  1.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for spagettysburg, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 6664/17550 [1:27:27<4:05:42,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for leekleak, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 6665/17550 [1:27:32<6:47:08,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for peeonatree, concept not found in hard grounding."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 6671/17550 [1:27:32<2:14:57,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 6879/17550 [1:30:40<1:27:17,  2.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 132110, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 6881/17550 [1:30:41<1:52:41,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for jaffcake, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 6954/17550 [1:31:31<1:45:50,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for jackinthebox, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 7102/17550 [1:33:34<1:51:52,  1.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 20 forheads, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 7117/17550 [1:33:51<2:01:33,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for basemint, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████▏     | 7263/17550 [1:35:39<1:48:14,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tshirt, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 7312/17550 [1:36:24<2:07:46,  1.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tailcat, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 7344/17550 [1:37:01<5:30:44,  1.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fficer, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 7365/17550 [1:37:22<1:36:43,  1.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 3, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 7373/17550 [1:37:29<1:59:29,  1.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 3, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 7375/17550 [1:37:31<1:57:22,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 3, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 7441/17550 [1:38:26<1:41:07,  1.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for derrek, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 7443/17550 [1:38:28<2:30:29,  1.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for quarterleaf, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 7455/17550 [1:38:35<1:33:35,  1.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for doggymnasium, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 7464/17550 [1:38:39<1:39:32,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for watermeleon, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 7471/17550 [1:38:43<1:21:05,  2.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for submerine, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▎     | 7674/17550 [1:42:11<1:23:49,  1.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for dandylion, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 7784/17550 [1:43:36<2:03:18,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for electracity, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 7795/17550 [1:43:39<55:44,  2.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for cddvd, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 7864/17550 [1:44:38<1:14:53,  2.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for cryote, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 7889/17550 [1:45:02<2:28:24,  1.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for boloon, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 7898/17550 [1:45:13<3:54:41,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 10, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 7945/17550 [1:45:45<57:07,  2.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for eurapean, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 7952/17550 [1:45:48<1:02:12,  2.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for quater, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 7964/17550 [1:45:54<1:38:28,  1.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for beachtowel   papertowel   bathtowel, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 7980/17550 [1:46:07<2:23:20,  1.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 444420, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 8078/17550 [1:47:35<1:59:02,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 964, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 8193/17550 [1:49:10<1:55:04,  1.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for ciphor, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 8195/17550 [1:49:12<2:05:19,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for bombey, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 8204/17550 [1:49:15<55:10,  2.82it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for rumplestilskin, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 8206/17550 [1:49:16<1:15:40,  2.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for potatoe, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 8260/17550 [1:50:00<1:24:30,  1.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 7, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 8264/17550 [1:50:02<1:31:02,  1.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 7, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 8271/17550 [1:50:05<1:03:50,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1214, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 8288/17550 [1:50:12<41:47,  3.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tae, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 8307/17550 [1:50:34<4:07:14,  1.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for arovar, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 8359/17550 [1:51:22<1:25:42,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for quartar, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 8398/17550 [1:51:51<1:50:12,  1.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 70, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 8426/17550 [1:52:06<1:03:48,  2.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for acteractress, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 8439/17550 [1:52:16<2:12:06,  1.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for banannana, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 8469/17550 [1:52:33<1:58:40,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for atomicache, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 8483/17550 [1:52:36<38:27,  3.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tommorow, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 8489/17550 [1:52:40<1:36:51,  1.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tommorow, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 8504/17550 [1:52:55<1:37:00,  1.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for coffincasket, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▊     | 8537/17550 [1:53:22<2:50:48,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for parachoute, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▊     | 8549/17550 [1:53:28<55:59,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tempeture, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 8574/17550 [1:53:40<1:10:14,  2.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for airporkairport, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 8593/17550 [1:53:51<1:15:51,  1.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for shdow, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 8625/17550 [1:54:07<39:36,  3.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for altoido, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|████▉     | 8694/17550 [1:54:58<2:48:05,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for eggcelent, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|████▉     | 8730/17550 [1:55:29<1:52:30,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for ice_cream, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 8776/17550 [1:56:06<2:37:51,  1.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for squarerect, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 8829/17550 [1:56:46<1:15:15,  1.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for chiminey, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 8837/17550 [1:56:50<1:05:34,  2.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for jasim, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 8840/17550 [1:56:51<54:00,  2.69it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for jasim, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 8924/17550 [1:58:12<1:56:15,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for kookoo, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 8969/17550 [1:58:48<1:11:09,  2.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1   moyet, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████▏    | 9013/17550 [1:59:27<51:46,  2.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 6666   661, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 9050/17550 [2:00:04<1:46:53,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 12111, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 9081/17550 [2:00:24<1:07:56,  2.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for errrrr i duno, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 9142/17550 [2:01:24<2:46:51,  1.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tommorro, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 9254/17550 [2:02:40<2:33:50,  1.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for ninehorses, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 9426/17550 [2:05:17<1:10:59,  1.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 5 369875465, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 9430/17550 [2:05:19<1:11:21,  1.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for trashbucket, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 9465/17550 [2:05:46<3:04:33,  1.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 4, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 9561/17550 [2:06:57<1:12:04,  1.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for ostritch, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 9584/17550 [2:07:13<1:00:57,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for snaketails, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 9602/17550 [2:07:35<2:03:16,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 200, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▍    | 9632/17550 [2:07:59<1:27:32,  1.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for spatchula, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 9773/17550 [2:09:45<2:03:25,  1.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for minoply, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 9819/17550 [2:10:22<3:53:25,  1.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 31131211131221, concept not found in hard grounding.\n",
            "for 2100, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▋    | 9904/17550 [2:11:38<1:01:12,  2.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for neddle, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 9932/17550 [2:12:02<1:09:15,  1.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for leapord, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 9984/17550 [2:12:51<1:20:27,  1.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for peper, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 10040/17550 [2:13:36<1:42:11,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for convertable, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 10050/17550 [2:13:44<1:07:22,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for wallnut, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 10073/17550 [2:14:00<2:56:50,  1.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for anny, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 10099/17550 [2:14:21<1:21:52,  1.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for towl, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 10108/17550 [2:14:24<42:40,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for towl, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 10110/17550 [2:14:25<41:16,  3.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for towl, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 10153/17550 [2:15:04<1:44:12,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for nght, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 10221/17550 [2:16:04<1:59:27,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for aragorn, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▊    | 10286/17550 [2:16:46<45:11,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 64   15625, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 10330/17550 [2:17:18<56:16,  2.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 123, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 10344/17550 [2:17:25<56:57,  2.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 5, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 10347/17550 [2:17:27<1:13:22,  1.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 5, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 10353/17550 [2:17:32<1:38:20,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 5, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 10530/17550 [2:19:48<1:21:58,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for oney, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 10590/17550 [2:20:29<2:13:26,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 11, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 10598/17550 [2:20:32<59:46,  1.94it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 11, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 10605/17550 [2:20:35<46:43,  2.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for aligator, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 10616/17550 [2:20:44<2:25:29,  1.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for dennys, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 10723/17550 [2:21:50<1:09:41,  1.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for agus, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 10729/17550 [2:21:52<43:31,  2.61it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for halfwaytree, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████▏   | 10769/17550 [2:22:25<1:10:22,  1.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tekettle, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 10805/17550 [2:22:53<2:15:47,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 11131221133112132113212221, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 10809/17550 [2:22:56<1:46:09,  1.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1931, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 10915/17550 [2:24:10<36:48,  3.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for snailor, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 10992/17550 [2:25:22<2:12:14,  1.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for gernade, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 11098/17550 [2:26:37<1:22:32,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1615201561, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 11111/17550 [2:26:47<2:44:01,  1.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for manequin, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 11135/17550 [2:27:04<1:21:57,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for oneme, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▎   | 11169/17550 [2:27:30<45:47,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for dono, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 11225/17550 [2:28:13<1:00:13,  1.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for buger, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 11319/17550 [2:29:01<38:31,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for hawii, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 11368/17550 [2:29:31<1:19:29,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for farmacy, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 11407/17550 [2:29:56<1:11:08,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for mississipi, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 11534/17550 [2:31:27<1:00:43,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for funnybone, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 11555/17550 [2:31:49<1:10:10,  1.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for cheapcheap, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 11578/17550 [2:32:01<45:53,  2.17it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fishstick, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▋   | 11665/17550 [2:33:07<3:09:00,  1.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for beespider, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 11684/17550 [2:33:14<36:20,  2.69it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1st, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 11688/17550 [2:33:17<51:51,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 2nd, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 11734/17550 [2:33:43<30:07,  3.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 117, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 11737/17550 [2:33:44<29:49,  3.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 121, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 11738/17550 [2:33:45<42:26,  2.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 119, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 11739/17550 [2:33:45<35:46,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 116   126, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 11825/17550 [2:34:45<2:08:39,  1.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fuckingnesday, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 11827/17550 [2:34:46<1:32:24,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fuckingursday, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 11866/17550 [2:35:14<1:05:06,  1.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for zoochini, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 11883/17550 [2:35:23<54:16,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fireerif, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 11918/17550 [2:35:48<44:12,  2.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for wordwrong, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 11936/17550 [2:35:59<46:40,  2.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for bluegood, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 11937/17550 [2:35:59<50:27,  1.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for streetlegal, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 11988/17550 [2:36:34<1:12:40,  1.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for cofin, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 11991/17550 [2:36:38<1:38:46,  1.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for cofin, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▊   | 12028/17550 [2:37:08<50:30,  1.82it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for blondin, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 12149/17550 [2:39:06<1:09:32,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for legolas, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 12183/17550 [2:39:28<48:33,  1.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for zues, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 12207/17550 [2:39:46<56:22,  1.58it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for bilinet, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|██████▉   | 12213/17550 [2:39:50<1:15:40,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for hisstory, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 12322/17550 [2:40:47<33:59,  2.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for adress, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 12324/17550 [2:40:48<34:16,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1349, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 12364/17550 [2:41:25<1:26:09,  1.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tailfirst, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 12365/17550 [2:41:27<1:50:51,  1.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for kmsqc, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 12479/17550 [2:42:52<59:09,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for isaidgoodday, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 12570/17550 [2:44:03<45:18,  1.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for emis, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 12619/17550 [2:44:40<1:00:54,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for agus, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 12624/17550 [2:44:43<53:10,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for sphits, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 12753/17550 [2:46:21<1:18:22,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fzer0slipper proning, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 12814/17550 [2:47:03<33:20,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tenhorses, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 12838/17550 [2:47:31<1:54:49,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 8, concept not found in hard grounding."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 12839/17550 [2:47:32<1:43:36,  1.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 12862/17550 [2:47:45<1:08:43,  1.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for inchyard, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 12864/17550 [2:47:47<1:22:54,  1.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for ocene, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 12868/17550 [2:47:49<45:42,  1.71it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tomorrw, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▎  | 12934/17550 [2:48:32<25:52,  2.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for armadilo, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▎  | 12939/17550 [2:48:38<1:21:01,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1 me, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 12964/17550 [2:48:53<26:33,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for ricanese, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 12970/17550 [2:48:56<41:57,  1.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tommarow, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 12975/17550 [2:48:58<26:25,  2.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for joannie, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 12992/17550 [2:49:05<27:59,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for itunes, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▍  | 13103/17550 [2:50:42<1:07:13,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for vowls, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 13204/17550 [2:51:58<56:23,  1.28it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for retarts, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 13270/17550 [2:52:39<1:03:11,  1.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for qaurter, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 13276/17550 [2:52:42<35:29,  2.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for doctopus, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 13292/17550 [2:52:48<27:55,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for spinitch, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 13300/17550 [2:52:55<1:13:12,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for purrple, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 13316/17550 [2:53:01<36:16,  1.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for qauter, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 13333/17550 [2:53:14<41:35,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for newspapper, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 13350/17550 [2:53:30<58:44,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for electrcity, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 13366/17550 [2:53:37<24:16,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tommorrow, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 13370/17550 [2:53:38<18:38,  3.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tommorrow, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 13380/17550 [2:53:55<1:08:26,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for adress adress, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 13657/17550 [2:56:55<32:01,  2.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for rius, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 13714/17550 [2:57:33<27:58,  2.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for kyte, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 13833/17550 [2:58:54<43:59,  1.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for ductape, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 13856/17550 [2:59:13<27:41,  2.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for leftright, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 13901/17550 [2:59:38<32:52,  1.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 07, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 13903/17550 [2:59:40<39:43,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 09, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 13904/17550 [2:59:41<39:06,  1.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 08, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 13974/17550 [3:00:28<30:22,  1.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for hinesward, concept not found in hard grounding."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 13976/17550 [3:00:28<23:32,  2.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 13986/17550 [3:00:31<22:34,  2.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for secet, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 14070/17550 [3:01:42<20:47,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1112213211, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 14087/17550 [3:01:51<48:57,  1.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for coughin, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 14113/17550 [3:02:02<21:07,  2.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for stampgolb, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 14137/17550 [3:02:16<17:58,  3.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for greetin, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 14187/17550 [3:02:51<21:25,  2.62it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for warewoff, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████▏ | 14263/17550 [3:03:52<50:00,  1.10it/s]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for kristen, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████▏ | 14301/17550 [3:04:17<34:06,  1.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for pastree, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 14312/17550 [3:04:23<28:42,  1.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for mirra, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 14317/17550 [3:04:25<23:03,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for snotzi, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 14356/17550 [3:04:55<1:24:22,  1.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for andrewanddrew, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 14495/17550 [3:06:25<30:55,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for boomarang, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 14588/17550 [3:07:23<24:50,  1.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for patato, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▎ | 14674/17550 [3:08:06<36:17,  1.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for mailmanmailbox, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▎ | 14683/17550 [3:08:15<58:40,  1.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for miaowmiaow   , concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 14754/17550 [3:09:01<39:43,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for hfqs, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 14918/17550 [3:10:39<30:26,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for boooooo, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 14975/17550 [3:11:20<48:18,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for mountian, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 14981/17550 [3:11:23<24:31,  1.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for chimny, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 14985/17550 [3:11:26<27:50,  1.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for parashoot, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 15004/17550 [3:11:51<39:20,  1.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 5p, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 15041/17550 [3:12:21<31:02,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 140, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 15045/17550 [3:12:24<24:46,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for uesday, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 15078/17550 [3:12:44<16:31,  2.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for umberella, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 15086/17550 [3:12:49<27:55,  1.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for wrestlemania, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 15130/17550 [3:13:21<48:29,  1.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1159, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▋ | 15148/17550 [3:13:39<44:01,  1.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for poision, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 15195/17550 [3:14:04<20:35,  1.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 7hrs, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 15255/17550 [3:14:40<17:07,  2.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 10005050000, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 15364/17550 [3:16:14<21:20,  1.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for dreem, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 15425/17550 [3:16:54<14:16,  2.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for psycopath, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 15432/17550 [3:17:01<27:50,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for statchu, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 15459/17550 [3:17:12<21:42,  1.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for greenwall, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▊ | 15570/17550 [3:18:09<19:29,  1.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 502070, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 15640/17550 [3:18:45<21:23,  1.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1113213211, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 15684/17550 [3:19:32<21:39,  1.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for colorcolour, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 15742/17550 [3:20:24<16:26,  1.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for cellfone, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 15786/17550 [3:20:46<09:10,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for spyfocals, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|████████▉ | 15791/17550 [3:20:49<13:30,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for gaard, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 15813/17550 [3:21:04<23:14,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for redpaint, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 15827/17550 [3:21:15<14:31,  1.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for rubberband, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 15842/17550 [3:21:21<14:42,  1.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for parkinglot, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 15850/17550 [3:21:28<19:51,  1.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for bakingsoda, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 15865/17550 [3:21:35<14:05,  1.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for policecar, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 15879/17550 [3:21:43<14:09,  1.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for lastsupper, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 15888/17550 [3:21:46<08:16,  3.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for frenchfries, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 15889/17550 [3:21:46<10:00,  2.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for youare, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 15898/17550 [3:21:49<07:04,  3.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for nailpolish, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 15914/17550 [3:21:58<17:47,  1.53it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for ironore, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 15934/17550 [3:22:07<07:34,  3.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for begood, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 15937/17550 [3:22:08<10:54,  2.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for waytogo, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 15942/17550 [3:22:10<12:44,  2.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for excuseme, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 15964/17550 [3:22:22<19:17,  1.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for aaarrrgghh, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 15973/17550 [3:22:25<11:16,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for oldcameras, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 16007/17550 [3:22:39<07:55,  3.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for claustraophobic, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 91%|█████████▏| 16021/17550 [3:22:44<09:32,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for witchhikers, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 16138/17550 [3:23:38<11:25,  2.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for broommates, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 16181/17550 [3:24:01<08:53,  2.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for mteverest, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 16205/17550 [3:24:08<08:05,  2.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 141, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 16241/17550 [3:24:36<10:30,  2.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for taqitos, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 16279/17550 [3:24:58<10:48,  1.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for applepie, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 16294/17550 [3:25:07<08:58,  2.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for quasedilla, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 16306/17550 [3:25:11<07:07,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for moneypenny, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 16349/17550 [3:25:28<06:27,  3.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for darkages, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 16394/17550 [3:25:45<05:20,  3.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for stungun, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 16487/17550 [3:26:20<07:46,  2.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for ducttape, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 16506/17550 [3:26:29<05:51,  2.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for comicbooks, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 16514/17550 [3:26:31<04:37,  3.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for figleaf, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 16529/17550 [3:26:37<07:04,  2.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for bigbird, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 16557/17550 [3:26:47<06:15,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for peptalk, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 16561/17550 [3:26:49<07:36,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for furcoat, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 16599/17550 [3:27:03<03:59,  3.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for cashcow, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 16651/17550 [3:27:23<05:40,  2.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fingerfood, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 16709/17550 [3:27:48<06:33,  2.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for pirateship, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 16725/17550 [3:27:54<05:22,  2.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for bigmac, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 16731/17550 [3:27:57<05:36,  2.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fruitsalad, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 16744/17550 [3:28:02<04:29,  2.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for goldchain, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 16797/17550 [3:28:23<05:46,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for paperroute, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 16839/17550 [3:28:39<05:59,  1.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for nesteggs, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 16855/17550 [3:28:46<05:40,  2.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for bumpercars, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 16881/17550 [3:28:55<04:05,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for baldspot, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 16897/17550 [3:28:59<02:55,  3.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for coolmusic, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 16904/17550 [3:29:02<04:14,  2.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for bloodtest, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▋| 16913/17550 [3:29:05<02:53,  3.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for coolcat, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 16974/17550 [3:29:28<04:02,  2.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for northpole, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 16983/17550 [3:29:32<05:05,  1.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for santaclaus, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 17136/17550 [3:30:50<03:09,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for dirtydozen, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 17141/17550 [3:30:52<02:47,  2.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for fivedegrees, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 17179/17550 [3:31:07<02:32,  2.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for freeforall, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 17208/17550 [3:31:16<02:08,  2.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for callme, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 17213/17550 [3:31:17<01:34,  3.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for offtopic, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 17229/17550 [3:31:23<02:34,  2.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for legram, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 17241/17550 [3:31:28<01:50,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for bodyodor, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 17275/17550 [3:31:41<02:36,  1.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for robstew, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▊| 17287/17550 [3:31:45<01:19,  3.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for forsure, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▊| 17308/17550 [3:31:51<00:57,  4.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for kanyewest, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 17364/17550 [3:32:13<01:12,  2.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for selenagomez, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 17398/17550 [3:32:25<00:58,  2.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for yeahright, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 17420/17550 [3:32:34<01:06,  1.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 8   2   10, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 17434/17550 [3:32:44<00:49,  2.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 111111111, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 17438/17550 [3:32:48<01:42,  1.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 11111100, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 17492/17550 [3:33:11<00:15,  3.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for batmreturns, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17550/17550 [3:33:42<00:00,  1.37it/s]\n",
            "100%|██████████| 17550/17550 [04:12<00:00, 69.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grounded concepts saved to /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/grounded/train.grounded.jsonl\n",
            "\n",
            "Successfully run riddle_sense\n"
          ]
        }
      ],
      "source": [
        "args=dict()\n",
        "args[\"run\"]=['riddle_sense']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "\n",
        "routines = {\n",
        "    'riddle_sense': [\n",
        "        {'func': ground, 'args': (output_paths['riddle_sense']['statement']['train'], output_paths['cpnet']['vocab'],\n",
        "                                  output_paths['cpnet']['patterns'], output_paths['riddle_sense']['grounded']['train'], args[\"nprocs\"])},\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hcvm3ykzPNRG"
      },
      "source": [
        "#####generate_adj_data_from_grounded_concepts__use_LM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoL77lhKZd3A",
        "outputId": "ffc5ea02-9320-476e-ead5-5cdd49c6c4c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating adj data for /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/grounded/train.grounded.jsonl...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17550/17550 [01:40<00:00, 174.30it/s]\n"
          ]
        }
      ],
      "source": [
        "# routines = {\n",
        "#         'riddle_sense': [\n",
        "#             {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['riddle_sense']['grounded']['dev'],\n",
        "#                   output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['riddle_sense']['graph']['adj-dev'], args[\"nprocs\"])},\n",
        "#         ],\n",
        "#     }\n",
        "# preprocess_func(args, routines)\n",
        "args=dict()\n",
        "args[\"run\"]=['riddle_sense']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "res1=generate_adj_data_from_grounded_concepts__use_LM(output_paths['riddle_sense']['grounded']['train'],\n",
        "                  output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['riddle_sense']['graph']['adj-train'], args[\"nprocs\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jAJCOTyUx9w"
      },
      "source": [
        "#####do part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIoX9eIlTgUe",
        "outputId": "d84e5b34-4799-4511-dfd1-f742357e31b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "CPU times: user 32min 26s, sys: 3.11 s, total: 32min 29s\n",
            "Wall time: 32min 47s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[0,1000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfwfjG3a4TTk",
        "outputId": "26936dd2-51fa-487e-c3bd-4e9d270370a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "CPU times: user 39min 51s, sys: 3.07 s, total: 39min 54s\n",
            "Wall time: 40min 8s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[1000, 2000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTKyWP3i4TBC",
        "outputId": "1d0fc3c4-e988-4980-e845-2127d7a077d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "CPU times: user 21min 18s, sys: 1.6 s, total: 21min 20s\n",
            "Wall time: 21min 25s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[2000, 3000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxlsZD67JAvH",
        "outputId": "859d6df6-8080-4606-be6c-6f9a396451ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "CPU times: user 37min 8s, sys: 2.95 s, total: 37min 11s\n",
            "Wall time: 37min 27s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[3000, 4000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9Mxd9etJAqN",
        "outputId": "47bda38b-7fbd-4d63-9828-5bc175ea46aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "CPU times: user 45min 40s, sys: 3.37 s, total: 45min 44s\n",
            "Wall time: 45min 54s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[4000, 5000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epqtNE3cWnSn",
        "outputId": "565aad66-4c70-49c5-bcbf-2eb7c1477926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "CPU times: user 48min 20s, sys: 3.03 s, total: 48min 23s\n",
            "Wall time: 48min 32s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[5000, 6000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShWL8AC5gv4v",
        "outputId": "47a55f2c-b11e-4377-9c24-6c993eb36970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "q index with problem: 6560\n",
            "q index with problem: 6561\n",
            "q index with problem: 6562\n",
            "q index with problem: 6563\n",
            "q index with problem: 6564\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "CPU times: user 34min 25s, sys: 3.18 s, total: 34min 28s\n",
            "Wall time: 35min 15s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[6000, 7000]\n",
        "res2, questions_with_problem=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ktRxG4MsjWb",
        "outputId": "4329e190-8499-405e-f58a-515a3df69a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "CPU times: user 47min 45s, sys: 3.56 s, total: 47min 48s\n",
            "Wall time: 48min 12s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[7000, 8000]\n",
        "res2, questions_with_problem=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjYex4xxWxpw",
        "outputId": "bd0f7c56-53c8-42e9-b777-a59a3e32ecfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n",
            "8700\n",
            "8800\n",
            "8900\n",
            "CPU times: user 35min 59s, sys: 2.45 s, total: 36min 1s\n",
            "Wall time: 36min 7s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[8000, 9000]\n",
        "res2, questions_with_problem=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEZpI7fkgy6S",
        "outputId": "8d77b44d-508d-4c22-f781-98aedcb6d056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9000\n",
            "9100\n",
            "9200\n",
            "9300\n",
            "9400\n",
            "9500\n",
            "9600\n",
            "9700\n",
            "9800\n",
            "9900\n",
            "CPU times: user 40min 26s, sys: 2.83 s, total: 40min 29s\n",
            "Wall time: 40min 51s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[9000, 10000]\n",
        "res2, questions_with_problem=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH0NUbnBvmsj",
        "outputId": "7206b1e3-2c71-4af7-d7e1-0957cd575e77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000\n",
            "10100\n",
            "10200\n",
            "10300\n",
            "10400\n",
            "10500\n",
            "10600\n",
            "10700\n",
            "10800\n",
            "10900\n",
            "CPU times: user 28min 52s, sys: 2.14 s, total: 28min 54s\n",
            "Wall time: 29min 11s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[10000, 11000]\n",
        "res2, questions_with_problem=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF67-D2sgvt0",
        "outputId": "6a1f3a44-0fb2-4645-d662-6688579d9c44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11000\n",
            "11100\n",
            "11200\n",
            "11300\n",
            "11400\n",
            "11500\n",
            "11600\n",
            "11700\n",
            "11800\n",
            "11900\n",
            "CPU times: user 25min 57s, sys: 1.87 s, total: 25min 59s\n",
            "Wall time: 26min 17s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[11000, 12000]\n",
        "res2, questions_with_problem=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5NT-9Oa_TMt",
        "outputId": "abca21a9-cb33-442c-e3b7-22ecd0a3d369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12000\n",
            "12100\n",
            "12200\n",
            "12300\n",
            "12400\n",
            "12500\n",
            "12600\n",
            "12700\n",
            "12800\n",
            "12900\n",
            "CPU times: user 31min 49s, sys: 1.98 s, total: 31min 51s\n",
            "Wall time: 31min 57s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[12000, 13000]\n",
        "res2, questions_with_problem=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Loe1yGpGTiLb",
        "outputId": "df339203-4ed0-4142-9259-968969b4d9e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13000\n",
            "13100\n",
            "13200\n",
            "13300\n",
            "13400\n",
            "13500\n",
            "13600\n",
            "13700\n",
            "13800\n",
            "13900\n",
            "CPU times: user 28min 7s, sys: 2.57 s, total: 28min 10s\n",
            "Wall time: 28min 19s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[13000, 14000]\n",
        "res2, questions_with_problem=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEVxTO63TiFm",
        "outputId": "f5fc91b0-fe5c-4a38-d014-b5c9de7f75cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14000\n",
            "14100\n",
            "14200\n",
            "14300\n",
            "14400\n",
            "14500\n",
            "14600\n",
            "14700\n",
            "14800\n",
            "14900\n",
            "CPU times: user 24min 34s, sys: 1.94 s, total: 24min 36s\n",
            "Wall time: 24min 42s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[14000, 15000]\n",
        "res2, questions_with_problem=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ljw0wm2T0g7",
        "outputId": "4684b732-810d-4ca3-834e-fa23526de3f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15000\n",
            "15100\n",
            "15200\n",
            "15300\n",
            "15400\n",
            "15500\n",
            "15600\n",
            "15700\n",
            "15800\n",
            "15900\n",
            "CPU times: user 28min 5s, sys: 2.17 s, total: 28min 7s\n",
            "Wall time: 28min 14s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[15000, 16000]\n",
        "res2, questions_with_problem=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X7wE7sAToTR",
        "outputId": "91cedb0b-7e63-468f-c1d6-03b168946afd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16000\n",
            "16100\n",
            "16200\n",
            "16300\n",
            "16400\n",
            "16500\n",
            "16600\n",
            "16700\n",
            "16800\n",
            "16900\n",
            "17000\n",
            "17100\n",
            "17200\n",
            "17300\n",
            "17400\n",
            "17500\n",
            "CPU times: user 16min 23s, sys: 1.26 s, total: 16min 24s\n",
            "Wall time: 16min 28s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data_range_to_process=[16000, 17550]\n",
        "res2, questions_with_problem=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8eHOoO9UjqJ"
      },
      "source": [
        "#####Combine parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGocBU_tUJSh",
        "outputId": "186c0f96-1d6c-47ad-ed8d-b7f00acf504f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_res2=[]\n",
        "i=1000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBwVMR2VUZI8",
        "outputId": "f80340e2-3284-4cee-ecb5-54e6256424a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=2000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VmfRkbCUZDw",
        "outputId": "18865a8a-5187-4fdf-dc4e-1484c6c27887"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=3000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdayWbrfUY8v",
        "outputId": "a3462b49-56dd-4638-be7e-b7b72e0e0db5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=4000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtvnMBrIUY20",
        "outputId": "900a5591-176b-4871-c2df-85395d3b30c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=5000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKD_l2C-UYxa",
        "outputId": "7ece2d80-8582-4c74-f434-4db0cb51efbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=6000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ksv2fo3UYrh",
        "outputId": "83dbbeb7-dc14-4972-e533-cf32fcbc40e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6995"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=7000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmz1lN41UYjt",
        "outputId": "9533f1d2-b2c2-46f9-e07d-41dd1a593db1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7995"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=8000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9P4_h9BUJQa",
        "outputId": "9f7c4569-54c5-434b-966e-96b15e9a8479"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8995"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=9000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC6Bnc00UJNV",
        "outputId": "8fb3c8c7-cb6f-443a-f3ac-40d12e88fdfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9995"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=10000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leFX5cGN4S6w",
        "outputId": "e912236b-364f-4b4e-f616-1b354236dbf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10995"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=11000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHh9TaYKUctd",
        "outputId": "6673066c-f3c7-4839-cc5c-1efe96dcffb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11995"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=12000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIuwC-95UcSN",
        "outputId": "b825136a-b915-4cc9-fc86-bcbd704d3102"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12995"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=13000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8MJMnJkUcLu",
        "outputId": "850bbf7a-3cc0-4272-f369-58c37260d03f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13995"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=14000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKpZCOlKUeJy",
        "outputId": "e91ecee2-e75a-4670-d57f-49123c310be0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14995"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=15000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyZZ0G1UUe9B",
        "outputId": "314fe56a-0951-4606-c48e-aa483ab9f4bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15995"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=16000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY3qv_zlqvnE",
        "outputId": "45a20b27-fa0d-41cd-aa6c-bfec13f5b9af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17545"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=17550\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp)\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l728-RTPUsGF"
      },
      "source": [
        "#####do part3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmxgtKGzxeHj",
        "outputId": "046ba82e-9be5-473c-c34c-67cffc1aa283"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([],\n",
              " [],\n",
              " '9+9=9 how can that be? 9918 189.',\n",
              " [],\n",
              " OrderedDict([(-1, -5.411866)]))"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_res2[6160]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4zI4mUV4S04",
        "outputId": "663d4e71-af75-49ae-dcf7-0c6b7146e8fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 6154/17545 [18:39<31:14,  6.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrupted data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 8069/17545 [25:08<18:53,  8.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrupted data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 8259/17545 [25:41<14:13, 10.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrupted data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 11719/17545 [34:43<07:21, 13.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrupted data\n",
            "corrupted data\n",
            "corrupted data\n",
            "corrupted data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 14456/17545 [40:48<03:17, 15.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrupted data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 17141/17545 [45:03<00:29, 13.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corrupted data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17545/17545 [45:17<00:00,  6.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "adj data saved to /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/train.graph.adj.pk\n",
            "\n"
          ]
        }
      ],
      "source": [
        "do_part3(temp_res2, args[\"nprocs\"], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['riddle_sense']['graph']['adj-train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fO9SaHIdnELz"
      },
      "outputs": [],
      "source": [
        "# routines = {\n",
        "#         'riddle_sense': [\n",
        "#             {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['riddle_sense']['grounded']['train'],\n",
        "#                   output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['riddle_sense']['graph']['adj-train'], args[\"nprocs\"])},\n",
        "#         ],\n",
        "#     }\n",
        "# preprocess_func(routines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t77aPWvLnA_q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP-3d6PwlXe5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwzojUKPldDT"
      },
      "source": [
        "##<font color=lightgreen>Extract concepts from questions and answer choices</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELEAskHzP3GG",
        "outputId": "c1e69b99-ef37-49f0-f0ee-d08ea14405fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j87C4256oM1N"
      },
      "source": [
        "###riddle-sense dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQOS_wIAdNyY",
        "outputId": "81fbeaec-75b9-4ec2-c7f5-e83b34b43a4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Riddle-Sense train size: 3510, Riddle-Sense dev size: 1021\n"
          ]
        }
      ],
      "source": [
        "DATA_FOLDER=\"/content/drive/MyDrive/brain_teaser/datasets\"\n",
        "\n",
        "\n",
        "linked_qa_file=f\"{DATA_FOLDER}/rs_train.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  rs_train_instances = [json.loads(line) for line in f.read().split(\"\\n\") if line]\n",
        "\n",
        "linked_qa_file=f\"{DATA_FOLDER}/rs_dev.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  rs_dev_instances = [json.loads(line) for line in f.read().split(\"\\n\") if line]\n",
        "\n",
        "print(f\"Riddle-Sense train size: {len(rs_train_instances)}, Riddle-Sense dev size: {len(rs_dev_instances)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io9HQlIZeFFI",
        "outputId": "58e1434b-6853-49d3-c991-327fc286d597"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'cxzvpoiuzckf-3123',\n",
              " 'question': {'stem': 'A man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand backwards and forwards across a field the size of a football pitch.  What is the one thing he can put in it to make it lighter?',\n",
              "  'choices': [{'label': 'A', 'text': 'throw'},\n",
              "   {'label': 'B', 'text': 'bit'},\n",
              "   {'label': 'C', 'text': 'gallon'},\n",
              "   {'label': 'D', 'text': 'mouse'},\n",
              "   {'label': 'E', 'text': 'hole'}]},\n",
              " 'answerKey': 'E'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rs_train_instances[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAjt9zEdlh-b",
        "outputId": "82ff8620-51c4-49cc-927e-7fecbf30d3e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "799273\n"
          ]
        }
      ],
      "source": [
        "DATA_FOLDER=\"/content/drive/MyDrive/brain_teaser/datasets\"\n",
        "concepts_path=f\"{DATA_FOLDER}/concept.txt\"\n",
        "\n",
        "def load_concept_vocab(cpnet_vocab_path):\n",
        "    global concept2id, id2concept\n",
        "\n",
        "    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n",
        "        id2concept = [w.strip() for w in fin]\n",
        "    concept2id = {w: i for i, w in enumerate(id2concept)}\n",
        "\n",
        "\n",
        "load_concept_vocab(concepts_path)\n",
        "print(len(id2concept))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNSodhiyuTBu"
      },
      "outputs": [],
      "source": [
        "def extract_concepts(question_list):\n",
        "  processed_qs=[]\n",
        "\n",
        "  for i in tqdm(range(len(question_list))):\n",
        "\n",
        "    sample=question_list[i]\n",
        "    q_id=sample['id']\n",
        "    q_answerKey=sample['answerKey']\n",
        "    q_stem=sample['question']['stem'].strip().lower()\n",
        "    q_choices=sample['question']['choices']\n",
        "\n",
        "    question_concepts=[]\n",
        "    for i in range(len(id2concept)):\n",
        "      concept=id2concept[i].strip().lower().replace(\"_\",\" \")\n",
        "      if len(concept)<=2:\n",
        "        continue\n",
        "      if concept in q_stem:\n",
        "        question_concepts.append(concept)\n",
        "\n",
        "\n",
        "    new_question_concepts=[]\n",
        "    for i in range(len(question_concepts)):\n",
        "      first_concept=question_concepts[i]\n",
        "      is_sub_concept=False\n",
        "      for j in range(len(question_concepts)):\n",
        "        if i==j:\n",
        "          continue\n",
        "        if first_concept in question_concepts[j]:\n",
        "          is_sub_concept=True\n",
        "          break\n",
        "\n",
        "      if is_sub_concept==False:\n",
        "        new_question_concepts.append(first_concept)\n",
        "\n",
        "\n",
        "    meaningful_question_concepts=set()\n",
        "    for concept in new_question_concepts:\n",
        "      if concept in wn.words():\n",
        "        meaningful_question_concepts.add(concept)\n",
        "        continue\n",
        "\n",
        "      concept_subwords=concept.split(\" \")\n",
        "      all_are_meaningful=True\n",
        "      meaningfuls=[]\n",
        "      for subword in concept_subwords:\n",
        "        if len(subword)<=2:\n",
        "          all_are_meaningful=False\n",
        "          continue\n",
        "\n",
        "        if subword in wn.words():\n",
        "          meaningfuls.append(subword)\n",
        "        else:\n",
        "          all_are_meaningful=False\n",
        "      if all_are_meaningful:\n",
        "        meaningful_question_concepts.add(concept)\n",
        "      else:\n",
        "        for c in meaningfuls:\n",
        "          meaningful_question_concepts.add(c)\n",
        "\n",
        "\n",
        "    q_dict={\n",
        "        'id':q_id,\n",
        "        'answerKey':q_answerKey,\n",
        "        'question':{\n",
        "            'question_concept': list(meaningful_question_concepts),\n",
        "            'choices': q_choices,\n",
        "            'stem': q_stem,\n",
        "        }\n",
        "    }\n",
        "    processed_qs.append(q_dict)\n",
        "\n",
        "  return processed_qs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24eCmpwneSsN",
        "outputId": "05d10a81-5634-4564-bc5d-cd74bc9e0876"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1021/1021 [11:13<00:00,  1.52it/s]\n"
          ]
        }
      ],
      "source": [
        "processed_dev_qs=extract_concepts(rs_dev_instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-DTiFqshtlR",
        "outputId": "ea100981-65b2-44f7-8952-81b2695cd896"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1021"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(processed_dev_qs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9LnKc4VfniT"
      },
      "outputs": [],
      "source": [
        "with open(f'{DATA_FOLDER}/rs_dev_preprocessed.jsonl', 'w') as outfile:\n",
        "  for entry in processed_dev_qs:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgR0UnU7fCGJ",
        "outputId": "119faa97-9eb1-4264-829d-3742a29bb593"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3510/3510 [41:29<00:00,  1.41it/s]\n"
          ]
        }
      ],
      "source": [
        "processed_train_qs=extract_concepts(rs_train_instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD4LSLmgmCKq",
        "outputId": "8c6778e9-1e66-4f92-c355-2c92992b4862"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3510"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(processed_train_qs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShcO1CdrgYVM"
      },
      "outputs": [],
      "source": [
        "with open(f'{DATA_FOLDER}/rs_train_preprocessed.jsonl', 'w') as outfile:\n",
        "  for entry in processed_train_qs:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR1C7RZtZd9Y",
        "outputId": "5ed1ad6b-1044-4eb6-c194-b2c5599697ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:04<00:00,  4.15s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'id': 'cxzvpoiuzckf-902',\n",
              "  'answerKey': 'C',\n",
              "  'question': {'question_concept': ['more',\n",
              "    'frozen',\n",
              "    'people',\n",
              "    'time',\n",
              "    'explorer',\n",
              "    'closely',\n",
              "    'antarctica',\n",
              "    'some',\n",
              "    'adam',\n",
              "    'know'],\n",
              "   'choices': [{'label': 'A', 'text': 'cold water'},\n",
              "    {'label': 'B', 'text': 'feel cold'},\n",
              "    {'label': 'C', 'text': 'they have no belly button'},\n",
              "    {'label': 'D', 'text': 'cooler'},\n",
              "    {'label': 'E', 'text': 'bone'}],\n",
              "   'stem': 'an explorer in antarctica is examining some of his ice samples and during this time, he finds two frozen people.  as examines them more closely he realizes that these people are adam and eve.  how does he know this?'}}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extract_concepts([rs_train_instances[1000]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMEvs91AfvCn",
        "outputId": "e342d23e-fe80-43d9-af56-b5bf1e7b03c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'cxzvpoiuzckf-3123',\n",
              " 'question': {'stem': 'A man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand backwards and forwards across a field the size of a football pitch.  What is the one thing he can put in it to make it lighter?',\n",
              "  'choices': [{'label': 'A', 'text': 'throw'},\n",
              "   {'label': 'B', 'text': 'bit'},\n",
              "   {'label': 'C', 'text': 'gallon'},\n",
              "   {'label': 'D', 'text': 'mouse'},\n",
              "   {'label': 'E', 'text': 'hole'}]},\n",
              " 'answerKey': 'E'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rs_train_instances[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbTZu2u6enoF",
        "outputId": "bd3ad9bc-b335-4fe0-8109-7eb1866092de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'cxzvpoiuzckf-902',\n",
              " 'answerKey': 'C',\n",
              " 'question': {'question_concept': ['closely',\n",
              "   'antarctica',\n",
              "   'are',\n",
              "   'know',\n",
              "   'some',\n",
              "   'eve',\n",
              "   'more',\n",
              "   'people',\n",
              "   'ice',\n",
              "   'time',\n",
              "   'explorer',\n",
              "   'two',\n",
              "   'adam',\n",
              "   'frozen'],\n",
              "  'choices': [{'label': 'A', 'text': 'cold water'},\n",
              "   {'label': 'B', 'text': 'feel cold'},\n",
              "   {'label': 'C', 'text': 'they have no belly button'},\n",
              "   {'label': 'D', 'text': 'cooler'},\n",
              "   {'label': 'E', 'text': 'bone'}],\n",
              "  'stem': 'an explorer in antarctica is examining some of his ice samples and during this time, he finds two frozen people.  as examines them more closely he realizes that these people are adam and eve.  how does he know this?'}}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_train_qs[1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CyZ-0QxeeEp"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "from the list of concepts below, select three concepts in the following question that helps get to the answer:\n",
        "[list]: ['closely',\n",
        "   'antarctica',\n",
        "   'are',\n",
        "   'know',\n",
        "   'some',\n",
        "   'eve',\n",
        "   'more',\n",
        "   'people',\n",
        "   'ice',\n",
        "   'time',\n",
        "   'explorer',\n",
        "   'two',\n",
        "   'adam',\n",
        "   'frozen']\n",
        "[question]: an explorer in antarctica is examining some of his ice samples and during this time, he finds two frozen people.\n",
        "as examines them more closely he realizes that these people are adam and eve.  how does he know this?\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX1RANkUoVcm"
      },
      "source": [
        "###brain-teaser dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX-UilHBpiAd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "3WhCboMRpD6P",
        "outputId": "048c6119-8df5-42ac-c170-bf321252cf09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "507\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-92310080-b360-4894-8b0d-7d8844261a86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>distractor1</th>\n",
              "      <th>distractor2</th>\n",
              "      <th>distractor(unsure)</th>\n",
              "      <th>label</th>\n",
              "      <th>choice_list</th>\n",
              "      <th>choice_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SP-0</td>\n",
              "      <td>Mr. and Mrs. Mustard have six daughters and ea...</td>\n",
              "      <td>Each daughter shares the same brother.</td>\n",
              "      <td>Some daughters get married and have their own ...</td>\n",
              "      <td>Some brothers were not loved by family and mov...</td>\n",
              "      <td>None of above.</td>\n",
              "      <td>1</td>\n",
              "      <td>[Some daughters get married and have their own...</td>\n",
              "      <td>[1, 0, 2, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SP-0_SR</td>\n",
              "      <td>The six daughters of Mr. and Mrs. Mustard each...</td>\n",
              "      <td>Each daughter shares the same brother.</td>\n",
              "      <td>Some daughters get married and have their own ...</td>\n",
              "      <td>Some brothers were not loved by family and mov...</td>\n",
              "      <td>None of above.</td>\n",
              "      <td>2</td>\n",
              "      <td>[Some brothers were not loved by family and mo...</td>\n",
              "      <td>[2, 1, 0, 3]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92310080-b360-4894-8b0d-7d8844261a86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92310080-b360-4894-8b0d-7d8844261a86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92310080-b360-4894-8b0d-7d8844261a86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4bb1e17d-25b0-45c8-b5e7-64fde1becb0b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4bb1e17d-25b0-45c8-b5e7-64fde1becb0b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4bb1e17d-25b0-45c8-b5e7-64fde1becb0b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        id                                           question  \\\n",
              "0     SP-0  Mr. and Mrs. Mustard have six daughters and ea...   \n",
              "1  SP-0_SR  The six daughters of Mr. and Mrs. Mustard each...   \n",
              "\n",
              "                                   answer  \\\n",
              "0  Each daughter shares the same brother.   \n",
              "1  Each daughter shares the same brother.   \n",
              "\n",
              "                                         distractor1  \\\n",
              "0  Some daughters get married and have their own ...   \n",
              "1  Some daughters get married and have their own ...   \n",
              "\n",
              "                                         distractor2 distractor(unsure)  \\\n",
              "0  Some brothers were not loved by family and mov...     None of above.   \n",
              "1  Some brothers were not loved by family and mov...     None of above.   \n",
              "\n",
              "   label                                        choice_list  choice_order  \n",
              "0      1  [Some daughters get married and have their own...  [1, 0, 2, 3]  \n",
              "1      2  [Some brothers were not loved by family and mo...  [2, 1, 0, 3]  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SP_dataset_train = np.load('/content/drive/MyDrive/brain_teaser/datasets/SP-train.npy', allow_pickle=True,encoding='bytes')\n",
        "print(len(SP_dataset_train))\n",
        "\n",
        "data_dict = {'id':[],\n",
        "             'question':[],\n",
        "             'answer':[],\n",
        "             'distractor1':[],\n",
        "             'distractor2':[],\n",
        "             'distractor(unsure)':[],\n",
        "             'label':[],\n",
        "             'choice_list':[],\n",
        "             'choice_order':[]}\n",
        "for i in SP_dataset_train:\n",
        "  for k,v in i.items():\n",
        "    data_dict[k].append(v)\n",
        "\n",
        "SP_train_df = pd.DataFrame(data_dict, columns=['id', 'question', 'answer', 'distractor1', 'distractor2', 'distractor(unsure)', 'label', 'choice_list', 'choice_order'])\n",
        "SP_train_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "Qm4Sa6c6pUhp",
        "outputId": "3d548a37-3f64-4b7e-a689-f8eb818a8395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "396\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                    question             answer  \\\n",
              "0     WP-0   How do you spell COW in thirteen letters?  SEE O DOUBLE YOU.   \n",
              "1  WP-0_SR  In thirteen letters, how do you spell COW?  SEE O DOUBLE YOU.   \n",
              "\n",
              "     distractor1      distractor2 distractor(unsure)  label  \\\n",
              "0  COWCOWCOWCOWW  SEE OH DEREFORD     None of above.      1   \n",
              "1  COWCOWCOWCOWW  SEE OH DEREFORD     None of above.      2   \n",
              "\n",
              "                                         choice_list  choice_order  \n",
              "0  [SEE OH DEREFORD, SEE O DOUBLE YOU., COWCOWCOW...  [2, 0, 1, 3]  \n",
              "1  [SEE OH DEREFORD, COWCOWCOWCOWW, SEE O DOUBLE ...  [2, 1, 0, 3]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c600d286-ae23-4905-ba5c-54447cd50d2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>distractor1</th>\n",
              "      <th>distractor2</th>\n",
              "      <th>distractor(unsure)</th>\n",
              "      <th>label</th>\n",
              "      <th>choice_list</th>\n",
              "      <th>choice_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WP-0</td>\n",
              "      <td>How do you spell COW in thirteen letters?</td>\n",
              "      <td>SEE O DOUBLE YOU.</td>\n",
              "      <td>COWCOWCOWCOWW</td>\n",
              "      <td>SEE OH DEREFORD</td>\n",
              "      <td>None of above.</td>\n",
              "      <td>1</td>\n",
              "      <td>[SEE OH DEREFORD, SEE O DOUBLE YOU., COWCOWCOW...</td>\n",
              "      <td>[2, 0, 1, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WP-0_SR</td>\n",
              "      <td>In thirteen letters, how do you spell COW?</td>\n",
              "      <td>SEE O DOUBLE YOU.</td>\n",
              "      <td>COWCOWCOWCOWW</td>\n",
              "      <td>SEE OH DEREFORD</td>\n",
              "      <td>None of above.</td>\n",
              "      <td>2</td>\n",
              "      <td>[SEE OH DEREFORD, COWCOWCOWCOWW, SEE O DOUBLE ...</td>\n",
              "      <td>[2, 1, 0, 3]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c600d286-ae23-4905-ba5c-54447cd50d2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c600d286-ae23-4905-ba5c-54447cd50d2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c600d286-ae23-4905-ba5c-54447cd50d2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d5faecd7-d46c-4fbf-b931-82f737597bc1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5faecd7-d46c-4fbf-b931-82f737597bc1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d5faecd7-d46c-4fbf-b931-82f737597bc1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "WP_dataset_train = np.load('/content/drive/MyDrive/brain_teaser/datasets/WP-train.npy', allow_pickle=True,encoding='bytes')\n",
        "print(len(WP_dataset_train))\n",
        "\n",
        "data_dict = {'id':[],\n",
        "             'question':[],\n",
        "             'answer':[],\n",
        "             'distractor1':[],\n",
        "             'distractor2':[],\n",
        "             'distractor(unsure)':[],\n",
        "             'label':[],\n",
        "             'choice_list':[],\n",
        "             'choice_order':[]}\n",
        "for i in WP_dataset_train:\n",
        "  for k,v in i.items():\n",
        "    data_dict[k].append(v)\n",
        "\n",
        "WP_train_df = pd.DataFrame(data_dict, columns=['id', 'question', 'answer', 'distractor1', 'distractor2', 'distractor(unsure)', 'label', 'choice_list', 'choice_order'])\n",
        "WP_train_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "18npNSh2pUdC",
        "outputId": "ea7d61ef-ed9a-4cc5-ff88-fe11e305c698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c8eb9090-a302-4b60-9207-5e4e2ebe8137\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Everyone called him \"Batman,\" but he knew noth...</td>\n",
              "      <td>[He tries to be friendly., He is afraid others...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>All of Mrs. Smith pets are dogs except one, an...</td>\n",
              "      <td>[Mrs.Smith has one additional pet that is neit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8eb9090-a302-4b60-9207-5e4e2ebe8137')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c8eb9090-a302-4b60-9207-5e4e2ebe8137 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c8eb9090-a302-4b60-9207-5e4e2ebe8137');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0abd70a2-9002-4a7b-bfd9-776648a1b90d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0abd70a2-9002-4a7b-bfd9-776648a1b90d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0abd70a2-9002-4a7b-bfd9-776648a1b90d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  Everyone called him \"Batman,\" but he knew noth...   \n",
              "1  All of Mrs. Smith pets are dogs except one, an...   \n",
              "\n",
              "                                         choice_list  \n",
              "0  [He tries to be friendly., He is afraid others...  \n",
              "1  [Mrs.Smith has one additional pet that is neit...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SP_dataset_val = np.load('/content/drive/MyDrive/brain_teaser/datasets/SP_eval_data_for_practice.npy', allow_pickle=True,encoding='bytes')\n",
        "print(len(SP_dataset_val))\n",
        "\n",
        "data_dict = {'question':[],\n",
        "             'choice_list':[]}\n",
        "for i in SP_dataset_val:\n",
        "  for k,v in i.items():\n",
        "    data_dict[k].append(v)\n",
        "\n",
        "SP_val_df = pd.DataFrame(data_dict, columns=['question', 'choice_list'])\n",
        "SP_val_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "OFHoD0pspUYA",
        "outputId": "33dcdfab-0649-4604-c412-117f03e1a7ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          question  \\\n",
              "0   What kind of nut has no shell?   \n",
              "1  Which nut doesn't have a shell?   \n",
              "\n",
              "                                         choice_list  \n",
              "0  [A peanut., A Doughnut., A walnut., None of ab...  \n",
              "1  [A Doughnut., A walnut., A peanut., None of ab...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cbe2ed8-9610-466f-83ec-bf8cfce44484\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What kind of nut has no shell?</td>\n",
              "      <td>[A peanut., A Doughnut., A walnut., None of ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Which nut doesn't have a shell?</td>\n",
              "      <td>[A Doughnut., A walnut., A peanut., None of ab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cbe2ed8-9610-466f-83ec-bf8cfce44484')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9cbe2ed8-9610-466f-83ec-bf8cfce44484 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9cbe2ed8-9610-466f-83ec-bf8cfce44484');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-138c9db9-8ecb-436d-b960-263c04b2677a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-138c9db9-8ecb-436d-b960-263c04b2677a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-138c9db9-8ecb-436d-b960-263c04b2677a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "WP_dataset_val = np.load('/content/drive/MyDrive/brain_teaser/datasets/WP_eval_data_for_practice.npy', allow_pickle=True,encoding='bytes')\n",
        "print(len(WP_dataset_val))\n",
        "\n",
        "data_dict = {'question':[],\n",
        "             'choice_list':[]}\n",
        "for i in WP_dataset_val:\n",
        "  for k,v in i.items():\n",
        "    data_dict[k].append(v)\n",
        "\n",
        "WP_val_df = pd.DataFrame(data_dict, columns=['question', 'choice_list'])\n",
        "WP_val_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'textcat'])\n",
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "id": "Xt2KM9V0idP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn93mD8eukPc",
        "outputId": "60d71790-4f54-4321-80f7-1445bc434ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "799273\n"
          ]
        }
      ],
      "source": [
        "DATA_FOLDER=\"/content/drive/MyDrive/brain_teaser/datasets\"\n",
        "concepts_path=f\"{DATA_FOLDER}/concept.txt\"\n",
        "\n",
        "# def load_cpnet_vocab(cpnet_vocab_path):\n",
        "#     with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n",
        "#         cpnet_vocab = [l.strip() for l in fin]\n",
        "#     cpnet_vocab = [c.replace(\"_\", \" \") for c in cpnet_vocab]\n",
        "#     return cpnet_vocab\n",
        "\n",
        "def load_concept_vocab(cpnet_vocab_path):\n",
        "    global concept2id, id2concept\n",
        "\n",
        "    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n",
        "        id2concept = [w.strip() for w in fin]\n",
        "    concept2id = {w: i for i, w in enumerate(id2concept)}\n",
        "\n",
        "\n",
        "load_concept_vocab(concepts_path)\n",
        "print(len(id2concept))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2Gm1EZ03w22",
        "outputId": "7d510b80-33d4-44f8-f11a-f29fcd943d1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5873"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concept2id['none_of']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'hello' in concept2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSdXnUMOjOAh",
        "outputId": "88e04f90-d29a-4b4c-ce5a-fd4d00b32483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def hard_ground(nlp, sent, cpnet_vocab):\n",
        "#     sent = sent.lower()\n",
        "#     doc = nlp(sent)\n",
        "#     res = set()\n",
        "#     for t in doc:\n",
        "#         if t.lemma_ in cpnet_vocab:\n",
        "#             res.add(t.lemma_)\n",
        "#     sent = \" \".join([t.text for t in doc])\n",
        "#     if sent in cpnet_vocab:\n",
        "#         res.add(sent)\n",
        "#     try:\n",
        "#         assert len(res) > 0\n",
        "#     except Exception:\n",
        "#         print(f\"for {sent}, concept not found in hard grounding.\")\n",
        "#     return res"
      ],
      "metadata": {
        "id": "tlfwMu9OioNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTcfYOX0uiXJ"
      },
      "outputs": [],
      "source": [
        "def extract_concepts(q_stem):\n",
        "\n",
        "  sent = q_stem.lower()\n",
        "  doc = nlp(sent)\n",
        "  question_concepts = set()\n",
        "  for t in doc:\n",
        "    if t.lemma_ in concept2id:\n",
        "      question_concepts.add(t.lemma_)\n",
        "  sent = \" \".join([t.text for t in doc])\n",
        "  if sent in concept2id:\n",
        "    question_concepts.add(sent)\n",
        "  try:\n",
        "    assert len(question_concepts) > 0\n",
        "  except Exception:\n",
        "      print(f\"for {sent}, concept not found in hard grounding.\")\n",
        "\n",
        "  # new_question_concepts=[]\n",
        "  # for i in range(len(question_concepts)):\n",
        "  #   first_concept=question_concepts[i]\n",
        "  #   is_sub_concept=False\n",
        "  #   for j in range(len(question_concepts)):\n",
        "  #     if i==j:\n",
        "  #       continue\n",
        "  #     if first_concept in question_concepts[j]:\n",
        "  #       is_sub_concept=True\n",
        "  #       break\n",
        "\n",
        "  #   if is_sub_concept==False:\n",
        "  #     new_question_concepts.append(first_concept)\n",
        "\n",
        "\n",
        "  # meaningful_question_concepts=set()\n",
        "  # for concept in new_question_concepts:\n",
        "  #   if concept in wn.words():\n",
        "  #     meaningful_question_concepts.add(concept)\n",
        "  #     continue\n",
        "\n",
        "  #   concept_subwords=concept.split(\" \")\n",
        "  #   all_are_meaningful=True\n",
        "  #   meaningfuls=[]\n",
        "  #   for subword in concept_subwords:\n",
        "  #     if len(subword)<=2:\n",
        "  #       all_are_meaningful=False\n",
        "  #       continue\n",
        "\n",
        "  #     if subword in wn.words():\n",
        "  #       meaningfuls.append(subword)\n",
        "  #     else:\n",
        "  #       all_are_meaningful=False\n",
        "  #   if all_are_meaningful:\n",
        "  #     meaningful_question_concepts.add(concept)\n",
        "  #   else:\n",
        "  #     for c in meaningfuls:\n",
        "  #       meaningful_question_concepts.add(c)\n",
        "\n",
        "  return list(question_concepts)\n",
        "\n",
        "\n",
        "def preprocess_qa(question_list, is_train_data):\n",
        "\n",
        "  processed_qs=[]\n",
        "  id_to_label={0:\"A\", 1:\"B\", 2:\"C\", 3:\"D\"}\n",
        "\n",
        "  for i in tqdm(range(len(question_list))):\n",
        "\n",
        "    sample=question_list.iloc[i]\n",
        "    q_stem=sample['question'].strip().lower()\n",
        "    q_choices_list=sample['choice_list']\n",
        "    if is_train_data:\n",
        "      q_answerKey=id_to_label[sample['label']]\n",
        "      q_id=sample['id']\n",
        "    else:\n",
        "      q_id=i\n",
        "\n",
        "\n",
        "    meaningful_question_concepts = extract_concepts(q_stem)\n",
        "\n",
        "    q_choices=[]\n",
        "\n",
        "    for j in range(len(q_choices_list)):\n",
        "      if j==0:\n",
        "        choice_label=\"A\"\n",
        "      elif j==1:\n",
        "        choice_label=\"B\"\n",
        "      elif j==2:\n",
        "        choice_label=\"C\"\n",
        "      else:\n",
        "        choice_label=\"D\"\n",
        "\n",
        "      choice_text=q_choices_list[j]\n",
        "      choice_dict={\n",
        "          'label': choice_label,\n",
        "          'text': choice_text.strip().lower()\n",
        "      }\n",
        "      meaningful_choice_concepts = extract_concepts(choice_dict['text'])\n",
        "\n",
        "      choice_dict['choice_concepts']= meaningful_choice_concepts\n",
        "      q_choices.append(choice_dict)\n",
        "\n",
        "    if is_train_data:\n",
        "      q_dict={\n",
        "            'id':q_id,\n",
        "            'answerKey':q_answerKey,\n",
        "            'question':{\n",
        "                'question_concept': meaningful_question_concepts,\n",
        "                'choices': q_choices,\n",
        "                'stem': q_stem,\n",
        "            }\n",
        "        }\n",
        "    else:\n",
        "        q_dict={\n",
        "            'id':q_id,\n",
        "            'question':{\n",
        "                'question_concept': meaningful_question_concepts,\n",
        "                'choices': q_choices,\n",
        "                'stem': q_stem,\n",
        "            }\n",
        "        }\n",
        "    processed_qs.append(q_dict)\n",
        "\n",
        "  return processed_qs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "mwGpvmgKvTpR",
        "outputId": "3627dcec-39b0-4ab9-f99f-e8f89b982248"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         question  \\\n",
              "0  What kind of nut has no shell?   \n",
              "\n",
              "                                         choice_list  \n",
              "0  [A peanut., A Doughnut., A walnut., None of ab...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3010eb5d-c56a-48d0-9fe3-7cdfebd67ecd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What kind of nut has no shell?</td>\n",
              "      <td>[A peanut., A Doughnut., A walnut., None of ab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3010eb5d-c56a-48d0-9fe3-7cdfebd67ecd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3010eb5d-c56a-48d0-9fe3-7cdfebd67ecd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3010eb5d-c56a-48d0-9fe3-7cdfebd67ecd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "WP_val_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAQCNCMEuiUY",
        "outputId": "dec70b83-7c3a-441d-fe02-701f0c5f5a4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 28/120 [00:00<00:02, 36.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abbit ., concept not found in hard grounding.\n",
            "for abbit ., concept not found in hard grounding.\n",
            "for smie ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 36/120 [00:01<00:02, 33.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for cowcowcowcoww, concept not found in hard grounding.\n",
            "for cowcowcowcoww, concept not found in hard grounding.\n",
            "for cobcobb, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▎   | 75/120 [00:02<00:01, 41.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n",
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n",
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 105/120 [00:02<00:00, 43.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for 28.0, concept not found in hard grounding.\n",
            "for 30.0, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:03<00:00, 39.47it/s]\n"
          ]
        }
      ],
      "source": [
        "# processed_dev_qs=preprocess_qa(SP_val_df, is_train_data=False)\n",
        "processed_dev_qs=preprocess_qa(WP_val_df, is_train_data=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_dev_qs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf82vGCwkfER",
        "outputId": "45d24073-9ec9-4fc7-e41f-d35f1f4554d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 0,\n",
              " 'question': {'question_concept': ['kind',\n",
              "   'no',\n",
              "   'of',\n",
              "   'have',\n",
              "   'shell',\n",
              "   'what',\n",
              "   'nut'],\n",
              "  'choices': [{'label': 'A',\n",
              "    'text': 'a peanut.',\n",
              "    'choice_concepts': ['peanut', 'a']},\n",
              "   {'label': 'B', 'text': 'a doughnut.', 'choice_concepts': ['doughnut', 'a']},\n",
              "   {'label': 'C', 'text': 'a walnut.', 'choice_concepts': ['walnut', 'a']},\n",
              "   {'label': 'D',\n",
              "    'text': 'none of above.',\n",
              "    'choice_concepts': ['above', 'none', 'of']}],\n",
              "  'stem': 'what kind of nut has no shell?'}}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrvWcpgKpUTc"
      },
      "outputs": [],
      "source": [
        "# with open(f'{DATA_FOLDER}/SP_dev_preprocessed.jsonl', 'w') as outfile:\n",
        "with open(f'{DATA_FOLDER}/WP_dev_preprocessed2.jsonl', 'w') as outfile:\n",
        "  for entry in processed_dev_qs:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "EGk_1DPMvRNr",
        "outputId": "b62f2503-14d5-42f8-932c-29a7db944052"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                   question             answer  \\\n",
              "0  WP-0  How do you spell COW in thirteen letters?  SEE O DOUBLE YOU.   \n",
              "\n",
              "     distractor1      distractor2 distractor(unsure)  label  \\\n",
              "0  COWCOWCOWCOWW  SEE OH DEREFORD     None of above.      1   \n",
              "\n",
              "                                         choice_list  choice_order  \n",
              "0  [SEE OH DEREFORD, SEE O DOUBLE YOU., COWCOWCOW...  [2, 0, 1, 3]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c135aab-7818-40f0-ba50-c19d4e8fccb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>distractor1</th>\n",
              "      <th>distractor2</th>\n",
              "      <th>distractor(unsure)</th>\n",
              "      <th>label</th>\n",
              "      <th>choice_list</th>\n",
              "      <th>choice_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WP-0</td>\n",
              "      <td>How do you spell COW in thirteen letters?</td>\n",
              "      <td>SEE O DOUBLE YOU.</td>\n",
              "      <td>COWCOWCOWCOWW</td>\n",
              "      <td>SEE OH DEREFORD</td>\n",
              "      <td>None of above.</td>\n",
              "      <td>1</td>\n",
              "      <td>[SEE OH DEREFORD, SEE O DOUBLE YOU., COWCOWCOW...</td>\n",
              "      <td>[2, 0, 1, 3]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c135aab-7818-40f0-ba50-c19d4e8fccb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c135aab-7818-40f0-ba50-c19d4e8fccb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c135aab-7818-40f0-ba50-c19d4e8fccb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "WP_train_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF2Cw7ijoYQQ",
        "outputId": "5c9c79a4-d484-4748-8ec9-be30b7c96bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 5/396 [00:00<00:15, 24.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for cowcowcowcoww, concept not found in hard grounding.\n",
            "for cowcowcowcoww, concept not found in hard grounding.\n",
            "for cobcobb, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 27/396 [00:01<00:14, 26.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for 28.0, concept not found in hard grounding.\n",
            "for 30.0, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 42/396 [00:01<00:11, 30.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abbit ., concept not found in hard grounding.\n",
            "for abbit ., concept not found in hard grounding.\n",
            "for smie ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 93/396 [00:03<00:12, 25.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n",
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n",
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▋      | 144/396 [00:05<00:08, 29.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for e., concept not found in hard grounding.\n",
            "for o., concept not found in hard grounding.\n",
            "for z., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 173/396 [00:06<00:05, 41.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for hho ., concept not found in hard grounding.\n",
            "for hho ., concept not found in hard grounding.\n",
            "for hotwa ., concept not found in hard grounding.\n",
            "for hotho ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 210/396 [00:07<00:04, 45.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for leftside ., concept not found in hard grounding.\n",
            "for rightside ., concept not found in hard grounding.\n",
            "for leftside ., concept not found in hard grounding.\n",
            "for rightside ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 225/396 [00:07<00:03, 45.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for stawberries ., concept not found in hard grounding.\n",
            "for stawberries ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 235/396 [00:07<00:03, 45.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for g., concept not found in hard grounding.\n",
            "for h., concept not found in hard grounding.\n",
            "for t., concept not found in hard grounding.\n",
            "for t., concept not found in hard grounding.\n",
            "for g., concept not found in hard grounding.\n",
            "for h., concept not found in hard grounding.\n",
            "for c., concept not found in hard grounding.\n",
            "for cooie ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▋   | 263/396 [00:08<00:02, 53.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for t.c.i ., concept not found in hard grounding.\n",
            "for e., concept not found in hard grounding.\n",
            "for t., concept not found in hard grounding.\n",
            "for d., concept not found in hard grounding.\n",
            "for t., concept not found in hard grounding.\n",
            "for d., concept not found in hard grounding.\n",
            "for e., concept not found in hard grounding.\n",
            "for l., concept not found in hard grounding.\n",
            "for h., concept not found in hard grounding.\n",
            "for b., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▎  | 292/396 [00:08<00:02, 46.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for tookit ., concept not found in hard grounding.\n",
            "for tookit ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▋ | 342/396 [00:09<00:01, 46.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for slingsham ., concept not found in hard grounding.\n",
            "for enclamp ., concept not found in hard grounding.\n",
            "for gaslamp ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 388/396 [00:10<00:00, 47.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for nightwatch ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 396/396 [00:11<00:00, 35.71it/s]\n"
          ]
        }
      ],
      "source": [
        "processed_train_qs=preprocess_qa(WP_train_df, is_train_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYfLayzB10Np"
      },
      "outputs": [],
      "source": [
        "# with open(f'{DATA_FOLDER}/SP_train_preprocessed.jsonl', 'w') as outfile:\n",
        "with open(f'{DATA_FOLDER}/WP_train_preprocessed2.jsonl', 'w') as outfile:\n",
        "  for entry in processed_train_qs:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_train_qs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVn5S7OvlOoA",
        "outputId": "2536cf73-eaf3-4dad-acea-d5f9a8d9dfb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'WP-0',\n",
              " 'answerKey': 'B',\n",
              " 'question': {'question_concept': ['in',\n",
              "   'cow',\n",
              "   'spell',\n",
              "   'do',\n",
              "   'thirteen',\n",
              "   'how',\n",
              "   'you',\n",
              "   'letter'],\n",
              "  'choices': [{'label': 'A',\n",
              "    'text': 'see oh dereford',\n",
              "    'choice_concepts': ['oh', 'see']},\n",
              "   {'label': 'B',\n",
              "    'text': 'see o double you.',\n",
              "    'choice_concepts': ['you', 'double', 'see', 'o']},\n",
              "   {'label': 'C', 'text': 'cowcowcowcoww', 'choice_concepts': []},\n",
              "   {'label': 'D',\n",
              "    'text': 'none of above.',\n",
              "    'choice_concepts': ['above', 'none', 'of']}],\n",
              "  'stem': 'how do you spell cow in thirteen letters?'}}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzXyXIemuNsS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "{'id': 'cxzvpoiuzckf-3123',\n",
        " 'question': {'stem': 'A man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand backwards and forwards across a field the size of a football pitch.  What is the one thing he can put in it to make it lighter?',\n",
        "  'choices': [{'label': 'A', 'text': 'throw'},\n",
        "   {'label': 'B', 'text': 'bit'},\n",
        "   {'label': 'C', 'text': 'gallon'},\n",
        "   {'label': 'D', 'text': 'mouse'},\n",
        "   {'label': 'E', 'text': 'hole', 'choice_concepts':[]}]},\n",
        " 'answerKey': 'E'}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMD8EoP5upFT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsQJXNdcupCE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg7kCoV3uo_Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deB-LosZuo9P"
      },
      "outputs": [],
      "source": [
        "# def extract_concepts(q_stem):\n",
        "\n",
        "#   question_concepts=[]\n",
        "#   for i in range(len(id2concept)):\n",
        "#     concept=id2concept[i].strip().lower().replace(\"_\",\" \")\n",
        "#     if len(concept)<=2:\n",
        "#       continue\n",
        "#     if concept in q_stem:\n",
        "#       question_concepts.append(concept)\n",
        "\n",
        "\n",
        "#   new_question_concepts=[]\n",
        "#   for i in range(len(question_concepts)):\n",
        "#     first_concept=question_concepts[i]\n",
        "#     is_sub_concept=False\n",
        "#     for j in range(len(question_concepts)):\n",
        "#       if i==j:\n",
        "#         continue\n",
        "#       if first_concept in question_concepts[j]:\n",
        "#         is_sub_concept=True\n",
        "#         break\n",
        "\n",
        "#     if is_sub_concept==False:\n",
        "#       new_question_concepts.append(first_concept)\n",
        "\n",
        "\n",
        "#   meaningful_question_concepts=set()\n",
        "#   for concept in new_question_concepts:\n",
        "#     if concept in wn.words():\n",
        "#       meaningful_question_concepts.add(concept)\n",
        "#       continue\n",
        "\n",
        "#     concept_subwords=concept.split(\" \")\n",
        "#     all_are_meaningful=True\n",
        "#     meaningfuls=[]\n",
        "#     for subword in concept_subwords:\n",
        "#       if len(subword)<=2:\n",
        "#         all_are_meaningful=False\n",
        "#         continue\n",
        "\n",
        "#       if subword in wn.words():\n",
        "#         meaningfuls.append(subword)\n",
        "#       else:\n",
        "#         all_are_meaningful=False\n",
        "#     if all_are_meaningful:\n",
        "#       meaningful_question_concepts.add(concept)\n",
        "#     else:\n",
        "#       for c in meaningfuls:\n",
        "#         meaningful_question_concepts.add(c)\n",
        "\n",
        "#   return list(meaningful_question_concepts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYtXg9P9uo3-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-Tm0jETk-Kv"
      },
      "source": [
        "##<font color=lightgreen>Calc concept occurance frequesncy</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngD1X0kf_owV"
      },
      "source": [
        "###riddle_sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILkVxlSPjrFh",
        "outputId": "d00f31aa-41d5-4519-d5bb-fba938d4bb41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Riddle-Sense train size: 3510, Riddle-Sense dev size: 1021\n"
          ]
        }
      ],
      "source": [
        "DATA_FOLDER=\"/content/drive/MyDrive/brain_teaser/datasets\"\n",
        "\n",
        "\n",
        "linked_qa_file=f\"{DATA_FOLDER}/rs_train_preprocessed.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  rs_train_instances = [json.loads(line) for line in f.read().split(\"\\n\") if line]\n",
        "\n",
        "linked_qa_file=f\"{DATA_FOLDER}/rs_dev_preprocessed.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  rs_dev_instances = [json.loads(line) for line in f.read().split(\"\\n\") if line]\n",
        "\n",
        "print(f\"Riddle-Sense train size: {len(rs_train_instances)}, Riddle-Sense dev size: {len(rs_dev_instances)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPGLXgq5lHUf",
        "outputId": "b682ff82-f270-4db7-f292-43f66019bf01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3510/3510 [00:00<00:00, 147817.25it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "5501"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concepts_frequency={}\n",
        "\n",
        "for i in tqdm(range(len(rs_train_instances))):\n",
        "  qa_sample=rs_train_instances[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  for concept in question_concepts:\n",
        "    concept_counter=concepts_frequency.get(concept)\n",
        "    if concept_counter!=None:\n",
        "      concepts_frequency[concept]=(concept_counter+1)\n",
        "    else:\n",
        "      concepts_frequency[concept]=1\n",
        "\n",
        "len(concepts_frequency.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVkTADsRrhDr",
        "outputId": "bba8beea-df60-434c-a8b3-19be36930560"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1021/1021 [00:00<00:00, 46236.56it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6435"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in tqdm(range(len(rs_dev_instances))):\n",
        "  qa_sample=rs_dev_instances[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  for concept in question_concepts:\n",
        "    concept_counter=concepts_frequency.get(concept)\n",
        "    if concept_counter!=None:\n",
        "      concepts_frequency[concept]=(concept_counter+1)\n",
        "    else:\n",
        "      concepts_frequency[concept]=1\n",
        "\n",
        "len(concepts_frequency.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F35CBXdapkEi"
      },
      "outputs": [],
      "source": [
        "sorted_dict={k: v for k, v in sorted(concepts_frequency.items(), key=lambda item: item[1], reverse=True)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLG_IZtxsrta"
      },
      "outputs": [],
      "source": [
        "most_common_concepts=['but',\n",
        " 'can',\n",
        " 'have',\n",
        " 'not',\n",
        " 'are',\n",
        " 'there',\n",
        " 'man',\n",
        " 'one',\n",
        " 'never',\n",
        " 'who',\n",
        " 'will',\n",
        " 'yet',\n",
        " 'all',\n",
        " 'get',\n",
        " 'why',\n",
        " 'many',\n",
        " 'out',\n",
        " 'two',\n",
        " 'only',\n",
        " 'then',\n",
        " 'make',\n",
        " 'like',\n",
        " 'always',\n",
        " 'possible',\n",
        " 'people',\n",
        " 'name',\n",
        " 'down',\n",
        " 'time',\n",
        " 'say',\n",
        " 'use',\n",
        " 'more',\n",
        " 'know',\n",
        " 'same',\n",
        " 'said',\n",
        " 'come',\n",
        " 'son',\n",
        " 'take',\n",
        " 'left',\n",
        " 'don',\n",
        " 'first',\n",
        " 'around',\n",
        " 'kind',\n",
        " 'want',\n",
        " 'find',\n",
        " 'some',\n",
        " 'there are',\n",
        " 'way',\n",
        " 'still',\n",
        " 'through',\n",
        " 'thing',\n",
        " 'end',\n",
        " 'men',\n",
        " 'sometimes',\n",
        " 'put',\n",
        " 'nothing',\n",
        " 'away',\n",
        " 'person',\n",
        " 'each',\n",
        " 'other',\n",
        " 'stop',\n",
        " 'right',\n",
        " 'hold',\n",
        " 'going',\n",
        " 'once',\n",
        " 'may',\n",
        " 'just',\n",
        " 'made',\n",
        " 'used',\n",
        " 'most',\n",
        " 'found',\n",
        " 'after',\n",
        " 'second',\n",
        " 'even',\n",
        " 'both',\n",
        " 'much',\n",
        " 'here',\n",
        " 'give',\n",
        " 'every',\n",
        " 'also',\n",
        " 'number',\n",
        " 'though',\n",
        " 'while',\n",
        " 'someone',\n",
        " 'word',\n",
        " 'full',\n",
        " 'third',\n",
        " 'any',\n",
        " 'body',\n",
        " 'before',\n",
        " 'tail',\n",
        " 'cant',\n",
        " 'hear',\n",
        " 'half',\n",
        " 'about',\n",
        " 'keep',\n",
        " 'stand',\"ways\",\n",
        " 'now',\"red\", \"black\", \"brown\", \"white\", \"round\",\"nearly\",\"green\",\"ever\",\"near\",\"very\",\n",
        "\"which\", \"what\", \"where\", \"when\", \"how\", \"who\", \"why\"\n",
        " ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1srudyfIwXd8",
        "outputId": "41ec7690-4501-44e4-9013-e9f7edef2d18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(most_common_concepts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUjA01BJpqE-",
        "outputId": "7be8adc2-1c8e-4414-8295-46eacb194c73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'but': 950,\n",
              " 'can': 721,\n",
              " 'have': 463,\n",
              " 'not': 385,\n",
              " 'are': 353,\n",
              " 'there': 349,\n",
              " 'man': 323,\n",
              " 'one': 269,\n",
              " 'never': 264,\n",
              " 'who': 236,\n",
              " 'will': 222,\n",
              " 'yet': 213,\n",
              " 'all': 208,\n",
              " 'see': 193,\n",
              " 'get': 176,\n",
              " 'why': 175,\n",
              " 'many': 170,\n",
              " 'out': 165,\n",
              " 'two': 144,\n",
              " 'only': 144,\n",
              " 'then': 128,\n",
              " 'make': 126,\n",
              " 'like': 126,\n",
              " 'always': 121,\n",
              " 'white': 113,\n",
              " 'black': 111,\n",
              " 'possible': 111,\n",
              " 'people': 108,\n",
              " 'three': 107,\n",
              " 'name': 102,\n",
              " 'down': 101,\n",
              " 'water': 100,\n",
              " 'day': 100,\n",
              " 'time': 98,\n",
              " 'say': 97,\n",
              " 'red': 97,\n",
              " 'use': 97,\n",
              " 'car': 96,\n",
              " 'more': 95,\n",
              " 'know': 93,\n",
              " 'same': 91,\n",
              " 'said': 90,\n",
              " 'head': 89,\n",
              " 'come': 88,\n",
              " 'son': 88,\n",
              " 'back': 87,\n",
              " 'take': 85,\n",
              " 'left': 85,\n",
              " 'call': 80,\n",
              " 'don': 78,\n",
              " 'first': 78,\n",
              " 'around': 77,\n",
              " 'kind': 76,\n",
              " 'want': 76,\n",
              " 'find': 74,\n",
              " 'world': 74,\n",
              " 'eat': 74,\n",
              " 'father': 74,\n",
              " 'some': 73,\n",
              " 'night': 72,\n",
              " 'light': 71,\n",
              " 'eyes': 70,\n",
              " 'there are': 70,\n",
              " 'four': 64,\n",
              " 'long': 64,\n",
              " 'way': 64,\n",
              " 'life': 63,\n",
              " 'still': 63,\n",
              " 'through': 63,\n",
              " 'die': 62,\n",
              " 'thing': 62,\n",
              " 'end': 62,\n",
              " 'house': 62,\n",
              " 'men': 60,\n",
              " 'legs': 59,\n",
              " 'sometimes': 59,\n",
              " 'inside': 59,\n",
              " 'put': 58,\n",
              " 'dead': 58,\n",
              " 'nothing': 58,\n",
              " 'away': 58,\n",
              " 'look': 58,\n",
              " 'person': 57,\n",
              " 'boy': 57,\n",
              " 'each': 56,\n",
              " 'tell': 55,\n",
              " 'walk': 55,\n",
              " 'other': 55,\n",
              " 'big': 54,\n",
              " 'stop': 54,\n",
              " 'right': 54,\n",
              " 'green': 53,\n",
              " 'days': 53,\n",
              " 'room': 53,\n",
              " 'hold': 52,\n",
              " 'going': 52,\n",
              " 'move': 51,\n",
              " 'home': 51,\n",
              " 'once': 51,\n",
              " 'may': 50,\n",
              " 'just': 50,\n",
              " 'made': 50,\n",
              " 'used': 50,\n",
              " 'live': 49,\n",
              " 'most': 49,\n",
              " 'found': 49,\n",
              " 'place': 49,\n",
              " 'middle': 49,\n",
              " 'after': 49,\n",
              " 'second': 49,\n",
              " 'even': 48,\n",
              " 'both': 48,\n",
              " 'much': 48,\n",
              " 'need': 48,\n",
              " 'here': 48,\n",
              " 'give': 47,\n",
              " 'every': 47,\n",
              " 'also': 47,\n",
              " 'run': 46,\n",
              " 'mother': 46,\n",
              " 'number': 45,\n",
              " 'though': 44,\n",
              " 'while': 44,\n",
              " 'someone': 44,\n",
              " 'friday': 44,\n",
              " 'word': 43,\n",
              " 'full': 43,\n",
              " 'third': 43,\n",
              " 'brown': 43,\n",
              " 'any': 42,\n",
              " 'body': 42,\n",
              " 'alive': 42,\n",
              " 'before': 42,\n",
              " 'old': 41,\n",
              " 'hard': 41,\n",
              " 'tail': 41,\n",
              " 'small': 41,\n",
              " 'cant': 41,\n",
              " 'face': 41,\n",
              " 'road': 40,\n",
              " 'hear': 39,\n",
              " 'half': 39,\n",
              " 'about': 39,\n",
              " 'keep': 39,\n",
              " 'stand': 39,\n",
              " 'dark': 39,\n",
              " 'now': 39,\n",
              " 'town': 39,\n",
              " 'round': 38,\n",
              " 'touch': 38,\n",
              " 'off': 38,\n",
              " 'love': 38,\n",
              " 'must': 37,\n",
              " 'side': 37,\n",
              " 'fly': 37,\n",
              " 'air': 37,\n",
              " 'between': 37,\n",
              " 'earth': 37,\n",
              " 'dog': 37,\n",
              " 'one day': 37,\n",
              " 'riddle': 36,\n",
              " 'turn': 36,\n",
              " 'cold': 36,\n",
              " 'outside': 36,\n",
              " 'over': 36,\n",
              " 'break': 35,\n",
              " 'answer': 35,\n",
              " 'different': 35,\n",
              " 'blue': 35,\n",
              " 'color': 35,\n",
              " 'eye': 35,\n",
              " 'windows': 35,\n",
              " 'buy': 35,\n",
              " 'saw': 35,\n",
              " 'driving': 35,\n",
              " 'can not': 34,\n",
              " 'born': 34,\n",
              " 'yellow': 34,\n",
              " 'animal': 34,\n",
              " 'wet': 33,\n",
              " 'under': 33,\n",
              " 'whole': 33,\n",
              " 'usually': 33,\n",
              " 'ground': 33,\n",
              " 'hands': 33,\n",
              " 'hair': 33,\n",
              " 'street': 33,\n",
              " 'five': 32,\n",
              " 'start': 32,\n",
              " 'doctor': 32,\n",
              " 'cat': 32,\n",
              " 'next': 32,\n",
              " 'kill': 31,\n",
              " 'sky': 31,\n",
              " 'can see': 31,\n",
              " 'play': 31,\n",
              " 'hole': 31,\n",
              " 'help': 31,\n",
              " 'own': 31,\n",
              " 'short': 30,\n",
              " 'work': 30,\n",
              " 'mouth': 30,\n",
              " 'good': 30,\n",
              " 'behind': 30,\n",
              " 'tall': 30,\n",
              " 'order': 30,\n",
              " 'wear': 29,\n",
              " 'last': 29,\n",
              " 'question': 29,\n",
              " 'too': 29,\n",
              " 'thin': 29,\n",
              " 'favorite': 29,\n",
              " 'brother': 29,\n",
              " 'woman': 29,\n",
              " 'front': 29,\n",
              " 'all over': 28,\n",
              " 'sea': 28,\n",
              " 'leave': 28,\n",
              " 'land': 28,\n",
              " 'door': 28,\n",
              " 'type': 28,\n",
              " 'plane crash': 28,\n",
              " 'open': 28,\n",
              " 'hand': 27,\n",
              " 'often': 27,\n",
              " 'tree': 27,\n",
              " 'matter': 27,\n",
              " 'guy': 27,\n",
              " 'think': 27,\n",
              " 'words': 26,\n",
              " 'lose': 26,\n",
              " 'heard': 26,\n",
              " 'little': 26,\n",
              " 'hot': 26,\n",
              " 'ten': 26,\n",
              " 'girl': 26,\n",
              " 'stays': 26,\n",
              " 'mean': 26,\n",
              " 'fish': 26,\n",
              " 'get out': 26,\n",
              " 'another': 26,\n",
              " 'let': 25,\n",
              " 'cry': 25,\n",
              " 'skin': 25,\n",
              " 'arms': 25,\n",
              " 'heart': 25,\n",
              " 'horse': 25,\n",
              " 'sun': 25,\n",
              " 'ever': 25,\n",
              " 'king': 25,\n",
              " 'nobody': 25,\n",
              " 'wrong': 25,\n",
              " 'operate': 25,\n",
              " 'things': 24,\n",
              " 'fast': 24,\n",
              " 'less': 24,\n",
              " 'try': 24,\n",
              " 'part': 24,\n",
              " 'everyday': 24,\n",
              " 'food': 24,\n",
              " 'none': 24,\n",
              " 'stay': 24,\n",
              " 'money': 24,\n",
              " 'imagine': 24,\n",
              " 'bury': 24,\n",
              " 'cross': 24,\n",
              " 'hospital': 24,\n",
              " 'corner': 24,\n",
              " 'win': 24,\n",
              " 'within': 23,\n",
              " 'won': 23,\n",
              " 'again': 23,\n",
              " 'empty': 23,\n",
              " 'year': 23,\n",
              " 'lot': 23,\n",
              " 'death': 23,\n",
              " 'floor': 23,\n",
              " 'standing': 23,\n",
              " 'across': 22,\n",
              " 'wings': 22,\n",
              " 'living': 22,\n",
              " 'read': 22,\n",
              " 'true': 22,\n",
              " 'filled': 22,\n",
              " 'wife': 22,\n",
              " 'store': 22,\n",
              " 'needs': 22,\n",
              " 'seven': 22,\n",
              " 'throw': 22,\n",
              " 'taken': 22,\n",
              " 'might': 21,\n",
              " 'sound': 21,\n",
              " 'bed': 21,\n",
              " 'blood': 21,\n",
              " 'mind': 21,\n",
              " 'sleep': 21,\n",
              " 'gold': 21,\n",
              " 'few': 21,\n",
              " 'fourth': 21,\n",
              " 'rest': 21,\n",
              " 'lost': 21,\n",
              " 'common': 21,\n",
              " 'best': 21,\n",
              " 'morning': 21,\n",
              " 'bar': 21,\n",
              " 'grow': 21,\n",
              " 'top': 21,\n",
              " 'boat': 21,\n",
              " 'dad': 21,\n",
              " 'box': 21,\n",
              " 'border': 21,\n",
              " 'bad': 21,\n",
              " 'rain': 21,\n",
              " 'dry': 20,\n",
              " 'everywhere': 20,\n",
              " 'glass': 20,\n",
              " 'quite': 20,\n",
              " 'ate': 20,\n",
              " 'neither': 20,\n",
              " 'ask': 20,\n",
              " 'far': 20,\n",
              " 'soft': 20,\n",
              " 'some people': 20,\n",
              " 'wood': 20,\n",
              " 'together': 20,\n",
              " 'hit': 20,\n",
              " 'man who': 20,\n",
              " 'fire': 19,\n",
              " 'god': 19,\n",
              " 'every day': 19,\n",
              " 'hill': 19,\n",
              " 'given': 19,\n",
              " 'bird': 19,\n",
              " 'rock': 19,\n",
              " 'ring': 19,\n",
              " 'today': 19,\n",
              " 'really': 19,\n",
              " 'fit': 19,\n",
              " 'ice': 19,\n",
              " 'child': 19,\n",
              " 'twice': 19,\n",
              " 'show': 19,\n",
              " 'lighter': 18,\n",
              " 'size': 18,\n",
              " 'sing': 18,\n",
              " 'truth': 18,\n",
              " 'young': 18,\n",
              " 'square': 18,\n",
              " 'near': 18,\n",
              " 'walking': 18,\n",
              " 'ball': 18,\n",
              " 'friend': 18,\n",
              " 'rushed': 18,\n",
              " 'shot': 18,\n",
              " 'backwards': 17,\n",
              " 'carry': 17,\n",
              " 'feather': 17,\n",
              " 'being': 17,\n",
              " 'four legs': 17,\n",
              " 'darkness': 17,\n",
              " 'enough': 17,\n",
              " 'well': 17,\n",
              " 'stairs': 17,\n",
              " 'fill': 17,\n",
              " 'known': 17,\n",
              " 'wind': 17,\n",
              " 'key': 17,\n",
              " 'large': 17,\n",
              " 'south': 17,\n",
              " 'single person': 17,\n",
              " 'umbrella': 17,\n",
              " 'teeth': 17,\n",
              " 'game': 17,\n",
              " 'hurt': 17,\n",
              " 'clean': 17,\n",
              " 'fall': 16,\n",
              " 'longer': 16,\n",
              " 'gone': 16,\n",
              " 'hate': 16,\n",
              " 'have one': 16,\n",
              " 'cool': 16,\n",
              " 'guess': 16,\n",
              " 'deep': 16,\n",
              " 'catch': 16,\n",
              " 'past': 16,\n",
              " 'travel': 16,\n",
              " 'mom': 16,\n",
              " 'six': 16,\n",
              " 'but one': 16,\n",
              " 'colors': 16,\n",
              " 'sister': 16,\n",
              " 'bring': 16,\n",
              " 'change': 16,\n",
              " 'numbers': 16,\n",
              " 'sunday': 16,\n",
              " 'come out': 16,\n",
              " 'who are': 16,\n",
              " 'canada': 16,\n",
              " 'happen': 16,\n",
              " 'city': 16,\n",
              " 'school': 16,\n",
              " 'bite': 16,\n",
              " 'gun': 16,\n",
              " 'field': 15,\n",
              " 'broken': 15,\n",
              " 'spell': 15,\n",
              " 'times': 15,\n",
              " 'cut': 15,\n",
              " 'become': 15,\n",
              " 'later': 15,\n",
              " 'ocean': 15,\n",
              " 'blind': 15,\n",
              " 'great': 15,\n",
              " 'add': 15,\n",
              " 'fear': 15,\n",
              " 'flesh': 15,\n",
              " 'close': 15,\n",
              " 'minutes': 15,\n",
              " 'high': 15,\n",
              " 'fruit': 15,\n",
              " 'above': 15,\n",
              " 'drink': 15,\n",
              " 'following': 15,\n",
              " 'falls': 15,\n",
              " 'ways': 15,\n",
              " 'law': 15,\n",
              " 'almost': 15,\n",
              " 'nose': 15,\n",
              " 'chicken': 15,\n",
              " 'mexico': 15,\n",
              " 'bridge': 15,\n",
              " 'wednesday': 15,\n",
              " 'flies': 15,\n",
              " 'shape': 15,\n",
              " 'fat': 15,\n",
              " 'breathe': 14,\n",
              " 'running': 14,\n",
              " 'clear': 14,\n",
              " 'paper': 14,\n",
              " 'river': 14,\n",
              " 'cause': 14,\n",
              " 'real': 14,\n",
              " 'foot': 14,\n",
              " 'weigh': 14,\n",
              " 'save': 14,\n",
              " 'coming': 14,\n",
              " 'feel': 14,\n",
              " 'strong': 14,\n",
              " 'lie': 14,\n",
              " 'sit': 14,\n",
              " 'all day': 14,\n",
              " 'point': 14,\n",
              " 'swim': 14,\n",
              " 'famous': 14,\n",
              " 'moon': 14,\n",
              " 'fifth': 14,\n",
              " 'sitting': 14,\n",
              " 'meet': 14,\n",
              " 'lady': 14,\n",
              " 'plane': 14,\n",
              " 'cow': 14,\n",
              " 'hint': 14,\n",
              " 'count': 14,\n",
              " 'stone': 14,\n",
              " 'many people': 14,\n",
              " 'driver': 14,\n",
              " 'white house': 14,\n",
              " 'space': 14,\n",
              " 'cowboy': 14,\n",
              " 'have none': 14,\n",
              " 'barrel': 13,\n",
              " 'ride': 13,\n",
              " 'talk': 13,\n",
              " 'new': 13,\n",
              " 'all around': 13,\n",
              " 'alone': 13,\n",
              " 'follow': 13,\n",
              " 'straight': 13,\n",
              " 'hide': 13,\n",
              " 'set': 13,\n",
              " 'stops': 13,\n",
              " 'pink': 13,\n",
              " 'stick': 13,\n",
              " 'egg': 13,\n",
              " 'happy': 13,\n",
              " 'have two': 13,\n",
              " 'yesterday': 13,\n",
              " 'speak': 13,\n",
              " 'done': 13,\n",
              " 'escape': 13,\n",
              " 'eggs': 13,\n",
              " 'sight': 13,\n",
              " 'heavy': 13,\n",
              " 'begin': 13,\n",
              " 'race': 13,\n",
              " 'able': 13,\n",
              " 'tuesday': 13,\n",
              " 'using': 13,\n",
              " 'monday': 13,\n",
              " 'orange': 13,\n",
              " 'looking': 13,\n",
              " 'baby': 13,\n",
              " 'red house': 13,\n",
              " 'rich': 13,\n",
              " 'yes': 12,\n",
              " 'easily': 12,\n",
              " 'creature': 12,\n",
              " 'eight': 12,\n",
              " 'clothes': 12,\n",
              " 'two people': 12,\n",
              " 'ship': 12,\n",
              " 'very': 12,\n",
              " 'sad': 12,\n",
              " 'wide': 12,\n",
              " 'hours': 12,\n",
              " 'form': 12,\n",
              " 'pass': 12,\n",
              " 'cant see': 12,\n",
              " 'sent': 12,\n",
              " 'elephant': 12,\n",
              " 'slow': 12,\n",
              " 'wearing': 12,\n",
              " 'green house': 12,\n",
              " 'cheese': 12,\n",
              " 'hotel': 12,\n",
              " 'enter': 12,\n",
              " 'stuck': 12,\n",
              " 'bottom': 12,\n",
              " 'survive': 12,\n",
              " 'soon': 11,\n",
              " 'forever': 11,\n",
              " 'loud': 11,\n",
              " 'bright': 11,\n",
              " 'dirty': 11,\n",
              " 'sure': 11,\n",
              " 'least': 11,\n",
              " 'week': 11,\n",
              " 'line': 11,\n",
              " 'thought': 11,\n",
              " 'pair': 11,\n",
              " 'lay': 11,\n",
              " 'appear': 11,\n",
              " 'sweet': 11,\n",
              " 'piece': 11,\n",
              " 'lots': 11,\n",
              " 'bill': 11,\n",
              " 'power': 11,\n",
              " 'war': 11,\n",
              " 'reach': 11,\n",
              " 'will not': 11,\n",
              " 'bee': 11,\n",
              " 'eve': 11,\n",
              " 'computer': 11,\n",
              " 'united': 11,\n",
              " 'waiting': 11,\n",
              " 'buried': 11,\n",
              " 'certain': 11,\n",
              " 'adam': 11,\n",
              " 'pound': 11,\n",
              " 'nice': 11,\n",
              " 'walking down': 11,\n",
              " 'drew': 11,\n",
              " 'needed': 11,\n",
              " 'jail': 11,\n",
              " 'pop': 11,\n",
              " 'look like': 11,\n",
              " 'surgery': 11,\n",
              " 'bigger': 11,\n",
              " 'step': 11,\n",
              " 'hour': 11,\n",
              " 'one thing': 10,\n",
              " 'lack': 10,\n",
              " 'easy': 10,\n",
              " 'can fly': 10,\n",
              " 'center': 10,\n",
              " 'shoes': 10,\n",
              " 'throw away': 10,\n",
              " 'cost': 10,\n",
              " 'rarely': 10,\n",
              " 'moving': 10,\n",
              " 'not walk': 10,\n",
              " 'cup': 10,\n",
              " 'fun': 10,\n",
              " 'lion': 10,\n",
              " 'shop': 10,\n",
              " 'ghost': 10,\n",
              " 'get wet': 10,\n",
              " 'married': 10,\n",
              " 'art': 10,\n",
              " 'means': 10,\n",
              " 'tomorrow': 10,\n",
              " 'wall': 10,\n",
              " 'opposite': 10,\n",
              " 'greater': 10,\n",
              " 'fine': 10,\n",
              " 'table': 10,\n",
              " 'hungry': 10,\n",
              " 'suddenly': 10,\n",
              " 'protect': 10,\n",
              " 'not move': 10,\n",
              " 'bear': 10,\n",
              " 'bus': 10,\n",
              " 'fight': 10,\n",
              " 'coat': 10,\n",
              " 'flying': 10,\n",
              " 'may not': 10,\n",
              " 'one eye': 10,\n",
              " 'touched': 10,\n",
              " 'story': 10,\n",
              " 'sharp': 10,\n",
              " 'tongue': 10,\n",
              " 'family': 10,\n",
              " 'all but': 10,\n",
              " 'car crash': 10,\n",
              " 'poor': 10,\n",
              " 'smile': 10,\n",
              " 'purple': 10,\n",
              " 'blue house': 10,\n",
              " 'voice': 9,\n",
              " 'burn': 9,\n",
              " 'cook': 9,\n",
              " 'pain': 9,\n",
              " 'laugh': 9,\n",
              " 'miss': 9,\n",
              " 'bone': 9,\n",
              " 'eats': 9,\n",
              " 'gray': 9,\n",
              " 'single': 9,\n",
              " 'instead': 9,\n",
              " 'shaped': 9,\n",
              " 'better': 9,\n",
              " 'wish': 9,\n",
              " 'kid': 9,\n",
              " 'grey': 9,\n",
              " 'eating': 9,\n",
              " 'liquid': 9,\n",
              " 'holding': 9,\n",
              " 'wait': 9,\n",
              " 'equal': 9,\n",
              " 'sign': 9,\n",
              " 'probably': 9,\n",
              " 'mountain': 9,\n",
              " 'beginning': 9,\n",
              " 'mary': 9,\n",
              " 'beast': 9,\n",
              " 'share': 9,\n",
              " 'daughter': 9,\n",
              " 'smell': 9,\n",
              " 'why are': 9,\n",
              " 'one man': 9,\n",
              " 'forest': 9,\n",
              " 'quickly': 9,\n",
              " 'pig': 9,\n",
              " 'thursday': 9,\n",
              " 'window': 9,\n",
              " 'row': 9,\n",
              " 'polar': 9,\n",
              " 'fell': 9,\n",
              " 'perfect': 9,\n",
              " 'dirt': 9,\n",
              " 'dime': 9,\n",
              " 'roll': 9,\n",
              " 'birth': 9,\n",
              " 'held': 9,\n",
              " 'explain': 9,\n",
              " 'crash': 9,\n",
              " 'faster': 9,\n",
              " 'accident': 9,\n",
              " 'drive': 9,\n",
              " 'taking': 9,\n",
              " 'rid': 9,\n",
              " 'remain': 9,\n",
              " 'bubble': 9,\n",
              " 'pee': 9,\n",
              " 'can eat': 9,\n",
              " 'mouse': 9,\n",
              " 'but then': 9,\n",
              " 'afraid': 9,\n",
              " 'mask': 9,\n",
              " 'milk': 9,\n",
              " 'snake': 9,\n",
              " 'tears': 9,\n",
              " 'minute': 9,\n",
              " 'forwards': 8,\n",
              " 'parts': 8,\n",
              " 'heat': 8,\n",
              " 'people like': 8,\n",
              " 'desert': 8,\n",
              " 'touching': 8,\n",
              " 'making': 8,\n",
              " 'bit': 8,\n",
              " 'trap': 8,\n",
              " 'beach': 8,\n",
              " 'people have': 8,\n",
              " 'forth': 8,\n",
              " 'hat': 8,\n",
              " 'golden': 8,\n",
              " 'immediately': 8,\n",
              " 'take away': 8,\n",
              " 'blow': 8,\n",
              " 'works': 8,\n",
              " 'tool': 8,\n",
              " 'present': 8,\n",
              " 'bound': 8,\n",
              " 'bones': 8,\n",
              " 'apart': 8,\n",
              " 'feed': 8,\n",
              " 'relation': 8,\n",
              " 'mine': 8,\n",
              " 'taste': 8,\n",
              " 'moment': 8,\n",
              " 'bare': 8,\n",
              " 'painted': 8,\n",
              " 'visit': 8,\n",
              " 'scared': 8,\n",
              " 'felt': 8,\n",
              " 'spot': 8,\n",
              " 'anywhere': 8,\n",
              " 'crossed': 8,\n",
              " 'covered': 8,\n",
              " 'snow': 8,\n",
              " 'meat': 8,\n",
              " 'east': 8,\n",
              " 'related': 8,\n",
              " 'people need': 8,\n",
              " 'doe': 8,\n",
              " 'except': 8,\n",
              " 'usa': 8,\n",
              " 'noise': 8,\n",
              " 'left turn': 8,\n",
              " 'wrong way': 8,\n",
              " 'trip': 8,\n",
              " 'write': 8,\n",
              " 'cows': 8,\n",
              " 'two men': 8,\n",
              " 'clock': 8,\n",
              " 'names': 8,\n",
              " 'america': 8,\n",
              " 'however': 8,\n",
              " 'country': 8,\n",
              " 'remember': 8,\n",
              " 'cover': 8,\n",
              " 'shine': 8,\n",
              " 'played': 8,\n",
              " 'woods': 8,\n",
              " 'lying': 8,\n",
              " 'job': 8,\n",
              " 'one who': 8,\n",
              " 'strength': 8,\n",
              " 'along': 8,\n",
              " 'roots': 8,\n",
              " 'forward': 8,\n",
              " 'each other': 8,\n",
              " 'sold': 8,\n",
              " 'police': 8,\n",
              " 'dig': 8,\n",
              " 'moses': 8,\n",
              " 'pretty': 8,\n",
              " 'building': 8,\n",
              " 'climb': 8,\n",
              " 'team': 8,\n",
              " 'gas': 8,\n",
              " 'instantly': 8,\n",
              " 'normal people': 8,\n",
              " 'comb': 8,\n",
              " 'surrounded': 8,\n",
              " 'wen': 8,\n",
              " 'draw': 8,\n",
              " 'teacher': 8,\n",
              " 'feeling': 8,\n",
              " 'bartender': 8,\n",
              " 'pick': 8,\n",
              " 'send': 8,\n",
              " 'neck': 8,\n",
              " 'devil': 8,\n",
              " 'rope': 8,\n",
              " 'star': 8,\n",
              " 'hie': 8,\n",
              " 'bag': 7,\n",
              " 'prison': 7,\n",
              " 'dance': 7,\n",
              " 'fragile': 7,\n",
              " 'beat': 7,\n",
              " 'giving': 7,\n",
              " 'amount': 7,\n",
              " 'moth': 7,\n",
              " 'deadly': 7,\n",
              " 'quick': 7,\n",
              " 'most people': 7,\n",
              " 'seek': 7,\n",
              " 'tom': 7,\n",
              " 'uca': 7,\n",
              " 'especially': 7,\n",
              " 'smart': 7,\n",
              " 'strange': 7,\n",
              " 'knife': 7,\n",
              " 'pale': 7,\n",
              " 'finished': 7,\n",
              " 'complete': 7,\n",
              " 'people think': 7,\n",
              " 'sorrow': 7,\n",
              " 'not talk': 7,\n",
              " 'force': 7,\n",
              " 'raise': 7,\n",
              " 'grown': 7,\n",
              " 'bold': 7,\n",
              " 'laughter': 7,\n",
              " 'circle': 7,\n",
              " 'penny': 7,\n",
              " 'path': 7,\n",
              " 'fork': 7,\n",
              " 'group': 7,\n",
              " 'colours': 7,\n",
              " 'turned': 7,\n",
              " 'ready': 7,\n",
              " 'every time': 7,\n",
              " 'duck': 7,\n",
              " 'north': 7,\n",
              " 'weather': 7,\n",
              " 'dinner': 7,\n",
              " 'age': 7,\n",
              " 'isn': 7,\n",
              " 'attack': 7,\n",
              " 'dozen': 7,\n",
              " 'nut': 7,\n",
              " 'twins': 7,\n",
              " 'completely': 7,\n",
              " 'bathroom': 7,\n",
              " 'getting': 7,\n",
              " 'single hair': 7,\n",
              " 'sur': 7,\n",
              " 'one side': 7,\n",
              " 'lake': 7,\n",
              " 'person who': 7,\n",
              " 'precious': 7,\n",
              " 'john': 7,\n",
              " 'music': 7,\n",
              " 'leg': 7,\n",
              " 'bus driver': 7,\n",
              " 'sick': 7,\n",
              " 'twenty': 7,\n",
              " 'est': 7,\n",
              " 'april': 7,\n",
              " 'can use': 7,\n",
              " 'smith': 7,\n",
              " 'spent': 7,\n",
              " 'tied': 7,\n",
              " 'roof': 7,\n",
              " 'mark': 7,\n",
              " 'favourite': 7,\n",
              " 'ant': 7,\n",
              " 'higher': 7,\n",
              " 'direction': 7,\n",
              " 'low': 7,\n",
              " 'cute': 7,\n",
              " 'talks': 7,\n",
              " 'stopped': 7,\n",
              " 'gain': 7,\n",
              " 'terrible': 7,\n",
              " 'surgeon': 7,\n",
              " 'years': 7,\n",
              " 'foe': 7,\n",
              " 'ancient': 7,\n",
              " 'song': 7,\n",
              " 'nowhere': 7,\n",
              " 'object': 7,\n",
              " 'apple': 7,\n",
              " 'drown': 7,\n",
              " 'june': 7,\n",
              " 'clue': 7,\n",
              " 'stupid': 7,\n",
              " 'chair': 7,\n",
              " 'pay': 7,\n",
              " 'silent': 7,\n",
              " 'flower': 7,\n",
              " 'every single': 7,\n",
              " 'please': 7,\n",
              " 'dangerous': 7,\n",
              " 'sand': 6,\n",
              " 'smaller': 6,\n",
              " 'finger': 6,\n",
              " 'con': 6,\n",
              " 'two hands': 6,\n",
              " 'nan': 6,\n",
              " 'shed': 6,\n",
              " 'float': 6,\n",
              " 'thirsty': 6,\n",
              " 'weak': 6,\n",
              " 'figure': 6,\n",
              " 'may have': 6,\n",
              " 'wont': 6,\n",
              " 'build': 6,\n",
              " 'below': 6,\n",
              " 'monster': 6,\n",
              " 'ink': 6,\n",
              " 'shoot': 6,\n",
              " 'late': 6,\n",
              " 'evil': 6,\n",
              " 'contain': 6,\n",
              " 'take off': 6,\n",
              " 'different colors': 6,\n",
              " 'paid': 6,\n",
              " 'value': 6,\n",
              " 'dumb': 6,\n",
              " 'fact': 6,\n",
              " 'free': 6,\n",
              " 'flight': 6,\n",
              " 'two arms': 6,\n",
              " 'wooden': 6,\n",
              " 'case': 6,\n",
              " 'shut': 6,\n",
              " 'queen': 6,\n",
              " 'toy': 6,\n",
              " 'arm': 6,\n",
              " 'treat': 6,\n",
              " 'course': 6,\n",
              " 'hated': 6,\n",
              " 'lunch': 6,\n",
              " 'one way': 6,\n",
              " 'spots': 6,\n",
              " 'pleasure': 6,\n",
              " 'saying': 6,\n",
              " 'worth': 6,\n",
              " 'other side': 6,\n",
              " 'answer yes': 6,\n",
              " 'farmer': 6,\n",
              " 'watch': 6,\n",
              " 'pouring rain': 6,\n",
              " 'difference between': 6,\n",
              " 'test': 6,\n",
              " 'steel': 6,\n",
              " 'dose': 6,\n",
              " 'wake': 6,\n",
              " 'tried': 6,\n",
              " 'vampire': 6,\n",
              " 'winter': 6,\n",
              " 'rabbit': 6,\n",
              " 'pronounced': 6,\n",
              " 'why not': 6,\n",
              " 'jump': 6,\n",
              " 'block': 6,\n",
              " 'digit': 6,\n",
              " 'discovered': 6,\n",
              " 'breakfast': 6,\n",
              " 'lead': 6,\n",
              " 'length': 6,\n",
              " 'get off': 6,\n",
              " 'sport': 6,\n",
              " 'hello': 6,\n",
              " 'thrown': 6,\n",
              " 'upside down': 6,\n",
              " 'false': 6,\n",
              " 'cane': 6,\n",
              " 'warm': 6,\n",
              " 'every night': 6,\n",
              " 'ark': 6,\n",
              " 'thick': 6,\n",
              " 'sudden': 6,\n",
              " 'not eat': 6,\n",
              " 'car accident': 6,\n",
              " 'cloud': 6,\n",
              " 'dead man': 6,\n",
              " 'package': 6,\n",
              " 'flat': 6,\n",
              " 'title': 6,\n",
              " 'book': 6,\n",
              " 'rich people': 6,\n",
              " 'handle': 6,\n",
              " 'stuff': 6,\n",
              " 'not speak': 6,\n",
              " 'tear': 6,\n",
              " 'pane': 6,\n",
              " 'look stupid': 6,\n",
              " 'first thing': 6,\n",
              " 'hem': 6,\n",
              " 'exactly': 6,\n",
              " 'match': 6,\n",
              " 'train': 6,\n",
              " 'insect': 6,\n",
              " 'bat': 6,\n",
              " 'style': 6,\n",
              " 'colour': 6,\n",
              " 'plain': 6,\n",
              " 'ugly': 6,\n",
              " 'band': 6,\n",
              " 'summer': 6,\n",
              " 'vegetable': 6,\n",
              " 'not one': 6,\n",
              " 'nine': 6,\n",
              " 'track': 6,\n",
              " 'coloured': 6,\n",
              " 'result': 6,\n",
              " 'long tail': 6,\n",
              " 'one foot': 6,\n",
              " 'self': 6,\n",
              " 'old man': 6,\n",
              " 'wetter': 6,\n",
              " 'treasure': 6,\n",
              " 'daily': 6,\n",
              " 'destroy': 6,\n",
              " ...}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkF95Fcx_4K0"
      },
      "source": [
        "###brain_teaser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z-C1-8y_6Dd",
        "outputId": "125df489-5eb1-4124-c07c-85f09396fa86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breain-Teaser SP_train size: 396, Breain-Teaser SP_dev size: 120\n"
          ]
        }
      ],
      "source": [
        "DATA_FOLDER=\"/content/drive/MyDrive/brain_teaser/datasets\"\n",
        "\n",
        "\n",
        "# linked_qa_file=f\"{DATA_FOLDER}/SP_train_preprocessed.jsonl\"\n",
        "linked_qa_file=f\"{DATA_FOLDER}/WP_train_preprocessed2.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  train_instances = [json.loads(line) for line in f.read().split(\"\\n\") if line]\n",
        "\n",
        "# linked_qa_file=f\"{DATA_FOLDER}/SP_dev_preprocessed.jsonl\"\n",
        "linked_qa_file=f\"{DATA_FOLDER}/WP_dev_preprocessed2.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  dev_instances = [json.loads(line) for line in f.read().split(\"\\n\") if line]\n",
        "\n",
        "print(f\"Breain-Teaser SP_train size: {len(train_instances)}, Breain-Teaser SP_dev size: {len(dev_instances)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIPy9Wc7BrJH",
        "outputId": "5517a891-32b4-4425-a2d1-0d771a3d4da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:00<00:00, 344973.60it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.016666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "concept_count=[]\n",
        "\n",
        "for i in tqdm(range(len(dev_instances))):\n",
        "  qa_sample=dev_instances[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  concept_count.append(len(question_concepts))\n",
        "\n",
        "np.mean(np.array(concept_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQxMCFWOBuG9",
        "outputId": "20c51e9a-b05f-45e4-8eaa-5802cae85112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 396/396 [00:00<00:00, 491549.09it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.618686868686869"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "concept_count=[]\n",
        "\n",
        "for i in tqdm(range(len(train_instances))):\n",
        "  qa_sample=train_instances[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  concept_count.append(len(question_concepts))\n",
        "\n",
        "np.mean(np.array(concept_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDO7AYSO_6Zr",
        "outputId": "908b8c16-9dac-4cee-a84a-cb823edaaf53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 396/396 [00:00<00:00, 30964.08it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1143"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "concepts_frequency={}\n",
        "\n",
        "for i in tqdm(range(len(train_instances))):\n",
        "  qa_sample=train_instances[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  choices=qa_sample['question']['choices']\n",
        "  for concept in question_concepts:\n",
        "    concept_counter=concepts_frequency.get(concept)\n",
        "    if concept_counter!=None:\n",
        "      concepts_frequency[concept]=(concept_counter+1)\n",
        "    else:\n",
        "      concepts_frequency[concept]=1\n",
        "\n",
        "  for j in range(len(choices)):\n",
        "    choice_concepts=choices[j]['choice_concepts']\n",
        "    for concept in choice_concepts:\n",
        "      concept_counter=concepts_frequency.get(concept)\n",
        "      if concept_counter!=None:\n",
        "        concepts_frequency[concept]=(concept_counter+1)\n",
        "      else:\n",
        "        concepts_frequency[concept]=1\n",
        "\n",
        "len(concepts_frequency.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2AOU22RAA6e",
        "outputId": "d93fe449-c47d-447d-f28a-16d45bf66e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:00<00:00, 41810.64it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1143"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "for i in tqdm(range(len(dev_instances))):\n",
        "  qa_sample=dev_instances[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  choices=qa_sample['question']['choices']\n",
        "  for concept in question_concepts:\n",
        "    concept_counter=concepts_frequency.get(concept)\n",
        "    if concept_counter!=None:\n",
        "      concepts_frequency[concept]=(concept_counter+1)\n",
        "    else:\n",
        "      concepts_frequency[concept]=1\n",
        "\n",
        "  for j in range(len(choices)):\n",
        "    choice_concepts=choices[j]['choice_concepts']\n",
        "    for concept in choice_concepts:\n",
        "      concept_counter=concepts_frequency.get(concept)\n",
        "      if concept_counter!=None:\n",
        "        concepts_frequency[concept]=(concept_counter+1)\n",
        "      else:\n",
        "        concepts_frequency[concept]=1\n",
        "\n",
        "len(concepts_frequency.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNYyzGWeADGc"
      },
      "outputs": [],
      "source": [
        "sorted_dict={k: v for k, v in sorted(concepts_frequency.items(), key=lambda item: item[1], reverse=True)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_concepts=[]"
      ],
      "metadata": {
        "id": "EofKz5IhVGJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9GkC4VVDF_R"
      },
      "outputs": [],
      "source": [
        "most_common_concepts=['but',\n",
        " 'can',\n",
        " 'have',\n",
        " 'not',\n",
        " 'are',\n",
        " 'there',\n",
        " 'never',\n",
        " 'who',\n",
        " 'will',\n",
        " 'yet',\n",
        " 'all',\n",
        " 'get',\n",
        " 'why',\n",
        " 'many',\n",
        " 'only',\n",
        " 'then',\n",
        " 'make',\n",
        " 'like',\n",
        " 'always',\n",
        " 'possible',\n",
        " 'people',\n",
        " 'name',\n",
        " 'down',\n",
        " 'say',\n",
        " 'more',\n",
        " 'know',\n",
        " 'same',\n",
        " 'said',\n",
        " 'come',\n",
        " 'son',\n",
        " 'take',\n",
        " 'left',\n",
        " 'don',\n",
        " 'around',\n",
        " 'want',\n",
        " 'some',\n",
        " 'there are',\n",
        " 'way',\n",
        " 'still',\n",
        " 'through',\n",
        " 'thing',\n",
        " 'end',\n",
        " 'men',\n",
        " 'sometimes',\n",
        " 'put',\n",
        " 'nothing',\n",
        " 'away',\n",
        " 'person',\n",
        " 'each',\n",
        " 'other',\n",
        " 'stop',\n",
        " 'right',\n",
        " 'hold',\n",
        " 'going',\n",
        " 'once',\n",
        " 'just',\n",
        " 'made',\n",
        " 'used',\n",
        " 'most',\n",
        " 'both',\n",
        " 'much',\n",
        " 'here',\n",
        " 'give',\n",
        " 'every',\n",
        " 'also',\n",
        " 'number',\n",
        " 'though',\n",
        " 'while',\n",
        " 'someone',\n",
        " 'full',\n",
        " 'any',\n",
        " 'cant',\n",
        " 'about',\n",
        " 'keep',\n",
        " 'stand',\n",
        " 'now',\"nearly\",\"ever\",\"near\",\"very\",\n",
        "\"which\", \"what\", \"where\", \"when\", \"how\", \"who\", \"why\",\n",
        "######################################################################################################################################################\n",
        " 'not',\n",
        " 'possible',\n",
        " 'there',\n",
        " 'are',\n",
        " 'all',\n",
        " 'but',\n",
        " 'why',\n",
        " 'only',\n",
        " 'have',\n",
        " 'same',\n",
        " 'each',\n",
        " 'too',\n",
        " 'get',\n",
        " 'people',\n",
        " 'there are',\n",
        " 'will',\n",
        " 'then',\n",
        " 'other',\n",
        " 'however',\n",
        " 'still',\n",
        " 'enough',\n",
        " 'who',\n",
        " 'more',\n",
        " 'just',\n",
        " 'yet',\n",
        " 'any',\n",
        " 'some',\n",
        " 'made',\n",
        " 'back',\n",
        " 'son',\n",
        " 'never','haven','wit',\n",
        " 'see','till','mr.','mrs','mrs.','ms.','ied','led','err','yon','aten',\n",
        "'don','george','smith','also','once','tried','why not','might', 'john','many people','ever','bob','yes','sam','such','cis','lent','but one',\n",
        "'isn','some people', 'likely', 'very', 'sandy','every other','names','lan','tum','nsa', 'rad','mary', 'eris','peri','sir', 'isi','ddi','din','rom']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FzzjrYV2fBh",
        "outputId": "682e7458-426f-440a-d400-852022231fc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_dict['isi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMkY1nxn17IH"
      },
      "outputs": [],
      "source": [
        "# list(sorted_dict.keys())[2500:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSvoVXVEBaoG",
        "outputId": "4f210bf6-02a9-4fca-cbcf-72f0b5b1cffc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'of': 804,\n",
              " 'the': 531,\n",
              " 'above': 518,\n",
              " 'none': 516,\n",
              " 'a': 400,\n",
              " 'what': 343,\n",
              " 'be': 336,\n",
              " 'letter': 317,\n",
              " 'in': 238,\n",
              " 'and': 188,\n",
              " 'do': 137,\n",
              " 'you': 133,\n",
              " 'how': 85,\n",
              " 'kind': 81,\n",
              " 'word': 78,\n",
              " 'not': 75,\n",
              " 'can': 73,\n",
              " 'one': 72,\n",
              " 'to': 67,\n",
              " 'with': 59,\n",
              " 'which': 54,\n",
              " 'have': 52,\n",
              " 'it': 48,\n",
              " 'two': 44,\n",
              " 'on': 42,\n",
              " 'e': 42,\n",
              " 'but': 42,\n",
              " 'four': 41,\n",
              " 'at': 41,\n",
              " 'alphabet': 40,\n",
              " 'an': 40,\n",
              " 'number': 39,\n",
              " 'type': 39,\n",
              " 'o': 38,\n",
              " 'when': 38,\n",
              " 'take': 37,\n",
              " 'never': 36,\n",
              " 'add': 35,\n",
              " 'three': 33,\n",
              " 'spell': 32,\n",
              " 'that': 32,\n",
              " 'n': 32,\n",
              " 'music': 32,\n",
              " 't': 31,\n",
              " 'each': 31,\n",
              " 'no': 31,\n",
              " 'find': 29,\n",
              " 'or': 29,\n",
              " 'make': 29,\n",
              " 'old': 29,\n",
              " 'house': 29,\n",
              " 'if': 28,\n",
              " 'than': 28,\n",
              " 'end': 28,\n",
              " 'world': 28,\n",
              " 'five': 27,\n",
              " 'they': 27,\n",
              " 'm': 27,\n",
              " 'eat': 27,\n",
              " 'for': 26,\n",
              " 'year': 26,\n",
              " 'wall': 26,\n",
              " 'from': 25,\n",
              " 'remove': 25,\n",
              " 'there': 25,\n",
              " 'r': 25,\n",
              " 'new': 25,\n",
              " 'contain': 25,\n",
              " 'blue': 24,\n",
              " 'leave': 23,\n",
              " 'by': 23,\n",
              " 'f': 23,\n",
              " 'as': 23,\n",
              " 'day': 23,\n",
              " 'become': 22,\n",
              " 'middle': 21,\n",
              " 'out': 21,\n",
              " 'only': 21,\n",
              " 'more': 21,\n",
              " 'see': 20,\n",
              " 'hold': 20,\n",
              " 'six': 20,\n",
              " 'ben': 20,\n",
              " 'english': 20,\n",
              " 'soup': 20,\n",
              " 'away': 20,\n",
              " 'right': 20,\n",
              " 'we': 19,\n",
              " 'price': 19,\n",
              " 'water': 19,\n",
              " 'ring': 19,\n",
              " 'fish': 19,\n",
              " 'mouse': 18,\n",
              " 'must': 18,\n",
              " 'where': 18,\n",
              " 'red': 18,\n",
              " 'bank': 18,\n",
              " 'bar': 18,\n",
              " 'tuesday': 17,\n",
              " 'all': 17,\n",
              " 'city': 17,\n",
              " 'most': 17,\n",
              " 'begin': 17,\n",
              " 'buy': 16,\n",
              " 'get': 16,\n",
              " 'sandwich': 16,\n",
              " 'ronnie': 16,\n",
              " 'band': 16,\n",
              " 'money': 16,\n",
              " 'thursday': 15,\n",
              " 'l': 15,\n",
              " 'h': 15,\n",
              " 'long': 15,\n",
              " 'white': 15,\n",
              " 'sort': 15,\n",
              " 'start': 15,\n",
              " 'cheese': 15,\n",
              " 'cow': 14,\n",
              " 'seven': 14,\n",
              " 'less': 14,\n",
              " 'root': 14,\n",
              " 'dollar': 14,\n",
              " 'time': 14,\n",
              " 'ice': 14,\n",
              " 'side': 14,\n",
              " 'pink': 14,\n",
              " 'ten': 13,\n",
              " 'part': 13,\n",
              " 'wednesday': 13,\n",
              " 'many': 13,\n",
              " 'between': 13,\n",
              " 'every': 13,\n",
              " 'without': 13,\n",
              " 'short': 13,\n",
              " 'come': 13,\n",
              " 'call': 13,\n",
              " 'because': 13,\n",
              " 'plant': 13,\n",
              " 'eleven': 12,\n",
              " 'remain': 12,\n",
              " 'digit': 12,\n",
              " 'sign': 12,\n",
              " 'hundred': 12,\n",
              " 'cost': 12,\n",
              " 'determine': 12,\n",
              " 'card': 12,\n",
              " 'beginning': 12,\n",
              " 'those': 12,\n",
              " 'bill': 12,\n",
              " 'p': 12,\n",
              " 'drop': 12,\n",
              " 'driver': 12,\n",
              " 'jam': 12,\n",
              " 'talk': 12,\n",
              " 'bean': 12,\n",
              " 'dish': 12,\n",
              " 'bottle': 12,\n",
              " 'your': 11,\n",
              " 'this': 11,\n",
              " 'who': 11,\n",
              " 'will': 11,\n",
              " 'monday': 11,\n",
              " 'use': 11,\n",
              " 'eye': 11,\n",
              " 'thing': 11,\n",
              " 'always': 11,\n",
              " 'y': 11,\n",
              " 'next': 11,\n",
              " 'plus': 10,\n",
              " 'nine': 10,\n",
              " 'friday': 10,\n",
              " 'thousand': 10,\n",
              " 'california': 10,\n",
              " 'u': 10,\n",
              " 'into': 10,\n",
              " 'twenty': 10,\n",
              " 'b': 10,\n",
              " 'peanut': 10,\n",
              " 'like': 10,\n",
              " 'week': 10,\n",
              " 'exactly': 10,\n",
              " 'room': 10,\n",
              " 'note': 10,\n",
              " 'well': 9,\n",
              " 'anything': 9,\n",
              " 'high': 9,\n",
              " 'wedding': 9,\n",
              " 'change': 9,\n",
              " 'pot': 9,\n",
              " 'woman': 9,\n",
              " 'ship': 9,\n",
              " 'fast': 9,\n",
              " 'outside': 9,\n",
              " 'tree': 9,\n",
              " 'rock': 9,\n",
              " 'pizza': 9,\n",
              " 'my': 9,\n",
              " 'mrs': 9,\n",
              " 'computer': 9,\n",
              " 'wrench': 9,\n",
              " 'ham': 9,\n",
              " 'pool': 9,\n",
              " 'double': 8,\n",
              " 'eight': 8,\n",
              " 'hand': 8,\n",
              " 'down': 8,\n",
              " 'tomorrow': 8,\n",
              " 'today': 8,\n",
              " 'center': 8,\n",
              " 'division': 8,\n",
              " 'item': 8,\n",
              " 'say': 8,\n",
              " 'store': 8,\n",
              " 'address': 8,\n",
              " 'oil': 8,\n",
              " 'show': 8,\n",
              " 'dress': 8,\n",
              " 'same': 8,\n",
              " 'tomato': 8,\n",
              " 'bell': 8,\n",
              " 'ant': 8,\n",
              " 'dog': 8,\n",
              " 'bird': 8,\n",
              " 'd': 8,\n",
              " 'g': 8,\n",
              " 'man': 8,\n",
              " 'jennifer': 8,\n",
              " 'play': 8,\n",
              " 'corgi': 8,\n",
              " 'husky': 8,\n",
              " 'catfish': 8,\n",
              " 'dictionary': 8,\n",
              " 'mr': 8,\n",
              " 'book': 8,\n",
              " 'candy': 8,\n",
              " 'stable': 8,\n",
              " 'office': 8,\n",
              " 'watch': 8,\n",
              " 'finger': 7,\n",
              " 'so': 7,\n",
              " 'subtract': 7,\n",
              " 's': 7,\n",
              " 'here': 7,\n",
              " 'second': 7,\n",
              " 'yet': 7,\n",
              " 'seventeen': 7,\n",
              " 'vowel': 7,\n",
              " 'home': 7,\n",
              " 'small': 7,\n",
              " 'wear': 7,\n",
              " 'food': 7,\n",
              " 'green': 7,\n",
              " 'even': 7,\n",
              " 'run': 7,\n",
              " 'cup': 7,\n",
              " 'lamp': 7,\n",
              " 'thirteen': 6,\n",
              " 'equal': 6,\n",
              " 'set': 6,\n",
              " 'imagine': 6,\n",
              " 'upright': 6,\n",
              " 'index': 6,\n",
              " 'now': 6,\n",
              " 'vertical': 6,\n",
              " 'result': 6,\n",
              " 'roman': 6,\n",
              " 'numeral': 6,\n",
              " 'possible': 6,\n",
              " 'yesterday': 6,\n",
              " 'season': 6,\n",
              " 'march': 6,\n",
              " 'april': 6,\n",
              " 'may': 6,\n",
              " 'month': 6,\n",
              " 'symbol': 6,\n",
              " 'great': 6,\n",
              " 'square': 6,\n",
              " 'head': 6,\n",
              " 'hardware': 6,\n",
              " 'liquid': 6,\n",
              " 'milk': 6,\n",
              " 'similar': 6,\n",
              " 'animal': 6,\n",
              " 'lengthen': 6,\n",
              " 'abbreviation': 6,\n",
              " 'truncation': 6,\n",
              " 'everyone': 6,\n",
              " 'antique': 6,\n",
              " 'after': 6,\n",
              " 'history': 6,\n",
              " 'public': 6,\n",
              " 'acceptable': 6,\n",
              " 'yes': 6,\n",
              " 'worth': 6,\n",
              " 'value': 6,\n",
              " 'whether': 6,\n",
              " 'study': 6,\n",
              " 'minestrone': 6,\n",
              " 'bottom': 6,\n",
              " 'tuna': 6,\n",
              " 'turkey': 6,\n",
              " 'texas': 6,\n",
              " 'monkey': 6,\n",
              " 'academic': 6,\n",
              " 'daniel': 6,\n",
              " 'valentina': 6,\n",
              " 'fred': 6,\n",
              " 'david': 6,\n",
              " 'box': 6,\n",
              " 'angry': 6,\n",
              " 'salmon': 6,\n",
              " 'bass': 6,\n",
              " 'law': 6,\n",
              " 'mean': 6,\n",
              " 'japan': 6,\n",
              " 'live': 6,\n",
              " 'should': 6,\n",
              " 'orange': 6,\n",
              " 'before': 6,\n",
              " 'drum': 6,\n",
              " 'incapable': 6,\n",
              " 'butter': 6,\n",
              " 'pump': 6,\n",
              " 'ink': 6,\n",
              " 'gravity': 5,\n",
              " 'place': 5,\n",
              " 'several': 5,\n",
              " 'own': 5,\n",
              " 'spring': 5,\n",
              " 'stone': 5,\n",
              " 'sandstone': 5,\n",
              " 'teacher': 5,\n",
              " 'hot': 5,\n",
              " 'enjoy': 5,\n",
              " 'eagle': 5,\n",
              " 'sum': 5,\n",
              " 'its': 5,\n",
              " 'length': 5,\n",
              " 'boy': 5,\n",
              " 'trumpet': 5,\n",
              " 'move': 5,\n",
              " 'people': 5,\n",
              " 'morning': 5,\n",
              " 'follow': 5,\n",
              " 'single': 5,\n",
              " 'fall': 5,\n",
              " 'lady': 5,\n",
              " 'c': 5,\n",
              " 'breakfast': 5,\n",
              " 'favorite': 5,\n",
              " 'jazz': 5,\n",
              " 'break': 5,\n",
              " 'light': 5,\n",
              " 'ear': 5,\n",
              " 'art': 5,\n",
              " 'oh': 4,\n",
              " 'top': 4,\n",
              " 'go': 4,\n",
              " 'someone': 4,\n",
              " 'undoubtedly': 4,\n",
              " 'minute': 4,\n",
              " 'february': 4,\n",
              " 'september': 4,\n",
              " 'december': 4,\n",
              " 'november': 4,\n",
              " 'june': 4,\n",
              " 'july': 4,\n",
              " 'january': 4,\n",
              " 'august': 4,\n",
              " 'october': 4,\n",
              " 'point': 4,\n",
              " 'decimal': 4,\n",
              " 'mathematical': 4,\n",
              " 'create': 4,\n",
              " 'know': 4,\n",
              " 'mississippi': 4,\n",
              " 'florida': 4,\n",
              " 'enemy': 4,\n",
              " 'some': 4,\n",
              " 'salesman': 4,\n",
              " 'per': 4,\n",
              " 'about': 4,\n",
              " 'purchase': 4,\n",
              " 'inquire': 4,\n",
              " 'enter': 4,\n",
              " 'tell': 4,\n",
              " 'jill': 4,\n",
              " 'form': 4,\n",
              " 'rearrange': 4,\n",
              " 'associate': 4,\n",
              " 'nursery': 4,\n",
              " 'row': 4,\n",
              " 'rhyme': 4,\n",
              " 'commonly': 4,\n",
              " 'stand': 4,\n",
              " 'award': 4,\n",
              " 'combine': 4,\n",
              " 'rabbit': 4,\n",
              " 'bunny': 4,\n",
              " 'language': 4,\n",
              " 'suit': 4,\n",
              " 'around': 4,\n",
              " 'pear': 4,\n",
              " 'cook': 4,\n",
              " 'while': 4,\n",
              " 'used': 4,\n",
              " 'front': 4,\n",
              " 'eternity': 4,\n",
              " 'whetstone': 4,\n",
              " 'limestone': 4,\n",
              " 'land': 4,\n",
              " 'woodland': 4,\n",
              " 'sink': 4,\n",
              " 'cheesesteak': 4,\n",
              " 'submarine': 4,\n",
              " 'reuben': 4,\n",
              " 'shell': 4,\n",
              " 'nut': 4,\n",
              " 'doughnut': 4,\n",
              " 'walnut': 4,\n",
              " 'france': 4,\n",
              " 'london': 4,\n",
              " 'worker': 4,\n",
              " 'queen': 4,\n",
              " 'name': 4,\n",
              " 'pie': 4,\n",
              " 'hamburger': 4,\n",
              " 'pea': 4,\n",
              " 'crazy': 4,\n",
              " 'soybean': 4,\n",
              " 'chickpea': 4,\n",
              " 'earth': 4,\n",
              " 'feather': 4,\n",
              " 'chicken': 4,\n",
              " 'cat': 4,\n",
              " 'goat': 4,\n",
              " 'chicago': 4,\n",
              " 'girl': 4,\n",
              " 'cause': 4,\n",
              " 'also': 4,\n",
              " 'dance': 4,\n",
              " 'rubber': 4,\n",
              " 'third': 4,\n",
              " 'chaise': 4,\n",
              " 'lounger': 4,\n",
              " 'recliner': 4,\n",
              " 'pet': 4,\n",
              " 'pirate': 4,\n",
              " 'chase': 4,\n",
              " 'sun': 4,\n",
              " 'salt': 4,\n",
              " 'door': 4,\n",
              " 'reflection': 4,\n",
              " 'mirror': 4,\n",
              " 'sausage': 4,\n",
              " 'pepper': 4,\n",
              " 'way': 4,\n",
              " 'myself': 4,\n",
              " 'inside': 4,\n",
              " 'incorrectly': 4,\n",
              " 'easily': 4,\n",
              " 'left': 4,\n",
              " 'washington': 4,\n",
              " 'garden': 4,\n",
              " 'england': 4,\n",
              " 'finish': 4,\n",
              " 'key': 4,\n",
              " 'would': 4,\n",
              " 'foot': 4,\n",
              " 'big': 4,\n",
              " 'once': 4,\n",
              " 'he': 4,\n",
              " 'chair': 4,\n",
              " 'v': 4,\n",
              " 'post': 4,\n",
              " 'keep': 4,\n",
              " 'chocolate': 4,\n",
              " 'ghost': 4,\n",
              " 'prison': 4,\n",
              " 'why': 4,\n",
              " 'guess': 4,\n",
              " 'just': 4,\n",
              " 'case': 4,\n",
              " 'tv': 4,\n",
              " 'sport': 4,\n",
              " 'coffee': 4,\n",
              " 'news': 4,\n",
              " 'exist': 3,\n",
              " 'saturday': 3,\n",
              " 'sunday': 3,\n",
              " 'walk': 3,\n",
              " 'sale': 3,\n",
              " 'movie': 3,\n",
              " 'open': 3,\n",
              " 'moment': 3,\n",
              " 'midst': 3,\n",
              " 'their': 3,\n",
              " 'wetland': 3,\n",
              " 'tub': 3,\n",
              " 'bathtub': 3,\n",
              " 'sound': 3,\n",
              " 'swim': 3,\n",
              " 'alcohol': 3,\n",
              " 'perform': 3,\n",
              " 'produce': 3,\n",
              " 'sit': 3,\n",
              " 'write': 3,\n",
              " 'false': 3,\n",
              " 'wrong': 3,\n",
              " 'evening': 3,\n",
              " 'unable': 3,\n",
              " 'need': 3,\n",
              " 'space': 3,\n",
              " 'classroom': 3,\n",
              " 'summer': 3,\n",
              " 'night': 3,\n",
              " 'little': 3,\n",
              " 'age': 3,\n",
              " 'height': 3,\n",
              " 'share': 3,\n",
              " 'brick': 3,\n",
              " 'greenhouse': 3,\n",
              " 'mix': 3,\n",
              " 'character': 3,\n",
              " 'hard': 3,\n",
              " 'love': 3,\n",
              " 'want': 3,\n",
              " 'visible': 3,\n",
              " 'everything': 3,\n",
              " 'envelope': 3,\n",
              " 'apple': 3,\n",
              " 'boil': 3,\n",
              " 'church': 3,\n",
              " 'deliver': 3,\n",
              " 'plane': 3,\n",
              " 'fry': 3,\n",
              " 'behind': 3,\n",
              " 'fly': 3,\n",
              " 'his': 3,\n",
              " 'national': 3,\n",
              " 'local': 3,\n",
              " 'blueberry': 3,\n",
              " 'geologist': 3,\n",
              " 'pop': 3,\n",
              " 'drunk': 3,\n",
              " 'cookie': 3,\n",
              " 'chutney': 3,\n",
              " 'curd': 3,\n",
              " 'traffic': 3,\n",
              " 'sequence': 3,\n",
              " 'odd': 3,\n",
              " 'replace': 3,\n",
              " 'blood': 3,\n",
              " 'soap': 3,\n",
              " 'opera': 3,\n",
              " 'facet': 3,\n",
              " 'adjustable': 3,\n",
              " 'stubby': 3,\n",
              " 'teapot': 3,\n",
              " 'waterfall': 3,\n",
              " 'freefall': 3,\n",
              " 'flip': 3,\n",
              " 'urban': 3,\n",
              " 'inner': 3,\n",
              " 'captain': 3,\n",
              " 'battleship': 3,\n",
              " 'spaceship': 3,\n",
              " 'teacup': 3,\n",
              " 'beverage': 3,\n",
              " 'soy': 3,\n",
              " 'smoke': 3,\n",
              " 'cocktail': 3,\n",
              " 'hotel': 3,\n",
              " 'suitcase': 3,\n",
              " 'bookcase': 3,\n",
              " 'carpool': 3,\n",
              " 'wade': 3,\n",
              " 'spa': 3,\n",
              " 'board': 3,\n",
              " 'chessboard': 3,\n",
              " 'investment': 3,\n",
              " 'central': 3,\n",
              " 'carrot': 3,\n",
              " 'cabbage': 3,\n",
              " 'wood': 3,\n",
              " 'softwood': 3,\n",
              " 'hardwood': 3,\n",
              " 'wristwatch': 3,\n",
              " 'flake': 3,\n",
              " 'cob': 2,\n",
              " 'cobbler': 2,\n",
              " 'bee': 2,\n",
              " 'split': 2,\n",
              " 'both': 2,\n",
              " 'x': 2,\n",
              " 'surely': 2,\n",
              " 'proverb': 2,\n",
              " 'decade': 2,\n",
              " 'century': 2,\n",
              " 'arithmetic': 2,\n",
              " 'minus': 2,\n",
              " 'aware': 2,\n",
              " 'any': 2,\n",
              " 'laughter': 2,\n",
              " 'ask': 2,\n",
              " 'seventy': 2,\n",
              " 'buying': 2,\n",
              " 'declare': 2,\n",
              " 'purchasing': 2,\n",
              " 'she': 2,\n",
              " 'owner': 2,\n",
              " 'garage': 2,\n",
              " 'her': 2,\n",
              " 'sticky': 2,\n",
              " 'tag': 2,\n",
              " 'represent': 2,\n",
              " 'nobel': 2,\n",
              " 'gram': 2,\n",
              " 'grammy': 2,\n",
              " 'select': 2,\n",
              " 'skipping': 2,\n",
              " 'abstract': 2,\n",
              " 'oscar': 2,\n",
              " 'skip': 2,\n",
              " 'pattern': 2,\n",
              " 'other': 2,\n",
              " 'representation': 2,\n",
              " 'smile': 2,\n",
              " 'tooth': 2,\n",
              " 'grin': 2,\n",
              " 'late': 2,\n",
              " 'too': 2,\n",
              " 'supper': 2,\n",
              " 'arrive': 2,\n",
              " 'suppertime': 2,\n",
              " 'flower': 2,\n",
              " 'appear': 2,\n",
              " 'pearl': 2,\n",
              " 'heat': 2,\n",
              " 'pressure': 2,\n",
              " 'process': 2,\n",
              " 'oyster': 2,\n",
              " 'biomineralization': 2,\n",
              " 'creation': 2,\n",
              " 'preferable': 2,\n",
              " 'rather': 2,\n",
              " 'prefer': 2,\n",
              " 'merchant': 2,\n",
              " 'base': 2,\n",
              " 'windy': 2,\n",
              " 'submerge': 2,\n",
              " 'rain': 2,\n",
              " 'lowland': 2,\n",
              " 'beneath': 2,\n",
              " 'freezer': 2,\n",
              " 'lightship': 2,\n",
              " 'cargo': 2,\n",
              " 'icebreaker': 2,\n",
              " 'fire': 2,\n",
              " 'bluebell': 2,\n",
              " 'area': 2,\n",
              " 'borders': 2,\n",
              " 'china': 2,\n",
              " 'korea': 2,\n",
              " 'often': 2,\n",
              " 'banking': 2,\n",
              " 'loan': 2,\n",
              " 'shark': 2,\n",
              " 'lurker': 2,\n",
              " 'mathematics': 2,\n",
              " 'math': 2,\n",
              " 'rude': 2,\n",
              " 'hum': 2,\n",
              " 'mock': 2,\n",
              " 'describe': 2,\n",
              " 'wild': 2,\n",
              " 'planet': 2,\n",
              " 'earthnut': 2,\n",
              " 'earthquake': 2,\n",
              " 'montreal': 2,\n",
              " 'female': 2,\n",
              " 'checkbox': 2,\n",
              " 'pencil': 2,\n",
              " 'cigar': 2,\n",
              " 'brief': 2,\n",
              " 'stirring': 2,\n",
              " 'license': 2,\n",
              " 'drive': 2,\n",
              " 'carpet': 2,\n",
              " 'manager': 2,\n",
              " 'pursue': 2,\n",
              " 'hotdog': 2,\n",
              " 'exit': 2,\n",
              " 'entrance': 2,\n",
              " 'table': 2,\n",
              " 'available': 2,\n",
              " 'dad': 2,\n",
              " 'sister': 2,\n",
              " 'brother': 2,\n",
              " 'weapon': 2,\n",
              " 'radar': 2,\n",
              " 'noon': 2,\n",
              " 'mum': 2,\n",
              " 'symmetry': 2,\n",
              " 'misspell': 2,\n",
              " 'rose': 2,\n",
              " 'blossom': 2,\n",
              " 'maple': 2,\n",
              " 'cherry': 2,\n",
              " 'leaf': 2,\n",
              " 'grove': 2,\n",
              " 'canada': 2,\n",
              " 'express': 2,\n",
              " 'danger': 2,\n",
              " 'risk': 2,\n",
              " 'happiness': 2,\n",
              " 'energy': 2,\n",
              " 'mushroom': 2,\n",
              " 'restroom': 2,\n",
              " 'lock': 2,\n",
              " 'combination': 2,\n",
              " 'up': 2,\n",
              " 'happen': 2,\n",
              " 'farmland': 2,\n",
              " 'finland': 2,\n",
              " 'skirt': 2,\n",
              " 'proper': 2,\n",
              " 'reside': 2,\n",
              " 'construct': 2,\n",
              " 'yellow': 2,\n",
              " 'brown': 2,\n",
              " 'twice': 2,\n",
              " 'thanksgive': 2,\n",
              " 'christmas': 2,\n",
              " 'biography': 2,\n",
              " 'physical': 2,\n",
              " 'subtraction': 2,\n",
              " 'addition': 2,\n",
              " 'multiplication': 2,\n",
              " 'k': 2,\n",
              " 'haw': 2,\n",
              " 'heaven': 2,\n",
              " 'regardless': 2,\n",
              " 'peace': 2,\n",
              " 'football': 2,\n",
              " 'horse': 2,\n",
              " 'fit': 2,\n",
              " 'below': 2,\n",
              " 'sight': 2,\n",
              " 'police': 2,\n",
              " 'government': 2,\n",
              " 'lunch': 2,\n",
              " 'dinner': 2,\n",
              " 'bread': 2,\n",
              " 'consume': 2,\n",
              " 'fruit': 2,\n",
              " 'travel': 2,\n",
              " 'british': 2,\n",
              " 'potato': 2,\n",
              " 'nationality': 2,\n",
              " 'french': 2,\n",
              " 'wine': 2,\n",
              " 'hole': 2,\n",
              " 'jump': 2,\n",
              " 'sleep': 2,\n",
              " 'yard': 2,\n",
              " 'backwards': 2,\n",
              " 'edam': 2,\n",
              " 'cheddar': 2,\n",
              " 'showman': 2,\n",
              " 'snow': 2,\n",
              " 'cranberry': 2,\n",
              " 'blackberry': 2,\n",
              " 'blackberries': 2,\n",
              " 'sugar': 2,\n",
              " 'treat': 2,\n",
              " 'tie': 2,\n",
              " 'balloon': 2,\n",
              " 'country': 2,\n",
              " 'arrest': 2,\n",
              " 'screw': 2,\n",
              " 'host': 2,\n",
              " 'prisoner': 2,\n",
              " 'state': 2,\n",
              " 'county': 2,\n",
              " 'opener': 2,\n",
              " 'pelican': 2,\n",
              " 'eve': 2,\n",
              " 'able': 2,\n",
              " 'tom': 2,\n",
              " 'conundrum': 2,\n",
              " 'india': 2,\n",
              " 'series': 2,\n",
              " 'figure': 2,\n",
              " 'panda': 2,\n",
              " 'avoid': 2,\n",
              " 'bed': 2,\n",
              " 'living': 2,\n",
              " 'rest': 2,\n",
              " 'engineer': 2,\n",
              " 'catch': 2,\n",
              " 'selfish': 2,\n",
              " 'impossible': 2,\n",
              " 'vampire': 2,\n",
              " 'currency': 2,\n",
              " 'champ': 2,\n",
              " 'leak': 2,\n",
              " 'repair': 2,\n",
              " 'trust': 2,\n",
              " 'evolve': 2,\n",
              " 'nightfall': 2,\n",
              " 'net': 2,\n",
              " 'turn': 2,\n",
              " 'race': 2,\n",
              " 'shocking': 2,\n",
              " 'electricity': 2,\n",
              " 'mate': 2,\n",
              " 'partnership': 2,\n",
              " 'lack': 2,\n",
              " 'cupcake': 2,\n",
              " 'lighthouse': 2,\n",
              " 'beach': 2,\n",
              " 'treehouse': 2,\n",
              " 'drink': 2,\n",
              " 'boxer': 2,\n",
              " 'coke': 2,\n",
              " 'punch': 2,\n",
              " 'sprite': 2,\n",
              " 'bear': 2,\n",
              " 'grow': 2,\n",
              " 'jelly': 2,\n",
              " 'good': 2,\n",
              " 'chip': 2,\n",
              " 'butterfly': 2,\n",
              " 'almond': 2,\n",
              " 'boxing': 2,\n",
              " 'sandbar': 2,\n",
              " 'alcoholic': 2,\n",
              " 'offer': 2,\n",
              " 'birmingham': 2,\n",
              " 'cure': 2,\n",
              " 'clamp': 2,\n",
              " 'lead': 2,\n",
              " 'emit': 2,\n",
              " 'crockpot': 2,\n",
              " 'jackpot': 2,\n",
              " 'lowercase': 2,\n",
              " 'involve': 2,\n",
              " 'game': 2,\n",
              " 'dartboard': 2,\n",
              " 'keyboard': 2,\n",
              " 'snowbank': 2,\n",
              " 'hungry': 2,\n",
              " 'indoor': 2,\n",
              " 'power': 2,\n",
              " 'hollywood': 2,\n",
              " 'cut': 2,\n",
              " 'satellite': 2,\n",
              " 'neck': 2,\n",
              " 'glass': 2,\n",
              " 'footnote': 2,\n",
              " 'pocket': 2,\n",
              " 'watchdog': 2,\n",
              " 'inflate': 2,\n",
              " 'bicycle': 2,\n",
              " 'pumpkin': 2,\n",
              " 'air': 2,\n",
              " 'pan': 2,\n",
              " 'stain': 2,\n",
              " 'link': 2,\n",
              " 'gallery': 2,\n",
              " 'contemporary': 2,\n",
              " 'fine': 2,\n",
              " 'tart': 2,\n",
              " 'doorbell': 2,\n",
              " 'cowbell': 2,\n",
              " 'dumbbell': 2,\n",
              " 'melt': 2,\n",
              " 'dice': 2,\n",
              " 'present': 1,\n",
              " 'suddenly': 1,\n",
              " 'poet': 1,\n",
              " 'culinary': 1,\n",
              " 'person': 1,\n",
              " 'rich': 1,\n",
              " 'narrative': 1,\n",
              " 'significance': 1,\n",
              " 'within': 1,\n",
              " 'carry': 1,\n",
              " 'very': 1,\n",
              " 'sea': 1,\n",
              " 'dive': 1,\n",
              " 'finch': 1,\n",
              " 'darkness': 1,\n",
              " 'crosse': 1,\n",
              " 'sorrow': 1,\n",
              " 'sickness': 1,\n",
              " 'constantly': 1,\n",
              " 'suffering': 1,\n",
              " 'shadow': 1,\n",
              " 'illness': 1,\n",
              " 'essential': 1,\n",
              " 'surround': 1,\n",
              " 'wallless': 1,\n",
              " 'gold': 1,\n",
              " 'car': 1,\n",
              " 'z': 1,\n",
              " 'except': 1,\n",
              " 'during': 1,\n",
              " 'occur': 1,\n",
              " 'concert': 1,\n",
              " 'cadenza': 1,\n",
              " 'prologue': 1,\n",
              " 'finale': 1,\n",
              " 'boot': 1,\n",
              " 'snake': 1,\n",
              " 'inhabit': 1,\n",
              " 'life': 1,\n",
              " 'quadrilateral': 1,\n",
              " 'triangle': 1,\n",
              " 'pentagon': 1,\n",
              " 'color': 1,\n",
              " 'university': 1,\n",
              " 'consider': 1,\n",
              " 'something': 1,\n",
              " 'consonant': 1,\n",
              " 'diphthong': 1,\n",
              " 'holiday': 1,\n",
              " 'pole': 1,\n",
              " 'north': 1,\n",
              " 'multiplying': 1,\n",
              " 'dividing': 1,\n",
              " 'el': 1,\n",
              " 'en': 1,\n",
              " 'pork': 1,\n",
              " 'vapor': 1,\n",
              " 'wise': 1,\n",
              " 'religion': 1,\n",
              " 'agree': 1,\n",
              " 'politic': 1,\n",
              " 'political': 1,\n",
              " 'sensible': 1,\n",
              " 'religious': 1,\n",
              " 'belief': 1,\n",
              " 'believe': 1,\n",
              " 'volleyball': 1,\n",
              " 'volley': 1,\n",
              " 'barn': 1,\n",
              " 'guy': 1,\n",
              " 'rush': 1,\n",
              " 'either': 1,\n",
              " 'rule': 1,\n",
              " 'bargain': 1,\n",
              " 'however': 1,\n",
              " 'nor': 1,\n",
              " 'total': 1,\n",
              " 'infinite': 1,\n",
              " 'marriage': 1,\n",
              " 'medicine': 1,\n",
              " 'afternoon': 1,\n",
              " 'delivery': 1,\n",
              " 'bus': 1,\n",
              " 'school': 1,\n",
              " 'group': 1,\n",
              " 'pair': 1,\n",
              " 'autumn': 1,\n",
              " 'quick': 1,\n",
              " 'technique': 1,\n",
              " 'graveyard': 1,\n",
              " 'situate': 1,\n",
              " 'cemetery': 1,\n",
              " 'sunshine': 1,\n",
              " 'eastside': 1,\n",
              " 'westside': 1,\n",
              " 'foreigner': 1,\n",
              " 'grape': 1,\n",
              " 'american': 1,\n",
              " 'italian': 1,\n",
              " 'hide': 1,\n",
              " 'singing': 1,\n",
              " 'preen': 1,\n",
              " 'branch': 1,\n",
              " 'twelve': 1,\n",
              " 'reverse': 1,\n",
              " 'pepperoni': 1,\n",
              " 'river': 1,\n",
              " 'unhappy': 1,\n",
              " 'dissatisfied': 1,\n",
              " 'phone': 1,\n",
              " 'depressed': 1,\n",
              " 'nokia': 1,\n",
              " 'sweet': 1,\n",
              " 'clothing': 1,\n",
              " 'painter': 1,\n",
              " 'palette': 1,\n",
              " 'bowtie': 1,\n",
              " 'bolo': 1,\n",
              " 'scared': 1,\n",
              " 'frightens': 1,\n",
              " 'over': 1,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "sorted_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgfWyhlqADDS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ETOkT-2_6WD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfgg8Ggu_6Gv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE4BK3BXyP0Y"
      },
      "source": [
        "##<font color=lightgreen>extract concepts with respect to concept frequencies</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bhxD-gFDg8S"
      },
      "source": [
        "###riddle_sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWv7IPuw0rR6",
        "outputId": "79774f13-ee46-4a8f-ac12-015f6a4dfb62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Riddle-Sense train size: 3510, Riddle-Sense dev size: 1021\n"
          ]
        }
      ],
      "source": [
        "DATA_FOLDER=\"/content/drive/MyDrive/brain_teaser/datasets\"\n",
        "\n",
        "\n",
        "linked_qa_file=f\"{DATA_FOLDER}/rs_train.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  rs_train_instances = [json.loads(line) for line in f.read().split(\"\\n\") if line]\n",
        "\n",
        "linked_qa_file=f\"{DATA_FOLDER}/rs_dev.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  rs_dev_instances = [json.loads(line) for line in f.read().split(\"\\n\") if line]\n",
        "\n",
        "print(f\"Riddle-Sense train size: {len(rs_train_instances)}, Riddle-Sense dev size: {len(rs_dev_instances)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V371_yASyPkB"
      },
      "outputs": [],
      "source": [
        "def extract_concepts(question_list):\n",
        "  processed_qs=[]\n",
        "\n",
        "  for i in tqdm(range(len(question_list))):\n",
        "\n",
        "    sample=question_list[i]\n",
        "    q_id=sample['id']\n",
        "    q_answerKey=sample['answerKey']\n",
        "    q_stem=sample['question']['stem'].strip().lower()\n",
        "    q_choices=sample['question']['choices']\n",
        "\n",
        "    question_concepts=[]\n",
        "    for i in range(len(id2concept)):\n",
        "      concept=id2concept[i].strip().lower().replace(\"_\",\" \")\n",
        "      if concept in most_common_concepts or len(concept)<=3:\n",
        "        continue\n",
        "      if concept in q_stem:\n",
        "        question_concepts.append(concept)\n",
        "\n",
        "\n",
        "    new_question_concepts=[]\n",
        "    for i in range(len(question_concepts)):\n",
        "      first_concept=question_concepts[i]\n",
        "      is_sub_concept=False\n",
        "      for j in range(len(question_concepts)):\n",
        "        if i==j:\n",
        "          continue\n",
        "        if first_concept in question_concepts[j]:\n",
        "          is_sub_concept=True\n",
        "          break\n",
        "\n",
        "      if is_sub_concept==False:\n",
        "        new_question_concepts.append(first_concept)\n",
        "\n",
        "\n",
        "    meaningful_question_concepts=set()\n",
        "    for concept in new_question_concepts:\n",
        "      if concept in wn.words():\n",
        "        meaningful_question_concepts.add(concept)\n",
        "        continue\n",
        "\n",
        "      concept_subwords=concept.split(\" \")\n",
        "      all_are_meaningful=True\n",
        "      meaningfuls=[]\n",
        "      for subword in concept_subwords:\n",
        "        if len(subword)<=3:\n",
        "          all_are_meaningful=False\n",
        "          continue\n",
        "\n",
        "        if subword in wn.words():\n",
        "          meaningfuls.append(subword)\n",
        "        else:\n",
        "          all_are_meaningful=False\n",
        "      if all_are_meaningful:\n",
        "        meaningful_question_concepts.add(concept)\n",
        "      else:\n",
        "        for c in meaningfuls:\n",
        "          if c not in most_common_concepts:\n",
        "            meaningful_question_concepts.add(c)\n",
        "\n",
        "\n",
        "    q_dict={\n",
        "        'id':q_id,\n",
        "        'answerKey':q_answerKey,\n",
        "        'question':{\n",
        "            'question_concept': list(meaningful_question_concepts),\n",
        "            'choices': q_choices,\n",
        "            'stem': q_stem,\n",
        "        }\n",
        "    }\n",
        "    processed_qs.append(q_dict)\n",
        "\n",
        "  return processed_qs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHhDe4yPyPfY",
        "outputId": "c5c28116-3153-4f14-e087-fbeed658ef48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1021/1021 [36:47<00:00,  2.16s/it]\n"
          ]
        }
      ],
      "source": [
        "processed_dev_qs=extract_concepts(rs_dev_instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTdYYyUxjrBW"
      },
      "outputs": [],
      "source": [
        "with open(f'{DATA_FOLDER}/rs_dev_preprocessed_pruned.jsonl', 'w') as outfile:\n",
        "  for entry in processed_dev_qs:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih2PoFckAEv3",
        "outputId": "ae42085a-8085-425c-e64f-b4476e491a2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1021/1021 [00:00<00:00, 410543.99it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "5.09696376101861"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concept_count=[]\n",
        "\n",
        "for i in tqdm(range(len(processed_dev_qs))):\n",
        "  qa_sample=processed_dev_qs[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  concept_count.append(len(question_concepts))\n",
        "\n",
        "np.mean(np.array(concept_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcr4A2ZeE7s2"
      },
      "source": [
        "check len qc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "145qgdfIjq8v",
        "outputId": "f5892ae8-e65d-4c67-bf3a-3d8c317222e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3510/3510 [2:04:17<00:00,  2.12s/it]\n"
          ]
        }
      ],
      "source": [
        "processed_train_qs=extract_concepts(rs_train_instances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLK6UGZveh8N"
      },
      "outputs": [],
      "source": [
        "with open(f'{DATA_FOLDER}/rs_train_preprocessed_pruned.jsonl', 'w') as outfile:\n",
        "  for entry in processed_train_qs:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH_IghJyIj1E",
        "outputId": "082db4db-e1ab-4da8-ba89-b137e0fac161"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3510/3510 [00:00<00:00, 490047.50it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4.323361823361823"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concept_count=[]\n",
        "\n",
        "for i in tqdm(range(len(processed_train_qs))):\n",
        "  qa_sample=processed_train_qs[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  concept_count.append(len(question_concepts))\n",
        "\n",
        "np.mean(np.array(concept_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aef1KimEeh4X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gbapeqU-GMT"
      },
      "source": [
        "mean concept count per q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG-hcRtg-Ye2"
      },
      "source": [
        "dev not pruned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8EYd4OL-aKR"
      },
      "outputs": [],
      "source": [
        "linked_qa_file=f\"{DATA_FOLDER}/rs_dev_preprocessed.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  rs_dev_instances = [json.loads(line) for line in f.read().split(\"\\n\") if line]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3n5v11c-bre",
        "outputId": "73236355-1cab-4a21-a32f-d0305f022620"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1021/1021 [00:00<00:00, 307399.64it/s]\n"
          ]
        }
      ],
      "source": [
        "concept_count=[]\n",
        "\n",
        "for i in tqdm(range(len(rs_dev_instances))):\n",
        "  qa_sample=rs_dev_instances[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  concept_count.append(len(question_concepts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXNmszLH-Saj",
        "outputId": "271a094b-15eb-4aa3-eb61-07d9d94cd661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.46620959843291"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.mean(np.array(concept_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyrI1Y0H-IXF"
      },
      "source": [
        "pruned dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdMjUF3Qeh0n",
        "outputId": "e28a2d1f-1a3f-4540-c1eb-e99d25d259fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1021/1021 [00:00<00:00, 475134.18it/s]\n"
          ]
        }
      ],
      "source": [
        "concept_count=[]\n",
        "\n",
        "for i in tqdm(range(len(processed_dev_qs))):\n",
        "  qa_sample=processed_dev_qs[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  concept_count.append(len(question_concepts))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbR7X_Hl-F62",
        "outputId": "7da028e3-5606-4420-d9b2-cae12fae3d62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7.078354554358472"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.mean(np.array(concept_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fyn5VOL_sGK"
      },
      "source": [
        "train not pruned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ars7HNOC-F2g"
      },
      "outputs": [],
      "source": [
        "linked_qa_file=f\"{DATA_FOLDER}/rs_train_preprocessed.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  rs_train_instances = [json.loads(line) for line in f.read().split(\"\\n\") if line]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVsxlgmo-Fxx",
        "outputId": "1db6ca58-661b-4eb2-fc17-61d4c7689608"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3510/3510 [00:00<00:00, 406471.94it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "7.445014245014245"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concept_count=[]\n",
        "\n",
        "for i in tqdm(range(len(rs_train_instances))):\n",
        "  qa_sample=rs_train_instances[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  concept_count.append(len(question_concepts))\n",
        "\n",
        "np.mean(np.array(concept_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7CgbSN0DmIS"
      },
      "source": [
        "###Brain_teaser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "MAmRmolUDl81",
        "outputId": "90b57bdd-75bd-42f9-b6d7-8278ef7afa57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "396\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                                   question             answer  \\\n",
              "0  WP-0  How do you spell COW in thirteen letters?  SEE O DOUBLE YOU.   \n",
              "\n",
              "     distractor1      distractor2 distractor(unsure)  label  \\\n",
              "0  COWCOWCOWCOWW  SEE OH DEREFORD     None of above.      1   \n",
              "\n",
              "                                         choice_list  choice_order  \n",
              "0  [SEE OH DEREFORD, SEE O DOUBLE YOU., COWCOWCOW...  [2, 0, 1, 3]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0761dac5-c602-4983-8788-c59b6d21ab2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>distractor1</th>\n",
              "      <th>distractor2</th>\n",
              "      <th>distractor(unsure)</th>\n",
              "      <th>label</th>\n",
              "      <th>choice_list</th>\n",
              "      <th>choice_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WP-0</td>\n",
              "      <td>How do you spell COW in thirteen letters?</td>\n",
              "      <td>SEE O DOUBLE YOU.</td>\n",
              "      <td>COWCOWCOWCOWW</td>\n",
              "      <td>SEE OH DEREFORD</td>\n",
              "      <td>None of above.</td>\n",
              "      <td>1</td>\n",
              "      <td>[SEE OH DEREFORD, SEE O DOUBLE YOU., COWCOWCOW...</td>\n",
              "      <td>[2, 0, 1, 3]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0761dac5-c602-4983-8788-c59b6d21ab2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0761dac5-c602-4983-8788-c59b6d21ab2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0761dac5-c602-4983-8788-c59b6d21ab2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# SP_dataset_train = np.load('/content/drive/MyDrive/brain_teaser/datasets/SP-train.npy', allow_pickle=True,encoding='bytes')\n",
        "dataset_train = np.load('/content/drive/MyDrive/brain_teaser/datasets/WP-train.npy', allow_pickle=True,encoding='bytes')\n",
        "print(len(dataset_train))\n",
        "\n",
        "data_dict = {'id':[],\n",
        "             'question':[],\n",
        "             'answer':[],\n",
        "             'distractor1':[],\n",
        "             'distractor2':[],\n",
        "             'distractor(unsure)':[],\n",
        "             'label':[],\n",
        "             'choice_list':[],\n",
        "             'choice_order':[]}\n",
        "for i in dataset_train:\n",
        "  for k,v in i.items():\n",
        "    data_dict[k].append(v)\n",
        "\n",
        "train_df = pd.DataFrame(data_dict, columns=['id', 'question', 'answer', 'distractor1', 'distractor2', 'distractor(unsure)', 'label', 'choice_list', 'choice_order'])\n",
        "train_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "vD4EmcPIDl6a",
        "outputId": "3bd4185d-553f-445e-fd94-fba61b12ef80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         question  \\\n",
              "0  What kind of nut has no shell?   \n",
              "\n",
              "                                         choice_list  \n",
              "0  [A peanut., A Doughnut., A walnut., None of ab...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-768f0816-0732-430c-ab95-439088415eda\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What kind of nut has no shell?</td>\n",
              "      <td>[A peanut., A Doughnut., A walnut., None of ab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-768f0816-0732-430c-ab95-439088415eda')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-768f0816-0732-430c-ab95-439088415eda button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-768f0816-0732-430c-ab95-439088415eda');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# SP_dataset_val = np.load('/content/drive/MyDrive/brain_teaser/datasets/SP_eval_data_for_practice.npy', allow_pickle=True,encoding='bytes')\n",
        "dataset_val = np.load('/content/drive/MyDrive/brain_teaser/datasets/WP_eval_data_for_practice.npy', allow_pickle=True,encoding='bytes')\n",
        "print(len(dataset_val))\n",
        "\n",
        "data_dict = {'question':[],\n",
        "             'choice_list':[]}\n",
        "for i in dataset_val:\n",
        "  for k,v in i.items():\n",
        "    data_dict[k].append(v)\n",
        "\n",
        "val_df = pd.DataFrame(data_dict, columns=['question', 'choice_list'])\n",
        "val_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "def load_matcher(nlp, pattern_path):\n",
        "    with open(pattern_path, \"r\", encoding=\"utf8\") as fin:\n",
        "        all_patterns = json.load(fin)\n",
        "\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    for concept, pattern in all_patterns.items():\n",
        "        # matcher.add(concept, None, pattern)\n",
        "        matcher.add(concept, [pattern])\n",
        "    return matcher"
      ],
      "metadata": {
        "id": "EfzIim0Je1ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATTERN_PATH=\"/content/drive/MyDrive/brain_teaser/datasets/cpnet/matcher_patterns.json\""
      ],
      "metadata": {
        "id": "Q2p6B9zsfaSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser', 'textcat'])\n",
        "# nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "nlp.add_pipe('sentencizer')\n",
        "\n",
        "def load_cpnet_vocab(cpnet_vocab_path):\n",
        "    with open(cpnet_vocab_path, \"r\", encoding=\"utf8\") as fin:\n",
        "        cpnet_vocab = [l.strip() for l in fin]\n",
        "    cpnet_vocab = [c.replace(\"_\", \" \") for c in cpnet_vocab]\n",
        "    return cpnet_vocab\n",
        "# matcher = load_matcher(nlp, PATTERN_PATH)"
      ],
      "metadata": {
        "id": "V8aNpBn3eo0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htnscwBofoDE",
        "outputId": "227f4d17-c508-4b2a-85b8-8f3ea96754cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                                                                 WP-0\n",
              "question                      How do you spell COW in thirteen letters?\n",
              "answer                                                SEE O DOUBLE YOU.\n",
              "distractor1                                               COWCOWCOWCOWW\n",
              "distractor2                                             SEE OH DEREFORD\n",
              "distractor(unsure)                                       None of above.\n",
              "label                                                                 1\n",
              "choice_list           [SEE OH DEREFORD, SEE O DOUBLE YOU., COWCOWCOW...\n",
              "choice_order                                               [2, 0, 1, 3]\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(train_df.iloc[0]['question'])\n",
        "doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roWTwasCgci1",
        "outputId": "097b7ff7-412d-4d47-ed2b-f5286b4eaa2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "How do you spell COW in thirteen letters?"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in doc:\n",
        "  print(t.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3Mt9sJThJfU",
        "outputId": "d5a9e29b-886d-43dc-bb0c-15071d2772e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how\n",
            "do\n",
            "you\n",
            "spell\n",
            "COW\n",
            "in\n",
            "thirteen\n",
            "letter\n",
            "?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def hard_ground(nlp, sent, cpnet_vocab):\n",
        "#     sent = sent.lower()\n",
        "#     doc = nlp(sent)\n",
        "#     res = set()\n",
        "#     for t in doc:\n",
        "#         if t.lemma_ in cpnet_vocab:\n",
        "#             res.add(t.lemma_)\n",
        "#     sent = \" \".join([t.text for t in doc])\n",
        "#     if sent in cpnet_vocab:\n",
        "#         res.add(sent)\n",
        "#     try:\n",
        "#         assert len(res) > 0\n",
        "#     except Exception:\n",
        "#         print(f\"for {sent}, concept not found in hard grounding.\")\n",
        "#     return res"
      ],
      "metadata": {
        "id": "qQvchNCzennz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFK5U3LiM-sb"
      },
      "outputs": [],
      "source": [
        "def extract_concepts(sentence, char_count_thresh):\n",
        "\n",
        "  # question_concepts=[]\n",
        "  # for i in range(len(id2concept)):\n",
        "  #   concept=id2concept[i].strip().lower().replace(\"_\",\" \")\n",
        "  #   if len(concept)<=char_count_thresh:\n",
        "  #     continue\n",
        "  #   if concept in sentence:\n",
        "  #     question_concepts.append(concept)\n",
        "\n",
        "  # meaningful_question_concepts=set()\n",
        "  # for concept in question_concepts:\n",
        "  #   if concept in wn.words():\n",
        "  #     meaningful_question_concepts.add(concept)\n",
        "  #     continue\n",
        "\n",
        "  #   concept_subwords=concept.split(\" \")\n",
        "  #   all_are_meaningful=True\n",
        "  #   meaningfuls=[]\n",
        "  #   for subword in concept_subwords:\n",
        "  #     if len(subword)<=char_count_thresh:\n",
        "  #       all_are_meaningful=False\n",
        "  #       continue\n",
        "\n",
        "  #     if subword in wn.words():\n",
        "  #       meaningfuls.append(subword)\n",
        "  #     else:\n",
        "  #       all_are_meaningful=False\n",
        "  #   if all_are_meaningful:\n",
        "  #     meaningful_question_concepts.add(concept)\n",
        "  #   else:\n",
        "  #     for c in meaningfuls:\n",
        "  #       meaningful_question_concepts.add(c)\n",
        "\n",
        "  # meaningful_question_concepts=list(meaningful_question_concepts)\n",
        "\n",
        "  # new_question_concepts=[]\n",
        "  # for i in range(len(meaningful_question_concepts)):\n",
        "  #   first_concept=meaningful_question_concepts[i]\n",
        "  #   is_sub_concept=False\n",
        "  #   for j in range(len(meaningful_question_concepts)):\n",
        "  #     if i==j:\n",
        "  #       continue\n",
        "  #     if first_concept in meaningful_question_concepts[j]:\n",
        "  #       is_sub_concept=True\n",
        "  #       break\n",
        "\n",
        "  #   if is_sub_concept==False:\n",
        "  #     new_question_concepts.append(first_concept)\n",
        "  sent = sentence.lower()\n",
        "  doc = nlp(sent)\n",
        "  question_concepts = set()\n",
        "  for t in doc:\n",
        "    if t.lemma_ in concept2id:\n",
        "      question_concepts.add(t.lemma_)\n",
        "  sent = \" \".join([t.text for t in doc])\n",
        "  if sent in concept2id:\n",
        "    question_concepts.add(sent)\n",
        "  try:\n",
        "    assert len(question_concepts) > 0\n",
        "  except Exception:\n",
        "      print(f\"for {sent}, concept not found in hard grounding.\")\n",
        "\n",
        "  final_concepts=[]\n",
        "  for concept in question_concepts:\n",
        "    if concept in most_common_concepts:\n",
        "      continue\n",
        "    else:\n",
        "      final_concepts.append(concept)\n",
        "\n",
        "  return final_concepts\n",
        "\n",
        "\n",
        "def preprocess_qa(question_list, is_train_data, char_count_thresh):\n",
        "\n",
        "  processed_qs=[]\n",
        "  id_to_label={0:\"A\", 1:\"B\", 2:\"C\", 3:\"D\"}\n",
        "\n",
        "  for i in tqdm(range(len(question_list))):\n",
        "\n",
        "    sample=question_list.iloc[i]\n",
        "    q_stem=sample['question'].strip().lower()\n",
        "    q_choices_list=sample['choice_list']\n",
        "    if is_train_data:\n",
        "      q_answerKey=id_to_label[sample['label']]\n",
        "      q_id=sample['id']\n",
        "    else:\n",
        "      q_id=i\n",
        "\n",
        "\n",
        "    meaningful_question_concepts = extract_concepts(q_stem, char_count_thresh)\n",
        "\n",
        "    q_choices=[]\n",
        "\n",
        "    for j in range(len(q_choices_list)):\n",
        "      if j==0:\n",
        "        choice_label=\"A\"\n",
        "      elif j==1:\n",
        "        choice_label=\"B\"\n",
        "      elif j==2:\n",
        "        choice_label=\"C\"\n",
        "      else:\n",
        "        choice_label=\"D\"\n",
        "\n",
        "      choice_text=q_choices_list[j]\n",
        "      choice_dict={\n",
        "          'label': choice_label,\n",
        "          'text': choice_text.strip().lower()\n",
        "      }\n",
        "\n",
        "      if \"none of above\" in choice_dict['text']:\n",
        "        meaningful_choice_concepts=['none']\n",
        "      else:\n",
        "        meaningful_choice_concepts = extract_concepts(choice_dict['text'], char_count_thresh)\n",
        "\n",
        "      choice_dict['choice_concepts']= meaningful_choice_concepts\n",
        "      q_choices.append(choice_dict)\n",
        "\n",
        "    if is_train_data:\n",
        "      q_dict={\n",
        "            'id':q_id,\n",
        "            'answerKey':q_answerKey,\n",
        "            'question':{\n",
        "                'question_concept': meaningful_question_concepts,\n",
        "                'choices': q_choices,\n",
        "                'stem': q_stem,\n",
        "            }\n",
        "        }\n",
        "    else:\n",
        "        q_dict={\n",
        "            'id':q_id,\n",
        "            'question':{\n",
        "                'question_concept': meaningful_question_concepts,\n",
        "                'choices': q_choices,\n",
        "                'stem': q_stem,\n",
        "            }\n",
        "        }\n",
        "    processed_qs.append(q_dict)\n",
        "    # break\n",
        "  return processed_qs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6V7DX96EO8b",
        "outputId": "38075842-cac5-459e-e22c-b336f7263dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 36/120 [00:00<00:00, 87.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abbit ., concept not found in hard grounding.\n",
            "for abbit ., concept not found in hard grounding.\n",
            "for smie ., concept not found in hard grounding.\n",
            "for cowcowcowcoww, concept not found in hard grounding.\n",
            "for cowcowcowcoww, concept not found in hard grounding.\n",
            "for cobcobb, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▎  | 87/120 [00:00<00:00, 94.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n",
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n",
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 107/120 [00:01<00:00, 90.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for 28.0, concept not found in hard grounding.\n",
            "for 30.0, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:01<00:00, 88.54it/s]\n"
          ]
        }
      ],
      "source": [
        "# processed_dev_qs=preprocess_qa(SP_val_df, is_train_data=False, char_count_thresh=2)\n",
        "processed_dev_qs=preprocess_qa(val_df, is_train_data=False, char_count_thresh=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_dev_qs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1QU5fpsWMmd",
        "outputId": "4d141b08-0930-4044-add4-54aa12cbf94b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 0,\n",
              " 'question': {'question_concept': ['kind',\n",
              "   'no',\n",
              "   'of',\n",
              "   'have',\n",
              "   'shell',\n",
              "   'what',\n",
              "   'nut'],\n",
              "  'choices': [{'label': 'A',\n",
              "    'text': 'a peanut.',\n",
              "    'choice_concepts': ['peanut', 'a']},\n",
              "   {'label': 'B', 'text': 'a doughnut.', 'choice_concepts': ['doughnut', 'a']},\n",
              "   {'label': 'C', 'text': 'a walnut.', 'choice_concepts': ['walnut', 'a']},\n",
              "   {'label': 'D', 'text': 'none of above.', 'choice_concepts': ['none']}],\n",
              "  'stem': 'what kind of nut has no shell?'}}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBVPcotsET6O"
      },
      "outputs": [],
      "source": [
        "# with open(f'{DATA_FOLDER}/SP_dev_preprocessed_pruned.jsonl', 'w') as outfile:\n",
        "with open(f'{DATA_FOLDER}/WP_dev_preprocessed_pruned2.jsonl', 'w') as outfile:\n",
        "  for entry in processed_dev_qs:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfQcDMkUEO5S",
        "outputId": "a0291801-42b3-435e-841e-8900a622710d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:00<00:00, 381878.97it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.016666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "concept_count=[]\n",
        "\n",
        "for i in tqdm(range(len(processed_dev_qs))):\n",
        "  qa_sample=processed_dev_qs[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  concept_count.append(len(question_concepts))\n",
        "\n",
        "np.mean(np.array(concept_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db-OSSaHEO2W",
        "outputId": "905feed9-20d7-405a-8f5c-b0c0c4990628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 7/396 [00:00<00:06, 58.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for cowcowcowcoww, concept not found in hard grounding.\n",
            "for cowcowcowcoww, concept not found in hard grounding.\n",
            "for cobcobb, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 30/396 [00:00<00:07, 50.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for 28.0, concept not found in hard grounding.\n",
            "for 30.0, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 48/396 [00:00<00:06, 50.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abbit ., concept not found in hard grounding.\n",
            "for abbit ., concept not found in hard grounding.\n",
            "for smie ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 92/396 [00:02<00:08, 33.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n",
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n",
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 150/396 [00:03<00:05, 48.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for e., concept not found in hard grounding.\n",
            "for o., concept not found in hard grounding.\n",
            "for z., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 175/396 [00:04<00:04, 51.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for hho ., concept not found in hard grounding.\n",
            "for hho ., concept not found in hard grounding.\n",
            "for hotwa ., concept not found in hard grounding.\n",
            "for hotho ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 208/396 [00:05<00:04, 44.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for leftside ., concept not found in hard grounding.\n",
            "for rightside ., concept not found in hard grounding.\n",
            "for leftside ., concept not found in hard grounding.\n",
            "for rightside ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 226/396 [00:05<00:03, 52.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for stawberries ., concept not found in hard grounding.\n",
            "for stawberries ., concept not found in hard grounding.\n",
            "for g., concept not found in hard grounding."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 238/396 [00:05<00:03, 51.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "for h., concept not found in hard grounding.\n",
            "for t., concept not found in hard grounding.\n",
            "for t., concept not found in hard grounding.\n",
            "for g., concept not found in hard grounding.\n",
            "for h., concept not found in hard grounding.\n",
            "for c., concept not found in hard grounding.\n",
            "for cooie ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 262/396 [00:06<00:02, 53.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for t.c.i ., concept not found in hard grounding.\n",
            "for e., concept not found in hard grounding.\n",
            "for t., concept not found in hard grounding.\n",
            "for d., concept not found in hard grounding.\n",
            "for t., concept not found in hard grounding.\n",
            "for d., concept not found in hard grounding.\n",
            "for e., concept not found in hard grounding.\n",
            "for l., concept not found in hard grounding.\n",
            "for h., concept not found in hard grounding.\n",
            "for b., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 295/396 [00:06<00:01, 58.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for tookit ., concept not found in hard grounding.\n",
            "for tookit ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 344/396 [00:07<00:00, 58.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for slingsham ., concept not found in hard grounding.\n",
            "for enclamp ., concept not found in hard grounding.\n",
            "for gaslamp ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 390/396 [00:08<00:00, 59.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for nightwatch ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 396/396 [00:08<00:00, 47.31it/s]\n"
          ]
        }
      ],
      "source": [
        "# processed_train_qs=preprocess_qa(SP_train_df, is_train_data=True, char_count_thresh=2)\n",
        "processed_train_qs=preprocess_qa(WP_train_df, is_train_data=True, char_count_thresh=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIhkToLTDlyf"
      },
      "outputs": [],
      "source": [
        "# with open(f'{DATA_FOLDER}/SP_train_preprocessed_pruned.jsonl', 'w') as outfile:\n",
        "with open(f'{DATA_FOLDER}/WP_train_preprocessed_pruned2.jsonl', 'w') as outfile:\n",
        "  for entry in processed_train_qs:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKyovbfxDlvw",
        "outputId": "2771b9c1-17ee-41fa-bbad-659a53939fd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 396/396 [00:00<00:00, 459331.96it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.618686868686869"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "concept_count=[]\n",
        "\n",
        "for i in tqdm(range(len(processed_train_qs))):\n",
        "  qa_sample=processed_train_qs[i]\n",
        "  question_concepts=qa_sample['question']['question_concept']\n",
        "  concept_count.append(len(question_concepts))\n",
        "\n",
        "np.mean(np.array(concept_count))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOb35rmynDjG"
      },
      "source": [
        "##<font color=pink>Brain-Teaser Preprocessing</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFEd4QpWvN6e"
      },
      "source": [
        "###convert_to_entailment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USCN7ICjnNal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf2ed996-14d2-4306-8700-1fbb9f689de6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brain-teaser train size: 396, Brain-teaser dev size: 120\n"
          ]
        }
      ],
      "source": [
        "DATA_FOLDER=\"/content/drive/MyDrive/brain_teaser/datasets\"\n",
        "\n",
        "\n",
        "# linked_qa_file=f\"{DATA_FOLDER}/SP_train_preprocessed_pruned.jsonl\"\n",
        "linked_qa_file=f\"{DATA_FOLDER}/WP_train_preprocessed_pruned2.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  processed_train_qs = [json.loads(line) for line in f.read().split(\"\\n\") if line]\n",
        "\n",
        "# linked_qa_file=f\"{DATA_FOLDER}/SP_dev_preprocessed_pruned.jsonl\"\n",
        "linked_qa_file=f\"{DATA_FOLDER}/WP_dev_preprocessed_pruned2.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  processed_dev_qs = [json.loads(line) for line in f.read().split(\"\\n\") if line]\n",
        "\n",
        "print(f\"Brain-teaser train size: {len(processed_train_qs)}, Brain-teaser dev size: {len(processed_dev_qs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEhTHtbLWyQ1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "convert to entailment output\n",
        "\n",
        "{\"id\": \"xzc81234ioioucv-1052\",\n",
        "\"answerKey\": \"B\",\n",
        "\n",
        "\"question\": {\n",
        "\"question_concept\": [\"foot\", \"different\", \"long\"],\n",
        "\n",
        "\"choices\": [{\"label\": \"A\", \"text\": \"object\"},\n",
        "{\"label\": \"B\", \"text\": \"shoe\"},\n",
        "{\"label\": \"C\", \"text\": \"footing\"},\n",
        "{\"label\": \"D\", \"text\": \"grave\"},\n",
        "{\"label\": \"E\", \"text\": \"column\"}],\n",
        "\n",
        "\"stem\": \"what comes in many different sizes but is always only 1 foot long?\"},\n",
        "\n",
        "\"statements\": [\n",
        "{\"label\": false, \"statement\": \"Object comes in many different sizes but is always only 1 foot long.\"},\n",
        "{\"label\": true, \"statement\": \"Shoe comes in many different sizes but is always only 1 foot long.\"},\n",
        "{\"label\": false, \"statement\": \"Footing comes in many different sizes but is always only 1 foot long.\"},\n",
        "{\"label\": false, \"statement\": \"Grave comes in many different sizes but is always only 1 foot long.\"},\n",
        "{\"label\": false, \"statement\": \"Column comes in many different sizes but is always only 1 foot long.\"}]}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtGtrwx2bXx7"
      },
      "outputs": [],
      "source": [
        "def bt_convert_to_entailemnt(qa_dataset, is_train_data):\n",
        "  qa_statements=[]\n",
        "\n",
        "  for i in tqdm(range(len(qa_dataset))):\n",
        "    sample=qa_dataset[i]\n",
        "    id=sample['id']\n",
        "\n",
        "    if is_train_data:\n",
        "      answerKey=sample['answerKey']\n",
        "    question=sample['question']['stem']\n",
        "    question_concept=sample['question']['question_concept']\n",
        "    q_choices=sample['question']['choices']\n",
        "\n",
        "    statements=[]\n",
        "\n",
        "    for choice in q_choices:\n",
        "      statement={}\n",
        "      if is_train_data:\n",
        "        statement['label']=choice[\"label\"] == sample.get(\"answerKey\")\n",
        "      else:\n",
        "        statement['label']=None\n",
        "\n",
        "      statement['statement']=question+\" \"+choice['text']\n",
        "\n",
        "      statements.append(statement)\n",
        "\n",
        "\n",
        "    if is_train_data:\n",
        "      q_dict={\n",
        "                'id':id,\n",
        "                'answerKey':answerKey,\n",
        "                'question':{\n",
        "                    'question_concept': question_concept,\n",
        "                    'choices': q_choices,\n",
        "                    'stem': question,\n",
        "                },\n",
        "                'statements':statements\n",
        "            }\n",
        "    else:\n",
        "      q_dict={\n",
        "                'id':id,\n",
        "                'question':{\n",
        "                    'question_concept': question_concept,\n",
        "                    'choices': q_choices,\n",
        "                    'stem': question,\n",
        "                },\n",
        "                'statements':statements\n",
        "            }\n",
        "    qa_statements.append(q_dict)\n",
        "    # break\n",
        "\n",
        "  return qa_statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgpgFvhBj5PA",
        "outputId": "b40e9cf1-cfe1-428f-9374-61c9d77c10fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 396/396 [00:00<00:00, 82445.37it/s]\n"
          ]
        }
      ],
      "source": [
        "train_entailemnts= bt_convert_to_entailemnt(processed_train_qs, is_train_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYDOScnZmWB2"
      },
      "outputs": [],
      "source": [
        "statement_folder=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement\"\n",
        "\n",
        "# with open(f'{statement_folder}/SP_train.statement.jsonl', 'w') as outfile:\n",
        "with open(f'{statement_folder}/WP_train.statement.jsonl', 'w') as outfile:\n",
        "  for entry in train_entailemnts:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ucuFFN6j_Td",
        "outputId": "e5f7ccbd-35c1-401d-ab64-53ea67c0c6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:00<00:00, 82214.39it/s]\n"
          ]
        }
      ],
      "source": [
        "dev_entailemnts= bt_convert_to_entailemnt(processed_dev_qs, is_train_data=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT0Lacqfl6WY"
      },
      "outputs": [],
      "source": [
        "# with open(f'{statement_folder}/SP_dev.statement.jsonl', 'w') as outfile:\n",
        "with open(f'{statement_folder}/WP_dev.statement.jsonl', 'w') as outfile:\n",
        "  for entry in dev_entailemnts:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_entailemnts[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YiGvZrCZqA_",
        "outputId": "8b1e7f79-8985-4ed5-b4a7-361624826bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'WP-0_SR',\n",
              " 'answerKey': 'C',\n",
              " 'question': {'question_concept': ['cow',\n",
              "   'spell',\n",
              "   'you',\n",
              "   'thirteen',\n",
              "   'do',\n",
              "   'how',\n",
              "   'in',\n",
              "   'letter'],\n",
              "  'choices': [{'label': 'A',\n",
              "    'text': 'see oh dereford',\n",
              "    'choice_concepts': ['oh', 'see']},\n",
              "   {'label': 'B', 'text': 'cowcowcowcoww', 'choice_concepts': []},\n",
              "   {'label': 'C',\n",
              "    'text': 'see o double you.',\n",
              "    'choice_concepts': ['you', 'double', 'see', 'o']},\n",
              "   {'label': 'D', 'text': 'none of above.', 'choice_concepts': ['none']}],\n",
              "  'stem': 'in thirteen letters, how do you spell cow?'},\n",
              " 'statements': [{'label': False,\n",
              "   'statement': 'in thirteen letters, how do you spell cow? see oh dereford'},\n",
              "  {'label': False,\n",
              "   'statement': 'in thirteen letters, how do you spell cow? cowcowcowcoww'},\n",
              "  {'label': True,\n",
              "   'statement': 'in thirteen letters, how do you spell cow? see o double you.'},\n",
              "  {'label': False,\n",
              "   'statement': 'in thirteen letters, how do you spell cow? none of above.'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdj1bWKKl4M9",
        "outputId": "2cb55f0d-8c1a-45b3-f2d7-e664ea63f796"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'SP-0',\n",
              " 'answerKey': 'B',\n",
              " 'question': {'question_concept': ['family',\n",
              "   'brother',\n",
              "   'daughter',\n",
              "   'six',\n",
              "   'one',\n",
              "   'mustard',\n",
              "   'hat'],\n",
              "  'choices': [{'label': 'A',\n",
              "    'text': 'some daughters get married and have their own family.',\n",
              "    'choice_concepts': ['heir', 'daughter', 'own family', 'get married']},\n",
              "   {'label': 'B',\n",
              "    'text': 'each daughter shares the same brother.',\n",
              "    'choice_concepts': ['ares', 'daughter', 'share', 'brother']},\n",
              "   {'label': 'C',\n",
              "    'text': 'some brothers were not loved by family and moved away.',\n",
              "    'choice_concepts': ['loved', 'moved', 'family', 'brother']},\n",
              "   {'label': 'D', 'text': 'none of above.', 'choice_concepts': ['none']}],\n",
              "  'stem': 'mr. and mrs. mustard have six daughters and each daughter has one brother. but there are only 9 people in the family, how is that possible?'},\n",
              " 'statements': [{'label': False,\n",
              "   'statement': 'mr. and mrs. mustard have six daughters and each daughter has one brother. but there are only 9 people in the family, how is that possible? some daughters get married and have their own family.'},\n",
              "  {'label': True,\n",
              "   'statement': 'mr. and mrs. mustard have six daughters and each daughter has one brother. but there are only 9 people in the family, how is that possible? each daughter shares the same brother.'},\n",
              "  {'label': False,\n",
              "   'statement': 'mr. and mrs. mustard have six daughters and each daughter has one brother. but there are only 9 people in the family, how is that possible? some brothers were not loved by family and moved away.'},\n",
              "  {'label': False,\n",
              "   'statement': 'mr. and mrs. mustard have six daughters and each daughter has one brother. but there are only 9 people in the family, how is that possible? none of above.'}]}"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_entailemnts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "111M2TuZl6Qo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwIz4-1QJNcS"
      },
      "source": [
        "grounding --> done with original code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMeyv4AJnq1x"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "\n",
        "grounding output\n",
        "\n",
        "{\"sent\": \"Object comes in many different sizes but is always only 1 foot long.\",\n",
        "\"ans\": \"object\",\n",
        "\"qc\": [\"always\", \"come\", \"comes\", \"different\", \"different_sizes\", \"foot\", \"long\", \"many\", \"size\", \"sizes\"],\n",
        "\"ac\": [\"object\"]}\n",
        "\n",
        "{\"sent\": \"Shoe comes in many different sizes but is always only 1 foot long.\", \"ans\": \"shoe\", \"qc\": [\"always\", \"come\", \"comes\", \"different\", \"different_sizes\", \"foot\", \"long\", \"many\", \"size\", \"sizes\"], \"ac\": [\"shoe\"]}\n",
        "{\"sent\": \"Footing comes in many different sizes but is always only 1 foot long.\", \"ans\": \"footing\", \"qc\": [\"always\", \"come\", \"comes\", \"different\", \"different_sizes\", \"long\", \"many\", \"size\", \"sizes\"], \"ac\": [\"foot\"]}\n",
        "{\"sent\": \"Grave comes in many different sizes but is always only 1 foot long.\", \"ans\": \"grave\", \"qc\": [\"always\", \"come\", \"comes\", \"different\", \"different_sizes\", \"foot\", \"long\", \"many\", \"size\", \"sizes\"], \"ac\": [\"grave\", \"graven\"]}\n",
        "{\"sent\": \"Column comes in many different sizes but is always only 1 foot long.\", \"ans\": \"column\", \"qc\": [\"always\", \"come\", \"comes\", \"different\", \"different_sizes\", \"foot\", \"long\", \"many\", \"size\", \"sizes\"], \"ac\": [\"column\"]}\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BipYjvDXQqmn"
      },
      "source": [
        "generate_adj_data_from_grounded_concepts__use_LM --> done with original code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqV5r4N2nqxn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynkYiLtLp8hL"
      },
      "source": [
        "###grounding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####SP"
      ],
      "metadata": {
        "id": "tmHPbVpCacmn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LcDeTZboFfE",
        "outputId": "5f5c00cc-bbbe-4037-e511-4c671213c212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "brain_teaser_ds\n",
            "{'func': <function ground at 0x7b5c99019870>, 'args': ('/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_dev.statement.jsonl', './data/cpnet/concept.txt', './data/cpnet/matcher_patterns.json', '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/SP_dev.grounded.jsonl', 2)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 451/480 [16:58<01:05,  2.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tumnioavy4g4yjtpm7nddbi9chaab9ruep, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 480/480 [17:30<00:00,  2.19s/it]\n",
            "100%|██████████| 480/480 [00:19<00:00, 24.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grounded concepts saved to /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/SP_dev.grounded.jsonl\n",
            "\n",
            "Successfully run brain_teaser_ds\n"
          ]
        }
      ],
      "source": [
        "args=dict()\n",
        "args[\"run\"]=['brain_teaser_ds']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "\n",
        "routines = {\n",
        "    'brain_teaser_ds': [\n",
        "        {'func': ground, 'args': (output_paths['brain_teaser_ds']['statement']['SP_dev'], output_paths['cpnet']['vocab'],\n",
        "                                  output_paths['cpnet']['patterns'], output_paths['brain_teaser_ds']['grounded']['SP_dev'], args[\"nprocs\"])},\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39n_v-COtwfj",
        "outputId": "24b083bc-6e08-4ca9-e534-682875da1d61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "brain_teaser_ds\n",
            "{'func': <function ground at 0x7d0c6ab5da20>, 'args': ('/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl', './data/cpnet/concept.txt', './data/cpnet/matcher_patterns.json', '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/SP_train.grounded.jsonl', 2)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 209/2028 [08:48<35:36,  1.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tumnioavy4g4yjtpm7nddbi9chaab9ruep, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 842/2028 [25:24<28:56,  1.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for jil ., concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 844/2028 [25:31<43:52,  2.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for jil ., concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 878/2028 [26:08<12:08,  1.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 2000.0, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 880/2028 [26:09<10:30,  1.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 2000.0, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▎     | 884/2028 [26:11<09:18,  2.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for 1776.0, concept not found in hard grounding.\n",
            "for 2020.0, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 1071/2028 [30:03<23:38,  1.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for tumnioavy4g4yjtpm7nddbi9chaab9ruep, concept not found in hard grounding.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2028/2028 [53:14<00:00,  1.58s/it]\n",
            "100%|██████████| 2028/2028 [01:22<00:00, 24.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grounded concepts saved to /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/SP_train.grounded.jsonl\n",
            "\n",
            "Successfully run brain_teaser_ds\n"
          ]
        }
      ],
      "source": [
        "args=dict()\n",
        "args[\"run\"]=['brain_teaser_ds']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "\n",
        "routines = {\n",
        "    'brain_teaser_ds': [\n",
        "        {'func': ground, 'args': (output_paths['brain_teaser_ds']['statement']['SP_train'], output_paths['cpnet']['vocab'],\n",
        "                                  output_paths['cpnet']['patterns'], output_paths['brain_teaser_ds']['grounded']['SP_train'], args[\"nprocs\"])},\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "preprocess_func(args, routines)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####WP"
      ],
      "metadata": {
        "id": "yyGBxbhnae8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpnet_vocab = load_cpnet_vocab(output_paths['cpnet']['vocab'])\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner', 'textcat'])"
      ],
      "metadata": {
        "id": "hNJCC2BAscIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args=dict()\n",
        "args[\"run\"]=['brain_teaser_ds']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "\n",
        "routines = {\n",
        "    'brain_teaser_ds': [\n",
        "        {'func': ground, 'args': (output_paths['brain_teaser_ds']['statement']['WP_dev'], output_paths['cpnet']['vocab'],\n",
        "                                  output_paths['cpnet']['patterns'], output_paths['brain_teaser_ds']['grounded']['WP_dev'], args[\"nprocs\"])},\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "preprocess_func(args, routines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ksee9MZkahX0",
        "outputId": "dff5ac49-d375-4e5d-eae7-1ab5f50d2998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brain_teaser_ds\n",
            "{'func': <function ground at 0x7d8596e37010>, 'args': ('/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_dev.statement.jsonl', './data/cpnet/concept.txt', './data/cpnet/matcher_patterns.json', '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/WP_dev.grounded.jsonl', 2)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 84/480 [04:16<06:02,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abbit ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 87/480 [04:18<05:19,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abbit ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 91/480 [04:20<04:19,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for smie ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 132/480 [04:40<02:14,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for cowcowcowcoww, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▊       | 137/480 [04:41<01:52,  3.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for cowcowcowcoww, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 140/480 [04:42<02:02,  2.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for cobcobb, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 278/480 [06:22<01:29,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 282/480 [06:24<01:11,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 286/480 [06:25<01:18,  2.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████▏ | 390/480 [07:16<01:00,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for 28.0, concept not found in hard grounding.\n",
            "for 30.0, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 480/480 [08:25<00:00,  1.05s/it]\n",
            "100%|██████████| 480/480 [00:07<00:00, 60.27it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grounded concepts saved to /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/WP_dev.grounded.jsonl\n",
            "\n",
            "Successfully run brain_teaser_ds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args=dict()\n",
        "args[\"run\"]=['brain_teaser_ds']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "\n",
        "routines = {\n",
        "    'brain_teaser_ds': [\n",
        "        {'func': ground, 'args': (output_paths['brain_teaser_ds']['statement']['WP_train'], output_paths['cpnet']['vocab'],\n",
        "                                  output_paths['cpnet']['patterns'], output_paths['brain_teaser_ds']['grounded']['WP_train'], args[\"nprocs\"])},\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "preprocess_func(args, routines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10D8qZV1ag-o",
        "outputId": "75683e21-00c7-47ac-fdd4-0b18cfbe7647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "brain_teaser_ds\n",
            "{'func': <function ground at 0x7d8596e37010>, 'args': ('/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl', './data/cpnet/concept.txt', './data/cpnet/matcher_patterns.json', '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/WP_train.grounded.jsonl', 2)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1584 [02:58<78:18:35, 178.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for cowcowcowcoww, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 5/1584 [03:00<8:30:50, 19.41s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for cowcowcowcoww, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 8/1584 [03:02<3:00:29,  6.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for cobcobb, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 78/1584 [03:59<21:29,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for 28.0, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 81/1584 [04:00<16:05,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for 30.0, concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 141/1584 [05:02<37:07,  1.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abbit ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 148/1584 [05:06<18:08,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abbit ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 151/1584 [05:08<17:32,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for smie ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 362/1584 [06:46<07:44,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 366/1584 [06:47<07:11,  2.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 370/1584 [06:49<07:57,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for abcdefghijklmnopqrstuvwxyz ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 560/1584 [09:00<08:01,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for e., concept not found in hard grounding.\n",
            "for o., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 562/1584 [09:01<07:23,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for z., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 671/1584 [10:19<10:56,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for hho ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 677/1584 [10:21<06:31,  2.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for hho ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 680/1584 [10:22<06:15,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for hotwa ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 682/1584 [10:23<05:44,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for hotho ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 805/1584 [11:45<05:51,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for leftside ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 806/1584 [11:45<06:08,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for rightside ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 808/1584 [11:46<06:04,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for leftside ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 809/1584 [11:46<04:54,  2.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for rightside ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 866/1584 [12:18<07:05,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for stawberries ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▍    | 870/1584 [12:20<05:58,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for stawberries ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 912/1584 [12:38<05:32,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for g., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 913/1584 [12:38<05:21,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for h., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 914/1584 [12:38<04:39,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for t., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 916/1584 [12:39<04:37,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for t., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 917/1584 [12:39<04:09,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for g., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 918/1584 [12:40<04:26,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for h., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 919/1584 [12:40<03:54,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for c., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 922/1584 [12:41<04:19,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for cooie ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 1003/1584 [13:20<04:07,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for t.c.i ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 1007/1584 [13:21<04:03,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for e., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▎   | 1009/1584 [13:22<04:16,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for t., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 1010/1584 [13:22<03:40,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for d., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 1012/1584 [13:24<05:34,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for t., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 1013/1584 [13:25<05:57,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for d., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 1014/1584 [13:26<06:50,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for e., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 1015/1584 [13:26<06:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for l., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 1016/1584 [13:28<07:54,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for b., concept not found in hard grounding.\n",
            "for h., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 1139/1584 [14:30<03:15,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for tookit ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 1143/1584 [14:32<04:01,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for tookit ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▍ | 1342/1584 [16:08<01:23,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for slingsham ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 1352/1584 [16:12<01:37,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for enclamp ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 1354/1584 [16:13<01:41,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for gaslamp ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 1521/1584 [17:25<00:36,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for nightwatch ., concept not found in hard grounding.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1584/1584 [17:51<00:00,  1.48it/s]\n",
            "100%|██████████| 1584/1584 [00:21<00:00, 72.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grounded concepts saved to /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/WP_train.grounded.jsonl\n",
            "\n",
            "Successfully run brain_teaser_ds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5bPbKdVrC6z"
      },
      "source": [
        "###generate_adj_data_from_grounded_concepts__use_LM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48YJR6gju2VW"
      },
      "source": [
        "####SP_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yn0FVUMoFco",
        "outputId": "7993423b-1a0d-4215-b7a7-01a7552bd5de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating adj data for /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/SP_dev.grounded.jsonl...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 480/480 [00:11<00:00, 40.69it/s]\n"
          ]
        }
      ],
      "source": [
        "args=dict()\n",
        "args[\"run\"]=['brain_teaser_ds']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "res1=generate_adj_data_from_grounded_concepts__use_LM(output_paths['brain_teaser_ds']['grounded']['SP_dev'],\n",
        "                  output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['brain_teaser_ds']['graph']['adj-SP_dev'], args[\"nprocs\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYIKfjHpye0d",
        "outputId": "cbcc4664-836e-472b-fbde-f1e636084c89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "300\n",
            "310\n",
            "320\n",
            "330\n",
            "340\n",
            "350\n",
            "360\n",
            "370\n",
            "380\n",
            "390\n",
            "400\n",
            "410\n",
            "420\n",
            "430\n",
            "440\n",
            "450\n",
            "460\n",
            "470\n"
          ]
        }
      ],
      "source": [
        "data_range_to_process=[0,480]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aQBGYtVQVYY",
        "outputId": "a2b23408-7688-42fa-f0c2-3d48a0dbd697"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "480"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(res2[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLT5pYpQxUTb",
        "outputId": "6d40fcdc-698d-48c2-afa2-0caaa776f05c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 480/480 [06:16<00:00,  1.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "adj data saved to /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_dev.graph.adj.pk\n",
            "\n"
          ]
        }
      ],
      "source": [
        "do_part3(res2[0], args[\"nprocs\"], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['brain_teaser_ds']['graph']['adj-SP_dev'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLYx4NmxxT58",
        "outputId": "cad30013-0c34-47d0-fcad-4e0137d9833f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([291,\n",
              "  1988,\n",
              "  2805,\n",
              "  3153,\n",
              "  4426,\n",
              "  4629,\n",
              "  6422,\n",
              "  8912,\n",
              "  9853,\n",
              "  14901,\n",
              "  17632,\n",
              "  17635,\n",
              "  23346,\n",
              "  36809,\n",
              "  72046,\n",
              "  147003,\n",
              "  184131,\n",
              "  376734,\n",
              "  472083],\n",
              " [6195, 15375, 52510, 229219, 404519],\n",
              " 'everyone called him \"batman,\" but he knew nothing about bats and thought they were disgusting. he still cherished being referred to as batman! how is this possible? he tries to be friendly..',\n",
              " [287,\n",
              "  289,\n",
              "  295,\n",
              "  306,\n",
              "  309,\n",
              "  567,\n",
              "  572,\n",
              "  575,\n",
              "  579,\n",
              "  648,\n",
              "  691,\n",
              "  695,\n",
              "  786,\n",
              "  874,\n",
              "  884,\n",
              "  1001,\n",
              "  1004,\n",
              "  1172,\n",
              "  1192,\n",
              "  1363,\n",
              "  1564,\n",
              "  1594,\n",
              "  1692,\n",
              "  1713,\n",
              "  1726,\n",
              "  1769,\n",
              "  2002,\n",
              "  2106,\n",
              "  2130,\n",
              "  2194,\n",
              "  2274,\n",
              "  2288,\n",
              "  2350,\n",
              "  2352,\n",
              "  2412,\n",
              "  2413,\n",
              "  2571,\n",
              "  2573,\n",
              "  2606,\n",
              "  2611,\n",
              "  3013,\n",
              "  3050,\n",
              "  3071,\n",
              "  3078,\n",
              "  3126,\n",
              "  3319,\n",
              "  3450,\n",
              "  3517,\n",
              "  3804,\n",
              "  3921,\n",
              "  4107,\n",
              "  4299,\n",
              "  4363,\n",
              "  4368,\n",
              "  4495,\n",
              "  4529,\n",
              "  4574,\n",
              "  4627,\n",
              "  5354,\n",
              "  5586,\n",
              "  5698,\n",
              "  5703,\n",
              "  5854,\n",
              "  6263,\n",
              "  6423,\n",
              "  6424,\n",
              "  6531,\n",
              "  6532,\n",
              "  6706,\n",
              "  6714,\n",
              "  6717,\n",
              "  6745,\n",
              "  6753,\n",
              "  6757,\n",
              "  6758,\n",
              "  6788,\n",
              "  6915,\n",
              "  7320,\n",
              "  7324,\n",
              "  7685,\n",
              "  7869,\n",
              "  8021,\n",
              "  8361,\n",
              "  8715,\n",
              "  8789,\n",
              "  9047,\n",
              "  9425,\n",
              "  9447,\n",
              "  9699,\n",
              "  9764,\n",
              "  9855,\n",
              "  9856,\n",
              "  9893,\n",
              "  10011,\n",
              "  10015,\n",
              "  10244,\n",
              "  10794,\n",
              "  10810,\n",
              "  10998,\n",
              "  11203,\n",
              "  11263,\n",
              "  11310,\n",
              "  11424,\n",
              "  11425,\n",
              "  11426,\n",
              "  11971,\n",
              "  12093,\n",
              "  12382,\n",
              "  12556,\n",
              "  12713,\n",
              "  12738,\n",
              "  12973,\n",
              "  13091,\n",
              "  13342,\n",
              "  13433,\n",
              "  13475,\n",
              "  13691,\n",
              "  14296,\n",
              "  14376,\n",
              "  14447,\n",
              "  14549,\n",
              "  14854,\n",
              "  15153,\n",
              "  15154,\n",
              "  15155,\n",
              "  15378,\n",
              "  15982,\n",
              "  16095,\n",
              "  17606,\n",
              "  17608,\n",
              "  18491,\n",
              "  21260,\n",
              "  23437,\n",
              "  23614,\n",
              "  27455,\n",
              "  29865,\n",
              "  30575,\n",
              "  31507,\n",
              "  31603,\n",
              "  36025,\n",
              "  36862,\n",
              "  38999,\n",
              "  39144,\n",
              "  42846,\n",
              "  47884,\n",
              "  48280,\n",
              "  54499,\n",
              "  55769,\n",
              "  55872,\n",
              "  56154,\n",
              "  61459,\n",
              "  62355,\n",
              "  63165,\n",
              "  65494,\n",
              "  65738,\n",
              "  65765,\n",
              "  65832,\n",
              "  65996,\n",
              "  66100,\n",
              "  68713,\n",
              "  69706,\n",
              "  73868,\n",
              "  74169,\n",
              "  74235,\n",
              "  74415,\n",
              "  75033,\n",
              "  76483,\n",
              "  87609,\n",
              "  93034,\n",
              "  120933,\n",
              "  133297,\n",
              "  165089,\n",
              "  181251,\n",
              "  183585,\n",
              "  185389,\n",
              "  187008,\n",
              "  214915,\n",
              "  217658,\n",
              "  385389,\n",
              "  411587,\n",
              "  497674,\n",
              "  576608,\n",
              "  581854,\n",
              "  602342,\n",
              "  699376,\n",
              "  699821,\n",
              "  704173],\n",
              " OrderedDict([(55872, -7.1989613),\n",
              "              (704173, -7.776122),\n",
              "              (786, -8.012945),\n",
              "              (133297, -8.016259),\n",
              "              (6195, -8.057086),\n",
              "              (63165, -8.184441),\n",
              "              (55769, -8.214766),\n",
              "              (2352, -8.233757),\n",
              "              (7324, -8.235179),\n",
              "              (87609, -8.299101),\n",
              "              (15375, -8.323656),\n",
              "              (1172, -8.392345),\n",
              "              (52510, -8.395995),\n",
              "              (4426, -8.439569),\n",
              "              (36809, -8.53639),\n",
              "              (12556, -8.5532),\n",
              "              (65832, -8.571836),\n",
              "              (1594, -8.614493),\n",
              "              (68713, -8.662603),\n",
              "              (229219, -8.669494),\n",
              "              (15153, -8.827476),\n",
              "              (75033, -8.829262),\n",
              "              (404519, -8.861881),\n",
              "              (65494, -8.962278),\n",
              "              (579, -8.977316),\n",
              "              (214915, -8.980687),\n",
              "              (9699, -8.988975),\n",
              "              (5354, -9.022917),\n",
              "              (9855, -9.122673),\n",
              "              (17632, -9.124646),\n",
              "              (-1, -9.2120495),\n",
              "              (27455, -9.252285),\n",
              "              (497674, -9.343916),\n",
              "              (7869, -9.3979225),\n",
              "              (73868, -9.407293),\n",
              "              (6424, -9.421107),\n",
              "              (291, -9.485567),\n",
              "              (2002, -9.487242),\n",
              "              (6263, -9.501049),\n",
              "              (93034, -9.517207),\n",
              "              (8021, -9.538255),\n",
              "              (1988, -9.580269),\n",
              "              (411587, -9.618804),\n",
              "              (8789, -9.712831),\n",
              "              (61459, -9.738408),\n",
              "              (8361, -9.766711),\n",
              "              (4629, -9.77242),\n",
              "              (42846, -9.873113),\n",
              "              (1692, -9.897671),\n",
              "              (54499, -9.9023),\n",
              "              (31603, -9.980537),\n",
              "              (576608, -10.115407),\n",
              "              (17606, -10.118902),\n",
              "              (39144, -10.145231),\n",
              "              (147003, -10.198061),\n",
              "              (9856, -10.40217),\n",
              "              (3319, -10.465435),\n",
              "              (65738, -10.494603),\n",
              "              (181251, -10.536544),\n",
              "              (1004, -10.718819),\n",
              "              (36862, -10.879913),\n",
              "              (289, -11.052989),\n",
              "              (65765, -11.096824),\n",
              "              (1001, -11.338105),\n",
              "              (36025, -11.430987),\n",
              "              (4574, -11.446846),\n",
              "              (9853, -11.466513),\n",
              "              (8912, -11.513254),\n",
              "              (38999, -11.541716),\n",
              "              (1713, -11.559392),\n",
              "              (691, -11.786684),\n",
              "              (581854, -11.797997),\n",
              "              (6423, -11.946724),\n",
              "              (6788, -11.982958),\n",
              "              (62355, -12.187888),\n",
              "              (10015, -12.390478),\n",
              "              (3126, -12.418005),\n",
              "              (2130, -12.599722),\n",
              "              (10244, -12.828595),\n",
              "              (7320, -12.948758),\n",
              "              (17635, -13.033985),\n",
              "              (2194, -13.236009),\n",
              "              (31507, -13.281084),\n",
              "              (10011, -13.285738),\n",
              "              (572, -13.337926),\n",
              "              (1363, -13.6962185),\n",
              "              (14549, -13.779297),\n",
              "              (12738, -13.88022),\n",
              "              (1726, -14.098649),\n",
              "              (2288, -14.236174),\n",
              "              (3078, -14.341013),\n",
              "              (6532, -14.345785),\n",
              "              (14854, -14.515726),\n",
              "              (699821, -14.57966),\n",
              "              (695, -14.701956),\n",
              "              (12382, -14.905483),\n",
              "              (2274, -15.0268345),\n",
              "              (1192, -15.036413),\n",
              "              (3450, -15.20609),\n",
              "              (3921, -15.264328),\n",
              "              (9764, -15.349123),\n",
              "              (884, -15.350082),\n",
              "              (4368, -15.357478),\n",
              "              (15155, -15.38871),\n",
              "              (10810, -15.522682),\n",
              "              (2350, -15.560108),\n",
              "              (287, -15.654535),\n",
              "              (9047, -15.664593),\n",
              "              (30575, -15.7078705),\n",
              "              (2106, -15.7692175),\n",
              "              (6745, -15.82814),\n",
              "              (14376, -16.057587),\n",
              "              (2611, -16.102299),\n",
              "              (13475, -16.518406),\n",
              "              (6758, -16.541283),\n",
              "              (13433, -16.667976),\n",
              "              (6757, -16.703802),\n",
              "              (567, -16.717525),\n",
              "              (6422, -16.79213),\n",
              "              (602342, -16.88874),\n",
              "              (13691, -16.983288),\n",
              "              (13091, -17.113848),\n",
              "              (2413, -17.297785),\n",
              "              (23346, -17.390932),\n",
              "              (185389, -17.535313),\n",
              "              (2571, -17.898598),\n",
              "              (11426, -18.127535),\n",
              "              (23437, -18.289928),\n",
              "              (6706, -18.574945),\n",
              "              (2412, -18.60897),\n",
              "              (1564, -18.708406),\n",
              "              (29865, -18.896748),\n",
              "              (56154, -18.976198),\n",
              "              (4627, -19.004093),\n",
              "              (7685, -19.076807),\n",
              "              (48280, -19.140776),\n",
              "              (13342, -19.151632),\n",
              "              (165089, -19.26384),\n",
              "              (12973, -19.429974),\n",
              "              (12093, -19.439638),\n",
              "              (6915, -19.559433),\n",
              "              (11310, -19.5669),\n",
              "              (295, -19.599863),\n",
              "              (2805, -19.655308),\n",
              "              (47884, -19.762074),\n",
              "              (8715, -19.774805),\n",
              "              (5703, -19.80809),\n",
              "              (6531, -19.903717),\n",
              "              (6717, -19.935884),\n",
              "              (309, -20.014717),\n",
              "              (11263, -20.131027),\n",
              "              (4495, -20.212238),\n",
              "              (4529, -20.25142),\n",
              "              (3050, -20.291225),\n",
              "              (5854, -20.298632),\n",
              "              (18491, -20.44183),\n",
              "              (5586, -20.476177),\n",
              "              (15378, -20.493488),\n",
              "              (10998, -20.548422),\n",
              "              (65996, -20.608635),\n",
              "              (14901, -20.677036),\n",
              "              (183585, -20.68127),\n",
              "              (1769, -20.726452),\n",
              "              (3517, -20.738337),\n",
              "              (74235, -20.792383),\n",
              "              (11971, -20.897495),\n",
              "              (4299, -20.936571),\n",
              "              (6714, -20.940804),\n",
              "              (385389, -20.9872),\n",
              "              (699376, -21.015396),\n",
              "              (2573, -21.048),\n",
              "              (6753, -21.083384),\n",
              "              (3013, -21.159721),\n",
              "              (376734, -21.229954),\n",
              "              (648, -21.27314),\n",
              "              (11203, -21.282679),\n",
              "              (12713, -21.284145),\n",
              "              (5698, -21.349943),\n",
              "              (3804, -21.395243),\n",
              "              (874, -21.425049),\n",
              "              (14447, -21.444622),\n",
              "              (15154, -21.472588),\n",
              "              (120933, -21.525616),\n",
              "              (10794, -21.64585),\n",
              "              (217658, -21.675667),\n",
              "              (11424, -21.689632),\n",
              "              (3153, -21.828156),\n",
              "              (72046, -21.859077),\n",
              "              (575, -21.88385),\n",
              "              (15982, -21.91603),\n",
              "              (16095, -22.0471),\n",
              "              (3071, -22.062534),\n",
              "              (17608, -22.096054),\n",
              "              (4107, -22.15079),\n",
              "              (69706, -22.273052),\n",
              "              (74169, -22.556341),\n",
              "              (306, -22.746181),\n",
              "              (2606, -22.77343),\n",
              "              (9893, -22.78639),\n",
              "              (66100, -23.03644),\n",
              "              (184131, -23.362167),\n",
              "              (9447, -23.364801),\n",
              "              (14296, -23.377232),\n",
              "              (11425, -23.414536),\n",
              "              (9425, -23.709435),\n",
              "              (21260, -23.928774),\n",
              "              (23614, -24.02748),\n",
              "              (472083, -24.271519),\n",
              "              (4363, -24.370037),\n",
              "              (74415, -24.668604),\n",
              "              (187008, -25.387598),\n",
              "              (76483, -25.452291)]))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_res2[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlfLRKLbrY9w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3myTUOzrY43"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti71TzHFu0wD"
      },
      "source": [
        "####SP_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwFVoFprrYz_",
        "outputId": "049de74f-91a8-4e56-c520-c1e19f3c70de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating adj data for /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/SP_train.grounded.jsonl...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2028/2028 [00:39<00:00, 51.43it/s]\n"
          ]
        }
      ],
      "source": [
        "args=dict()\n",
        "args[\"run\"]=['brain_teaser_ds']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "res1=generate_adj_data_from_grounded_concepts__use_LM(output_paths['brain_teaser_ds']['grounded']['SP_train'],\n",
        "                  output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['brain_teaser_ds']['graph']['adj-SP_train'], args[\"nprocs\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5QmEulZR_0D",
        "outputId": "86ebfbfd-533a-4deb-ae67-7aeac195fa14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "300\n",
            "310\n",
            "320\n",
            "330\n",
            "340\n",
            "350\n",
            "360\n",
            "370\n",
            "380\n",
            "390\n",
            "400\n",
            "410\n",
            "420\n",
            "430\n",
            "440\n",
            "450\n",
            "460\n",
            "470\n",
            "480\n",
            "490\n"
          ]
        }
      ],
      "source": [
        "data_range_to_process=[0,500]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0cvRYvAh5Jk",
        "outputId": "a6bf02d0-398b-4a76-c9c8-07416208f6cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n",
            "510\n",
            "520\n",
            "530\n",
            "540\n",
            "550\n",
            "560\n",
            "570\n",
            "580\n",
            "590\n",
            "600\n",
            "610\n",
            "620\n",
            "630\n",
            "640\n",
            "650\n",
            "660\n",
            "670\n",
            "680\n",
            "690\n",
            "700\n",
            "710\n",
            "720\n",
            "730\n",
            "740\n",
            "750\n",
            "760\n",
            "770\n",
            "780\n",
            "790\n",
            "800\n",
            "810\n",
            "820\n",
            "830\n",
            "840\n",
            "850\n",
            "860\n",
            "870\n",
            "880\n",
            "890\n",
            "900\n",
            "910\n",
            "920\n",
            "930\n",
            "940\n",
            "950\n",
            "960\n",
            "970\n",
            "980\n",
            "990\n"
          ]
        }
      ],
      "source": [
        "data_range_to_process=[500,1000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXhIQ6B3iBSw",
        "outputId": "676255d4-c05d-4a4e-fcdd-21b70d5bd893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n",
            "1010\n",
            "1020\n",
            "1030\n",
            "1040\n",
            "1050\n",
            "1060\n",
            "1070\n",
            "1080\n",
            "1090\n",
            "1100\n",
            "1110\n",
            "1120\n",
            "1130\n",
            "1140\n",
            "1150\n",
            "1160\n",
            "1170\n",
            "1180\n",
            "1190\n",
            "1200\n",
            "1210\n",
            "1220\n",
            "1230\n",
            "1240\n",
            "1250\n",
            "1260\n",
            "1270\n",
            "1280\n",
            "1290\n",
            "1300\n",
            "1310\n",
            "1320\n",
            "1330\n",
            "1340\n",
            "1350\n",
            "1360\n",
            "1370\n",
            "1380\n",
            "1390\n",
            "1400\n",
            "1410\n",
            "1420\n",
            "1430\n",
            "1440\n",
            "1450\n",
            "1460\n",
            "1470\n",
            "1480\n",
            "1490\n"
          ]
        }
      ],
      "source": [
        "data_range_to_process=[1000, 1500]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4rebKEniBPT",
        "outputId": "6959bbe1-d677-4643-b686-ece9c0b650e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1500\n",
            "1510\n",
            "1520\n",
            "1530\n",
            "1540\n",
            "1550\n",
            "1560\n",
            "1570\n",
            "1580\n",
            "1590\n",
            "1600\n",
            "1610\n",
            "1620\n",
            "1630\n",
            "1640\n",
            "1650\n",
            "1660\n",
            "1670\n",
            "1680\n",
            "1690\n",
            "1700\n",
            "1710\n",
            "1720\n",
            "1730\n",
            "1740\n",
            "1750\n",
            "1760\n",
            "1770\n",
            "1780\n",
            "1790\n",
            "1800\n",
            "1810\n",
            "1820\n",
            "1830\n",
            "1840\n",
            "1850\n",
            "1860\n",
            "1870\n",
            "1880\n",
            "1890\n",
            "1900\n",
            "1910\n",
            "1920\n",
            "1930\n",
            "1940\n",
            "1950\n",
            "1960\n",
            "1970\n",
            "1980\n",
            "1990\n",
            "2000\n",
            "2010\n",
            "2020\n"
          ]
        }
      ],
      "source": [
        "data_range_to_process=[1500,2028]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVHLz2KDh5Eb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r61TgbEvSuT3"
      },
      "source": [
        "combine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t1Qs-9gTyDQ",
        "outputId": "3354a9c4-3bf2-4b0e-fa52-aba88103f7eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp_res2=[]\n",
        "i=500\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp[0])\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PV4EN9cT-jh",
        "outputId": "b667749d-926f-46d3-f43b-798c887302ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=1000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp[0])\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTkkTJtoiO3y",
        "outputId": "ebb8ebd7-ddc4-4f96-a7a9-dc680a89cbfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1500"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=1500\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp[0])\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shmAFIcFS_4L",
        "outputId": "356c2ff4-f9e7-4c1a-d967-ff886ad18445"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2028"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i=2028\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp[0])\n",
        "len(temp_res2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxnFTAKQUvCt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcTULyykS6Pz"
      },
      "source": [
        "part3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvKpgG1AS0Oy",
        "outputId": "9733a148-b561-417e-a34d-9e377d260636"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2028/2028 [22:52<00:00,  1.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "adj data saved to /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_train.graph.adj.pk\n",
            "\n"
          ]
        }
      ],
      "source": [
        "args=dict()\n",
        "args[\"run\"]=['brain_teaser_ds']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "\n",
        "do_part3(temp_res2, args[\"nprocs\"], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['brain_teaser_ds']['graph']['adj-SP_train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YglwvA33oFZI",
        "outputId": "429416cf-171d-4bee-c4ab-4b66fd3a5832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'/content/data/csqa' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa'\n",
            "'/content/data/csqa/grounded' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/grounded'\n",
            "'/content/data/csqa/grounded/test.grounded.jsonl' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/grounded/test.grounded.jsonl'\n",
            "'/content/data/csqa/grounded/train.grounded.jsonl' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/grounded/train.grounded.jsonl'\n",
            "'/content/data/csqa/grounded/dev.grounded.jsonl' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/grounded/dev.grounded.jsonl'\n",
            "'/content/data/csqa/graph' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/graph'\n",
            "'/content/data/csqa/graph/test.graph.adj.pk' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/graph/test.graph.adj.pk'\n",
            "'/content/data/csqa/graph/dev.graph.adj.pk.loaded_cache' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/graph/dev.graph.adj.pk.loaded_cache'\n",
            "'/content/data/csqa/graph/train.graph.adj.pk' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/graph/train.graph.adj.pk'\n",
            "'/content/data/csqa/graph/test.graph.adj.pk.loaded_cache' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/graph/test.graph.adj.pk.loaded_cache'\n",
            "'/content/data/csqa/graph/dev.graph.adj.pk' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/graph/dev.graph.adj.pk'\n",
            "'/content/data/csqa/graph/train.graph.adj.pk.loaded_cache' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/graph/train.graph.adj.pk.loaded_cache'\n",
            "'/content/data/csqa/train_rand_split.jsonl' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/train_rand_split.jsonl'\n",
            "'/content/data/csqa/dev_rand_split.jsonl' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/dev_rand_split.jsonl'\n",
            "'/content/data/csqa/inhouse_split_qids.txt' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/inhouse_split_qids.txt'\n",
            "'/content/data/csqa/test_rand_split_no_answers.jsonl' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/test_rand_split_no_answers.jsonl'\n",
            "'/content/data/csqa/statement' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/statement'\n",
            "'/content/data/csqa/statement/dev.statement.jsonl' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/statement/dev.statement.jsonl'\n",
            "'/content/data/csqa/statement/train.statement.jsonl' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/statement/train.statement.jsonl'\n",
            "'/content/data/csqa/statement/test.statement.jsonl' -> '/content/drive/MyDrive/brain_teaser/datasets/csqa/csqa/statement/test.statement.jsonl'\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/data\"\n",
        "\n",
        "%cp -av /content/data/csqa   /content/drive/MyDrive/brain_teaser/datasets/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjW_eu6goFNR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####WP_dev"
      ],
      "metadata": {
        "id": "VG-3JX23L7wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args=dict()\n",
        "args[\"run\"]=['brain_teaser_ds']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "res1=generate_adj_data_from_grounded_concepts__use_LM(output_paths['brain_teaser_ds']['grounded']['WP_dev'],\n",
        "                  output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['brain_teaser_ds']['graph']['adj-WP_dev'], args[\"nprocs\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBEooXOKMAWU",
        "outputId": "ad47d7f7-0722-4bed-e5bd-11bc9c47280d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generating adj data for /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/WP_dev.grounded.jsonl...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 480/480 [00:01<00:00, 314.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_range_to_process=[0,480]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/WP_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znVi6kzIMOTb",
        "outputId": "2108f90b-f73b-4f67-974e-8cee8f486078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "300\n",
            "310\n",
            "320\n",
            "330\n",
            "340\n",
            "350\n",
            "360\n",
            "370\n",
            "380\n",
            "390\n",
            "400\n",
            "410\n",
            "420\n",
            "430\n",
            "440\n",
            "450\n",
            "460\n",
            "470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "do_part3(res2[0], args[\"nprocs\"], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['brain_teaser_ds']['graph']['adj-WP_dev'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU_dgGf4MOO5",
        "outputId": "89bb8ecd-96fe-4b51-875b-246eb972da0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 480/480 [00:38<00:00, 12.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adj data saved to /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_dev.graph.adj.pk\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f8hLhH0aL9lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####WP_train"
      ],
      "metadata": {
        "id": "DeTAphGUL-Ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args=dict()\n",
        "args[\"run\"]=['brain_teaser_ds']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "res1=generate_adj_data_from_grounded_concepts__use_LM(output_paths['brain_teaser_ds']['grounded']['WP_train'],\n",
        "                  output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['brain_teaser_ds']['graph']['adj-WP_train'], args[\"nprocs\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATZvL4YANTH4",
        "outputId": "9ae52790-e25f-4638-d9c5-d7a7c95175b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generating adj data for /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/WP_train.grounded.jsonl...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1584/1584 [00:03<00:00, 406.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "part2"
      ],
      "metadata": {
        "id": "6ziON5eFSlVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_range_to_process=[0,500]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_WP_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0TUoSqGNTEC",
        "outputId": "0a611503-23c2-41d8-d0ed-c4b95689ff70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "300\n",
            "310\n",
            "320\n",
            "330\n",
            "340\n",
            "350\n",
            "360\n",
            "370\n",
            "380\n",
            "390\n",
            "400\n",
            "410\n",
            "420\n",
            "430\n",
            "440\n",
            "450\n",
            "460\n",
            "470\n",
            "480\n",
            "490\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_range_to_process=[500,1000]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_WP_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6DZ90T6NdUr",
        "outputId": "506a9c9d-d6b7-4420-aee7-b69bc0659568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n",
            "510\n",
            "520\n",
            "530\n",
            "540\n",
            "550\n",
            "560\n",
            "570\n",
            "580\n",
            "590\n",
            "600\n",
            "610\n",
            "620\n",
            "630\n",
            "640\n",
            "650\n",
            "660\n",
            "670\n",
            "680\n",
            "690\n",
            "700\n",
            "710\n",
            "720\n",
            "730\n",
            "740\n",
            "750\n",
            "760\n",
            "770\n",
            "780\n",
            "790\n",
            "800\n",
            "810\n",
            "820\n",
            "830\n",
            "840\n",
            "850\n",
            "860\n",
            "870\n",
            "880\n",
            "890\n",
            "900\n",
            "910\n",
            "920\n",
            "930\n",
            "940\n",
            "950\n",
            "960\n",
            "970\n",
            "980\n",
            "990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_range_to_process=[1000, 1584]\n",
        "res2=do_part2(data_range_to_process, res1)\n",
        "\n",
        "res2_path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_WP_res2_{data_range_to_process[1]}.pickle\"\n",
        "with open(res2_path, 'wb') as fout:\n",
        "  pickle.dump(res2, fout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx5kU2LXO7YX",
        "outputId": "56c11484-67db-4e42-cd20-19573919a5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "1010\n",
            "1020\n",
            "1030\n",
            "1040\n",
            "1050\n",
            "1060\n",
            "1070\n",
            "1080\n",
            "1090\n",
            "1100\n",
            "1110\n",
            "1120\n",
            "1130\n",
            "1140\n",
            "1150\n",
            "1160\n",
            "1170\n",
            "1180\n",
            "1190\n",
            "1200\n",
            "1210\n",
            "1220\n",
            "1230\n",
            "1240\n",
            "1250\n",
            "1260\n",
            "1270\n",
            "1280\n",
            "1290\n",
            "1300\n",
            "1310\n",
            "1320\n",
            "1330\n",
            "1340\n",
            "1350\n",
            "1360\n",
            "1370\n",
            "1380\n",
            "1390\n",
            "1400\n",
            "1410\n",
            "1420\n",
            "1430\n",
            "1440\n",
            "1450\n",
            "1460\n",
            "1470\n",
            "1480\n",
            "1490\n",
            "1500\n",
            "1510\n",
            "1520\n",
            "1530\n",
            "1540\n",
            "1550\n",
            "1560\n",
            "1570\n",
            "1580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "combining"
      ],
      "metadata": {
        "id": "NfKfVRu3Sh9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_res2=[]\n",
        "i=500\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_WP_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp[0])\n",
        "len(temp_res2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMml6zj6NdQb",
        "outputId": "1ce411d0-9f5d-41cd-ff27-145d7c0f3cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=1000\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_WP_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp[0])\n",
        "len(temp_res2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8hlBxorL_2l",
        "outputId": "2f0287c0-f642-47c9-a0cb-783e979246d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=1584\n",
        "path=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/train_WP_res2_{i}.pickle\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "  temp=pickle.load(file)\n",
        "\n",
        "temp_res2.extend(temp[0])\n",
        "len(temp_res2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2SU7JICPKFC",
        "outputId": "570e4150-af5d-41f4-99d0-1d6944e6b1db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1584"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "part3"
      ],
      "metadata": {
        "id": "LAYGhmTpNuvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args=dict()\n",
        "args[\"run\"]=['brain_teaser_ds']\n",
        "args[\"path_prune_threshold\"]=0.12\n",
        "args[\"max_node_num\"]=200\n",
        "args[\"nprocs\"]=cpu_count()\n",
        "args[\"seed\"]=0\n",
        "args[\"debug\"]=False\n",
        "\n",
        "do_part3(temp_res2, args[\"nprocs\"], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['brain_teaser_ds']['graph']['adj-WP_train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0mT2CxkNn2u",
        "outputId": "fef91269-4e42-42c7-e56f-2666680f4a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1584/1584 [01:27<00:00, 18.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adj data saved to /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_train.graph.adj.pk\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ELVJa_w7NnzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i1rwYdjhL_zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sd27P_uSL_wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyAN0PhVKxG1"
      },
      "source": [
        "##<font color=lightblue>Brain-teaser In-house Train-split</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHm-Lmjenqob",
        "outputId": "36963559-ead3-455b-eaa2-b9f324e73df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brain-teaser train size: 396\n"
          ]
        }
      ],
      "source": [
        "DATA_FOLDER=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement\"\n",
        "\n",
        "# linked_qa_file=f\"{DATA_FOLDER}/original_SP_train.statement.jsonl\"\n",
        "linked_qa_file=f\"{DATA_FOLDER}/original_WP_train.statement.jsonl\"\n",
        "\n",
        "with open(linked_qa_file) as f:\n",
        "  processed_train_qs = [json.loads(line) for line in f.read().split(\"\\n\") if line]\n",
        "\n",
        "\n",
        "print(f\"Brain-teaser train size: {len(processed_train_qs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SP\n",
        "# train_keys_path=\"/content/drive/MyDrive/brain_teaser/datasets/SP_train_best_split_ids.pickle\"\n",
        "#WP\n",
        "train_keys_path=\"/content/drive/MyDrive/brain_teaser/datasets/WP_train_best_split_ids.pickle\""
      ],
      "metadata": {
        "id": "EtK4VbGAlr-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SP\n",
        "# dev_keys_path=\"/content/drive/MyDrive/brain_teaser/datasets/SP_dev_best_split_ids.pickle\"\n",
        "#WP\n",
        "dev_keys_path=\"/content/drive/MyDrive/brain_teaser/datasets/WP_dev_best_split_ids.pickle\""
      ],
      "metadata": {
        "id": "723-W-EPlu2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(train_keys_path, 'rb') as f:\n",
        "  train_qa_ids = pickle.load(f)\n",
        "\n",
        "len(train_qa_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo16m8-x_20S",
        "outputId": "d85ecc07-94e5-4220-d314-f58890ed96d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "356"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(dev_keys_path, 'rb') as f:\n",
        "  dev_qa_ids = pickle.load(f)\n",
        "\n",
        "len(dev_qa_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWyEH0yFAvDc",
        "outputId": "e63c88f7-bcff-4b2b-f993-7fe689f17ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABRqyZUDnqsy"
      },
      "outputs": [],
      "source": [
        "# len(processed_train_qs)*0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jgpxg00NLj0p"
      },
      "outputs": [],
      "source": [
        "# all_qa_ids=[]\n",
        "\n",
        "# for i in range(len(processed_train_qs)):\n",
        "#   all_qa_ids.append(processed_train_qs[i]['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpuxNEVRMdJW",
        "outputId": "8f429ff1-71c4-41f3-bc52-ba6badbcf285"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['WP-24_CR', 'WP-155_SR', 'WP-27', 'WP-27_CR', 'WP-138_CR']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "train_qa_ids[:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_qa_ids[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W5hZju0BCYh",
        "outputId": "2f084439-923d-434a-c6bf-f9524cb1692d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['WP-66', 'WP-24_SR', 'WP-104_SR', 'WP-115_SR', 'WP-45_SR']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnhIWV2LMLZV"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# SEED = 42\n",
        "\n",
        "# random.seed(SEED)\n",
        "# random.shuffle(all_qa_ids)\n",
        "\n",
        "# print(all_qa_ids[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiHpy2mLLjs9"
      },
      "outputs": [],
      "source": [
        "# train_qa_ids_split_upper_idx=int(len(all_qa_ids)*0.9)\n",
        "# train_qa_ids_split_upper_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYNyBnOENP48"
      },
      "outputs": [],
      "source": [
        "# train_qa_ids=all_qa_ids[:train_qa_ids_split_upper_idx]\n",
        "# dev_qa_ids=all_qa_ids[train_qa_ids_split_upper_idx:]\n",
        "# print(len(train_qa_ids), len(dev_qa_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEcP_m-9Og1l"
      },
      "outputs": [],
      "source": [
        "# folder=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds\"\n",
        "\n",
        "# with open(f'{folder}/WP_inhouse_split_qids.txt', 'w') as outfile:\n",
        "#   for entry in train_qa_ids:\n",
        "#       json.dump(entry, outfile)\n",
        "#       outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4qx9orXaBA7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xdTdJAGbBAz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zns9H8gPCI9",
        "outputId": "0b483a70-31b0-4233-8d79-dc4c3764aa4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "'WP-16_SR' in train_qa_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NaEkb5jehqS",
        "outputId": "9364df81-adf3-4546-b595-78383336eb5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "'WP-16_SR' in dev_qa_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ed61Ls6TS0t"
      },
      "outputs": [],
      "source": [
        "dataset=\"brain_teaser_ds\"\n",
        "folder=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds\"\n",
        "\n",
        "\n",
        "# train_graph=f\"{folder}/graph/original_SP_train.graph.adj.pk\"\n",
        "train_graph=f\"{folder}/graph/original_WP_train.graph.adj.pk\"\n",
        "\n",
        "# train_statements=f\"{folder}/statement/original_SP_train.statement.jsonl\"\n",
        "train_statements=f\"{folder}/statement/original_WP_train.statement.jsonl\"\n",
        "\n",
        "# train_grounded=f\"{folder}/grounded/original_SP_train.grounded.jsonl\"\n",
        "train_grounded=f\"{folder}/grounded/original_WP_train.grounded.jsonl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "z-sd45TqYNgp",
        "outputId": "50c6054f-b823-49d2-9900-1f4987297824"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/grounded/original_WP_train.grounded.jsonl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "train_grounded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWpg4F4pTSuF"
      },
      "outputs": [],
      "source": [
        "train_statements_examples=[]\n",
        "with open(train_statements, \"r\", encoding=\"utf-8\") as f:\n",
        "  for line in f.readlines():\n",
        "      json_dic = json.loads(line)\n",
        "      train_statements_examples.append(json_dic)\n",
        "\n",
        "train_grounded_examples=[]\n",
        "with open(train_grounded, \"r\", encoding=\"utf-8\") as f:\n",
        "  for line in f.readlines():\n",
        "      json_dic = json.loads(line)\n",
        "      train_grounded_examples.append(json_dic)\n",
        "\n",
        "with open(train_graph, 'rb') as fin:\n",
        "   train_graph_adj_concept_pairs = pickle.load(fin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYlvwLzMTn2l",
        "outputId": "5ea41c3c-13f9-4a5c-f443-e35f656758a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(396, 1584, 1584)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "len(train_statements_examples), len(train_grounded_examples), len(train_graph_adj_concept_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNN9QaYkTSgb"
      },
      "outputs": [],
      "source": [
        "new_train_statements=[]\n",
        "new_dev_statements=[]\n",
        "new_train_grounded=[]\n",
        "new_dev_grounded=[]\n",
        "new_train_graph=[]\n",
        "new_dev_graph=[]\n",
        "\n",
        "for i in range(len(train_statements_examples)):\n",
        "  sample=train_statements_examples[i]\n",
        "  id=sample['id']\n",
        "  try:\n",
        "    if id in train_qa_ids:\n",
        "      new_train_statements.append(sample)\n",
        "      idx=i*4\n",
        "      for j in range(4):\n",
        "        new_train_grounded.append(train_grounded_examples[idx+j])\n",
        "        new_train_graph.append(train_graph_adj_concept_pairs[idx+j])\n",
        "    else:\n",
        "      new_dev_statements.append(sample)\n",
        "      dx=i*4\n",
        "      for j in range(4):\n",
        "        new_dev_grounded.append(train_grounded_examples[idx+j])\n",
        "        new_dev_graph.append(train_graph_adj_concept_pairs[idx+j])\n",
        "  except:\n",
        "    print(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsTIyuyxTSXo",
        "outputId": "d0ff1a38-e89e-4387-9bdb-3b57079afb32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 356)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "len(new_dev_graph)//4, len(new_train_graph)//4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljsi4vUHTSPz",
        "outputId": "dae61d89-4ae5-459d-d190-c2d6c67fa365"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(356, 40, 1424, 160, 1424, 160)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "len(new_train_statements),len(new_dev_statements),len(new_train_grounded), len(new_dev_grounded), len(new_train_graph), len(new_dev_graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "speeZD1tXWST"
      },
      "outputs": [],
      "source": [
        "dataset=\"brain_teaser_ds\"\n",
        "folder=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds\"\n",
        "\n",
        "\n",
        "# train_graph_path=f\"{folder}/graph/SP_train.graph.adj.pk\"\n",
        "# dev_graph_path=f\"{folder}/graph/SP_dev.graph.adj.pk\"\n",
        "\n",
        "# train_statements_path=f\"{folder}/statement/SP_train.statement.jsonl\"\n",
        "# dev_statements_path=f\"{folder}/statement/SP_dev.statement.jsonl\"\n",
        "\n",
        "# train_grounded_path=f\"{folder}/grounded/SP_train.grounded.jsonl\"\n",
        "# dev_grounded_path=f\"{folder}/grounded/SP_dev.grounded.jsonl\"\n",
        "\n",
        "train_graph_path=f\"{folder}/graph/WP_train.graph.adj.pk\"\n",
        "dev_graph_path=f\"{folder}/graph/WP_dev.graph.adj.pk\"\n",
        "\n",
        "train_statements_path=f\"{folder}/statement/WP_train.statement.jsonl\"\n",
        "dev_statements_path=f\"{folder}/statement/WP_dev.statement.jsonl\"\n",
        "\n",
        "train_grounded_path=f\"{folder}/grounded/WP_train.grounded.jsonl\"\n",
        "dev_grounded_path=f\"{folder}/grounded/WP_dev.grounded.jsonl\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJv_u2_DZEwB"
      },
      "source": [
        "Saving train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1gcDpcfXSxI"
      },
      "outputs": [],
      "source": [
        "with open(train_graph_path, 'wb') as f:\n",
        "  pickle.dump(new_train_graph, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igxKs9m0XSuT"
      },
      "outputs": [],
      "source": [
        "with open(train_grounded_path, 'w') as outfile:\n",
        "  for entry in new_train_grounded:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wqh_-_WCXSre"
      },
      "outputs": [],
      "source": [
        "with open(train_statements_path, 'w') as outfile:\n",
        "  for entry in new_train_statements:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AoQaYSxZEQ_"
      },
      "source": [
        "Saving dev data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dg6zuaSHXSor"
      },
      "outputs": [],
      "source": [
        "with open(dev_graph_path, 'wb') as f:\n",
        "  pickle.dump(new_dev_graph, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w2_uHXSWuSg"
      },
      "outputs": [],
      "source": [
        "with open(dev_grounded_path, 'w') as outfile:\n",
        "  for entry in new_dev_grounded:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPfHVXKjWuKC"
      },
      "outputs": [],
      "source": [
        "with open(dev_statements_path, 'w') as outfile:\n",
        "  for entry in new_dev_statements:\n",
        "      json.dump(entry, outfile)\n",
        "      outfile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13uMv-tHTSF0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtgNN9PVNIXX"
      },
      "source": [
        "####temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWEb1W0wNKiv"
      },
      "outputs": [],
      "source": [
        "# def extract_concepts(q_stem):\n",
        "\n",
        "#   question_concepts=[]\n",
        "#   for i in range(len(id2concept)):\n",
        "#     concept=id2concept[i].strip().lower().replace(\"_\",\" \")\n",
        "#     # if concept in most_common_concepts or len(concept)<=3:\n",
        "#     if len(concept)<=3:\n",
        "#       continue\n",
        "#     if concept in q_stem:\n",
        "#       question_concepts.append(concept)\n",
        "\n",
        "\n",
        "#   new_question_concepts=[]\n",
        "#   for i in range(len(question_concepts)):\n",
        "#     first_concept=question_concepts[i]\n",
        "#     is_sub_concept=False\n",
        "#     for j in range(len(question_concepts)):\n",
        "#       if i==j:\n",
        "#         continue\n",
        "#       if first_concept in question_concepts[j]:\n",
        "#         is_sub_concept=True\n",
        "#         break\n",
        "\n",
        "#     if is_sub_concept==False:\n",
        "#       new_question_concepts.append(first_concept)\n",
        "\n",
        "#   meaningful_question_concepts=set()\n",
        "#   for concept in new_question_concepts:\n",
        "#     if concept in wn.words():\n",
        "#       meaningful_question_concepts.add(concept)\n",
        "#       continue\n",
        "\n",
        "#     concept_subwords=concept.split(\" \")\n",
        "#     all_are_meaningful=True\n",
        "#     meaningfuls=[]\n",
        "#     for subword in concept_subwords:\n",
        "#       if len(subword)<=3:\n",
        "#         all_are_meaningful=False\n",
        "#         continue\n",
        "\n",
        "#       if subword in wn.words():\n",
        "#         meaningfuls.append(subword)\n",
        "#       else:\n",
        "#         all_are_meaningful=False\n",
        "#     if all_are_meaningful:\n",
        "#       meaningful_question_concepts.add(concept)\n",
        "#     else:\n",
        "#       for c in meaningfuls:\n",
        "#         meaningful_question_concepts.add(c)\n",
        "\n",
        "#   meaningful_question_concepts=list(meaningful_question_concepts)\n",
        "#   final_concepts=[]\n",
        "#   for concept in meaningful_question_concepts:\n",
        "#     if concept in most_common_concepts:\n",
        "#       continue\n",
        "#     else:\n",
        "#       final_concepts.append(concept)\n",
        "\n",
        "#   return final_concepts\n",
        "#   # return list(meaningful_question_concepts)\n",
        "\n",
        "\n",
        "# def preprocess_qa(question_list, is_train_data):\n",
        "\n",
        "#   processed_qs=[]\n",
        "#   id_to_label={0:\"A\", 1:\"B\", 2:\"C\", 3:\"D\"}\n",
        "\n",
        "#   for i in tqdm(range(len(question_list))):\n",
        "\n",
        "#     sample=question_list.iloc[i]\n",
        "#     q_stem=sample['question'].strip().lower()\n",
        "#     q_choices_list=sample['choice_list']\n",
        "#     if is_train_data:\n",
        "#       q_answerKey=id_to_label[sample['label']]\n",
        "#       q_id=sample['id']\n",
        "#     else:\n",
        "#       q_id=i\n",
        "\n",
        "\n",
        "#     meaningful_question_concepts = extract_concepts(q_stem)\n",
        "\n",
        "#     q_choices=[]\n",
        "\n",
        "#     for j in range(len(q_choices_list)):\n",
        "#       if j==0:\n",
        "#         choice_label=\"A\"\n",
        "#       elif j==1:\n",
        "#         choice_label=\"B\"\n",
        "#       elif j==2:\n",
        "#         choice_label=\"C\"\n",
        "#       else:\n",
        "#         choice_label=\"D\"\n",
        "\n",
        "#       choice_text=q_choices_list[j]\n",
        "#       choice_dict={\n",
        "#           'label': choice_label,\n",
        "#           'text': choice_text.strip().lower()\n",
        "#       }\n",
        "#       meaningful_choice_concepts = extract_concepts(choice_dict['text'])\n",
        "\n",
        "#       choice_dict['choice_concepts']= meaningful_choice_concepts\n",
        "#       q_choices.append(choice_dict)\n",
        "\n",
        "#     if is_train_data:\n",
        "#       q_dict={\n",
        "#             'id':q_id,\n",
        "#             'answerKey':q_answerKey,\n",
        "#             'question':{\n",
        "#                 'question_concept': meaningful_question_concepts,\n",
        "#                 'choices': q_choices,\n",
        "#                 'stem': q_stem,\n",
        "#             }\n",
        "#         }\n",
        "#     else:\n",
        "#         q_dict={\n",
        "#             'id':q_id,\n",
        "#             'question':{\n",
        "#                 'question_concept': meaningful_question_concepts,\n",
        "#                 'choices': q_choices,\n",
        "#                 'stem': q_stem,\n",
        "#             }\n",
        "#         }\n",
        "#     processed_qs.append(q_dict)\n",
        "#     break\n",
        "#   return processed_qs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgP-Vziweewm"
      },
      "source": [
        "####test on a few samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OKP7gO36rzb",
        "outputId": "0ad9a78a-c08b-427a-dbe9-d4d6bd07be4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:03<00:00,  1.08s/it]\n"
          ]
        }
      ],
      "source": [
        "processed_qs=extract_concepts(riddle_sense_temp_q_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu636Pyp6vIB",
        "outputId": "392e3b55-65d7-4acd-8f57-10406e05dbf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['question_concept', 'choices', 'stem'])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_qs[0]['question'].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G0nNfsouf2z",
        "outputId": "e1e47e07-aa90-4d3b-ac67-6e2573008d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a man is incarcerated in prison, and as his punishment he has to carry a one tonne bag of sand backwards and forwards across a field the size of a football pitch.  what is the one thing he can put in it to make it lighter?\n"
          ]
        }
      ],
      "source": [
        "print(processed_qs[0]['question']['stem'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOHqpOlj6okS",
        "outputId": "4cc3ac3c-b6bc-43ea-92ef-ece69c82cdd3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tonne',\n",
              " 'in prison',\n",
              " 'bag',\n",
              " 'can',\n",
              " 'football pitch',\n",
              " 'lighter',\n",
              " 'he',\n",
              " 'punishment',\n",
              " 'size',\n",
              " 'across',\n",
              " 'sand',\n",
              " 'backwards',\n",
              " 'forwards',\n",
              " 'put in',\n",
              " 'man',\n",
              " 'field',\n",
              " 'make it',\n",
              " 'in it',\n",
              " 'carry',\n",
              " 'one thing']"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_qs[0]['question']['question_concept']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vU1Dh_H3EpTw",
        "outputId": "9ee4448a-396d-4d26-f257-0032fe605bd0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'what gets smaller as it gets fuller?'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_qs[1]['question']['stem']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv_sHzRME60P",
        "outputId": "ad791e15-6b2a-4bb1-c057-eecfcfb3aa1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fuller', 'smaller', 'it', 'as']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_qs[1]['question']['question_concept']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AQ07KeEFGLLD",
        "outputId": "771a1c65-e67f-4d19-da54-e34717b382eb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'whats weightless, visible to the naked eye, and when you put it in a barrel of water it will make the barrel lighter in weight. ?'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_qs[2]['question']['stem']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQo5Rj_F12D",
        "outputId": "437735d2-dc30-4c72-9481-dd21948b761e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lighter',\n",
              " 'weightless',\n",
              " 'visible',\n",
              " 'put it',\n",
              " 'barrel',\n",
              " 'water',\n",
              " 'it in',\n",
              " 'put',\n",
              " 'naked eye',\n",
              " 'will',\n",
              " 'water it',\n",
              " 'make']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_qs[2]['question']['question_concept']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RCblOkMLEJK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_Hkt1YQMOL8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdP8LCLps0E6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMJJDl3Bv9pg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYK__uSSwAe2"
      },
      "source": [
        "####**obqa**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBynctBzvK28"
      },
      "outputs": [],
      "source": [
        "def main_3():\n",
        "    args=dict()\n",
        "    args[\"run\"]=[\"obqa\"]\n",
        "    args[\"path_prune_threshold\"]=0.12\n",
        "    args[\"max_node_num\"]=200\n",
        "    args[\"nprocs\"]=cpu_count()\n",
        "    args[\"seed\"]=0\n",
        "    args[\"debug\"]=False\n",
        "\n",
        "    routines = {\n",
        "\n",
        "        'obqa': [\n",
        "            {'func': convert_to_obqa_statement, 'args': (input_paths['obqa']['train'], output_paths['obqa']['statement']['train'], output_paths['obqa']['statement']['train-fairseq'])},\n",
        "            {'func': convert_to_obqa_statement, 'args': (input_paths['obqa']['dev'], output_paths['obqa']['statement']['dev'], output_paths['obqa']['statement']['dev-fairseq'])},\n",
        "            {'func': convert_to_obqa_statement, 'args': (input_paths['obqa']['test'], output_paths['obqa']['statement']['test'], output_paths['obqa']['statement']['test-fairseq'])},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    for rt in args[\"run\"]:\n",
        "        print(rt)\n",
        "        for rt_dic in routines[rt]:\n",
        "            print(rt_dic)\n",
        "            rt_dic['func'](*rt_dic['args'])\n",
        "\n",
        "    print('Successfully run {}'.format(' '.join(args[\"run\"])))\n",
        "\n",
        "\n",
        "main_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziHBXwYi3D7l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFohX4YJ3D4h"
      },
      "outputs": [],
      "source": [
        "def main_3():\n",
        "    args=dict()\n",
        "    args[\"run\"]=[\"obqa\"]\n",
        "    args[\"path_prune_threshold\"]=0.12\n",
        "    args[\"max_node_num\"]=200\n",
        "    args[\"nprocs\"]=cpu_count()\n",
        "    args[\"seed\"]=0\n",
        "    args[\"debug\"]=False\n",
        "\n",
        "    routines = {\n",
        "\n",
        "        'obqa': [\n",
        "            {'func': ground, 'args': (output_paths['obqa']['statement']['train'], output_paths['cpnet']['vocab'],\n",
        "                                      output_paths['cpnet']['patterns'], output_paths['obqa']['grounded']['train'], args[\"nprocs\"])},\n",
        "            {'func': ground, 'args': (output_paths['obqa']['statement']['dev'], output_paths['cpnet']['vocab'],\n",
        "                                      output_paths['cpnet']['patterns'], output_paths['obqa']['grounded']['dev'], args[\"nprocs\"])},\n",
        "            {'func': ground, 'args': (output_paths['obqa']['statement']['test'], output_paths['cpnet']['vocab'],\n",
        "                                      output_paths['cpnet']['patterns'], output_paths['obqa']['grounded']['test'], args[\"nprocs\"])},\n",
        "            {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['obqa']['grounded']['train'], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['obqa']['graph']['adj-train'], args[\"nprocs\"])},\n",
        "            {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['obqa']['grounded']['dev'], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['obqa']['graph']['adj-dev'], args[\"nprocs\"])},\n",
        "            {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['obqa']['grounded']['test'], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['obqa']['graph']['adj-test'], args[\"nprocs\"])},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    for rt in args[\"run\"]:\n",
        "        print(rt)\n",
        "        for rt_dic in routines[rt]:\n",
        "            print(rt_dic)\n",
        "            rt_dic['func'](*rt_dic['args'])\n",
        "\n",
        "    print('Successfully run {}'.format(' '.join(args[\"run\"])))\n",
        "\n",
        "\n",
        "main_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpmuVg2N3D2s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyHR8fGb055E"
      },
      "outputs": [],
      "source": [
        "def main_3():\n",
        "    args=dict()\n",
        "    args[\"run\"]=[\"obqa\"]\n",
        "    args[\"path_prune_threshold\"]=0.12\n",
        "    args[\"max_node_num\"]=200\n",
        "    args[\"nprocs\"]=cpu_count()\n",
        "    args[\"seed\"]=0\n",
        "    args[\"debug\"]=False\n",
        "\n",
        "    routines = {\n",
        "\n",
        "        'obqa': [\n",
        "            {'func': ground, 'args': (output_paths['obqa']['statement']['train'], output_paths['cpnet']['vocab'],\n",
        "                                      output_paths['cpnet']['patterns'], output_paths['obqa']['grounded']['train'], args[\"nprocs\"])},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    for rt in args[\"run\"]:\n",
        "        print(rt)\n",
        "        for rt_dic in routines[rt]:\n",
        "            print(rt_dic)\n",
        "            rt_dic['func'](*rt_dic['args'])\n",
        "\n",
        "    print('Successfully run {}'.format(' '.join(args[\"run\"])))\n",
        "\n",
        "\n",
        "main_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftvKVF5A3Ivc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OquFbzp13Itw"
      },
      "outputs": [],
      "source": [
        "def main_3():\n",
        "    args=dict()\n",
        "    args[\"run\"]=[\"obqa\"]\n",
        "    args[\"path_prune_threshold\"]=0.12\n",
        "    args[\"max_node_num\"]=200\n",
        "    args[\"nprocs\"]=cpu_count()\n",
        "    args[\"seed\"]=0\n",
        "    args[\"debug\"]=False\n",
        "\n",
        "    routines = {\n",
        "\n",
        "        'obqa': [\n",
        "            {'func': ground, 'args': (output_paths['obqa']['statement']['dev'], output_paths['cpnet']['vocab'],\n",
        "                                      output_paths['cpnet']['patterns'], output_paths['obqa']['grounded']['dev'], args[\"nprocs\"])},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    for rt in args[\"run\"]:\n",
        "        print(rt)\n",
        "        for rt_dic in routines[rt]:\n",
        "            print(rt_dic)\n",
        "            rt_dic['func'](*rt_dic['args'])\n",
        "\n",
        "    print('Successfully run {}'.format(' '.join(args[\"run\"])))\n",
        "\n",
        "\n",
        "main_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsFPmeKR3Iqg"
      },
      "outputs": [],
      "source": [
        "def main_3():\n",
        "    args=dict()\n",
        "    args[\"run\"]=[\"obqa\"]\n",
        "    args[\"path_prune_threshold\"]=0.12\n",
        "    args[\"max_node_num\"]=200\n",
        "    args[\"nprocs\"]=cpu_count()\n",
        "    args[\"seed\"]=0\n",
        "    args[\"debug\"]=False\n",
        "\n",
        "    routines = {\n",
        "\n",
        "        'obqa': [\n",
        "            {'func': ground, 'args': (output_paths['obqa']['statement']['test'], output_paths['cpnet']['vocab'],\n",
        "                                      output_paths['cpnet']['patterns'], output_paths['obqa']['grounded']['test'], args[\"nprocs\"])},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    for rt in args[\"run\"]:\n",
        "        print(rt)\n",
        "        for rt_dic in routines[rt]:\n",
        "            print(rt_dic)\n",
        "            rt_dic['func'](*rt_dic['args'])\n",
        "\n",
        "    print('Successfully run {}'.format(' '.join(args[\"run\"])))\n",
        "\n",
        "\n",
        "main_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOu4XHtU3NZ0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hawe2Q8_3NVZ"
      },
      "outputs": [],
      "source": [
        "def main_3():\n",
        "    args=dict()\n",
        "    args[\"run\"]=[\"obqa\"]\n",
        "    args[\"path_prune_threshold\"]=0.12\n",
        "    args[\"max_node_num\"]=200\n",
        "    args[\"nprocs\"]=cpu_count()\n",
        "    args[\"seed\"]=0\n",
        "    args[\"debug\"]=False\n",
        "\n",
        "    routines = {\n",
        "\n",
        "        'obqa': [\n",
        "            {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['obqa']['grounded']['train'], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['obqa']['graph']['adj-train'], args[\"nprocs\"])},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    for rt in args[\"run\"]:\n",
        "        print(rt)\n",
        "        for rt_dic in routines[rt]:\n",
        "            print(rt_dic)\n",
        "            rt_dic['func'](*rt_dic['args'])\n",
        "\n",
        "    print('Successfully run {}'.format(' '.join(args[\"run\"])))\n",
        "\n",
        "\n",
        "main_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufsb-jaO3NTH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQZ982tr3NRP"
      },
      "outputs": [],
      "source": [
        "def main_3():\n",
        "    args=dict()\n",
        "    args[\"run\"]=[\"obqa\"]\n",
        "    args[\"path_prune_threshold\"]=0.12\n",
        "    args[\"max_node_num\"]=200\n",
        "    args[\"nprocs\"]=cpu_count()\n",
        "    args[\"seed\"]=0\n",
        "    args[\"debug\"]=False\n",
        "\n",
        "    routines = {\n",
        "\n",
        "        'obqa': [\n",
        "            {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['obqa']['grounded']['dev'], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['obqa']['graph']['adj-dev'], args[\"nprocs\"])},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    for rt in args[\"run\"]:\n",
        "        print(rt)\n",
        "        for rt_dic in routines[rt]:\n",
        "            print(rt_dic)\n",
        "            rt_dic['func'](*rt_dic['args'])\n",
        "\n",
        "    print('Successfully run {}'.format(' '.join(args[\"run\"])))\n",
        "\n",
        "\n",
        "main_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXuVYoZU051U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRFJBfAR3Rm2"
      },
      "outputs": [],
      "source": [
        "def main_3():\n",
        "    args=dict()\n",
        "    args[\"run\"]=[\"obqa\"]\n",
        "    args[\"path_prune_threshold\"]=0.12\n",
        "    args[\"max_node_num\"]=200\n",
        "    args[\"nprocs\"]=cpu_count()\n",
        "    args[\"seed\"]=0\n",
        "    args[\"debug\"]=False\n",
        "\n",
        "    routines = {\n",
        "\n",
        "        'obqa': [\n",
        "            {'func': generate_adj_data_from_grounded_concepts__use_LM, 'args': (output_paths['obqa']['grounded']['test'], output_paths['cpnet']['pruned-graph'], output_paths['cpnet']['vocab'], output_paths['obqa']['graph']['adj-test'], args[\"nprocs\"])},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    for rt in args[\"run\"]:\n",
        "        print(rt)\n",
        "        for rt_dic in routines[rt]:\n",
        "            print(rt_dic)\n",
        "            rt_dic['func'](*rt_dic['args'])\n",
        "\n",
        "    print('Successfully run {}'.format(' '.join(args[\"run\"])))\n",
        "\n",
        "\n",
        "main_3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZkoPCLK05yf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRZI4N37ADCy"
      },
      "source": [
        "#Train QA-GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuTPDe6kUUq2"
      },
      "source": [
        "###from modeling.modeling_qagnn import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApSWZUPeU_js"
      },
      "source": [
        "####from utils.utils import freeze_net\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bjyoFeMAVAKH"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "\n",
        "def bool_flag(v):\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
        "\n",
        "\n",
        "def check_path(path):\n",
        "    d = os.path.dirname(path)\n",
        "    if not os.path.exists(d):\n",
        "        os.makedirs(d)\n",
        "\n",
        "\n",
        "def check_file(file):\n",
        "    return os.path.isfile(file)\n",
        "\n",
        "\n",
        "def export_config(config, path):\n",
        "    # param_dict = dict(vars(config))\n",
        "    param_dict = config\n",
        "    check_path(path)\n",
        "    with open(path, 'w') as fout:\n",
        "        json.dump(param_dict, fout, indent=4)\n",
        "\n",
        "\n",
        "def freeze_net(module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "\n",
        "def unfreeze_net(module):\n",
        "    for p in module.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "\n",
        "def test_data_loader_ms_per_batch(data_loader, max_steps=10000):\n",
        "    start = time.time()\n",
        "    n_batch = sum(1 for batch, _ in zip(data_loader, range(max_steps)))\n",
        "    return (time.time() - start) * 1000 / n_batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnjMGgv_U199"
      },
      "source": [
        "####from utils.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2Yh22yCaU22V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import numpy as np\n",
        "import math\n",
        "# from utils.utils import freeze_net\n",
        "\n",
        "\n",
        "def gelu(x):\n",
        "    \"\"\" Implementation of the gelu activation function currently in Google Bert repo (identical to OpenAI GPT).\n",
        "        Also see https://arxiv.org/abs/1606.08415\n",
        "    \"\"\"\n",
        "    return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return gelu(x)\n",
        "\n",
        "\n",
        "class TypedLinear(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, n_type):\n",
        "        super().__init__(in_features, n_type * out_features)\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.n_type = n_type\n",
        "\n",
        "    def forward(self, X, type_ids=None):\n",
        "        \"\"\"\n",
        "        X: tensor of shape (*, in_features)\n",
        "        type_ids: long tensor of shape (*)\n",
        "        \"\"\"\n",
        "        output = super().forward(X)\n",
        "        if type_ids is None:\n",
        "            return output\n",
        "        output_shape = output.size()[:-1] + (self.out_features,)\n",
        "        output = output.view(-1, self.n_type, self.out_features)\n",
        "        idx = torch.arange(output.size(0), dtype=torch.long, device=type_ids.device)\n",
        "        output = output[idx, type_ids.view(-1)].view(*output_shape)\n",
        "        return output\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-layer perceptron\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_layers: number of hidden layers\n",
        "    \"\"\"\n",
        "    activation_classes = {'gelu': GELU, 'relu': nn.ReLU, 'tanh': nn.Tanh}\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout, batch_norm=False,\n",
        "                 init_last_layer_bias_to_zero=False, layer_norm=False, activation='gelu'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.batch_norm = batch_norm\n",
        "        self.layer_norm = layer_norm\n",
        "\n",
        "        assert not (self.batch_norm and self.layer_norm)    # assert statement has a condition or expression which is supposed to be always true\n",
        "\n",
        "        self.layers = nn.Sequential()\n",
        "        for i in range(self.num_layers + 1):\n",
        "            n_in = self.input_size if i == 0 else self.hidden_size\n",
        "            n_out = self.hidden_size if i < self.num_layers else self.output_size\n",
        "            self.layers.add_module(f'{i}-Linear', nn.Linear(n_in, n_out))\n",
        "            if i < self.num_layers:\n",
        "                self.layers.add_module(f'{i}-Dropout', nn.Dropout(self.dropout))\n",
        "                if self.batch_norm:\n",
        "                    self.layers.add_module(f'{i}-BatchNorm1d', nn.BatchNorm1d(self.hidden_size))\n",
        "                if self.layer_norm:\n",
        "                    self.layers.add_module(f'{i}-LayerNorm', nn.LayerNorm(self.hidden_size))\n",
        "                self.layers.add_module(f'{i}-{activation}', self.activation_classes[activation.lower()]())\n",
        "        if init_last_layer_bias_to_zero:\n",
        "            self.layers[-1].bias.data.fill_(0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.layers(input)\n",
        "\n",
        "\n",
        "class MaxPoolLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    A layer that performs max pooling along the sequence dimension\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, inputs, mask_or_lengths):\n",
        "        \"\"\"\n",
        "        inputs: tensor of shape (batch_size, seq_len, hidden_size)\n",
        "        mask_or_lengths: tensor of shape (batch_size) or (batch_size, seq_len)\n",
        "\n",
        "        returns: tensor of shape (batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        bs, sl, _ = inputs.size()\n",
        "        if len(mask_or_lengths.size()) == 1:\n",
        "            mask = (torch.arange(sl, device=inputs.device).unsqueeze(0).expand(bs, sl) >= mask_or_lengths.unsqueeze(1))\n",
        "        else:\n",
        "            mask = mask_or_lengths\n",
        "        masked_inputs = inputs.masked_fill(mask.unsqueeze(-1).expand_as(inputs), float('-inf'))\n",
        "        max_pooled = masked_inputs.max(1)[0]\n",
        "        return max_pooled\n",
        "\n",
        "\n",
        "class MeanPoolLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    A layer that performs mean pooling along the sequence dimension\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, inputs, mask_or_lengths):\n",
        "        \"\"\"\n",
        "        inputs: tensor of shape (batch_size, seq_len, hidden_size)\n",
        "        mask_or_lengths: tensor of shape (batch_size) or (batch_size, seq_len)\n",
        "\n",
        "        returns: tensor of shape (batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        bs, sl, _ = inputs.size()\n",
        "        if len(mask_or_lengths.size()) == 1:\n",
        "            mask = (torch.arange(sl, device=inputs.device).unsqueeze(0).expand(bs, sl) >= mask_or_lengths.unsqueeze(1))\n",
        "            lengths = mask_or_lengths.float()\n",
        "        else:\n",
        "            mask, lengths = mask_or_lengths, (1 - mask_or_lengths.float()).sum(1)\n",
        "        masked_inputs = inputs.masked_fill(mask.unsqueeze(-1).expand_as(inputs), 0.0)\n",
        "        mean_pooled = masked_inputs.sum(1) / lengths.unsqueeze(-1)\n",
        "        return mean_pooled\n",
        "\n",
        "\n",
        "def dropout_mask(x, sz, p: float):\n",
        "    \"\"\"\n",
        "    Return a dropout mask of the same type as `x`, size `sz`, with probability `p` to cancel an element.\n",
        "\n",
        "    (adapted from https://github.com/fastai/fastai/blob/1.0.42/fastai/text/models/awd_lstm.py)\n",
        "    \"\"\"\n",
        "    return x.new(*sz).bernoulli_(1 - p).div_(1 - p)\n",
        "\n",
        "\n",
        "class EmbeddingDropout(nn.Module):\n",
        "    \"\"\"\n",
        "    Apply dropout with probabily `embed_p` to an embedding layer `emb`.\n",
        "\n",
        "    (adapted from https://github.com/fastai/fastai/blob/1.0.42/fastai/text/models/awd_lstm.py)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, emb: nn.Module, embed_p: float):\n",
        "        super().__init__()\n",
        "        self.emb, self.embed_p = emb, embed_p\n",
        "        self.pad_idx = self.emb.padding_idx\n",
        "        if self.pad_idx is None:\n",
        "            self.pad_idx = -1\n",
        "\n",
        "    def forward(self, words):\n",
        "        if self.training and self.embed_p != 0:\n",
        "            size = (self.emb.weight.size(0), 1)\n",
        "            mask = dropout_mask(self.emb.weight.data, size, self.embed_p)\n",
        "            masked_embed = self.emb.weight * mask\n",
        "        else:\n",
        "            masked_embed = self.emb.weight\n",
        "        return F.embedding(words, masked_embed, self.pad_idx, self.emb.max_norm,\n",
        "                           self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)\n",
        "\n",
        "\n",
        "class RNNDropout(nn.Module):\n",
        "    \"Dropout with probability `p` that is consistent on the seq_len dimension.\"\n",
        "\n",
        "    def __init__(self, p: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training or self.p == 0.:\n",
        "            return x\n",
        "        m = dropout_mask(x.data, (x.size(0), 1, x.size(2)), self.p)\n",
        "        return x * m\n",
        "\n",
        "\n",
        "class LSTMEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size=300, emb_size=300, hidden_size=300, num_layers=2, bidirectional=True,\n",
        "                 emb_p=0, input_p=0, hidden_p=0, output_p=0, pretrained_emb=None, pooling=True, pad=False):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_size = emb_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.bidirectional = bidirectional\n",
        "        self.emb_p = emb_p\n",
        "        self.input_p = input_p\n",
        "        self.hidden_p = hidden_p\n",
        "        self.output_p = output_p\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.emb = EmbeddingDropout(nn.Embedding(vocab_size, emb_size), emb_p)\n",
        "        if pretrained_emb is not None:\n",
        "            self.emb.emb.weight.data.copy_(pretrained_emb)\n",
        "        else:\n",
        "            bias = np.sqrt(6.0 / emb_size)\n",
        "            nn.init.uniform_(self.emb.emb.weight, -bias, bias)\n",
        "        self.input_dropout = nn.Dropout(input_p)\n",
        "        self.output_dropout = nn.Dropout(output_p)\n",
        "        self.rnn = nn.LSTM(input_size=emb_size, hidden_size=(hidden_size // 2 if self.bidirectional else hidden_size),\n",
        "                           num_layers=num_layers, dropout=hidden_p, bidirectional=bidirectional,\n",
        "                           batch_first=True)\n",
        "        self.max_pool = MaxPoolLayer()\n",
        "\n",
        "    def forward(self, inputs, lengths):\n",
        "        \"\"\"\n",
        "        inputs: tensor of shape (batch_size, seq_len)\n",
        "        lengths: tensor of shape (batch_size)\n",
        "\n",
        "        returns: tensor of shape (batch_size, hidden_size)\n",
        "        \"\"\"\n",
        "        bz, full_length = inputs.size()\n",
        "        embed = self.emb(inputs)\n",
        "        embed = self.input_dropout(embed)\n",
        "        lstm_inputs = pack_padded_sequence(embed, lengths, batch_first=True, enforce_sorted=False)\n",
        "        rnn_outputs, _ = self.rnn(lstm_inputs)\n",
        "        rnn_outputs, _ = pad_packed_sequence(rnn_outputs, batch_first=True, total_length=full_length)\n",
        "        rnn_outputs = self.output_dropout(rnn_outputs)\n",
        "        return self.max_pool(rnn_outputs, lengths) if self.pooling else rnn_outputs\n",
        "\n",
        "\n",
        "class TripleEncoder(nn.Module):\n",
        "    def __init__(self, emb_dim, hidden_dim, input_p, output_p, hidden_p, num_layers, bidirectional=True, pad=False,\n",
        "                 concept_emb=None, relation_emb=None\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        if pad:\n",
        "            raise NotImplementedError\n",
        "        self.input_p = input_p\n",
        "        self.output_p = output_p\n",
        "        self.hidden_p = hidden_p\n",
        "        self.cpt_emb = concept_emb\n",
        "        self.rel_emb = relation_emb\n",
        "        self.input_dropout = nn.Dropout(input_p)\n",
        "        self.output_dropout = nn.Dropout(output_p)\n",
        "        self.bidirectional = bidirectional\n",
        "        self.rnn = nn.GRU(input_size=emb_dim, hidden_size=(hidden_dim // 2 if self.bidirectional else hidden_dim),\n",
        "                          num_layers=num_layers, dropout=hidden_p, bidirectional=bidirectional,\n",
        "                          batch_first=True)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        '''\n",
        "        inputs: (batch_size, seq_len)\n",
        "\n",
        "        returns: (batch_size, h_dim(*2))\n",
        "        '''\n",
        "        bz, sl = inputs.size()\n",
        "        h, r, t = torch.chunk(inputs, 3, dim=1)  # (bz, 1)\n",
        "\n",
        "        h, t = self.input_dropout(self.cpt_emb(h)), self.input_dropout(self.cpt_emb(t))  # (bz, 1, dim)\n",
        "        r = self.input_dropout(self.rel_emb(r))\n",
        "        inputs = torch.cat((h, r, t), dim=1)  # (bz, 3, dim)\n",
        "        rnn_outputs, _ = self.rnn(inputs)  # (bz, 3, dim)\n",
        "        if self.bidirectional:\n",
        "            outputs_f, outputs_b = torch.chunk(rnn_outputs, 2, dim=2)\n",
        "            outputs = torch.cat((outputs_f[:, -1, :], outputs_b[:, 0, :]), 1)  # (bz, 2 * h_dim)\n",
        "        else:\n",
        "            outputs = rnn_outputs[:, -1, :]\n",
        "\n",
        "        return self.output_dropout(outputs)\n",
        "\n",
        "\n",
        "class MatrixVectorScaledDotProductAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, temperature, attn_dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.dropout = nn.Dropout(attn_dropout)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        \"\"\"\n",
        "        q: tensor of shape (n*b, d_k)\n",
        "        k: tensor of shape (n*b, l, d_k)\n",
        "        v: tensor of shape (n*b, l, d_v)\n",
        "\n",
        "        returns: tensor of shape (n*b, d_v), tensor of shape(n*b, l)\n",
        "        \"\"\"\n",
        "        attn = (q.unsqueeze(1) * k).sum(2)  # (n*b, l)\n",
        "        attn = attn / self.temperature\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(mask, -np.inf)\n",
        "        attn = self.softmax(attn)\n",
        "        attn = self.dropout(attn)\n",
        "        output = (attn.unsqueeze(2) * v).sum(1)\n",
        "        return output, attn\n",
        "\n",
        "\n",
        "class AttPoolLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_q, d_k, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.w_qs = nn.Linear(d_q, d_k)\n",
        "        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_q + d_k)))\n",
        "        self.attention = MatrixVectorScaledDotProductAttention(temperature=np.power(d_k, 0.5))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, q, k, mask=None):\n",
        "        \"\"\"\n",
        "        q: tensor of shape (b, d_q)\n",
        "        k: tensor of shape (b, l, d_k)\n",
        "        mask: tensor of shape (b, l) (optional, default None)\n",
        "        returns: tensor of shape (b, d_k)\n",
        "        \"\"\"\n",
        "        qs = self.w_qs(q)  # (b, d_k)\n",
        "        output, attn = self.attention(qs, k, k, mask=mask)\n",
        "        output = self.dropout(output)\n",
        "        return output, attn\n",
        "\n",
        "\n",
        "class MultiheadAttPoolLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, n_head, d_q_original, d_k_original, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_k_original % n_head == 0  # make sure the outpute dimension equals to d_k_origin\n",
        "        self.n_head = n_head\n",
        "        self.d_k = d_k_original // n_head\n",
        "        self.d_v = d_k_original // n_head\n",
        "\n",
        "        self.w_qs = nn.Linear(d_q_original, n_head * self.d_k)\n",
        "        self.w_ks = nn.Linear(d_k_original, n_head * self.d_k)\n",
        "        self.w_vs = nn.Linear(d_k_original, n_head * self.d_v)\n",
        "\n",
        "        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_q_original + self.d_k)))\n",
        "        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_k_original + self.d_k)))\n",
        "        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_k_original + self.d_v)))\n",
        "\n",
        "        self.attention = MatrixVectorScaledDotProductAttention(temperature=np.power(self.d_k, 0.5))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, q, k, mask=None):\n",
        "        \"\"\"\n",
        "        q: tensor of shape (b, d_q_original)\n",
        "        k: tensor of shape (b, l, d_k_original)\n",
        "        mask: tensor of shape (b, l) (optional, default None)\n",
        "        returns: tensor of shape (b, n*d_v)\n",
        "        \"\"\"\n",
        "        n_head, d_k, d_v = self.n_head, self.d_k, self.d_v\n",
        "\n",
        "        bs, _ = q.size()\n",
        "        bs, len_k, _ = k.size()\n",
        "\n",
        "        qs = self.w_qs(q).view(bs, n_head, d_k)  # (b, n, dk)\n",
        "        ks = self.w_ks(k).view(bs, len_k, n_head, d_k)  # (b, l, n, dk)\n",
        "        vs = self.w_vs(k).view(bs, len_k, n_head, d_v)  # (b, l, n, dv)\n",
        "\n",
        "        qs = qs.permute(1, 0, 2).contiguous().view(n_head * bs, d_k)\n",
        "        ks = ks.permute(2, 0, 1, 3).contiguous().view(n_head * bs, len_k, d_k)\n",
        "        vs = vs.permute(2, 0, 1, 3).contiguous().view(n_head * bs, len_k, d_v)\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.repeat(n_head, 1)\n",
        "        output, attn = self.attention(qs, ks, vs, mask=mask)\n",
        "\n",
        "        output = output.view(n_head, bs, d_v)\n",
        "        output = output.permute(1, 0, 2).contiguous().view(bs, n_head * d_v)  # (b, n*dv)\n",
        "        output = self.dropout(output)\n",
        "        return output, attn\n",
        "\n",
        "\n",
        "class TypedMultiheadAttPoolLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, n_head, d_q_original, d_k_original, dropout=0.1, n_type=1):\n",
        "        super().__init__()\n",
        "        assert d_k_original % n_head == 0  # make sure the outpute dimension equals to d_k_origin\n",
        "        self.n_head = n_head\n",
        "        self.d_k = d_k_original // n_head\n",
        "        self.d_v = d_k_original // n_head\n",
        "\n",
        "        self.w_qs = nn.Linear(d_q_original, n_head * self.d_k)\n",
        "        self.w_ks = TypedLinear(d_k_original, n_head * self.d_k, n_type)\n",
        "        self.w_vs = TypedLinear(d_k_original, n_head * self.d_v, n_type)\n",
        "\n",
        "        nn.init.normal_(self.w_qs.weight, mean=0, std=np.sqrt(2.0 / (d_q_original + self.d_k)))\n",
        "        nn.init.normal_(self.w_ks.weight, mean=0, std=np.sqrt(2.0 / (d_k_original + self.d_k)))\n",
        "        nn.init.normal_(self.w_vs.weight, mean=0, std=np.sqrt(2.0 / (d_k_original + self.d_v)))\n",
        "\n",
        "        self.attention = MatrixVectorScaledDotProductAttention(temperature=np.power(self.d_k, 0.5))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, q, k, mask=None, type_ids=None):\n",
        "        \"\"\"\n",
        "        q: tensor of shape (b, d_q_original)\n",
        "        k: tensor of shape (b, l, d_k_original)\n",
        "        mask: bool tensor of shape (b, l) (optional, default None)\n",
        "        type_ids: long tensor of shape (b, l) (optional, default None)\n",
        "        returns: tensor of shape (b, n*d_v)\n",
        "        \"\"\"\n",
        "        n_head, d_k, d_v = self.n_head, self.d_k, self.d_v\n",
        "\n",
        "        bs, _ = q.size()\n",
        "        bs, len_k, _ = k.size()\n",
        "\n",
        "        qs = self.w_qs(q).view(bs, n_head, d_k)  # (b, n, dk)\n",
        "        ks = self.w_ks(k, type_ids=type_ids).view(bs, len_k, n_head, d_k)  # (b, l, n, dk)\n",
        "        vs = self.w_vs(k, type_ids=type_ids).view(bs, len_k, n_head, d_v)  # (b, l, n, dv)\n",
        "\n",
        "        qs = qs.permute(1, 0, 2).contiguous().view(n_head * bs, d_k)\n",
        "        ks = ks.permute(2, 0, 1, 3).contiguous().view(n_head * bs, len_k, d_k)\n",
        "        vs = vs.permute(2, 0, 1, 3).contiguous().view(n_head * bs, len_k, d_v)\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.repeat(n_head, 1)\n",
        "        output, attn = self.attention(qs, ks, vs, mask=mask)\n",
        "\n",
        "        output = output.view(n_head, bs, d_v)\n",
        "        output = output.permute(1, 0, 2).contiguous().view(bs, n_head * d_v)  # (b, n*dv)\n",
        "        output = self.dropout(output)\n",
        "        return output, attn\n",
        "\n",
        "\n",
        "class BilinearAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, query_dim, value_dim):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(value_dim, query_dim, bias=False)\n",
        "        self.softmax = nn.Softmax(1)\n",
        "\n",
        "    def forward(self, query, value, node_mask=None):\n",
        "        \"\"\"\n",
        "        query: tensor of shape (batch_size, query_dim)\n",
        "        value: tensor of shape (batch_size, seq_len, value_dim)\n",
        "        node_mask: tensor of shape (batch_size, seq_len)\n",
        "\n",
        "        returns: tensor of shape (batch_size, value_dim)\n",
        "        \"\"\"\n",
        "        attn = self.linear(value).bmm(query.unsqueeze(-1))\n",
        "        attn = self.softmax(attn.squeeze(-1))\n",
        "        if node_mask is not None:\n",
        "            attn = attn * node_mask\n",
        "            attn = attn / attn.sum(1, keepdim=True)\n",
        "        pooled = attn.unsqueeze(1).bmm(value).squeeze(1)\n",
        "        return pooled, attn\n",
        "\n",
        "\n",
        "def masked_softmax(vector: torch.Tensor,\n",
        "                   mask: torch.Tensor,\n",
        "                   dim: int = -1,\n",
        "                   memory_efficient: bool = True,\n",
        "                   mask_fill_value: float = -1e32) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    ``torch.nn.functional.softmax(vector)`` does not work if some elements of ``vector`` should be\n",
        "    masked.  This performs a softmax on just the non-masked portions of ``vector``.  Passing\n",
        "    ``None`` in for the mask is also acceptable; you'll just get a regular softmax.\n",
        "    ``vector`` can have an arbitrary number of dimensions; the only requirement is that ``mask`` is\n",
        "    broadcastable to ``vector's`` shape.  If ``mask`` has fewer dimensions than ``vector``, we will\n",
        "    unsqueeze on dimension 1 until they match.  If you need a different unsqueezing of your mask,\n",
        "    do it yourself before passing the mask into this function.\n",
        "    If ``memory_efficient`` is set to true, we will simply use a very large negative number for those\n",
        "    masked positions so that the probabilities of those positions would be approximately 0.\n",
        "    This is not accurate in math, but works for most cases and consumes less memory.\n",
        "    In the case that the input vector is completely masked and ``memory_efficient`` is false, this function\n",
        "    returns an array of ``0.0``. This behavior may cause ``NaN`` if this is used as the last layer of\n",
        "    a model that uses categorical cross-entropy loss. Instead, if ``memory_efficient`` is true, this function\n",
        "    will treat every element as equal, and do softmax over equal numbers.\n",
        "    \"\"\"\n",
        "    if mask is None:\n",
        "        result = nn.functional.softmax(vector, dim=dim)\n",
        "    else:\n",
        "        mask = mask.float()\n",
        "        while mask.dim() < vector.dim():\n",
        "            mask = mask.unsqueeze(1)\n",
        "        if not memory_efficient:\n",
        "            # # To limit numerical errors from large vector elements outside the mask, we zero these out.\n",
        "            # result = nn.functional.softmax(vector * mask, dim=dim)\n",
        "            # result = result * mask\n",
        "            # result = result / (result.sum(dim=dim, keepdim=True) + 1e-13)\n",
        "            raise NotImplementedError\n",
        "        else:\n",
        "            masked_vector = vector.masked_fill(mask.to(dtype=torch.uint8), mask_fill_value)\n",
        "            result = nn.functional.softmax(masked_vector, dim=dim)\n",
        "            result = result * (1 - mask)\n",
        "    return result\n",
        "\n",
        "\n",
        "class DiffTopK(torch.autograd.Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, k):\n",
        "        \"\"\"\n",
        "        x: tensor of shape (batch_size, n_node)\n",
        "        k: int\n",
        "        returns: tensor of shape (batch_size, n_node)\n",
        "        \"\"\"\n",
        "        bs, _ = x.size()\n",
        "        _, topk_indexes = x.topk(k, 1)  # (batch_size, k)\n",
        "        output = x.new_zeros(x.size())\n",
        "        ri = torch.arange(bs).unsqueeze(1).expand(bs, k).contiguous().view(-1)\n",
        "        output[ri, topk_indexes.view(-1)] = 1\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return grad_output.clone(), None\n",
        "\n",
        "\n",
        "class SimilarityFunction(nn.Module):\n",
        "    \"\"\"\n",
        "    A ``SimilarityFunction`` takes a pair of tensors with the same shape, and computes a similarity\n",
        "    function on the vectors in the last dimension.  For example, the tensors might both have shape\n",
        "    `(batch_size, sentence_length, embedding_dim)`, and we will compute some function of the two\n",
        "    vectors of length `embedding_dim` for each position `(batch_size, sentence_length)`, returning a\n",
        "    tensor of shape `(batch_size, sentence_length)`.\n",
        "    The similarity function could be as simple as a dot product, or it could be a more complex,\n",
        "    parameterized function.\n",
        "    \"\"\"\n",
        "    default_implementation = 'dot_product'\n",
        "\n",
        "    def forward(self, tensor_1: torch.Tensor, tensor_2: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Takes two tensors of the same shape, such as ``(batch_size, length_1, length_2,\n",
        "        embedding_dim)``.  Computes a (possibly parameterized) similarity on the final dimension\n",
        "        and returns a tensor with one less dimension, such as ``(batch_size, length_1, length_2)``.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class DotProductSimilarity(SimilarityFunction):\n",
        "    \"\"\"\n",
        "    This similarity function simply computes the dot product between each pair of vectors, with an\n",
        "    optional scaling to reduce the variance of the output elements.\n",
        "    Parameters\n",
        "    ----------\n",
        "    scale_output : ``bool``, optional\n",
        "        If ``True``, we will scale the output by ``math.sqrt(tensor.size(-1))``, to reduce the\n",
        "        variance in the result.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, scale_output: bool = False) -> None:\n",
        "        super(DotProductSimilarity, self).__init__()\n",
        "        self._scale_output = scale_output\n",
        "\n",
        "    def forward(self, tensor_1: torch.Tensor, tensor_2: torch.Tensor) -> torch.Tensor:\n",
        "        result = (tensor_1 * tensor_2).sum(dim=-1)\n",
        "        if self._scale_output:\n",
        "            result *= math.sqrt(tensor_1.size(-1))\n",
        "        return result\n",
        "\n",
        "\n",
        "class MatrixAttention(nn.Module):\n",
        "    def __init__(self, similarity_function: SimilarityFunction = None) -> None:\n",
        "        super().__init__()\n",
        "        self._similarity_function = similarity_function or DotProductSimilarity()\n",
        "\n",
        "    def forward(self, matrix_1: torch.Tensor, matrix_2: torch.Tensor) -> torch.Tensor:\n",
        "        tiled_matrix_1 = matrix_1.unsqueeze(2).expand(matrix_1.size()[0],\n",
        "                                                      matrix_1.size()[1],\n",
        "                                                      matrix_2.size()[1],\n",
        "                                                      matrix_1.size()[2])\n",
        "        tiled_matrix_2 = matrix_2.unsqueeze(1).expand(matrix_2.size()[0],\n",
        "                                                      matrix_1.size()[1],\n",
        "                                                      matrix_2.size()[1],\n",
        "                                                      matrix_2.size()[2])\n",
        "\n",
        "        return self._similarity_function(tiled_matrix_1, tiled_matrix_2)\n",
        "\n",
        "\n",
        "class CustomizedEmbedding(nn.Module):\n",
        "    def __init__(self, concept_num, concept_in_dim, concept_out_dim, use_contextualized=False,\n",
        "                 pretrained_concept_emb=None, freeze_ent_emb=True, scale=1.0, init_range=0.02):\n",
        "        super().__init__()\n",
        "        self.scale = scale\n",
        "        self.use_contextualized = use_contextualized\n",
        "        if not use_contextualized:\n",
        "            self.emb = nn.Embedding(concept_num, concept_in_dim)\n",
        "            if pretrained_concept_emb is not None:\n",
        "                self.emb.weight.data.copy_(pretrained_concept_emb)\n",
        "            else:\n",
        "                self.emb.weight.data.normal_(mean=0.0, std=init_range)\n",
        "            if freeze_ent_emb:\n",
        "                freeze_net(self.emb)\n",
        "\n",
        "        if concept_in_dim != concept_out_dim:\n",
        "            self.cpt_transform = nn.Linear(concept_in_dim, concept_out_dim)\n",
        "            self.activation = GELU()\n",
        "\n",
        "    def forward(self, index, contextualized_emb=None):\n",
        "        \"\"\"\n",
        "        index: size (bz, a)\n",
        "        contextualized_emb: size (bz, b, emb_size) (optional)\n",
        "        \"\"\"\n",
        "        if contextualized_emb is not None:\n",
        "            assert index.size(0) == contextualized_emb.size(0)\n",
        "            if hasattr(self, 'cpt_transform'):\n",
        "                contextualized_emb = self.activation(self.cpt_transform(contextualized_emb * self.scale))\n",
        "            else:\n",
        "                contextualized_emb = contextualized_emb * self.scale\n",
        "            emb_dim = contextualized_emb.size(-1)\n",
        "            return contextualized_emb.gather(1, index.unsqueeze(-1).expand(-1, -1, emb_dim))\n",
        "        else:\n",
        "            if hasattr(self, 'cpt_transform'):\n",
        "                return self.activation(self.cpt_transform(self.emb(index) * self.scale))\n",
        "            else:\n",
        "                return self.emb(index) * self.scale\n",
        "\n",
        "\n",
        "def run_test():\n",
        "    print('testing BilinearAttentionLayer...')\n",
        "    att = BilinearAttentionLayer(100, 20)\n",
        "    mask = (torch.randn(70, 30) > 0).float()\n",
        "    mask.requires_grad_()\n",
        "    v = torch.randn(70, 30, 20)\n",
        "    q = torch.randn(70, 100)\n",
        "    o, _ = att(q, v, mask)\n",
        "    o.sum().backward()\n",
        "    print(mask.grad)\n",
        "\n",
        "    print('testing DiffTopK...')\n",
        "    x = torch.randn(5, 3)\n",
        "    x.requires_grad_()\n",
        "    k = 2\n",
        "    r = DiffTopK.apply(x, k)\n",
        "    loss = (r ** 2).sum()\n",
        "    loss.backward()\n",
        "    assert (x.grad == r * 2).all()\n",
        "    print('pass')\n",
        "\n",
        "    a = TripleEncoder()\n",
        "\n",
        "    triple_input = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "    res = a(triple_input)\n",
        "    print(res.size())\n",
        "\n",
        "    b = LSTMEncoder(pooling=False)\n",
        "    lstm_inputs = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
        "    lengths = torch.tensor([3, 2])\n",
        "    res = b(lstm_inputs, lengths)\n",
        "    print(res.size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoNvZ9axVKqI"
      },
      "source": [
        "####from utils.data_utils import get_gpt_token_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KlJaQp3eVLi2"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (OpenAIGPTTokenizer, BertTokenizer, XLNetTokenizer, RobertaTokenizer, AutoTokenizer)\n",
        "try:\n",
        "    from transformers import AlbertTokenizer\n",
        "except:\n",
        "    pass\n",
        "\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "GPT_SPECIAL_TOKENS = ['_start_', '_delimiter_', '_classify_']\n",
        "\n",
        "\n",
        "class MultiGPUSparseAdjDataBatchGenerator(object):\n",
        "    def __init__(self, args, mode, device0, device1, batch_size, indexes, qids, labels,\n",
        "                 tensors0=[], lists0=[], tensors1=[], lists1=[], adj_data=None):\n",
        "        self.args = args\n",
        "        self.mode = mode\n",
        "        self.device0 = device0\n",
        "        self.device1 = device1\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = indexes\n",
        "        self.qids = qids\n",
        "        self.labels = labels\n",
        "        self.tensors0 = tensors0\n",
        "        self.lists0 = lists0\n",
        "        self.tensors1 = tensors1\n",
        "        self.lists1 = lists1\n",
        "        # self.adj_empty = adj_empty.to(self.device1)\n",
        "        self.adj_data = adj_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.indexes.size(0) - 1) // self.batch_size + 1\n",
        "\n",
        "    def __iter__(self):\n",
        "        bs = self.batch_size\n",
        "        n = self.indexes.size(0)\n",
        "        if self.mode=='train' and self.args[\"drop_partial_batch\"]:\n",
        "            print ('dropping partial batch')\n",
        "            n = (n//bs) *bs\n",
        "        elif self.mode=='train' and self.args[\"fill_partial_batch\"]:\n",
        "            print ('filling partial batch')\n",
        "            remain = n % bs\n",
        "            if remain > 0:\n",
        "                extra = np.random.choice(self.indexes[:-remain], size=(bs-remain), replace=False)\n",
        "                self.indexes = torch.cat([self.indexes, torch.tensor(extra)])\n",
        "                n = self.indexes.size(0)\n",
        "                assert n % bs == 0\n",
        "\n",
        "        for a in range(0, n, bs):\n",
        "            b = min(n, a + bs)\n",
        "            batch_indexes = self.indexes[a:b]\n",
        "            batch_qids = [self.qids[idx] for idx in batch_indexes]\n",
        "            batch_labels = self._to_device(self.labels[batch_indexes], self.device1)\n",
        "            batch_tensors0 = [self._to_device(x[batch_indexes], self.device0) for x in self.tensors0]\n",
        "            batch_tensors1 = [self._to_device(x[batch_indexes], self.device1) for x in self.tensors1]\n",
        "            batch_lists0 = [self._to_device([x[i] for i in batch_indexes], self.device0) for x in self.lists0]\n",
        "            batch_lists1 = [self._to_device([x[i] for i in batch_indexes], self.device1) for x in self.lists1]\n",
        "\n",
        "\n",
        "            edge_index_all, edge_type_all = self.adj_data\n",
        "            #edge_index_all: nested list of shape (n_samples, num_choice), where each entry is tensor[2, E]\n",
        "            #edge_type_all:  nested list of shape (n_samples, num_choice), where each entry is tensor[E, ]\n",
        "            edge_index = self._to_device([edge_index_all[i] for i in batch_indexes], self.device1)\n",
        "            edge_type  = self._to_device([edge_type_all[i] for i in batch_indexes], self.device1)\n",
        "\n",
        "            yield tuple([batch_qids, batch_labels, *batch_tensors0, *batch_lists0, *batch_tensors1, *batch_lists1, edge_index, edge_type])\n",
        "\n",
        "    def _to_device(self, obj, device):\n",
        "        if isinstance(obj, (tuple, list)):\n",
        "            return [self._to_device(item, device) for item in obj]\n",
        "        else:\n",
        "            return obj.to(device)\n",
        "\n",
        "\n",
        "def load_sparse_adj_data_with_contextnode(adj_pk_path, max_node_num, num_choice, args):\n",
        "    cache_path = adj_pk_path +'.loaded_cache'\n",
        "    use_cache = True\n",
        "\n",
        "    if use_cache and not os.path.exists(cache_path):\n",
        "        use_cache = False\n",
        "\n",
        "    if use_cache:\n",
        "        with open(cache_path, 'rb') as f:\n",
        "            adj_lengths_ori, concept_ids, node_type_ids, node_scores, adj_lengths, edge_index, edge_type, half_n_rel = pickle.load(f)\n",
        "    else:\n",
        "        with open(adj_pk_path, 'rb') as fin:\n",
        "            adj_concept_pairs = pickle.load(fin)\n",
        "\n",
        "        n_samples = len(adj_concept_pairs) #this is actually n_questions x n_choices\n",
        "        edge_index, edge_type = [], []\n",
        "        adj_lengths = torch.zeros((n_samples,), dtype=torch.long)\n",
        "        concept_ids = torch.full((n_samples, max_node_num), 1, dtype=torch.long)\n",
        "        node_type_ids = torch.full((n_samples, max_node_num), 2, dtype=torch.long) #default 2: \"other node\"\n",
        "        node_scores = torch.zeros((n_samples, max_node_num, 1), dtype=torch.float)\n",
        "\n",
        "        adj_lengths_ori = adj_lengths.clone()\n",
        "        for idx, _data in tqdm(enumerate(adj_concept_pairs), total=n_samples, desc='loading adj matrices'):\n",
        "            adj, concepts, qm, am, cid2score = _data['adj'], _data['concepts'], _data['qmask'], _data['amask'], _data['cid2score']\n",
        "            #adj: e.g. <4233x249 (n_nodes*half_n_rels x n_nodes) sparse matrix of type '<class 'numpy.bool'>' with 2905 stored elements in COOrdinate format>\n",
        "            #concepts: np.array(num_nodes, ), where entry is concept id\n",
        "            #qm: np.array(num_nodes, ), where entry is True/False\n",
        "            #am: np.array(num_nodes, ), where entry is True/False\n",
        "            assert len(concepts) == len(set(concepts))\n",
        "            qam = qm | am\n",
        "            #sanity check: should be T,..,T,F,F,..F\n",
        "            assert qam[0] == True\n",
        "            F_start = False\n",
        "            for TF in qam:\n",
        "                if TF == False:\n",
        "                    F_start = True\n",
        "                else:\n",
        "                    assert F_start == False\n",
        "            num_concept = min(len(concepts), max_node_num-1) + 1 #this is the final number of nodes including contextnode but excluding PAD\n",
        "            adj_lengths_ori[idx] = len(concepts)\n",
        "            adj_lengths[idx] = num_concept\n",
        "\n",
        "            #Prepare nodes\n",
        "            concepts = concepts[:num_concept-1]\n",
        "            concept_ids[idx, 1:num_concept] = torch.tensor(concepts +1)  #To accomodate contextnode, original concept_ids incremented by 1\n",
        "            concept_ids[idx, 0] = 0 #this is the \"concept_id\" for contextnode\n",
        "\n",
        "            #Prepare node scores\n",
        "            if (cid2score is not None):\n",
        "                for _j_ in range(num_concept):\n",
        "                    _cid = int(concept_ids[idx, _j_]) - 1\n",
        "                    assert _cid in cid2score\n",
        "                    node_scores[idx, _j_, 0] = torch.tensor(cid2score[_cid])\n",
        "\n",
        "            #Prepare node types\n",
        "            node_type_ids[idx, 0] = 3 #contextnode\n",
        "            node_type_ids[idx, 1:num_concept][torch.tensor(qm, dtype=torch.bool)[:num_concept-1]] = 0\n",
        "            node_type_ids[idx, 1:num_concept][torch.tensor(am, dtype=torch.bool)[:num_concept-1]] = 1\n",
        "\n",
        "            #Load adj\n",
        "            ij = torch.tensor(adj.row, dtype=torch.int64) #(num_matrix_entries, ), where each entry is coordinate\n",
        "            k = torch.tensor(adj.col, dtype=torch.int64)  #(num_matrix_entries, ), where each entry is coordinate\n",
        "            n_node = adj.shape[1]\n",
        "            half_n_rel = adj.shape[0] // n_node\n",
        "            i, j = ij // n_node, ij % n_node\n",
        "\n",
        "            #Prepare edges\n",
        "            i += 2; j += 1; k += 1  # **** increment coordinate by 1, rel_id by 2 ****\n",
        "            extra_i, extra_j, extra_k = [], [], []\n",
        "            for _coord, q_tf in enumerate(qm):\n",
        "                _new_coord = _coord + 1\n",
        "                if _new_coord > num_concept:\n",
        "                    break\n",
        "                if q_tf:\n",
        "                    extra_i.append(0) #rel from contextnode to question concept\n",
        "                    extra_j.append(0) #contextnode coordinate\n",
        "                    extra_k.append(_new_coord) #question concept coordinate\n",
        "            for _coord, a_tf in enumerate(am):\n",
        "                _new_coord = _coord + 1\n",
        "                if _new_coord > num_concept:\n",
        "                    break\n",
        "                if a_tf:\n",
        "                    extra_i.append(1) #rel from contextnode to answer concept\n",
        "                    extra_j.append(0) #contextnode coordinate\n",
        "                    extra_k.append(_new_coord) #answer concept coordinate\n",
        "\n",
        "            half_n_rel += 2 #should be 19 now\n",
        "            if len(extra_i) > 0:\n",
        "                i = torch.cat([i, torch.tensor(extra_i)], dim=0)\n",
        "                j = torch.cat([j, torch.tensor(extra_j)], dim=0)\n",
        "                k = torch.cat([k, torch.tensor(extra_k)], dim=0)\n",
        "            ########################\n",
        "\n",
        "            mask = (j < max_node_num) & (k < max_node_num)\n",
        "            i, j, k = i[mask], j[mask], k[mask]\n",
        "            i, j, k = torch.cat((i, i + half_n_rel), 0), torch.cat((j, k), 0), torch.cat((k, j), 0)  # add inverse relations\n",
        "            edge_index.append(torch.stack([j,k], dim=0)) #each entry is [2, E]\n",
        "            edge_type.append(i) #each entry is [E, ]\n",
        "\n",
        "        with open(cache_path, 'wb') as f:\n",
        "            pickle.dump([adj_lengths_ori, concept_ids, node_type_ids, node_scores, adj_lengths, edge_index, edge_type, half_n_rel], f)\n",
        "\n",
        "\n",
        "    ori_adj_mean  = adj_lengths_ori.float().mean().item()\n",
        "    ori_adj_sigma = np.sqrt(((adj_lengths_ori.float() - ori_adj_mean)**2).mean().item())\n",
        "    print('| ori_adj_len: mu {:.2f} sigma {:.2f} | adj_len: {:.2f} |'.format(ori_adj_mean, ori_adj_sigma, adj_lengths.float().mean().item()) +\n",
        "          ' prune_rate： {:.2f} |'.format((adj_lengths_ori > adj_lengths).float().mean().item()) +\n",
        "          ' qc_num: {:.2f} | ac_num: {:.2f} |'.format((node_type_ids == 0).float().sum(1).mean().item(),\n",
        "                                                      (node_type_ids == 1).float().sum(1).mean().item()))\n",
        "\n",
        "    edge_index = list(map(list, zip(*(iter(edge_index),) * num_choice))) #list of size (n_questions, n_choices), where each entry is tensor[2, E] #this operation corresponds to .view(n_questions, n_choices)\n",
        "    edge_type = list(map(list, zip(*(iter(edge_type),) * num_choice))) #list of size (n_questions, n_choices), where each entry is tensor[E, ]\n",
        "\n",
        "    concept_ids, node_type_ids, node_scores, adj_lengths = [x.view(-1, num_choice, *x.size()[1:]) for x in (concept_ids, node_type_ids, node_scores, adj_lengths)]\n",
        "    #concept_ids: (n_questions, num_choice, max_node_num)\n",
        "    #node_type_ids: (n_questions, num_choice, max_node_num)\n",
        "    #node_scores: (n_questions, num_choice, max_node_num)\n",
        "    #adj_lengths: (n_questions,　num_choice)\n",
        "    return concept_ids, node_type_ids, node_scores, adj_lengths, (edge_index, edge_type) #, half_n_rel * 2 + 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_gpt_input_tensors(statement_jsonl_path, max_seq_length):\n",
        "    def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "        while True:\n",
        "            total_length = len(tokens_a) + len(tokens_b)\n",
        "            if total_length <= max_length:\n",
        "                break\n",
        "            if len(tokens_a) > len(tokens_b):\n",
        "                tokens_a.pop()\n",
        "            else:\n",
        "                tokens_b.pop()\n",
        "\n",
        "    def load_qa_dataset(dataset_path):\n",
        "        \"\"\" Output a list of tuples(story, 1st continuation, 2nd continuation, label) \"\"\"\n",
        "        with open(dataset_path, \"r\", encoding=\"utf-8\") as fin:\n",
        "            output = []\n",
        "            for line in fin:\n",
        "                input_json = json.loads(line)\n",
        "                label = ord(input_json.get(\"answerKey\", \"A\")) - ord(\"A\")\n",
        "                output.append((input_json['id'], input_json[\"question\"][\"stem\"], *[ending[\"text\"] for ending in input_json[\"question\"][\"choices\"]], label))\n",
        "        return output\n",
        "\n",
        "    def pre_process_datasets(encoded_datasets, num_choices, max_seq_length, start_token, delimiter_token, clf_token):\n",
        "        \"\"\" Pre-process datasets containing lists of tuples(story, 1st continuation, 2nd continuation, label)\n",
        "\n",
        "            To Transformer inputs of shape (n_batch, n_alternative, length) comprising for each batch, continuation:\n",
        "            input_ids[batch, alternative, :] = [start_token] + story[:cap_length] + [delimiter_token] + cont1[:cap_length] + [clf_token]\n",
        "        \"\"\"\n",
        "        tensor_datasets = []\n",
        "        for dataset in encoded_datasets:\n",
        "            n_batch = len(dataset)\n",
        "            input_ids = np.zeros((n_batch, num_choices, max_seq_length), dtype=np.int64)\n",
        "            mc_token_ids = np.zeros((n_batch, num_choices), dtype=np.int64)\n",
        "            lm_labels = np.full((n_batch, num_choices, max_seq_length), fill_value=-1, dtype=np.int64)\n",
        "            mc_labels = np.zeros((n_batch,), dtype=np.int64)\n",
        "            for i, data, in enumerate(dataset):\n",
        "                q, mc_label = data[0], data[-1]\n",
        "                choices = data[1:-1]\n",
        "                for j in range(len(choices)):\n",
        "                    _truncate_seq_pair(q, choices[j], max_seq_length - 3)\n",
        "                    qa = [start_token] + q + [delimiter_token] + choices[j] + [clf_token]\n",
        "                    input_ids[i, j, :len(qa)] = qa\n",
        "                    mc_token_ids[i, j] = len(qa) - 1\n",
        "                    lm_labels[i, j, :len(qa) - 1] = qa[1:]\n",
        "                mc_labels[i] = mc_label\n",
        "            all_inputs = (input_ids, mc_token_ids, lm_labels, mc_labels)\n",
        "            tensor_datasets.append(tuple(torch.tensor(t) for t in all_inputs))\n",
        "        return tensor_datasets\n",
        "\n",
        "    def tokenize_and_encode(tokenizer, obj):\n",
        "        \"\"\" Tokenize and encode a nested object \"\"\"\n",
        "        if isinstance(obj, str):\n",
        "            return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(obj))\n",
        "        elif isinstance(obj, int):\n",
        "            return obj\n",
        "        else:\n",
        "            return list(tokenize_and_encode(tokenizer, o) for o in obj)\n",
        "\n",
        "    tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')\n",
        "    tokenizer.add_tokens(GPT_SPECIAL_TOKENS)\n",
        "    special_tokens_ids = tokenizer.convert_tokens_to_ids(GPT_SPECIAL_TOKENS)\n",
        "\n",
        "    dataset = load_qa_dataset(statement_jsonl_path)\n",
        "    examples_ids = [data[0] for data in dataset]\n",
        "    dataset = [data[1:] for data in dataset]  # discard example ids\n",
        "    num_choices = len(dataset[0]) - 2\n",
        "\n",
        "    encoded_dataset = tokenize_and_encode(tokenizer, dataset)\n",
        "\n",
        "    (input_ids, mc_token_ids, lm_labels, mc_labels), = pre_process_datasets([encoded_dataset], num_choices, max_seq_length, *special_tokens_ids)\n",
        "    return examples_ids, mc_labels, input_ids, mc_token_ids, lm_labels\n",
        "\n",
        "\n",
        "def get_gpt_token_num():\n",
        "    tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')\n",
        "    tokenizer.add_tokens(GPT_SPECIAL_TOKENS)\n",
        "    return len(tokenizer)\n",
        "\n",
        "\n",
        "\n",
        "def load_bert_xlnet_roberta_input_tensors(statement_jsonl_path, model_type, model_name, max_seq_length):\n",
        "    class InputExample(object):\n",
        "\n",
        "        def __init__(self, example_id, question, contexts, endings, label=None):\n",
        "            self.example_id = example_id\n",
        "            self.question = question\n",
        "            self.contexts = contexts\n",
        "            self.endings = endings\n",
        "            self.label = label\n",
        "\n",
        "    class InputFeatures(object):\n",
        "\n",
        "        def __init__(self, example_id, choices_features, label):\n",
        "            self.example_id = example_id\n",
        "            self.choices_features = [\n",
        "                {\n",
        "                    'input_ids': input_ids,\n",
        "                    'input_mask': input_mask,\n",
        "                    'segment_ids': segment_ids,\n",
        "                    'output_mask': output_mask,\n",
        "                }\n",
        "                for _, input_ids, input_mask, segment_ids, output_mask in choices_features\n",
        "            ]\n",
        "            self.label = label\n",
        "\n",
        "    def read_examples(input_file):\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            examples = []\n",
        "            for line in f.readlines():\n",
        "                json_dic = json.loads(line)\n",
        "                label = ord(json_dic[\"answerKey\"]) - ord(\"A\") if 'answerKey' in json_dic else 0\n",
        "                contexts = json_dic[\"question\"][\"stem\"]\n",
        "                if \"para\" in json_dic:\n",
        "                    contexts = json_dic[\"para\"] + \" \" + contexts\n",
        "                if \"fact1\" in json_dic:\n",
        "                    contexts = json_dic[\"fact1\"] + \" \" + contexts\n",
        "                examples.append(\n",
        "                    InputExample(\n",
        "                        example_id=json_dic[\"id\"],\n",
        "                        contexts=[contexts] * len(json_dic[\"question\"][\"choices\"]),\n",
        "                        question=\"\",\n",
        "                        endings=[ending[\"text\"] for ending in json_dic[\"question\"][\"choices\"]],\n",
        "                        label=label\n",
        "                    ))\n",
        "        return examples\n",
        "\n",
        "    def convert_examples_to_features(examples, label_list, max_seq_length,\n",
        "                                     tokenizer,\n",
        "                                     cls_token_at_end=False,\n",
        "                                     cls_token='[CLS]',\n",
        "                                     cls_token_segment_id=1,\n",
        "                                     sep_token='[SEP]',\n",
        "                                     sequence_a_segment_id=0,\n",
        "                                     sequence_b_segment_id=1,\n",
        "                                     sep_token_extra=False,\n",
        "                                     pad_token_segment_id=0,\n",
        "                                     pad_on_left=False,\n",
        "                                     pad_token=0,\n",
        "                                     mask_padding_with_zero=True):\n",
        "        \"\"\" Loads a data file into a list of `InputBatch`s\n",
        "            `cls_token_at_end` define the location of the CLS token:\n",
        "                - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
        "                - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
        "            `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
        "        \"\"\"\n",
        "        label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "        features = []\n",
        "        for ex_index, example in enumerate(tqdm(examples)):\n",
        "            choices_features = []\n",
        "            for ending_idx, (context, ending) in enumerate(zip(example.contexts, example.endings)):\n",
        "                tokens_a = tokenizer.tokenize(context)\n",
        "                tokens_b = tokenizer.tokenize(example.question + \" \" + ending)\n",
        "\n",
        "                special_tokens_count = 4 if sep_token_extra else 3\n",
        "                _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - special_tokens_count)\n",
        "\n",
        "                # The convention in BERT is:\n",
        "                # (a) For sequence pairs:\n",
        "                #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "                #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
        "                # (b) For single sequences:\n",
        "                #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "                #  type_ids:   0   0   0   0  0     0   0\n",
        "                #\n",
        "                # Where \"type_ids\" are used to indicate whether this is the first\n",
        "                # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "                # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "                # embedding vector (and position vector). This is not *strictly* necessary\n",
        "                # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "                # it easier for the model to learn the concept of sequences.\n",
        "                #\n",
        "                # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "                # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "                # the entire model is fine-tuned.\n",
        "                tokens = tokens_a + [sep_token]\n",
        "                if sep_token_extra:\n",
        "                    # roberta uses an extra separator b/w pairs of sentences\n",
        "                    tokens += [sep_token]\n",
        "\n",
        "                segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "                if tokens_b:\n",
        "                    tokens += tokens_b + [sep_token]\n",
        "                    segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
        "\n",
        "                if cls_token_at_end:\n",
        "                    tokens = tokens + [cls_token]\n",
        "                    segment_ids = segment_ids + [cls_token_segment_id]\n",
        "                else:\n",
        "                    tokens = [cls_token] + tokens\n",
        "                    segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "                input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "                # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "                # tokens are attended to.\n",
        "\n",
        "                input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "                special_token_id = tokenizer.convert_tokens_to_ids([cls_token, sep_token])\n",
        "                output_mask = [1 if id in special_token_id else 0 for id in input_ids]  # 1 for mask\n",
        "\n",
        "                # Zero-pad up to the sequence length.\n",
        "                padding_length = max_seq_length - len(input_ids)\n",
        "                if pad_on_left:\n",
        "                    input_ids = ([pad_token] * padding_length) + input_ids\n",
        "                    input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
        "                    output_mask = ([1] * padding_length) + output_mask\n",
        "\n",
        "                    segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
        "                else:\n",
        "                    input_ids = input_ids + ([pad_token] * padding_length)\n",
        "                    input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "                    output_mask = output_mask + ([1] * padding_length)\n",
        "                    segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
        "\n",
        "                assert len(input_ids) == max_seq_length\n",
        "                assert len(output_mask) == max_seq_length\n",
        "                assert len(input_mask) == max_seq_length\n",
        "                assert len(segment_ids) == max_seq_length\n",
        "                choices_features.append((tokens, input_ids, input_mask, segment_ids, output_mask))\n",
        "            label = label_map[example.label]\n",
        "            features.append(InputFeatures(example_id=example.example_id, choices_features=choices_features, label=label))\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "        # This is a simple heuristic which will always truncate the longer sequence\n",
        "        # one token at a time. This makes more sense than truncating an equal percent\n",
        "        # of tokens from each, since if one sequence is very short then each token\n",
        "        # that's truncated likely contains more information than a longer sequence.\n",
        "        while True:\n",
        "            total_length = len(tokens_a) + len(tokens_b)\n",
        "            if total_length <= max_length:\n",
        "                break\n",
        "            if len(tokens_a) > len(tokens_b):\n",
        "                tokens_a.pop()\n",
        "            else:\n",
        "                tokens_b.pop()\n",
        "\n",
        "    def select_field(features, field):\n",
        "        return [[choice[field] for choice in feature.choices_features] for feature in features]\n",
        "\n",
        "    def convert_features_to_tensors(features):\n",
        "        all_input_ids = torch.tensor(select_field(features, 'input_ids'), dtype=torch.long)\n",
        "        all_input_mask = torch.tensor(select_field(features, 'input_mask'), dtype=torch.long)\n",
        "        all_segment_ids = torch.tensor(select_field(features, 'segment_ids'), dtype=torch.long)\n",
        "        all_output_mask = torch.tensor(select_field(features, 'output_mask'), dtype=torch.bool)\n",
        "        all_label = torch.tensor([f.label for f in features], dtype=torch.long)\n",
        "        return all_input_ids, all_input_mask, all_segment_ids, all_output_mask, all_label\n",
        "\n",
        "    # try:\n",
        "    #     tokenizer_class = {'bert': BertTokenizer, 'xlnet': XLNetTokenizer, 'roberta': RobertaTokenizer, 'albert': AlbertTokenizer}.get(model_type)\n",
        "    # except:\n",
        "    #     tokenizer_class = {'bert': BertTokenizer, 'xlnet': XLNetTokenizer, 'roberta': RobertaTokenizer}.get(model_type)\n",
        "    tokenizer_class = AutoTokenizer\n",
        "    tokenizer = tokenizer_class.from_pretrained(model_name)\n",
        "    examples = read_examples(statement_jsonl_path)\n",
        "    features = convert_examples_to_features(examples, list(range(len(examples[0].endings))), max_seq_length, tokenizer,\n",
        "                                            cls_token_at_end=bool(model_type in ['xlnet']),  # xlnet has a cls token at the end\n",
        "                                            cls_token=tokenizer.cls_token,\n",
        "                                            sep_token=tokenizer.sep_token,\n",
        "                                            sep_token_extra=bool(model_type in ['roberta', 'albert']),\n",
        "                                            cls_token_segment_id=2 if model_type in ['xlnet'] else 0,\n",
        "                                            pad_on_left=bool(model_type in ['xlnet']),  # pad on the left for xlnet\n",
        "                                            pad_token_segment_id=4 if model_type in ['xlnet'] else 0,\n",
        "                                            sequence_b_segment_id=0 if model_type in ['roberta', 'albert'] else 1)\n",
        "    example_ids = [f.example_id for f in features]\n",
        "    *data_tensors, all_label = convert_features_to_tensors(features)\n",
        "    return (example_ids, all_label, *data_tensors)\n",
        "\n",
        "\n",
        "\n",
        "def load_input_tensors(input_jsonl_path, model_type, model_name, max_seq_length):\n",
        "    if model_type in ('lstm',):\n",
        "        raise NotImplementedError\n",
        "    elif model_type in ('gpt',):\n",
        "        return load_gpt_input_tensors(input_jsonl_path, max_seq_length)\n",
        "    elif model_type in ('bert', 'xlnet', 'roberta', 'albert'):\n",
        "        return load_bert_xlnet_roberta_input_tensors(input_jsonl_path, model_type, model_name, max_seq_length)\n",
        "\n",
        "\n",
        "def load_info(statement_path: str):\n",
        "    n = sum(1 for _ in open(statement_path, \"r\"))\n",
        "    num_choice = None\n",
        "    with open(statement_path, \"r\", encoding=\"utf-8\") as fin:\n",
        "        ids = []\n",
        "        labels = []\n",
        "        for line in fin:\n",
        "            input_json = json.loads(line)\n",
        "            labels.append(ord(input_json.get(\"answerKey\", \"A\")) - ord(\"A\"))\n",
        "            ids.append(input_json['id'])\n",
        "            if num_choice is None:\n",
        "                num_choice = len(input_json[\"question\"][\"choices\"])\n",
        "        labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return ids, labels, num_choice\n",
        "\n",
        "\n",
        "def load_statement_dict(statement_path):\n",
        "    all_dict = {}\n",
        "    with open(statement_path, 'r', encoding='utf-8') as fin:\n",
        "        for line in fin:\n",
        "            instance_dict = json.loads(line)\n",
        "            qid = instance_dict['id']\n",
        "            all_dict[qid] = {\n",
        "                'question': instance_dict['question']['stem'],\n",
        "                'answers': [dic['text'] for dic in instance_dict['question']['choices']]\n",
        "            }\n",
        "    return all_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_T8Sa4xUooQ"
      },
      "source": [
        "####from modeling.modeling_encoder import TextEncoder, MODEL_NAME_TO_CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sdLOXZgRUpf8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from transformers import (OPENAI_GPT_PRETRAINED_CONFIG_ARCHIVE_MAP, BERT_PRETRAINED_CONFIG_ARCHIVE_MAP,\n",
        "                          XLNET_PRETRAINED_CONFIG_ARCHIVE_MAP, ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP)\n",
        "try:\n",
        "    from transformers import ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP\n",
        "except:\n",
        "    pass\n",
        "from transformers import AutoModel, BertModel, BertConfig\n",
        "# from transformers.modeling_bert import BERT_PRETRAINED_MODEL_ARCHIVE_MAP\n",
        "# from utils.layers import *\n",
        "# from utils.data_utils import get_gpt_token_num\n",
        "\n",
        "MODEL_CLASS_TO_NAME = {\n",
        "    'gpt': list(OPENAI_GPT_PRETRAINED_CONFIG_ARCHIVE_MAP.keys()),\n",
        "    'bert': list(BERT_PRETRAINED_CONFIG_ARCHIVE_MAP.keys()),\n",
        "    'xlnet': list(XLNET_PRETRAINED_CONFIG_ARCHIVE_MAP.keys()),\n",
        "    'roberta': list(ROBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP.keys()),\n",
        "    'lstm': ['lstm'],\n",
        "}\n",
        "try:\n",
        "    MODEL_CLASS_TO_NAME['albert'] =  list(ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP.keys())\n",
        "except:\n",
        "    pass\n",
        "\n",
        "MODEL_NAME_TO_CLASS = {model_name: model_class for model_class, model_name_list in MODEL_CLASS_TO_NAME.items() for model_name in model_name_list}\n",
        "\n",
        "# #Add SapBERT configuration\n",
        "# model_name = 'cambridgeltl/SapBERT-from-PubMedBERT-fulltext'\n",
        "# MODEL_NAME_TO_CLASS[model_name] = 'bert'\n",
        "\n",
        "\n",
        "# class LSTMTextEncoder(nn.Module):\n",
        "#     pool_layer_classes = {'mean': MeanPoolLayer, 'max': MaxPoolLayer}\n",
        "\n",
        "#     def __init__(self, vocab_size=1, emb_size=300, hidden_size=300, output_size=300, num_layers=2, bidirectional=True,\n",
        "#                  emb_p=0.0, input_p=0.0, hidden_p=0.0, pretrained_emb_or_path=None, freeze_emb=True,\n",
        "#                  pool_function='max', output_hidden_states=False):\n",
        "#         super().__init__()\n",
        "#         self.output_size = output_size\n",
        "#         self.num_layers = num_layers\n",
        "#         self.output_hidden_states = output_hidden_states\n",
        "#         assert not bidirectional or hidden_size % 2 == 0\n",
        "\n",
        "#         if pretrained_emb_or_path is not None:\n",
        "#             if isinstance(pretrained_emb_or_path, str):  # load pretrained embedding from a .npy file\n",
        "#                 pretrained_emb_or_path = torch.tensor(np.load(pretrained_emb_or_path), dtype=torch.float)\n",
        "#             emb = nn.Embedding.from_pretrained(pretrained_emb_or_path, freeze=freeze_emb)\n",
        "#             emb_size = emb.weight.size(1)\n",
        "#         else:\n",
        "#             emb = nn.Embedding(vocab_size, emb_size)\n",
        "#         self.emb = EmbeddingDropout(emb, emb_p)\n",
        "#         self.rnns = nn.ModuleList([nn.LSTM(emb_size if l == 0 else hidden_size,\n",
        "#                                            (hidden_size if l != num_layers else output_size) // (2 if bidirectional else 1),\n",
        "#                                            1, bidirectional=bidirectional, batch_first=True) for l in range(num_layers)])\n",
        "#         self.pooler = self.pool_layer_classes[pool_function]()\n",
        "\n",
        "#         self.input_dropout = nn.Dropout(input_p)\n",
        "#         self.hidden_dropout = nn.ModuleList([RNNDropout(hidden_p) for _ in range(num_layers)])\n",
        "\n",
        "#     def forward(self, inputs, lengths):\n",
        "#         \"\"\"\n",
        "#         inputs: tensor of shape (batch_size, seq_len)\n",
        "#         lengths: tensor of shape (batch_size)\n",
        "\n",
        "#         returns: tensor of shape (batch_size, hidden_size)\n",
        "#         \"\"\"\n",
        "#         assert (lengths > 0).all()\n",
        "#         batch_size, seq_len = inputs.size()\n",
        "#         hidden_states = self.input_dropout(self.emb(inputs))\n",
        "#         all_hidden_states = [hidden_states]\n",
        "#         for l, (rnn, hid_dp) in enumerate(zip(self.rnns, self.hidden_dropout)):\n",
        "#             hidden_states = pack_padded_sequence(hidden_states, lengths, batch_first=True, enforce_sorted=False)\n",
        "#             hidden_states, _ = rnn(hidden_states)\n",
        "#             hidden_states, _ = pad_packed_sequence(hidden_states, batch_first=True, total_length=seq_len)\n",
        "#             all_hidden_states.append(hidden_states)\n",
        "#             if l != self.num_layers - 1:\n",
        "#                 hidden_states = hid_dp(hidden_states)\n",
        "#         pooled = self.pooler(all_hidden_states[-1], lengths)\n",
        "#         assert len(all_hidden_states) == self.num_layers + 1\n",
        "#         outputs = (all_hidden_states[-1], pooled)\n",
        "#         if self.output_hidden_states:\n",
        "#             outputs = outputs + (all_hidden_states,)\n",
        "#         return outputs\n",
        "\n",
        "\n",
        "class TextEncoder(nn.Module):\n",
        "    valid_model_types = set(MODEL_CLASS_TO_NAME.keys())\n",
        "\n",
        "    def __init__(self, model_name, output_token_states=False, from_checkpoint=None, **kwargs):\n",
        "        super().__init__()\n",
        "        self.model_type = MODEL_NAME_TO_CLASS[model_name]\n",
        "        self.output_token_states = output_token_states\n",
        "        assert not self.output_token_states or self.model_type in ('bert', 'roberta', 'albert')\n",
        "\n",
        "        if self.model_type in ('lstm',):\n",
        "            self.module = LSTMTextEncoder(**kwargs, output_hidden_states=True)\n",
        "            self.sent_dim = self.module.output_size\n",
        "        else:\n",
        "            model_class = AutoModel\n",
        "            self.module = model_class.from_pretrained(model_name, output_hidden_states=True)\n",
        "            if from_checkpoint is not None:\n",
        "                self.module = self.module.from_pretrained(from_checkpoint, output_hidden_states=True)\n",
        "            if self.model_type in ('gpt',):\n",
        "                self.module.resize_token_embeddings(get_gpt_token_num())\n",
        "            self.sent_dim = self.module.config.n_embd if self.model_type in ('gpt',) else self.module.config.hidden_size\n",
        "\n",
        "    def forward(self, *inputs, layer_id=-1):\n",
        "        '''\n",
        "        layer_id: only works for non-LSTM encoders\n",
        "        output_token_states: if True, return hidden states of specific layer and attention masks\n",
        "        '''\n",
        "\n",
        "        if self.model_type in ('lstm',):  # lstm\n",
        "            input_ids, lengths = inputs\n",
        "            outputs = self.module(input_ids, lengths)\n",
        "        elif self.model_type in ('gpt',):  # gpt\n",
        "            input_ids, cls_token_ids, lm_labels = inputs  # lm_labels is not used\n",
        "            outputs = self.module(input_ids)\n",
        "        else:  # bert / xlnet / roberta\n",
        "            input_ids, attention_mask, token_type_ids, output_mask = inputs\n",
        "            outputs = self.module(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
        "        all_hidden_states = outputs[-1]\n",
        "        hidden_states = all_hidden_states[layer_id]\n",
        "\n",
        "        if self.model_type in ('lstm',):\n",
        "            sent_vecs = outputs[1]\n",
        "        elif self.model_type in ('gpt',):\n",
        "            cls_token_ids = cls_token_ids.view(-1).unsqueeze(-1).unsqueeze(-1).expand(-1, 1, hidden_states.size(-1))\n",
        "            sent_vecs = hidden_states.gather(1, cls_token_ids).squeeze(1)\n",
        "        elif self.model_type in ('xlnet',):\n",
        "            sent_vecs = hidden_states[:, -1]\n",
        "        elif self.model_type in ('albert',):\n",
        "            if self.output_token_states:\n",
        "                return hidden_states, output_mask\n",
        "            sent_vecs = hidden_states[:, 0]\n",
        "        else:  # bert / roberta\n",
        "            if self.output_token_states:\n",
        "                return hidden_states, output_mask\n",
        "            sent_vecs = self.module.pooler(hidden_states)\n",
        "        return sent_vecs, all_hidden_states\n",
        "\n",
        "\n",
        "# def run_test():\n",
        "#     encoder = TextEncoder('lstm', vocab_size=100, emb_size=100, hidden_size=200, num_layers=4)\n",
        "#     input_ids = torch.randint(0, 100, (30, 70))\n",
        "#     lenghts = torch.randint(1, 70, (30,))\n",
        "#     outputs = encoder(input_ids, lenghts)\n",
        "#     assert outputs[0].size() == (30, 200)\n",
        "#     assert len(outputs[1]) == 4 + 1\n",
        "#     assert all([x.size() == (30, 70, 100 if l == 0 else 200) for l, x in enumerate(outputs[1])])\n",
        "#     print('all tests are passed')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjH6fwkBVWlj"
      },
      "source": [
        "####Main model classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uY8jmk33UWsK"
      },
      "outputs": [],
      "source": [
        "# from modeling.modeling_encoder import TextEncoder, MODEL_NAME_TO_CLASS\n",
        "# from utils.data_utils import *\n",
        "# from utils.layers import *\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class QAGNN_Message_Passing(nn.Module):\n",
        "    def __init__(self, args, k, n_ntype, n_etype, input_size, hidden_size, output_size, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert input_size == output_size\n",
        "        self.args = args\n",
        "        self.n_ntype = n_ntype\n",
        "        self.n_etype = n_etype\n",
        "\n",
        "        assert input_size == hidden_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.emb_node_type = nn.Linear(self.n_ntype, hidden_size//2)\n",
        "\n",
        "        self.basis_f = 'sin' #['id', 'linact', 'sin', 'none']\n",
        "        if self.basis_f in ['id']:\n",
        "            self.emb_score = nn.Linear(1, hidden_size//2)\n",
        "        elif self.basis_f in ['linact']:\n",
        "            self.B_lin = nn.Linear(1, hidden_size//2)\n",
        "            self.emb_score = nn.Linear(hidden_size//2, hidden_size//2)\n",
        "        elif self.basis_f in ['sin']:\n",
        "            self.emb_score = nn.Linear(hidden_size//2, hidden_size//2)\n",
        "\n",
        "        self.edge_encoder = torch.nn.Sequential(torch.nn.Linear(n_etype +1 + n_ntype *2, hidden_size), torch.nn.BatchNorm1d(hidden_size),\n",
        "                                                torch.nn.ReLU(), torch.nn.Linear(hidden_size, hidden_size))\n",
        "\n",
        "\n",
        "        self.k = k\n",
        "        self.gnn_layers = nn.ModuleList([GATConvE(args, hidden_size, n_ntype, n_etype, self.edge_encoder) for _ in range(k)])\n",
        "\n",
        "\n",
        "        self.Vh = nn.Linear(input_size, output_size)\n",
        "        self.Vx = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.activation = GELU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.dropout_rate = dropout\n",
        "\n",
        "\n",
        "    def mp_helper(self, _X, edge_index, edge_type, _node_type, _node_feature_extra):\n",
        "        for _ in range(self.k):\n",
        "            _X = self.gnn_layers[_](_X, edge_index, edge_type, _node_type, _node_feature_extra)\n",
        "            _X = self.activation(_X)\n",
        "            _X = F.dropout(_X, self.dropout_rate, training = self.training)\n",
        "        return _X\n",
        "\n",
        "\n",
        "    def forward(self, H, A, node_type, node_score, cache_output=False):\n",
        "        \"\"\"\n",
        "        H: tensor of shape (batch_size, n_node, d_node)\n",
        "            node features from the previous layer\n",
        "        A: (edge_index, edge_type)\n",
        "        node_type: long tensor of shape (batch_size, n_node)\n",
        "            0 == question entity; 1 == answer choice entity; 2 == other node; 3 == context node\n",
        "        node_score: tensor of shape (batch_size, n_node, 1)\n",
        "        \"\"\"\n",
        "        _batch_size, _n_nodes = node_type.size()\n",
        "\n",
        "        #Embed type\n",
        "        T = make_one_hot(node_type.view(-1).contiguous(), self.n_ntype).view(_batch_size, _n_nodes, self.n_ntype)\n",
        "        node_type_emb = self.activation(self.emb_node_type(T)) #[batch_size, n_node, dim/2]\n",
        "\n",
        "        #Embed score\n",
        "        if self.basis_f == 'sin':\n",
        "            js = torch.arange(self.hidden_size//2).unsqueeze(0).unsqueeze(0).float().to(node_type.device) #[1,1,dim/2]\n",
        "            js = torch.pow(1.1, js) #[1,1,dim/2]\n",
        "            B = torch.sin(js * node_score) #[batch_size, n_node, dim/2]\n",
        "            node_score_emb = self.activation(self.emb_score(B)) #[batch_size, n_node, dim/2]\n",
        "        elif self.basis_f == 'id':\n",
        "            B = node_score\n",
        "            node_score_emb = self.activation(self.emb_score(B)) #[batch_size, n_node, dim/2]\n",
        "        elif self.basis_f == 'linact':\n",
        "            B = self.activation(self.B_lin(node_score)) #[batch_size, n_node, dim/2]\n",
        "            node_score_emb = self.activation(self.emb_score(B)) #[batch_size, n_node, dim/2]\n",
        "\n",
        "\n",
        "        X = H\n",
        "        edge_index, edge_type = A #edge_index: [2, total_E]   edge_type: [total_E, ]  where total_E is for the batched graph\n",
        "        _X = X.view(-1, X.size(2)).contiguous() #[`total_n_nodes`, d_node] where `total_n_nodes` = b_size * n_node\n",
        "        _node_type = node_type.view(-1).contiguous() #[`total_n_nodes`, ]\n",
        "        _node_feature_extra = torch.cat([node_type_emb, node_score_emb], dim=2).view(_node_type.size(0), -1).contiguous() #[`total_n_nodes`, dim]\n",
        "\n",
        "        _X = self.mp_helper(_X, edge_index, edge_type, _node_type, _node_feature_extra)\n",
        "\n",
        "        X = _X.view(node_type.size(0), node_type.size(1), -1) #[batch_size, n_node, dim]\n",
        "\n",
        "        output = self.activation(self.Vh(H) + self.Vx(X))\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "class QAGNN(nn.Module):\n",
        "    def __init__(self, args, k, n_ntype, n_etype, sent_dim,\n",
        "                 n_concept, concept_dim, concept_in_dim, n_attention_head,\n",
        "                 fc_dim, n_fc_layer, p_emb, p_gnn, p_fc,\n",
        "                 pretrained_concept_emb=None, freeze_ent_emb=True,\n",
        "                 init_range=0.02):\n",
        "        super().__init__()\n",
        "        self.init_range = init_range\n",
        "\n",
        "        self.concept_emb = CustomizedEmbedding(concept_num=n_concept, concept_out_dim=concept_dim,\n",
        "                                               use_contextualized=False, concept_in_dim=concept_in_dim,\n",
        "                                               pretrained_concept_emb=pretrained_concept_emb, freeze_ent_emb=freeze_ent_emb)\n",
        "        self.svec2nvec = nn.Linear(sent_dim, concept_dim)\n",
        "\n",
        "        self.concept_dim = concept_dim\n",
        "\n",
        "        self.activation = GELU()\n",
        "\n",
        "        self.gnn = QAGNN_Message_Passing(args, k=k, n_ntype=n_ntype, n_etype=n_etype,\n",
        "                                        input_size=concept_dim, hidden_size=concept_dim, output_size=concept_dim, dropout=p_gnn)\n",
        "\n",
        "        self.pooler = MultiheadAttPoolLayer(n_attention_head, sent_dim, concept_dim)\n",
        "\n",
        "        self.fc = MLP(concept_dim + sent_dim + concept_dim, fc_dim, 1, n_fc_layer, p_fc, layer_norm=True)\n",
        "\n",
        "        self.dropout_e = nn.Dropout(p_emb)\n",
        "        self.dropout_fc = nn.Dropout(p_fc)\n",
        "\n",
        "        if init_range > 0:\n",
        "            self.apply(self._init_weights)\n",
        "\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.init_range)\n",
        "            if hasattr(module, 'bias') and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "\n",
        "    def forward(self, sent_vecs, concept_ids, node_type_ids, node_scores, adj_lengths, adj, emb_data=None, cache_output=False):\n",
        "        \"\"\"\n",
        "        sent_vecs: (batch_size, dim_sent)\n",
        "        concept_ids: (batch_size, n_node)\n",
        "        adj: edge_index, edge_type\n",
        "        adj_lengths: (batch_size,)\n",
        "        node_type_ids: (batch_size, n_node)\n",
        "            0 == question entity; 1 == answer choice entity; 2 == other node; 3 == context node\n",
        "        node_scores: (batch_size, n_node, 1)\n",
        "\n",
        "        returns: (batch_size, 1)\n",
        "        \"\"\"\n",
        "        gnn_input0 = self.activation(self.svec2nvec(sent_vecs)).unsqueeze(1) #(batch_size, 1, dim_node)\n",
        "        gnn_input1 = self.concept_emb(concept_ids[:, 1:]-1, emb_data) #(batch_size, n_node-1, dim_node)\n",
        "        gnn_input1 = gnn_input1.to(node_type_ids.device)\n",
        "        gnn_input = self.dropout_e(torch.cat([gnn_input0, gnn_input1], dim=1)) #(batch_size, n_node, dim_node)\n",
        "\n",
        "\n",
        "        #Normalize node score (use norm from Z)\n",
        "        _mask = (torch.arange(node_scores.size(1), device=node_scores.device) < adj_lengths.unsqueeze(1)).float() #0 means masked out #[batch_size, n_node]\n",
        "        node_scores = -node_scores\n",
        "        node_scores = node_scores - node_scores[:, 0:1, :] #[batch_size, n_node, 1]\n",
        "        node_scores = node_scores.squeeze(2) #[batch_size, n_node]\n",
        "        node_scores = node_scores * _mask\n",
        "        mean_norm  = (torch.abs(node_scores)).sum(dim=1) / adj_lengths  #[batch_size, ]\n",
        "        node_scores = node_scores / (mean_norm.unsqueeze(1) + 1e-05) #[batch_size, n_node]\n",
        "        node_scores = node_scores.unsqueeze(2) #[batch_size, n_node, 1]\n",
        "\n",
        "\n",
        "        gnn_output = self.gnn(gnn_input, adj, node_type_ids, node_scores)\n",
        "\n",
        "        Z_vecs = gnn_output[:,0]   #(batch_size, dim_node)\n",
        "\n",
        "        mask = torch.arange(node_type_ids.size(1), device=node_type_ids.device) >= adj_lengths.unsqueeze(1) #1 means masked out\n",
        "\n",
        "        mask = mask | (node_type_ids == 3) #pool over all KG nodes\n",
        "        mask[mask.all(1), 0] = 0  # a temporary solution to avoid zero node\n",
        "\n",
        "        sent_vecs_for_pooler = sent_vecs\n",
        "        graph_vecs, pool_attn = self.pooler(sent_vecs_for_pooler, gnn_output, mask)\n",
        "\n",
        "        if cache_output:\n",
        "            self.concept_ids = concept_ids\n",
        "            self.adj = adj\n",
        "            self.pool_attn = pool_attn\n",
        "\n",
        "        concat = self.dropout_fc(torch.cat((graph_vecs, sent_vecs, Z_vecs), 1))\n",
        "        logits = self.fc(concat)\n",
        "        return logits, pool_attn\n",
        "\n",
        "\n",
        "class LM_QAGNN(nn.Module):\n",
        "    def __init__(self, args, model_name, k, n_ntype, n_etype,\n",
        "                 n_concept, concept_dim, concept_in_dim, n_attention_head,\n",
        "                 fc_dim, n_fc_layer, p_emb, p_gnn, p_fc,\n",
        "                 pretrained_concept_emb=None, freeze_ent_emb=True,\n",
        "                 init_range=0.0, encoder_config={}):\n",
        "        super().__init__()\n",
        "        self.encoder = TextEncoder(model_name, **encoder_config)\n",
        "        self.decoder = QAGNN(args, k, n_ntype, n_etype, self.encoder.sent_dim,\n",
        "                                        n_concept, concept_dim, concept_in_dim, n_attention_head,\n",
        "                                        fc_dim, n_fc_layer, p_emb, p_gnn, p_fc,\n",
        "                                        pretrained_concept_emb=pretrained_concept_emb, freeze_ent_emb=freeze_ent_emb,\n",
        "                                        init_range=init_range)\n",
        "\n",
        "\n",
        "    def forward(self, *inputs, layer_id=-1, cache_output=False, detail=False):\n",
        "        \"\"\"\n",
        "        sent_vecs: (batch_size, num_choice, d_sent)    -> (batch_size * num_choice, d_sent)\n",
        "        concept_ids: (batch_size, num_choice, n_node)  -> (batch_size * num_choice, n_node)\n",
        "        node_type_ids: (batch_size, num_choice, n_node) -> (batch_size * num_choice, n_node)\n",
        "        adj_lengths: (batch_size, num_choice)          -> (batch_size * num_choice, )\n",
        "        adj -> edge_index, edge_type\n",
        "            edge_index: list of (batch_size, num_choice) -> list of (batch_size * num_choice, ); each entry is torch.tensor(2, E(variable))\n",
        "                                                         -> (2, total E)\n",
        "            edge_type:  list of (batch_size, num_choice) -> list of (batch_size * num_choice, ); each entry is torch.tensor(E(variable), )\n",
        "                                                         -> (total E, )\n",
        "        returns: (batch_size, 1)\n",
        "        \"\"\"\n",
        "        bs, nc = inputs[0].size(0), inputs[0].size(1)\n",
        "\n",
        "        #Here, merge the batch dimension and the num_choice dimension\n",
        "        edge_index_orig, edge_type_orig = inputs[-2:]\n",
        "        _inputs = [x.view(x.size(0) * x.size(1), *x.size()[2:]) for x in inputs[:-6]] + [x.view(x.size(0) * x.size(1), *x.size()[2:]) for x in inputs[-6:-2]] + [sum(x,[]) for x in inputs[-2:]]\n",
        "\n",
        "        *lm_inputs, concept_ids, node_type_ids, node_scores, adj_lengths, edge_index, edge_type = _inputs\n",
        "        edge_index, edge_type = self.batch_graph(edge_index, edge_type, concept_ids.size(1))\n",
        "        adj = (edge_index.to(node_type_ids.device), edge_type.to(node_type_ids.device)) #edge_index: [2, total_E]   edge_type: [total_E, ]\n",
        "\n",
        "        sent_vecs, all_hidden_states = self.encoder(*lm_inputs, layer_id=layer_id)\n",
        "        logits, attn = self.decoder(sent_vecs.to(node_type_ids.device),\n",
        "                                    concept_ids,\n",
        "                                    node_type_ids, node_scores, adj_lengths, adj,\n",
        "                                    emb_data=None, cache_output=cache_output)\n",
        "        logits = logits.view(bs, nc)\n",
        "        if not detail:\n",
        "            return logits, attn\n",
        "        else:\n",
        "            return logits, attn, concept_ids.view(bs, nc, -1), node_type_ids.view(bs, nc, -1), edge_index_orig, edge_type_orig\n",
        "            #edge_index_orig: list of (batch_size, num_choice). each entry is torch.tensor(2, E)\n",
        "            #edge_type_orig: list of (batch_size, num_choice). each entry is torch.tensor(E, )\n",
        "\n",
        "\n",
        "    def batch_graph(self, edge_index_init, edge_type_init, n_nodes):\n",
        "        #edge_index_init: list of (n_examples, ). each entry is torch.tensor(2, E)\n",
        "        #edge_type_init:  list of (n_examples, ). each entry is torch.tensor(E, )\n",
        "        n_examples = len(edge_index_init)\n",
        "        edge_index = [edge_index_init[_i_] + _i_ * n_nodes for _i_ in range(n_examples)]\n",
        "        edge_index = torch.cat(edge_index, dim=1) #[2, total_E]\n",
        "        edge_type = torch.cat(edge_type_init, dim=0) #[total_E, ]\n",
        "        return edge_index, edge_type\n",
        "\n",
        "\n",
        "\n",
        "class LM_QAGNN_DataLoader(object):\n",
        "    def __init__(self, args, train_statement_path, train_adj_path,\n",
        "                 dev_statement_path, dev_adj_path,\n",
        "                 test_statement_path, test_adj_path,\n",
        "                 batch_size, eval_batch_size, device, model_name, max_node_num=200, max_seq_length=128,\n",
        "                 is_inhouse=False, inhouse_train_qids_path=None,\n",
        "                 subsample=1.0, use_cache=True):\n",
        "        super().__init__()\n",
        "        self.args = args\n",
        "        self.batch_size = batch_size\n",
        "        self.eval_batch_size = eval_batch_size\n",
        "        self.device0, self.device1 = device\n",
        "        self.is_inhouse = is_inhouse\n",
        "\n",
        "        model_type = MODEL_NAME_TO_CLASS[model_name]\n",
        "        print('train_statement_path', train_statement_path)\n",
        "\n",
        "        self.train_qids, self.train_labels, *self.train_encoder_data = load_input_tensors(train_statement_path, model_type, model_name, max_seq_length)\n",
        "        self.dev_qids, self.dev_labels, *self.dev_encoder_data = load_input_tensors(dev_statement_path, model_type, model_name, max_seq_length)\n",
        "\n",
        "        num_choice = self.train_encoder_data[0].size(1)\n",
        "        self.num_choice = num_choice\n",
        "        print ('num_choice', num_choice)\n",
        "\n",
        "        *self.train_decoder_data, self.train_adj_data = load_sparse_adj_data_with_contextnode(train_adj_path, max_node_num, num_choice, args)\n",
        "        *self.dev_decoder_data, self.dev_adj_data = load_sparse_adj_data_with_contextnode(dev_adj_path, max_node_num, num_choice, args)\n",
        "\n",
        "        assert all(len(self.train_qids) == len(self.train_adj_data[0]) == x.size(0) for x in [self.train_labels] + self.train_encoder_data + self.train_decoder_data)\n",
        "        assert all(len(self.dev_qids) == len(self.dev_adj_data[0]) == x.size(0) for x in [self.dev_labels] + self.dev_encoder_data + self.dev_decoder_data)\n",
        "\n",
        "        if test_statement_path is not None:\n",
        "            self.test_qids, self.test_labels, *self.test_encoder_data = load_input_tensors(test_statement_path, model_type, model_name, max_seq_length)\n",
        "            *self.test_decoder_data, self.test_adj_data = load_sparse_adj_data_with_contextnode(test_adj_path, max_node_num, num_choice, args)\n",
        "            assert all(len(self.test_qids) == len(self.test_adj_data[0]) == x.size(0) for x in [self.test_labels] + self.test_encoder_data + self.test_decoder_data)\n",
        "\n",
        "\n",
        "        if self.is_inhouse:\n",
        "            with open(inhouse_train_qids_path, 'r') as fin:\n",
        "                inhouse_qids = set(line.strip() for line in fin)\n",
        "            self.inhouse_train_indexes = torch.tensor([i for i, qid in enumerate(self.train_qids) if qid in inhouse_qids])\n",
        "            self.inhouse_test_indexes = torch.tensor([i for i, qid in enumerate(self.train_qids) if qid not in inhouse_qids])\n",
        "\n",
        "        assert 0. < subsample <= 1.\n",
        "        if subsample < 1.:\n",
        "            n_train = int(self.train_size() * subsample)\n",
        "            assert n_train > 0\n",
        "            if self.is_inhouse:\n",
        "                self.inhouse_train_indexes = self.inhouse_train_indexes[:n_train]\n",
        "            else:\n",
        "                self.train_qids = self.train_qids[:n_train]\n",
        "                self.train_labels = self.train_labels[:n_train]\n",
        "                self.train_encoder_data = [x[:n_train] for x in self.train_encoder_data]\n",
        "                self.train_decoder_data = [x[:n_train] for x in self.train_decoder_data]\n",
        "                self.train_adj_data = self.train_adj_data[:n_train]\n",
        "                assert all(len(self.train_qids) == len(self.train_adj_data[0]) == x.size(0) for x in [self.train_labels] + self.train_encoder_data + self.train_decoder_data)\n",
        "            assert self.train_size() == n_train\n",
        "\n",
        "    def train_size(self):\n",
        "        return self.inhouse_train_indexes.size(0) if self.is_inhouse else len(self.train_qids)\n",
        "\n",
        "    def dev_size(self):\n",
        "        return len(self.dev_qids)\n",
        "\n",
        "    def test_size(self):\n",
        "        if self.is_inhouse:\n",
        "            return self.inhouse_test_indexes.size(0)\n",
        "        else:\n",
        "            return len(self.test_qids) if hasattr(self, 'test_qids') else 0\n",
        "\n",
        "    def train(self):\n",
        "        if self.is_inhouse:\n",
        "            n_train = self.inhouse_train_indexes.size(0)\n",
        "            train_indexes = self.inhouse_train_indexes[torch.randperm(n_train)]\n",
        "        else:\n",
        "            train_indexes = torch.randperm(len(self.train_qids))\n",
        "        return MultiGPUSparseAdjDataBatchGenerator(self.args, 'train', self.device0, self.device1, self.batch_size, train_indexes, self.train_qids, self.train_labels, tensors0=self.train_encoder_data, tensors1=self.train_decoder_data, adj_data=self.train_adj_data)\n",
        "\n",
        "    def train_eval(self):\n",
        "        return MultiGPUSparseAdjDataBatchGenerator(self.args, 'eval', self.device0, self.device1, self.eval_batch_size, torch.arange(len(self.train_qids)), self.train_qids, self.train_labels, tensors0=self.train_encoder_data, tensors1=self.train_decoder_data, adj_data=self.train_adj_data)\n",
        "\n",
        "    def dev(self):\n",
        "        return MultiGPUSparseAdjDataBatchGenerator(self.args, 'eval', self.device0, self.device1, self.eval_batch_size, torch.arange(len(self.dev_qids)), self.dev_qids, self.dev_labels, tensors0=self.dev_encoder_data, tensors1=self.dev_decoder_data, adj_data=self.dev_adj_data)\n",
        "\n",
        "    def test(self):\n",
        "        if self.is_inhouse:\n",
        "            return MultiGPUSparseAdjDataBatchGenerator(self.args, 'eval', self.device0, self.device1, self.eval_batch_size, self.inhouse_test_indexes, self.train_qids, self.train_labels, tensors0=self.train_encoder_data, tensors1=self.train_decoder_data, adj_data=self.train_adj_data)\n",
        "        else:\n",
        "            return MultiGPUSparseAdjDataBatchGenerator(self.args, 'eval', self.device0, self.device1, self.eval_batch_size, torch.arange(len(self.test_qids)), self.test_qids, self.test_labels, tensors0=self.test_encoder_data, tensors1=self.test_decoder_data, adj_data=self.test_adj_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "############################### GNN architecture ##############################\n",
        "###############################################################################\n",
        "\n",
        "from torch.autograd import Variable\n",
        "def make_one_hot(labels, C):\n",
        "    '''\n",
        "    Converts an integer label torch.autograd.Variable to a one-hot Variable.\n",
        "    labels : torch.autograd.Variable of torch.cuda.LongTensor\n",
        "        (N, ), where N is batch size.\n",
        "        Each value is an integer representing correct classification.\n",
        "    C : integer.\n",
        "        number of classes in labels.\n",
        "    Returns : torch.autograd.Variable of torch.cuda.FloatTensor\n",
        "        N x C, where C is class number. One-hot encoded.\n",
        "    '''\n",
        "    labels = labels.unsqueeze(1)\n",
        "    one_hot = torch.FloatTensor(labels.size(0), C).zero_().to(labels.device)\n",
        "    target = one_hot.scatter_(1, labels.data, 1)\n",
        "    target = Variable(target)\n",
        "    return target\n",
        "\n",
        "\n",
        "\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree, softmax\n",
        "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool, GlobalAttention, Set2Set\n",
        "import torch.nn.functional as F\n",
        "from torch_scatter import scatter_add, scatter\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "\n",
        "\n",
        "\n",
        "class GATConvE(MessagePassing):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        emb_dim (int): dimensionality of GNN hidden states\n",
        "        n_ntype (int): number of node types (e.g. 4)\n",
        "        n_etype (int): number of edge relation types (e.g. 38)\n",
        "    \"\"\"\n",
        "    def __init__(self, args, emb_dim, n_ntype, n_etype, edge_encoder, head_count=4, aggr=\"add\"):\n",
        "        super(GATConvE, self).__init__(aggr=aggr)\n",
        "        self.args = args\n",
        "\n",
        "        assert emb_dim % 2 == 0\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.n_ntype = n_ntype; self.n_etype = n_etype\n",
        "        self.edge_encoder = edge_encoder\n",
        "\n",
        "        #For attention\n",
        "        self.head_count = head_count\n",
        "        assert emb_dim % head_count == 0\n",
        "        self.dim_per_head = emb_dim // head_count\n",
        "        self.linear_key = nn.Linear(3*emb_dim, head_count * self.dim_per_head)\n",
        "        self.linear_msg = nn.Linear(3*emb_dim, head_count * self.dim_per_head)\n",
        "        self.linear_query = nn.Linear(2*emb_dim, head_count * self.dim_per_head)\n",
        "\n",
        "        self._alpha = None\n",
        "\n",
        "        #For final MLP\n",
        "        self.mlp = torch.nn.Sequential(torch.nn.Linear(emb_dim, emb_dim), torch.nn.BatchNorm1d(emb_dim), torch.nn.ReLU(), torch.nn.Linear(emb_dim, emb_dim))\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, edge_type, node_type, node_feature_extra, return_attention_weights=False):\n",
        "        # x: [N, emb_dim]\n",
        "        # edge_index: [2, E]\n",
        "        # edge_type [E,] -> edge_attr: [E, 39] / self_edge_attr: [N, 39]\n",
        "        # node_type [N,] -> headtail_attr [E, 8(=4+4)] / self_headtail_attr: [N, 8]\n",
        "        # node_feature_extra [N, dim]\n",
        "\n",
        "        #Prepare edge feature\n",
        "        edge_vec = make_one_hot(edge_type, self.n_etype +1) #[E, 39]\n",
        "        self_edge_vec = torch.zeros(x.size(0), self.n_etype +1).to(edge_vec.device)\n",
        "        self_edge_vec[:,self.n_etype] = 1\n",
        "\n",
        "        head_type = node_type[edge_index[0]] #[E,] #head=src\n",
        "        tail_type = node_type[edge_index[1]] #[E,] #tail=tgt\n",
        "        head_vec = make_one_hot(head_type, self.n_ntype) #[E,4]\n",
        "        tail_vec = make_one_hot(tail_type, self.n_ntype) #[E,4]\n",
        "        headtail_vec = torch.cat([head_vec, tail_vec], dim=1) #[E,8]\n",
        "        self_head_vec = make_one_hot(node_type, self.n_ntype) #[N,4]\n",
        "        self_headtail_vec = torch.cat([self_head_vec, self_head_vec], dim=1) #[N,8]\n",
        "\n",
        "        edge_vec = torch.cat([edge_vec, self_edge_vec], dim=0) #[E+N, ?]\n",
        "        headtail_vec = torch.cat([headtail_vec, self_headtail_vec], dim=0) #[E+N, ?]\n",
        "        edge_embeddings = self.edge_encoder(torch.cat([edge_vec, headtail_vec], dim=1)) #[E+N, emb_dim]\n",
        "\n",
        "        #Add self loops to edge_index\n",
        "        loop_index = torch.arange(0, x.size(0), dtype=torch.long, device=edge_index.device)\n",
        "        loop_index = loop_index.unsqueeze(0).repeat(2, 1)\n",
        "        edge_index = torch.cat([edge_index, loop_index], dim=1)  #[2, E+N]\n",
        "\n",
        "        x = torch.cat([x, node_feature_extra], dim=1)\n",
        "        x = (x, x)\n",
        "        aggr_out = self.propagate(edge_index, x=x, edge_attr=edge_embeddings) #[N, emb_dim]\n",
        "        out = self.mlp(aggr_out)\n",
        "\n",
        "        alpha = self._alpha\n",
        "        self._alpha = None\n",
        "\n",
        "        if return_attention_weights:\n",
        "            assert alpha is not None\n",
        "            return out, (edge_index, alpha)\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "\n",
        "    def message(self, edge_index, x_i, x_j, edge_attr): #i: tgt, j:src\n",
        "        # print (\"edge_attr.size()\", edge_attr.size()) #[E, emb_dim]\n",
        "        # print (\"x_j.size()\", x_j.size()) #[E, emb_dim]\n",
        "        # print (\"x_i.size()\", x_i.size()) #[E, emb_dim]\n",
        "        assert len(edge_attr.size()) == 2\n",
        "        assert edge_attr.size(1) == self.emb_dim\n",
        "        assert x_i.size(1) == x_j.size(1) == 2*self.emb_dim\n",
        "        assert x_i.size(0) == x_j.size(0) == edge_attr.size(0) == edge_index.size(1)\n",
        "\n",
        "        key   = self.linear_key(torch.cat([x_i, edge_attr], dim=1)).view(-1, self.head_count, self.dim_per_head) #[E, heads, _dim]\n",
        "        msg = self.linear_msg(torch.cat([x_j, edge_attr], dim=1)).view(-1, self.head_count, self.dim_per_head) #[E, heads, _dim]\n",
        "        query = self.linear_query(x_j).view(-1, self.head_count, self.dim_per_head) #[E, heads, _dim]\n",
        "\n",
        "\n",
        "        query = query / math.sqrt(self.dim_per_head)\n",
        "        scores = (query * key).sum(dim=2) #[E, heads]\n",
        "        src_node_index = edge_index[0] #[E,]\n",
        "        alpha = softmax(scores, src_node_index) #[E, heads] #group by src side node\n",
        "        self._alpha = alpha\n",
        "\n",
        "        #adjust by outgoing degree of src\n",
        "        E = edge_index.size(1)            #n_edges\n",
        "        N = int(src_node_index.max()) + 1 #n_nodes\n",
        "        ones = torch.full((E,), 1.0, dtype=torch.float).to(edge_index.device)\n",
        "        src_node_edge_count = scatter(ones, src_node_index, dim=0, dim_size=N, reduce='sum')[src_node_index] #[E,]\n",
        "        assert len(src_node_edge_count.size()) == 1 and len(src_node_edge_count) == E\n",
        "        alpha = alpha * src_node_edge_count.unsqueeze(1) #[E, heads]\n",
        "\n",
        "        out = msg * alpha.view(-1, self.head_count, 1) #[E, heads, _dim]\n",
        "        return out.view(-1, self.head_count * self.dim_per_head)  #[E, emb_dim]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvKvsTHxVobU"
      },
      "source": [
        "####from utils.optimization_utils import OPTIMIZER_CLASSES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qKR2dn6iVpi0"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from transformers import AdamW\n",
        "from torch.optim import SGD, Adam\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "\n",
        "class RAdam(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "\n",
        "        self.degenerated_to_sgd = degenerated_to_sgd\n",
        "        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n",
        "            for param in params:\n",
        "                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n",
        "                    param['buffer'] = [[None, None, None] for _ in range(10)]\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, buffer=[[None, None, None] for _ in range(10)])\n",
        "        super(RAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(RAdam, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = group['buffer'][int(state['step'] % 10)]\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, step_size = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    elif self.degenerated_to_sgd:\n",
        "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        step_size = -1\n",
        "                    buffered[2] = step_size\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:\n",
        "                    if group['weight_decay'] != 0:\n",
        "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
        "                    p.data.copy_(p_data_fp32)\n",
        "                elif step_size > 0:\n",
        "                    if group['weight_decay'] != 0:\n",
        "                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
        "                    p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "OPTIMIZER_CLASSES = {\n",
        "    'sgd': SGD,\n",
        "    'adam': Adam,\n",
        "    'adamw': AdamW,\n",
        "    'radam': RAdam,\n",
        "}\n",
        "\n",
        "\n",
        "# def run_test():\n",
        "#     import torch.nn as nn\n",
        "#     model = nn.Sequential(*[nn.Linear(100, 10), nn.ReLU(), nn.Linear(10, 2)])\n",
        "#     x = torch.randn(10, 100).repeat(100, 1)\n",
        "#     y = torch.randint(0, 2, (10,)).repeat(100)\n",
        "#     crit = nn.CrossEntropyLoss()\n",
        "#     optim = RAdam(model.parameters(), lr=1e-2, weight_decay=0.01)\n",
        "#     model.train()\n",
        "#     for a in range(0, 1000, 10):\n",
        "#         b = a + 10\n",
        "#         loss = crit(model(x[a:b]), y[a:b])\n",
        "#         loss.backward()\n",
        "#         optim.step()\n",
        "#         print('| loss: {:.4f} |'.format(loss.item()))\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     run_test()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeVNdraXVya7"
      },
      "source": [
        "####from utils.parser_utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "O1phlcuYV2YT"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "# from utils.utils import *\n",
        "# from modeling.modeling_encoder import MODEL_NAME_TO_CLASS\n",
        "\n",
        "ENCODER_DEFAULT_LR = {\n",
        "    'default': 1e-3,\n",
        "    'csqa': {\n",
        "        'lstm': 3e-4,\n",
        "        'openai-gpt': 1e-4,\n",
        "        'bert-base-uncased': 3e-5,\n",
        "        'bert-large-uncased': 2e-5,\n",
        "        'roberta-large': 1e-5,\n",
        "    },\n",
        "    'obqa': {\n",
        "        'lstm': 3e-4,\n",
        "        'openai-gpt': 3e-5,\n",
        "        'bert-base-cased': 1e-4,\n",
        "        'bert-large-cased': 1e-4,\n",
        "        'roberta-large': 1e-5,\n",
        "    },\n",
        "    'medqa_usmle': {\n",
        "        'cambridgeltl/SapBERT-from-PubMedBERT-fulltext': 5e-5,\n",
        "    },\n",
        "}\n",
        "\n",
        "DATASET_LIST = ['csqa', 'obqa', 'socialiqa', 'medqa_usmle']\n",
        "\n",
        "DATASET_SETTING = {\n",
        "    'csqa': 'inhouse',\n",
        "    'obqa': 'official',\n",
        "    'socialiqa': 'official',\n",
        "    'medqa_usmle': 'official',\n",
        "}\n",
        "\n",
        "DATASET_NO_TEST = ['socialiqa']\n",
        "\n",
        "EMB_PATHS = {\n",
        "    'transe': 'data/transe/glove.transe.sgd.ent.npy',\n",
        "    'lm': 'data/transe/glove.transe.sgd.ent.npy',\n",
        "    'numberbatch': 'data/transe/concept.nb.npy',\n",
        "    'tzw': 'data/cpnet/tzw.ent.npy',\n",
        "    'ddb': 'data/ddb/ent_emb.npy',\n",
        "}\n",
        "\n",
        "\n",
        "# def add_data_arguments(parser):\n",
        "#     # arguments that all datasets share\n",
        "#     parser.add_argument('--ent_emb', default=['tzw'], nargs='+', help='sources for entity embeddings')\n",
        "#     # dataset specific\n",
        "#     parser.add_argument('-ds', '--dataset', default='csqa', choices=DATASET_LIST, help='dataset name')\n",
        "#     parser.add_argument('-ih', '--inhouse', type=bool_flag, nargs='?', const=True, help='run in-house setting')\n",
        "#     parser.add_argument('--inhouse_train_qids', default='data/{dataset}/inhouse_split_qids.txt', help='qids of the in-house training set')\n",
        "#     # statements\n",
        "#     parser.add_argument('--train_statements', default='data/{dataset}/statement/train.statement.jsonl')\n",
        "#     parser.add_argument('--dev_statements', default='data/{dataset}/statement/dev.statement.jsonl')\n",
        "#     parser.add_argument('--test_statements', default='data/{dataset}/statement/test.statement.jsonl')\n",
        "#     # preprocessing options\n",
        "#     parser.add_argument('-sl', '--max_seq_len', default=100, type=int)\n",
        "#     # set dataset defaults\n",
        "#     args, _ = parser.parse_known_args()\n",
        "#     parser.set_defaults(ent_emb_paths=[EMB_PATHS.get(s) for s in args[\"ent_emb\"]],\n",
        "#                         inhouse=(DATASET_SETTING[args[\"dataset\"]] == 'inhouse'),\n",
        "#                         inhouse_train_qids=args[\"inhouse_train_qids\"].format(dataset=args[\"dataset\"]))\n",
        "#     data_splits = ('train', 'dev') if args[\"dataset\"] in DATASET_NO_TEST else ('train', 'dev', 'test')\n",
        "#     for split in data_splits:\n",
        "#         for attribute in ('statements',):\n",
        "#             attr_name = f'{split}_{attribute}'\n",
        "#             parser.set_defaults(**{attr_name: getattr(args, attr_name).format(dataset=args[\"dataset\"])})\n",
        "#     if 'test' not in data_splits:\n",
        "#         parser.set_defaults(test_statements=None)\n",
        "\n",
        "\n",
        "# def add_encoder_arguments(parser):\n",
        "#     parser.add_argument('-enc', '--encoder', default='bert-large-uncased', help='encoder type')\n",
        "#     parser.add_argument('--encoder_layer', default=-1, type=int, help='encoder layer ID to use as features (used only by non-LSTM encoders)')\n",
        "#     parser.add_argument('-elr', '--encoder_lr', default=2e-5, type=float, help='learning rate')\n",
        "#     args, _ = parser.parse_known_args()\n",
        "#     parser.set_defaults(encoder_lr=ENCODER_DEFAULT_LR[args[\"dataset\"]].get(args[\"encoder\"], ENCODER_DEFAULT_LR['default']))\n",
        "\n",
        "\n",
        "# def add_optimization_arguments(parser):\n",
        "#     parser.add_argument('--loss', default='cross_entropy', choices=['margin_rank', 'cross_entropy'], help='model type')\n",
        "#     parser.add_argument('--optim', default='radam', choices=['sgd', 'adam', 'adamw', 'radam'], help='learning rate scheduler')\n",
        "#     parser.add_argument('--lr_schedule', default='fixed', choices=['fixed', 'warmup_linear', 'warmup_constant'], help='learning rate scheduler')\n",
        "#     parser.add_argument('-bs', '--batch_size', default=32, type=int)\n",
        "#     parser.add_argument('--warmup_steps', type=float, default=150)\n",
        "#     parser.add_argument('--max_grad_norm', default=1.0, type=float, help='max grad norm (0 to disable)')\n",
        "#     parser.add_argument('--weight_decay', default=1e-2, type=float, help='l2 weight decay strength')\n",
        "#     parser.add_argument('--n_epochs', default=100, type=int, help='total number of training epochs to perform.')\n",
        "#     parser.add_argument('-me', '--max_epochs_before_stop', default=10, type=int, help='stop training if dev does not increase for N epochs')\n",
        "\n",
        "\n",
        "# def add_additional_arguments(parser):\n",
        "#     parser.add_argument('--log_interval', default=10, type=int)\n",
        "#     parser.add_argument('--cuda', default=True, type=bool_flag, nargs='?', const=True, help='use GPU')\n",
        "#     parser.add_argument('--seed', default=0, type=int, help='random seed')\n",
        "#     parser.add_argument('--debug', default=False, type=bool_flag, nargs='?', const=True, help='run in debug mode')\n",
        "#     args, _ = parser.parse_known_args()\n",
        "#     if args[\"debug\"]:\n",
        "#         parser.set_defaults(batch_size=1, log_interval=1, eval_interval=5)\n",
        "\n",
        "\n",
        "# def get_parser():\n",
        "#     \"\"\"A helper function that handles the arguments that all models share\"\"\"\n",
        "#     parser = argparse.ArgumentParser(add_help=False)\n",
        "#     add_data_arguments(parser)\n",
        "#     add_encoder_arguments(parser)\n",
        "#     add_optimization_arguments(parser)\n",
        "#     add_additional_arguments(parser)\n",
        "#     return parser\n",
        "\n",
        "\n",
        "def get_lstm_config_from_args(args):\n",
        "    lstm_config = {\n",
        "        'hidden_size': args[\"encoder_dim\"],\n",
        "        'output_size': args[\"encoder_dim\"],\n",
        "        'num_layers': args[\"encoder_layer_num\"],\n",
        "        'bidirectional': args[\"encoder_bidir\"],\n",
        "        'emb_p': args[\"encoder_dropoute\"],\n",
        "        'input_p': args[\"encoder_dropouti\"],\n",
        "        'hidden_p': args[\"encoder_dropouth\"],\n",
        "        'pretrained_emb_or_path': args[\"encoder_pretrained_emb\"],\n",
        "        'freeze_emb': args[\"encoder_freeze_emb\"],\n",
        "        'pool_function': args[\"encoder_pooler\"],\n",
        "    }\n",
        "    return lstm_config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmQq-Ig_UXMw"
      },
      "source": [
        "###main func."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlUcnVkoAFp1",
        "outputId": "797512bb-b080-4a4f-949b-3d5283f5edfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96c4552eff2c\n",
            "pid: 2005\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "try:\n",
        "    from transformers import (ConstantLRSchedule, WarmupLinearSchedule, WarmupConstantSchedule)\n",
        "except:\n",
        "    from transformers import get_constant_schedule, get_constant_schedule_with_warmup,  get_linear_schedule_with_warmup\n",
        "\n",
        "# from modeling.modeling_qagnn import *\n",
        "# from utils.optimization_utils import OPTIMIZER_CLASSES\n",
        "# from utils.parser_utils import *\n",
        "\n",
        "\n",
        "DECODER_DEFAULT_LR = {\n",
        "    'csqa': 1e-3,\n",
        "    'brain_teaser_ds': 1e-3,\n",
        "    'obqa': 3e-4,\n",
        "    'medqa_usmle': 1e-3,\n",
        "}\n",
        "\n",
        "from collections import defaultdict, OrderedDict\n",
        "import numpy as np\n",
        "import socket, os, subprocess, datetime\n",
        "\n",
        "print(socket.gethostname())\n",
        "print (\"pid:\", os.getpid())\n",
        "# print (\"conda env:\", os.environ['CONDA_DEFAULT_ENV'])\n",
        "# print (\"screen: %s\" % subprocess.check_output('echo $STY', shell=True).decode('utf'))\n",
        "# print (\"gpu: %s\" % subprocess.check_output('echo $CUDA_VISIBLE_DEVICES', shell=True).decode('utf'))\n",
        "\n",
        "\n",
        "def evaluate_accuracy(eval_set, model):\n",
        "    n_samples, n_correct = 0, 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for qids, labels, *input_data in tqdm(eval_set):\n",
        "            logits, _ = model(*input_data)\n",
        "            n_correct += (logits.argmax(1) == labels).sum().item()\n",
        "            n_samples += labels.size(0)\n",
        "    return n_correct / n_samples\n",
        "\n",
        "\n",
        "\n",
        "def train(args, global_step, best_dev_epoch, is_finetuning_on_new_ds):\n",
        "    print(args)\n",
        "\n",
        "    best_dev_acc=None\n",
        "    lower_epoch=None\n",
        "\n",
        "    random.seed(args[\"seed\"])\n",
        "    np.random.seed(args[\"seed\"])\n",
        "    torch.manual_seed(args[\"seed\"])\n",
        "    if torch.cuda.is_available() and args[\"cuda\"]:\n",
        "        torch.cuda.manual_seed(args[\"seed\"])\n",
        "\n",
        "    config_path = os.path.join(args[\"log_save_dir\"], 'config.json')\n",
        "    log_path = os.path.join(args[\"log_save_dir\"], 'log.csv')\n",
        "    best_model_path = os.path.join(args[\"best_model_save_dir\"], 'model.pt')\n",
        "    checkpoint_path = os.path.join(args[\"checkpoint_save_dir\"], 'model.pt')\n",
        "    export_config(args, config_path)\n",
        "    check_path(best_model_path)\n",
        "    check_path(checkpoint_path)\n",
        "    check_path(log_path)\n",
        "    with open(log_path, 'w') as fout:\n",
        "        fout.write('step,dev_acc,test_acc\\n')\n",
        "\n",
        "    ###################################################################################################\n",
        "    #   Load data                                                                                     #\n",
        "    ###################################################################################################\n",
        "    cp_emb = [np.load(path) for path in args[\"ent_emb_paths\"]]\n",
        "    cp_emb = torch.tensor(np.concatenate(cp_emb, 1), dtype=torch.float)\n",
        "\n",
        "    concept_num, concept_dim = cp_emb.size(0), cp_emb.size(1)\n",
        "    print('| num_concepts: {} |'.format(concept_num))\n",
        "    print('| concept_dim: {} |'.format(concept_dim))\n",
        "\n",
        "    # try:\n",
        "    if True:\n",
        "        if torch.cuda.device_count() >= 2 and args[\"cuda\"]:\n",
        "            device0 = torch.device(\"cuda:0\")\n",
        "            device1 = torch.device(\"cuda:1\")\n",
        "        elif torch.cuda.device_count() == 1 and args[\"cuda\"]:\n",
        "            device0 = torch.device(\"cuda:0\")\n",
        "            device1 = torch.device(\"cuda:0\")\n",
        "        else:\n",
        "            device0 = torch.device(\"cpu\")\n",
        "            device1 = torch.device(\"cpu\")\n",
        "        dataset = LM_QAGNN_DataLoader(args, args[\"train_statements\"], args[\"train_adj\"],\n",
        "                                               args[\"dev_statements\"], args[\"dev_adj\"],\n",
        "                                               args[\"test_statements\"], args[\"test_adj\"],\n",
        "                                               batch_size=args[\"batch_size\"], eval_batch_size=args[\"eval_batch_size\"],\n",
        "                                               device=(device0, device1),\n",
        "                                               model_name=args[\"encoder\"],\n",
        "                                               max_node_num=args[\"max_node_num\"], max_seq_length=args[\"max_seq_len\"],\n",
        "                                               is_inhouse=args[\"inhouse\"], inhouse_train_qids_path=args[\"inhouse_train_qids\"],\n",
        "                                               subsample=args[\"subsample\"], use_cache=args[\"use_cache\"])\n",
        "\n",
        "        #!\n",
        "        # return dataset\n",
        "\n",
        "        ###################################################################################################\n",
        "        #   Build model                                                                                   #\n",
        "        ###################################################################################################\n",
        "        print('args.num_relation', args[\"num_relation\"])\n",
        "        model = LM_QAGNN(args, args[\"encoder\"], k=args[\"k\"], n_ntype=4, n_etype=args[\"num_relation\"], n_concept=concept_num,\n",
        "                                   concept_dim=args[\"gnn_dim\"],\n",
        "                                   concept_in_dim=concept_dim,\n",
        "                                   n_attention_head=args[\"att_head_num\"], fc_dim=args[\"fc_dim\"], n_fc_layer=args[\"fc_layer_num\"],\n",
        "                                   p_emb=args[\"dropouti\"], p_gnn=args[\"dropoutg\"], p_fc=args[\"dropoutf\"],\n",
        "                                   pretrained_concept_emb=cp_emb, freeze_ent_emb=args[\"freeze_ent_emb\"],\n",
        "                                   init_range=args[\"init_range\"],\n",
        "                                   encoder_config={})\n",
        "\n",
        "        if args[\"load_model_path\"]:\n",
        "            print(f'loading and initializing model from {args[\"load_model_path\"]}')\n",
        "            # model_state_dict, old_args = torch.load(args[\"load_model_path\"], map_location=torch.device('cpu'))\n",
        "            # model.load_state_dict(model_state_dict)\n",
        "            checkpoint = torch.load(args[\"load_model_path\"], map_location=torch.device('cpu'))\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            best_dev_acc=checkpoint['best_dev_acc']\n",
        "            lower_epoch = checkpoint['epoch']+1\n",
        "\n",
        "            if is_finetuning_on_new_ds:\n",
        "              best_dev_acc=None\n",
        "              lower_epoch=None\n",
        "            print(f\"previous best_dev_acc: {best_dev_acc}\")\n",
        "            print(f\"current training epoch start from: {lower_epoch}\")\n",
        "\n",
        "        model.encoder.to(device0)\n",
        "        model.decoder.to(device1)\n",
        "\n",
        "\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "\n",
        "    grouped_parameters = [\n",
        "        {'params': [p for n, p in model.encoder.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args[\"weight_decay\"], 'lr': args[\"encoder_lr\"]},\n",
        "        {'params': [p for n, p in model.encoder.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0, 'lr': args[\"encoder_lr\"]},\n",
        "        {'params': [p for n, p in model.decoder.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args[\"weight_decay\"], 'lr': args[\"decoder_lr\"]},\n",
        "        {'params': [p for n, p in model.decoder.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0, 'lr': args[\"decoder_lr\"]},\n",
        "    ]\n",
        "\n",
        "    optimizer = OPTIMIZER_CLASSES[args[\"optim\"]](grouped_parameters)\n",
        "\n",
        "    if args[\"lr_schedule\"] == 'fixed':\n",
        "        try:\n",
        "            scheduler = ConstantLRSchedule(optimizer)\n",
        "        except:\n",
        "            scheduler = get_constant_schedule(optimizer)\n",
        "    elif args[\"lr_schedule\"] == 'warmup_constant':\n",
        "        try:\n",
        "            scheduler = WarmupConstantSchedule(optimizer, warmup_steps=args[\"warmup_steps\"])\n",
        "        except:\n",
        "            scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=args[\"warmup_steps\"])\n",
        "    elif args[\"lr_schedule\"] == 'warmup_linear':\n",
        "        max_steps = int(args[\"n_epochs\"] * (dataset.train_size() / args[\"batch_size\"]))\n",
        "        try:\n",
        "            scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args[\"warmup_steps\"], t_total=max_steps)\n",
        "        except:\n",
        "            scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args[\"warmup_steps\"], num_training_steps=max_steps)\n",
        "\n",
        "    print('parameters:')\n",
        "    for name, param in model.decoder.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print('\\t{:45}\\ttrainable\\t{}\\tdevice:{}'.format(name, param.size(), param.device))\n",
        "        else:\n",
        "            print('\\t{:45}\\tfixed\\t{}\\tdevice:{}'.format(name, param.size(), param.device))\n",
        "    num_params = sum(p.numel() for p in model.decoder.parameters() if p.requires_grad)\n",
        "    print('\\ttotal:', num_params)\n",
        "\n",
        "    if args[\"loss\"] == 'margin_rank':\n",
        "        loss_func = nn.MarginRankingLoss(margin=0.1, reduction='mean')\n",
        "    elif args[\"loss\"] == 'cross_entropy':\n",
        "        loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "    def compute_loss(logits, labels):\n",
        "        if args[\"loss\"] == 'margin_rank':\n",
        "            num_choice = logits.size(1)\n",
        "            flat_logits = logits.view(-1)\n",
        "            correct_mask = F.one_hot(labels, num_classes=num_choice).view(-1)  # of length batch_size*num_choice\n",
        "            correct_logits = flat_logits[correct_mask == 1].contiguous().view(-1, 1).expand(-1, num_choice - 1).contiguous().view(-1)  # of length batch_size*(num_choice-1)\n",
        "            wrong_logits = flat_logits[correct_mask == 0]\n",
        "            y = wrong_logits.new_ones((wrong_logits.size(0),))\n",
        "            loss = loss_func(correct_logits, wrong_logits, y)  # margin ranking loss\n",
        "        elif args[\"loss\"] == 'cross_entropy':\n",
        "            loss = loss_func(logits, labels)\n",
        "        return loss\n",
        "\n",
        "    ###################################################################################################\n",
        "    #   Training                                                                                      #\n",
        "    ###################################################################################################\n",
        "\n",
        "    print()\n",
        "    print('-' * 71)\n",
        "    if args[\"fp16\"]:\n",
        "        print ('Using fp16 training')\n",
        "        scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # global_step, best_dev_epoch = 0, 0\n",
        "\n",
        "    # best_dev_acc, final_test_acc, total_loss = 0.0, 0.0, 0.0\n",
        "\n",
        "    final_test_acc, total_loss = 0.0, 0.0\n",
        "\n",
        "    if best_dev_acc is None:\n",
        "      best_dev_acc=0.0\n",
        "\n",
        "    if lower_epoch==None:\n",
        "      lower_epoch=0\n",
        "    # if args['best_dev_acc']!=None:\n",
        "    #   best_dev_acc=args['best_dev_acc']\n",
        "    # else:\n",
        "    #   best_dev_acc=0.0\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    freeze_net(model.encoder)\n",
        "    if True:\n",
        "    # try:\n",
        "        for epoch_id in range(lower_epoch, args[\"n_epochs\"]):\n",
        "            print(f\"epoch: {epoch_id+1}/{args['n_epochs']}\")\n",
        "            if epoch_id == args[\"unfreeze_epoch\"]:\n",
        "                unfreeze_net(model.encoder)\n",
        "            if epoch_id == args[\"refreeze_epoch\"]:\n",
        "                freeze_net(model.encoder)\n",
        "            model.train()\n",
        "            for qids, labels, *input_data in dataset.train():\n",
        "                optimizer.zero_grad()\n",
        "                bs = labels.size(0)\n",
        "                for a in range(0, bs, args[\"mini_batch_size\"]):\n",
        "                    b = min(a + args[\"mini_batch_size\"], bs)\n",
        "                    if args[\"fp16\"]:\n",
        "                        with torch.cuda.amp.autocast():\n",
        "                            logits, _ = model(*[x[a:b] for x in input_data], layer_id=args[\"encoder_layer\"])\n",
        "                            loss = compute_loss(logits, labels[a:b])\n",
        "                    else:\n",
        "                        logits, _ = model(*[x[a:b] for x in input_data], layer_id=args[\"encoder_layer\"])\n",
        "                        loss = compute_loss(logits, labels[a:b])\n",
        "                    loss = loss * (b - a) / bs\n",
        "                    if args[\"fp16\"]:\n",
        "                        scaler.scale(loss).backward()\n",
        "                    else:\n",
        "                        loss.backward()\n",
        "                    total_loss += loss.item()\n",
        "                if args[\"max_grad_norm\"] > 0:\n",
        "                    if args[\"fp16\"]:\n",
        "                        scaler.unscale_(optimizer)\n",
        "                        nn.utils.clip_grad_norm_(model.parameters(), args[\"max_grad_norm\"])\n",
        "                    else:\n",
        "                        nn.utils.clip_grad_norm_(model.parameters(), args[\"max_grad_norm\"])\n",
        "                scheduler.step()\n",
        "                if args[\"fp16\"]:\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    optimizer.step()\n",
        "\n",
        "                if (global_step + 1) % args[\"log_interval\"] == 0:\n",
        "                    total_loss /= args[\"log_interval\"]\n",
        "                    ms_per_batch = 1000 * (time.time() - start_time) / args[\"log_interval\"]\n",
        "                    print('| step {:5} |  lr: {:9.7f} | loss {:7.4f} | ms/batch {:7.2f} |'.format(global_step, scheduler.get_lr()[0], total_loss, ms_per_batch))\n",
        "                    total_loss = 0\n",
        "                    start_time = time.time()\n",
        "                global_step += 1\n",
        "\n",
        "\n",
        "            \"\"\" Evaluation \"\"\"\n",
        "            model.eval()\n",
        "            dev_acc = evaluate_accuracy(dataset.dev(), model)\n",
        "            # save_test_preds = args[\"save_model\"]\n",
        "            save_test_preds = args[\"save_test_preds\"]\n",
        "            if not save_test_preds:\n",
        "                test_acc = evaluate_accuracy(dataset.test(), model) if args[\"test_statements\"] else 0.0\n",
        "            else:\n",
        "                eval_set = dataset.test()\n",
        "                total_acc = []\n",
        "                count = 0\n",
        "                preds_path = os.path.join(args[\"log_save_dir\"], 'test_e{}_preds.csv'.format(epoch_id))\n",
        "                with open(preds_path, 'w') as f_preds:\n",
        "                    with torch.no_grad():\n",
        "                        for qids, labels, *input_data in tqdm(eval_set):\n",
        "                            count += 1\n",
        "                            logits, _, concept_ids, node_type_ids, edge_index, edge_type = model(*input_data, detail=True)\n",
        "                            predictions = logits.argmax(1) #[bsize, ]\n",
        "                            preds_ranked = (-logits).argsort(1) #[bsize, n_choices]\n",
        "                            for i, (qid, label, pred, _preds_ranked, cids, ntype, edges, etype) in enumerate(zip(qids, labels, predictions, preds_ranked, concept_ids, node_type_ids, edge_index, edge_type)):\n",
        "                                acc = int(pred.item()==label.item())\n",
        "                                print ('{},{}'.format(qid, chr(ord('A') + pred.item())), file=f_preds)\n",
        "                                f_preds.flush()\n",
        "                                total_acc.append(acc)\n",
        "                test_acc = float(sum(total_acc))/len(total_acc)\n",
        "\n",
        "            print('-' * 71)\n",
        "            print('| epoch {:3} | step {:5} | dev_acc {:7.4f} | test_acc {:7.4f} |'.format(epoch_id, global_step, dev_acc, test_acc))\n",
        "            print('-' * 71)\n",
        "            with open(log_path, 'a') as fout:\n",
        "                fout.write('{},{},{}\\n'.format(global_step, dev_acc, test_acc))\n",
        "            if dev_acc >= best_dev_acc:\n",
        "                best_dev_acc = dev_acc\n",
        "                final_test_acc = test_acc\n",
        "                best_dev_epoch = epoch_id\n",
        "                if args[\"save_best_model\"]:\n",
        "                    # torch.save([model.state_dict(), args], f\"{model_path}.{epoch_id}.best_model\")\n",
        "                    torch.save({\n",
        "                          'epoch': epoch_id,\n",
        "                          'model_state_dict': model.state_dict(),\n",
        "                          'args':args,\n",
        "                          'best_dev_acc':best_dev_acc,\n",
        "                          'total_loss': total_loss,\n",
        "                          'global_step':global_step,\n",
        "                          }, f\"{best_model_path}.{epoch_id}.best_model\")\n",
        "                    # with open(model_path +\".{}.log.txt\".format(epoch_id), 'w') as f:\n",
        "                    #     for p in model.named_parameters():\n",
        "                    #         print (p, file=f)\n",
        "                    print(f'model saved to {best_model_path}.{epoch_id}.best_model')\n",
        "            else:\n",
        "                if args[\"save_checkpoint\"]:\n",
        "                    # torch.save([model.state_dict(), args], f\"{model_path}.{epoch_id}.temp_checkpoint\")\n",
        "                    torch.save({\n",
        "                          'epoch': epoch_id,\n",
        "                          'model_state_dict': model.state_dict(),\n",
        "                          'args':args,\n",
        "                          'best_dev_acc':best_dev_acc,\n",
        "                          'total_loss': total_loss,\n",
        "                          'global_step':global_step,\n",
        "                          }, f\"{checkpoint_path}.{epoch_id}.temp_checkpoint\")\n",
        "\n",
        "                    # with open(model_path +\".{}.log.txt\".format(epoch_id), 'w') as f:\n",
        "                    #     for p in model.named_parameters():\n",
        "                    #         print (p, file=f)\n",
        "\n",
        "\n",
        "                    print(f'model saved to {checkpoint_path}.{epoch_id}.temp_checkpoint')\n",
        "            model.train()\n",
        "            start_time = time.time()\n",
        "            if epoch_id > args[\"unfreeze_epoch\"] and epoch_id - best_dev_epoch >= args[\"max_epochs_before_stop\"]:\n",
        "                break\n",
        "    # except (KeyboardInterrupt, RuntimeError) as e:\n",
        "    #     print(e)\n",
        "\n",
        "\n",
        "\n",
        "def eval_detail(args):\n",
        "    assert args[\"load_model_path\"] is not None\n",
        "    model_path = args[\"load_model_path\"]\n",
        "\n",
        "    cp_emb = [np.load(path) for path in args[\"ent_emb_paths\"]]\n",
        "    cp_emb = torch.tensor(np.concatenate(cp_emb, 1), dtype=torch.float)\n",
        "    concept_num, concept_dim = cp_emb.size(0), cp_emb.size(1)\n",
        "    print('| num_concepts: {} |'.format(concept_num))\n",
        "\n",
        "    model_state_dict, old_args = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "    model = LM_QAGNN(old_args, old_args[\"encoder\"], k=old_args[\"k\"], n_ntype=4, n_etype=old_args[\"num_relation\"], n_concept=concept_num,\n",
        "                               concept_dim=old_args[\"gnn_dim\"],\n",
        "                               concept_in_dim=concept_dim,\n",
        "                               n_attention_head=old_args[\"att_head_num\"], fc_dim=old_args[\"fc_dim\"], n_fc_layer=old_args[\"fc_layer_num\"],\n",
        "                               p_emb=old_args[\"dropouti\"], p_gnn=old_args[\"dropoutg\"], p_fc=old_args[\"dropoutf\"],\n",
        "                               pretrained_concept_emb=cp_emb, freeze_ent_emb=old_args[\"freeze_ent_emb\"],\n",
        "                               init_range=old_args[\"init_range\"],\n",
        "                               encoder_config={})\n",
        "    # model.load_state_dict(model_state_dict)\n",
        "    checkpoint = torch.load(args[\"load_model_path\"], map_location=torch.device('cpu'))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if torch.cuda.device_count() >= 2 and args[\"cuda\"]:\n",
        "        device0 = torch.device(\"cuda:0\")\n",
        "        device1 = torch.device(\"cuda:1\")\n",
        "    elif torch.cuda.device_count() == 1 and args[\"cuda\"]:\n",
        "        device0 = torch.device(\"cuda:0\")\n",
        "        device1 = torch.device(\"cuda:0\")\n",
        "    else:\n",
        "        device0 = torch.device(\"cpu\")\n",
        "        device1 = torch.device(\"cpu\")\n",
        "    model.encoder.to(device0)\n",
        "    model.decoder.to(device1)\n",
        "    model.eval()\n",
        "\n",
        "    statement_dic = {}\n",
        "    for statement_path in (args[\"train_statements\"], args[\"dev_statements\"], args[\"test_statements\"]):\n",
        "        statement_dic.update(load_statement_dict(statement_path))\n",
        "\n",
        "    # use_contextualized = 'lm' in old_args[\"ent_emb\"]\n",
        "    use_contextualized = 'lm' in args[\"ent_emb\"]\n",
        "\n",
        "    print ('inhouse?', args[\"inhouse\"])\n",
        "\n",
        "    print ('args.train_statements', args[\"train_statements\"])\n",
        "    print ('args.dev_statements', args[\"dev_statements\"])\n",
        "    print ('args.test_statements', args[\"test_statements\"])\n",
        "    print ('args.train_adj', args[\"train_adj\"])\n",
        "    print ('args.dev_adj', args[\"dev_adj\"])\n",
        "    print ('args.test_adj', args[\"test_adj\"])\n",
        "\n",
        "    dataset = LM_QAGNN_DataLoader(args, args[\"train_statements\"], args[\"train_adj\"],\n",
        "                                           args[\"dev_statements\"], args[\"dev_adj\"],\n",
        "                                           args[\"test_statements\"], args[\"test_adj\"],\n",
        "                                           batch_size=args[\"batch_size\"], eval_batch_size=args[\"eval_batch_size\"],\n",
        "                                           device=(device0, device1),\n",
        "                                           model_name=old_args[\"encoder\"],\n",
        "                                           max_node_num=old_args[\"max_node_num\"], max_seq_length=old_args[\"max_seq_len\"],\n",
        "                                           is_inhouse=args[\"inhouse\"], inhouse_train_qids_path=args[\"inhouse_train_qids\"],\n",
        "                                           subsample=args[\"subsample\"], use_cache=args[\"use_cache\"])\n",
        "\n",
        "    save_test_preds = args[\"save_test_preds\"]\n",
        "    dev_acc = evaluate_accuracy(dataset.dev(), model)\n",
        "    print('dev_acc {:7.4f}'.format(dev_acc))\n",
        "    if not save_test_preds:\n",
        "        test_acc = evaluate_accuracy(dataset.test(), model) if args[\"test_statements\"] else 0.0\n",
        "    else:\n",
        "        eval_set = dataset.test()\n",
        "        total_acc = []\n",
        "        count = 0\n",
        "        dt = datetime.datetime.today().strftime('%Y%m%d%H%M%S')\n",
        "        preds_path = os.path.join(args[\"log_save_dir\"], 'test_preds_{}.csv'.format(dt))\n",
        "        with open(preds_path, 'w') as f_preds:\n",
        "            with torch.no_grad():\n",
        "                for qids, labels, *input_data in tqdm(eval_set):\n",
        "                    count += 1\n",
        "                    logits, _, concept_ids, node_type_ids, edge_index, edge_type = model(*input_data, detail=True)\n",
        "                    predictions = logits.argmax(1) #[bsize, ]\n",
        "                    preds_ranked = (-logits).argsort(1) #[bsize, n_choices]\n",
        "                    for i, (qid, label, pred, _preds_ranked, cids, ntype, edges, etype) in enumerate(zip(qids, labels, predictions, preds_ranked, concept_ids, node_type_ids, edge_index, edge_type)):\n",
        "                        acc = int(pred.item()==label.item())\n",
        "                        print ('{},{}'.format(qid, chr(ord('A') + pred.item())), file=f_preds)\n",
        "                        f_preds.flush()\n",
        "                        total_acc.append(acc)\n",
        "        test_acc = float(sum(total_acc))/len(total_acc)\n",
        "\n",
        "        print('-' * 71)\n",
        "        print('test_acc {:7.4f}'.format(test_acc))\n",
        "        print('-' * 71)\n",
        "\n",
        "\n",
        "\n",
        "def predict(args):\n",
        "  assert args[\"load_model_path\"] is not None\n",
        "  model_path = args[\"load_model_path\"]\n",
        "\n",
        "  cp_emb = [np.load(path) for path in args[\"ent_emb_paths\"]]\n",
        "  cp_emb = torch.tensor(np.concatenate(cp_emb, 1), dtype=torch.float)\n",
        "  concept_num, concept_dim = cp_emb.size(0), cp_emb.size(1)\n",
        "  print('| num_concepts: {} |'.format(concept_num))\n",
        "\n",
        "  args[\"use_cache\"]=True        #use cached data to accelerate data loading\n",
        "\n",
        "  # model architecture\n",
        "  args[\"att_head_num\"]=2    # type=int, help='number of attention heads'\n",
        "  args[\"fc_dim\"]=200    # type=int, help='number of FC hidden units'\n",
        "  args[\"fc_layer_num\"]=1   # help='number of FC layers'\n",
        "  args[\"freeze_ent_emb\"]=True     # help='freeze entity embedding layer'\n",
        "\n",
        "  args[\"max_node_num\"]=200\n",
        "  args[\"simple\"]=False    # type=bool_flag, nargs='?', const=True\n",
        "  args[\"subsample\"]=1.0\n",
        "  args[\"init_range\"]=0.02     #type=float, help='stddev when initializing with normal distribution'\n",
        "\n",
        "\n",
        "  # regularization\n",
        "  args[\"dropouti\"]=0.2   # help='dropout for embedding layer'\n",
        "  args[\"dropoutg\"]=0.2    #help='dropout for GNN layers'\n",
        "  args[\"dropoutf\"]=0.2    #help='dropout for fully-connected layers'\n",
        "\n",
        "  # optimization\n",
        "  args[\"mbs\"]=1\n",
        "  args[\"ebs\"]=2\n",
        "  args[\"eval_batch_size\"]=2\n",
        "  args[\"unfreeze_epoch\"]=4\n",
        "  args[\"refreeze_epoch\"]=10000\n",
        "  args[\"drop_partial_batch\"]=False\n",
        "  args[\"fill_partial_batch\"]=False\n",
        "\n",
        "  model = LM_QAGNN(args, args[\"encoder\"], k=args[\"k\"], n_ntype=4, n_etype=args[\"num_relation\"], n_concept=concept_num,\n",
        "                                    concept_dim=args[\"gnn_dim\"],\n",
        "                                    concept_in_dim=concept_dim,\n",
        "                                    n_attention_head=args[\"att_head_num\"], fc_dim=args[\"fc_dim\"], n_fc_layer=args[\"fc_layer_num\"],\n",
        "                                    p_emb=args[\"dropouti\"], p_gnn=args[\"dropoutg\"], p_fc=args[\"dropoutf\"],\n",
        "                                    pretrained_concept_emb=cp_emb, freeze_ent_emb=args[\"freeze_ent_emb\"],\n",
        "                                    init_range=args[\"init_range\"],\n",
        "                                    encoder_config={})\n",
        "  checkpoint = torch.load(args[\"load_model_path\"], map_location=torch.device('cpu'))\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "  if torch.cuda.device_count() >= 2 and args[\"cuda\"]:\n",
        "      device0 = torch.device(\"cuda:0\")\n",
        "      device1 = torch.device(\"cuda:1\")\n",
        "  elif torch.cuda.device_count() == 1 and args[\"cuda\"]:\n",
        "      device0 = torch.device(\"cuda:0\")\n",
        "      device1 = torch.device(\"cuda:0\")\n",
        "  else:\n",
        "      device0 = torch.device(\"cpu\")\n",
        "      device1 = torch.device(\"cpu\")\n",
        "  model.encoder.to(device0)\n",
        "  model.decoder.to(device1)\n",
        "  model.eval()\n",
        "\n",
        "  print ('inhouse?', args[\"inhouse\"])\n",
        "\n",
        "  print ('args.train_statements', args[\"train_statements\"])\n",
        "  print ('args.dev_statements', args[\"dev_statements\"])\n",
        "  print ('args.test_statements', args[\"test_statements\"])\n",
        "  print ('args.train_adj', args[\"train_adj\"])\n",
        "  print ('args.dev_adj', args[\"dev_adj\"])\n",
        "  print ('args.test_adj', args[\"test_adj\"])\n",
        "\n",
        "\n",
        "  dataset = LM_QAGNN_DataLoader(args, args[\"train_statements\"], args[\"train_adj\"],\n",
        "                                          args[\"dev_statements\"], args[\"dev_adj\"],\n",
        "                                          args[\"test_statements\"], args[\"test_adj\"],\n",
        "                                          batch_size=args[\"batch_size\"], eval_batch_size=args[\"eval_batch_size\"],\n",
        "                                          device=(device0, device1),\n",
        "                                          model_name=args[\"encoder\"],\n",
        "                                          max_node_num=args[\"max_node_num\"], max_seq_length=args[\"max_seq_len\"],\n",
        "                                          is_inhouse=args[\"inhouse\"], inhouse_train_qids_path=args[\"inhouse_train_qids\"],\n",
        "                                          subsample=args[\"subsample\"], use_cache=args[\"use_cache\"])\n",
        "\n",
        "  save_test_preds = args[\"save_test_preds\"]\n",
        "  dev_acc = evaluate_accuracy(dataset.dev(), model)\n",
        "  print('dev_acc {:7.4f}'.format(dev_acc))\n",
        "  test_preds=[]\n",
        "  if not save_test_preds:\n",
        "      test_acc = evaluate_accuracy(dataset.test(), model) if args[\"test_statements\"] else 0.0\n",
        "  else:\n",
        "      eval_set = dataset.test()\n",
        "      count = 0\n",
        "      dt = datetime.datetime.today().strftime('%Y%m%d%H%M%S')\n",
        "      preds_path = os.path.join(args[\"log_save_dir\"], 'test_preds_{}.csv'.format(dt))\n",
        "      with open(preds_path, 'w') as f_preds:\n",
        "          with torch.no_grad():\n",
        "              for qids, labels, *input_data in tqdm(eval_set):\n",
        "                  count += 1\n",
        "                  logits, _, concept_ids, node_type_ids, edge_index, edge_type = model(*input_data, detail=True)\n",
        "                  predictions = logits.argmax(1) #[bsize, ]\n",
        "                  preds_ranked = (-logits).argsort(1) #[bsize, n_choices]\n",
        "                  for i, (qid, label, pred, _preds_ranked, cids, ntype, edges, etype) in enumerate(zip(qids, labels, predictions, preds_ranked, concept_ids, node_type_ids, edge_index, edge_type)):\n",
        "                      print ('{},{}'.format(qid, pred.item()), file=f_preds)\n",
        "                      test_preds.append(pred.item())\n",
        "                      f_preds.flush()\n",
        "\n",
        "      print()\n",
        "      print('-' * 71)\n",
        "  return test_preds\n",
        "\n",
        "\n",
        "\n",
        "def main_5(args, global_step, best_dev_epoch, is_finetuning_on_new_ds):\n",
        "\n",
        "    # args[\"save_dir\"]=f'/content/drive/Shareddrives/Gdrive/My_Thesis/QA_GNN/saved_models'   #model output directory\n",
        "    # args[\"load_model_path\"]='/content/drive/Shareddrives/Gdrive/My_Thesis/QA_GNN/saved_models/csqa/enc-roberta-large__k5__gnndim100__bs8__seed0/model.pt.2'\n",
        "\n",
        "    args[\"use_cache\"]=True        #use cached data to accelerate data loading\n",
        "\n",
        "    # model architecture\n",
        "    args[\"att_head_num\"]=2    # type=int, help='number of attention heads'\n",
        "    args[\"fc_dim\"]=200    # type=int, help='number of FC hidden units'\n",
        "    args[\"fc_layer_num\"]=1   # help='number of FC layers'\n",
        "    args[\"freeze_ent_emb\"]=True     # help='freeze entity embedding layer'\n",
        "\n",
        "    args[\"max_node_num\"]=200\n",
        "    args[\"simple\"]=False    # type=bool_flag, nargs='?', const=True\n",
        "    args[\"subsample\"]=1.0\n",
        "    args[\"init_range\"]=0.02     #type=float, help='stddev when initializing with normal distribution'\n",
        "\n",
        "\n",
        "    # regularization\n",
        "    args[\"dropouti\"]=0.2   # help='dropout for embedding layer'\n",
        "    args[\"dropoutg\"]=0.2    #help='dropout for GNN layers'\n",
        "    args[\"dropoutf\"]=0.2    #help='dropout for fully-connected layers'\n",
        "\n",
        "    # optimization\n",
        "    args[\"mbs\"]=1\n",
        "    args[\"ebs\"]=2\n",
        "    args[\"eval_batch_size\"]=2\n",
        "    args[\"unfreeze_epoch\"]=4\n",
        "    args[\"refreeze_epoch\"]=10000\n",
        "    args[\"drop_partial_batch\"]=False\n",
        "    args[\"fill_partial_batch\"]=False\n",
        "\n",
        "\n",
        "    if args[\"simple\"]:\n",
        "        args[\"k\"]=1\n",
        "\n",
        "    args[\"fp16\"] = args[\"fp16\"] and (torch.__version__ >= '1.6.0')\n",
        "\n",
        "    if args[\"mode\"] == 'train':\n",
        "        train(args, global_step, best_dev_epoch, is_finetuning_on_new_ds)\n",
        "    elif args[\"mode\"] == 'eval_detail':\n",
        "        # raise NotImplementedError\n",
        "        eval_detail(args)\n",
        "    else:\n",
        "        raise ValueError('Invalid mode')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jsmXGCHqEsV"
      },
      "source": [
        "##<font color=greeen>Train brain_teaser</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WErM5QzDqH3J",
        "outputId": "9b9f14bb-5f7d-4db5-8695-3b79ae1c50e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** hyperparameters *****\n",
            "dataset: brain_teaser_ds\n",
            "enc_name: roberta-large\n",
            "batch_size: 128\n",
            "learning_rate: elr 0.0002 dlr 0.001\n",
            "gnn: dim 200 layer 5\n",
            "Epochs: 100\n",
            "******************************\n"
          ]
        }
      ],
      "source": [
        "dataset=\"brain_teaser_ds\"\n",
        "model='roberta-large'\n",
        "# model='bert-large-uncased'\n",
        "\n",
        "# elr=1e-5 #encoder learning rate\n",
        "elr=2e-4 #encoder learning rate\n",
        "dlr=1e-3  #decoder learing rate\n",
        "batch_size=128 #128 default\n",
        "mbs=2   #mini-batch-size\n",
        "n_epochs=100   #def 100\n",
        "num_relation=38 #(17 +2) * 2: originally 17, add 2 relation types (QA context -> Q node; QA context -> A node), and double because we add reverse edges\n",
        "seed=0\n",
        "\n",
        "k=5 #num of gnn layers\n",
        "gnndim=200    #dimension of the GNN layers def 200\n",
        "\n",
        "!echo \"***** hyperparameters *****\"\n",
        "!echo \"dataset: $dataset\"\n",
        "!echo \"enc_name: $model\"\n",
        "!echo \"batch_size: $batch_size\"\n",
        "!echo \"learning_rate: elr $elr dlr $dlr\"\n",
        "!echo \"gnn: dim $gnndim layer $k\"\n",
        "!echo \"Epochs: $n_epochs\"\n",
        "!echo \"******************************\"\n",
        "\n",
        "main_dir='/content/drive/MyDrive/brain_teaser'\n",
        "save_dir_pref=f\"{main_dir}/QA_GNN/saved_models\"\n",
        "\n",
        "if not os.path.exists(save_dir_pref):\n",
        "  %mkdir -p $save_dir_pref\n",
        "%mkdir -p logs\n",
        "\n",
        "args=dict()\n",
        "\n",
        "args['enc']=model\n",
        "args['encoder']=model\n",
        "\n",
        "# args[\"best_model_save_dir\"]=f\"{save_dir_pref}/new_SP_best_model_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "# # args[\"checkpoint_save_dir\"]=f\"{save_dir_pref}/new_SP_checkpoint_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "# args[\"checkpoint_save_dir\"]=f\"/content/new_SP_checkpoint_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "# args[\"log_save_dir\"]=f\"{save_dir_pref}/new_SP_log_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "\n",
        "\n",
        "args[\"best_model_save_dir\"]=f\"{save_dir_pref}/new_WP_best_model_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "# args[\"checkpoint_save_dir\"]=f\"{save_dir_pref}/new_WP_checkpoint_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"checkpoint_save_dir\"]=f\"/content/new_WP_checkpoint_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"log_save_dir\"]=f\"{save_dir_pref}/new_WP_log_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "\n",
        "\n",
        "args[\"save_best_model\"]=True\n",
        "args['save_test_preds']=False\n",
        "args[\"save_checkpoint\"]=True\n",
        "\n",
        "args['loss']='cross_entropy'\n",
        "args['lr_schedule']='fixed'\n",
        "args['bs']=batch_size\n",
        "args['batch_size']=batch_size\n",
        "\n",
        "args['warmup_steps']=0\n",
        "\n",
        "args['max_grad_norm']=1.0\n",
        "args['me']=10\n",
        "args['log_interval']=5\n",
        "args['debug']=False\n",
        "args[\"optim\"]=\"radam\"\n",
        "\n",
        "args[\"mode\"]=\"train\"    #choices=['train', 'eval_detail'], help='run training or evaluation\n",
        "args[\"dataset\"]=dataset\n",
        "args[\"encoder\"]=model\n",
        "args['enc']=model\n",
        "args[\"k\"]=k   #perform k-layer message passing\n",
        "args[\"gnn_dim\"]=gnndim\n",
        "args[\"encoder_lr\"]=elr\n",
        "args[\"decoder_lr\"]=dlr\n",
        "args[\"batch_size\"]=batch_size\n",
        "args[\"mini_batch_size\"]=mbs\n",
        "args[\"fp16\"]=False   #use fp16 training. this requires torch>=1.6.0\n",
        "args[\"seed\"]=seed\n",
        "args[\"num_relation\"]=num_relation\n",
        "args[\"n_epochs\"]=n_epochs\n",
        "args[\"max_epochs_before_stop\"]=10\n",
        "# args[\"train_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/SP_train.graph.adj.pk\"\n",
        "# args[\"dev_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/SP_dev.graph.adj.pk\"\n",
        "args[\"train_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/WP_train.graph.adj.pk\"\n",
        "args[\"dev_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/WP_dev.graph.adj.pk\"\n",
        "args[\"test_adj\"]=None\n",
        "# args[\"test_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/SP_test.graph.adj.pk\"\n",
        "\n",
        "# args[\"train_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/SP_train.statement.jsonl\"\n",
        "# args[\"dev_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/SP_dev.statement.jsonl\"\n",
        "args[\"train_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/WP_train.statement.jsonl\"\n",
        "args[\"dev_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/WP_dev.statement.jsonl\"\n",
        "\n",
        "args[\"test_statements\"]=None\n",
        "# args[\"test_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/SP_test.statement.jsonl\"\n",
        "\n",
        "\n",
        "args[\"cuda\"]=True\n",
        "# args[\"ent_emb_paths\"]=['data/cpnet/tzw.ent.npy']\n",
        "args[\"ent_emb_paths\"]=['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy']\n",
        "\n",
        "args[\"max_seq_len\"]=128\n",
        "args[\"inhouse\"]=False\n",
        "# args[\"inhouse_train_qids\"]=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/inhouse_split_qids.txt\"\n",
        "args[\"inhouse_train_qids\"]=f\"/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/WP_inhouse_split_qids.txt\"\n",
        "\n",
        "args[\"weight_decay\"]=1e-2\n",
        "\n",
        "args['encoder_layer']=-1\n",
        "# args['elr']=2e-4\n",
        "# args[\"encoder_lr\"]=2e-4\n",
        "\n",
        "# args[\"load_model_path\"]='/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.16.best_model'\n",
        "\n",
        "args[\"load_model_path\"]=None\n",
        "# args[\"load_model_path\"]=\"/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.26.best_model\"\n",
        "# args[\"load_model_path\"]=\"/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.21.best_model\"\n",
        "# args[\"load_model_path\"]='/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-bert-large-uncased_k5__gnndim200__bs128__seed0/model.pt.7.best_model'\n",
        "# args[\"load_model_path\"]='/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_checkpoint_brain_teaser_ds__enc-bert-large-uncased_k5__gnndim200__bs128__seed0/model.pt.8.temp_checkpoint'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###predict on test data"
      ],
      "metadata": {
        "id": "MpTq0mqwYRlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "PF3kEWT6YQrk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####SP"
      ],
      "metadata": {
        "id": "0UHotuXYYVF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args[\"save_test_preds\"]=True\n",
        "\n",
        "k=5 #num of gnn layers\n",
        "\n",
        "task_type=\"SP\"\n",
        "# args[\"load_model_path\"]=f\"/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/{task_type}_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.21.best_model\"\n",
        "args[\"load_model_path\"]=f\"/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_{task_type}_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.33.best_model\"\n",
        "\n",
        "\n",
        "main_dir='/content/drive/MyDrive/brain_teaser'\n",
        "save_dir_pref=f\"{main_dir}/QA_GNN/saved_models\"\n",
        "dataset=\"brain_teaser_ds\"\n",
        "model='roberta-large'\n",
        "\n",
        "args[\"train_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_train.graph.adj.pk\"\n",
        "args[\"dev_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_dev.graph.adj.pk\"\n",
        "args[\"test_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_test.graph.adj.pk\"\n",
        "\n",
        "args[\"train_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_train.statement.jsonl\"\n",
        "args[\"dev_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_dev.statement.jsonl\"\n",
        "args[\"test_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_test.statement.jsonl\"\n",
        "\n",
        "args[\"best_model_save_dir\"]=f\"{save_dir_pref}/new_{task_type}_best_model_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"log_save_dir\"]=f\"{save_dir_pref}/new_{task_type}_log_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n"
      ],
      "metadata": {
        "id": "e1nDHZNrYRD0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args[\"best_model_save_dir\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fF9_sMOAeJ0x",
        "outputId": "c6ee6465-036f-4a80-a9c0-d6b9ead1143e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp_test_pred=predict(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740,
          "referenced_widgets": [
            "2b21316c9d624080a39b71567b137fde",
            "3eb3884b7c5142faa0fd1fc626680564",
            "34ca28d4626f43efa6adf4ba838c443d",
            "e4bab30c46f84bde915fcb9f486e0be6",
            "5756f82d73a249ea9a8db88920a48ede",
            "29b76ca112b14487a7884a7c3e6effaa",
            "d7b64afac4284c8782a81be37281eab1",
            "b3007747147c49628e977705c639961b",
            "05835ea718ec4f33aebd4b6edce9bdf2",
            "6842aa0e6d38477b849a1877d4465bc0",
            "2a608f59847e490082648355e94b5090",
            "b9fbc27ae7c34bebbcf8859efa3bc6f2",
            "e0be1dfbcaaa4817a3109f7140975252",
            "f5418179275d41afada48581a87730ca",
            "086ecd5d73284ef7b111f216eeb15703",
            "1471aa6f1cce4531a7eda9ad22ff5c95",
            "4f7973970ffb47c89de7c2d67995abc8",
            "e0b7083aea5c478093fa4986b0cfd261",
            "c26bdeec290848eba5c1dec59180d5bf",
            "d92550066df743f096294f5a832f4a27",
            "d518865e90854b47ba721c2a5d8c6d1f",
            "46b5ff9d83a84f6fb8654cdfb1e4b360",
            "77b387e66a78495788777dbf7d0b6667",
            "834d98911d4a473d8b2a46439c2c5ea9",
            "c6dedce0790b4383acef74e5c2cbd89a",
            "0b91449d5bac4a7e9f5e35ec3f427a94",
            "7fe043b046c24eb7a3c1dba8bfca4445",
            "78459338634e4989b871b87667ba7653",
            "7d0106726065476780f72187ae3f6d58",
            "d865548c544a4a62ad1d152c46ad4ca1",
            "777dcc47065640b8bc51d692840c7154",
            "5268d0c349ba430f8cc489737a88ab43",
            "000017bdcc9d47c197ed028450f3ddb4",
            "c500209e24be43e3ba24c3e36d868275",
            "c211156905fc4522a7b0a9dc661d85e4",
            "d56c52ead86d400db1be250755272aca",
            "d8650c1019574638b8baeecb80fe0ac7",
            "7fc31c83750b4c0fa32cd5075162af2d",
            "0404a5727b91485eadf3af9104d53223",
            "5acc0096591e4c99a41769b8fe6056ab",
            "e09a5d3cf486495ba34f9f008a0c1681",
            "3352ed4957534ecdb91a288fc9dd8821",
            "462300d4cff4451e8a042d35f5e121b3",
            "20ecacdae30c45b69d1b54bc50bbc3f2",
            "2fb4e841728d4dd5909d4d740047d72b",
            "2faacd41c0394407b88d7a354d40ebd3",
            "f905256e0e94468b85a4f09497e27bd1",
            "ba0d18c7ad3643d58183678c79ebecf5",
            "7e21d20a56b149d2a9a082a3563c4f2c",
            "4d7d3f9e1f21400a84504d197795d4d7",
            "53f5c29f48644191baadf672e2d7433f",
            "17f3d169001940f0ac2e4854bc4b853e",
            "4e948b265a524a29a5c043a22b18d8a1",
            "8854f06b063c4864ad280d41cc605b87",
            "a7496c19abac467f81e839663f2d9bc5"
          ]
        },
        "id": "X0eOyjrpYXDK",
        "outputId": "a4167e49-4fdb-45f8-d20c-4b26efb557c6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| num_concepts: 799273 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b21316c9d624080a39b71567b137fde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9fbc27ae7c34bebbcf8859efa3bc6f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inhouse? False\n",
            "args.train_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl\n",
            "args.dev_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_dev.statement.jsonl\n",
            "args.test_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_test.statement.jsonl\n",
            "args.train_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_train.graph.adj.pk\n",
            "args.dev_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_dev.graph.adj.pk\n",
            "args.test_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_test.graph.adj.pk\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77b387e66a78495788777dbf7d0b6667"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c500209e24be43e3ba24c3e36d868275"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fb4e841728d4dd5909d4d740047d72b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 456/456 [00:00<00:00, 939.95it/s]\n",
            "100%|██████████| 51/51 [00:00<00:00, 870.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_choice 4\n",
            "| ori_adj_len: mu 395.12 sigma 287.74 | adj_len: 177.72 | prune_rate： 0.73 | qc_num: 18.76 | ac_num: 5.46 |\n",
            "| ori_adj_len: mu 384.36 sigma 272.02 | adj_len: 175.26 | prune_rate： 0.69 | qc_num: 18.13 | ac_num: 5.17 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:00<00:00, 911.71it/s]\n",
            "loading adj matrices: 100%|██████████| 480/480 [00:02<00:00, 232.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ori_adj_len: mu 369.61 sigma 278.58 | adj_len: 172.92 | prune_rate： 0.61 | qc_num: 17.12 | ac_num: 4.92 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev_acc  0.9020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [00:13<00:00,  4.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sp_test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA9NGsK6YbAj",
        "outputId": "f0e54de5-5e50-4a7c-fd08-dd44e6b5f8db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SP_dataset_val = np.load('/content/drive/MyDrive/brain_teaser/datasets/SP_eval_data_for_practice.npy', allow_pickle=True,encoding='bytes')\n",
        "SP_dataset_val = np.load('/content/drive/MyDrive/brain_teaser/datasets/SP_new_test.npy', allow_pickle=True,encoding='bytes')\n",
        "print(len(SP_dataset_val))\n",
        "\n",
        "data_dict = {'question':[],\n",
        "             'choice_list':[]}\n",
        "for i in SP_dataset_val:\n",
        "  for k,v in i.items():\n",
        "    data_dict[k].append(v)\n",
        "\n",
        "SP_val_df = pd.DataFrame(data_dict, columns=['question', 'choice_list'])\n",
        "SP_val_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "E3bDMAdHYatT",
        "outputId": "718825c5-bc73-4cf8-8da3-86caba37d1ca"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  In a small village, two farmers are working in...   \n",
              "1  Romeo and Juliet are discovered dead on the be...   \n",
              "\n",
              "                                         choice_list  \n",
              "0  [The lazy farmer is his mother., The lazy farm...  \n",
              "1  [They were sleeping and scared by the sound of...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02a08148-3aab-4ddf-9104-c93a2f58950b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In a small village, two farmers are working in...</td>\n",
              "      <td>[The lazy farmer is his mother., The lazy farm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Romeo and Juliet are discovered dead on the be...</td>\n",
              "      <td>[They were sleeping and scared by the sound of...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02a08148-3aab-4ddf-9104-c93a2f58950b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-02a08148-3aab-4ddf-9104-c93a2f58950b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-02a08148-3aab-4ddf-9104-c93a2f58950b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-28252f68-0b27-4cd5-a57c-e3b4074f6a93\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-28252f68-0b27-4cd5-a57c-e3b4074f6a93')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-28252f68-0b27-4cd5-a57c-e3b4074f6a93 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids=[]\n",
        "questions=[]\n",
        "choice_lists=[]\n",
        "predicted_labels=[]\n",
        "\n",
        "for i in tqdm(range(len(SP_val_df))):\n",
        "  sample=SP_val_df.iloc[i]\n",
        "  pred=sp_test_pred[i]\n",
        "  ids.append(i)\n",
        "  questions.append(sample['question'].strip())\n",
        "  predicted_labels.append(pred)\n",
        "  choice_lists.append(sample['choice_list'])\n",
        "\n",
        "temp_dict={'id':ids,\n",
        "'question':questions,\n",
        "'choice_list':choice_lists,\n",
        "'label':predicted_labels}\n",
        "\n",
        "sp_new_df=pd.DataFrame(data=temp_dict)\n",
        "sp_new_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "BpQmDQdFYf4p",
        "outputId": "615b95d0-3dfe-464e-c558-b1589469ced0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:00<00:00, 19801.58it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                           question  \\\n",
              "0      0  In a small village, two farmers are working in...   \n",
              "1      1  Romeo and Juliet are discovered dead on the be...   \n",
              "2      2  How many years in your life it happens that be...   \n",
              "3      3  Who would serve as the team's captain if a cru...   \n",
              "4      4  In one city, 5% of the population has an unlis...   \n",
              "..   ...                                                ...   \n",
              "115  115  A professional fisherman caught 30 fish during...   \n",
              "116  116  Bob was working on a project when suddenly int...   \n",
              "117  117  He has wed numerous women, but never himself. ...   \n",
              "118  118  You walk into a room and see a bed and lie on ...   \n",
              "119  119  Four of Mrs. Jones' daughters exist. She has o...   \n",
              "\n",
              "                                           choice_list  label  \n",
              "0    [The lazy farmer is his mother., The lazy farm...      0  \n",
              "1    [They were sleeping and scared by the sound of...      2  \n",
              "2    [In ech leap year., In the first year of gradu...      2  \n",
              "3    [The first officer., The captain., The second ...      1  \n",
              "4    [One hundred people., Ninty-five people., Five...      1  \n",
              "..                                                 ...    ...  \n",
              "115               [Two., One., Three., None of above.]      3  \n",
              "116  [He needed a membership to search in google., ...      2  \n",
              "117  [A teacher., A preacher., A laywer., None of a...      3  \n",
              "118  [Thirty-six, as there are eighteen animals., S...      0  \n",
              "119  [Some brothers were not loved by family and mo...      2  \n",
              "\n",
              "[120 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a028d29-21cc-4e2c-a7ff-ced066e433e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>In a small village, two farmers are working in...</td>\n",
              "      <td>[The lazy farmer is his mother., The lazy farm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Romeo and Juliet are discovered dead on the be...</td>\n",
              "      <td>[They were sleeping and scared by the sound of...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>How many years in your life it happens that be...</td>\n",
              "      <td>[In ech leap year., In the first year of gradu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Who would serve as the team's captain if a cru...</td>\n",
              "      <td>[The first officer., The captain., The second ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>In one city, 5% of the population has an unlis...</td>\n",
              "      <td>[One hundred people., Ninty-five people., Five...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>115</td>\n",
              "      <td>A professional fisherman caught 30 fish during...</td>\n",
              "      <td>[Two., One., Three., None of above.]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>116</td>\n",
              "      <td>Bob was working on a project when suddenly int...</td>\n",
              "      <td>[He needed a membership to search in google., ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>117</td>\n",
              "      <td>He has wed numerous women, but never himself. ...</td>\n",
              "      <td>[A teacher., A preacher., A laywer., None of a...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>118</td>\n",
              "      <td>You walk into a room and see a bed and lie on ...</td>\n",
              "      <td>[Thirty-six, as there are eighteen animals., S...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>119</td>\n",
              "      <td>Four of Mrs. Jones' daughters exist. She has o...</td>\n",
              "      <td>[Some brothers were not loved by family and mo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a028d29-21cc-4e2c-a7ff-ced066e433e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a028d29-21cc-4e2c-a7ff-ced066e433e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a028d29-21cc-4e2c-a7ff-ced066e433e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2845b81-8444-42c5-8155-0f907bd9d3f1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2845b81-8444-42c5-8155-0f907bd9d3f1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2845b81-8444-42c5-8155-0f907bd9d3f1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ead2eefa-6514-48d6-b61b-1991c5bba008\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sp_new_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ead2eefa-6514-48d6-b61b-1991c5bba008 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sp_new_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "dt = datetime.datetime.today().strftime('%Y_%m_%d')\n",
        "dt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3aJobk0CYmtX",
        "outputId": "a99a8a34-013c-4727-91e8-56cdd1e83a9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2024_01_21'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp_new_df.to_csv(f\"/content/drive/MyDrive/brain_teaser/SP_qagnn_predictions_test_{dt}.csv\", index=False)"
      ],
      "metadata": {
        "id": "iGR2FEGfYnm7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=[str(x) for x in sp_new_df['label'].values]\n",
        "with open('answer_sen.txt', 'w') as f:\n",
        "    f.write('\\n'.join(res))"
      ],
      "metadata": {
        "id": "O0UzXY2eYfze"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vqyhso1bYW-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####WP"
      ],
      "metadata": {
        "id": "yH1ZZO33Yz-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args[\"save_test_preds\"]=True\n",
        "\n",
        "k=5 #num of gnn layers\n",
        "task_type=\"WP\"\n",
        "# args[\"load_model_path\"]=f\"/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/{task_type}_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.26.best_model\"\n",
        "args[\"load_model_path\"]=f\"/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_{task_type}_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.28.best_model\"\n",
        "\n",
        "\n",
        "main_dir='/content/drive/MyDrive/brain_teaser'\n",
        "save_dir_pref=f\"{main_dir}/QA_GNN/saved_models\"\n",
        "dataset=\"brain_teaser_ds\"\n",
        "model='roberta-large'\n",
        "\n",
        "args[\"train_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_train.graph.adj.pk\"\n",
        "args[\"dev_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_dev.graph.adj.pk\"\n",
        "args[\"test_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_test.graph.adj.pk\"\n",
        "\n",
        "args[\"train_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_train.statement.jsonl\"\n",
        "args[\"dev_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_dev.statement.jsonl\"\n",
        "args[\"test_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_test.statement.jsonl\"\n",
        "\n",
        "args[\"best_model_save_dir\"]=f\"{save_dir_pref}/new_{task_type}_best_model_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"log_save_dir\"]=f\"{save_dir_pref}/new_{task_type}_log_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\""
      ],
      "metadata": {
        "id": "Rj9L6O2PY0yv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args[\"best_model_save_dir\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0by8nhNcY1Lw",
        "outputId": "6c391ed9-fd94-4061-f686-c4c4121fa7f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wp_test_pred=predict(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4Y7iJ4KY1Hf",
        "outputId": "6eb82730-39cf-4547-95ff-6f5b4c9408c2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| num_concepts: 799273 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inhouse? False\n",
            "args.train_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl\n",
            "args.dev_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_dev.statement.jsonl\n",
            "args.test_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_test.statement.jsonl\n",
            "args.train_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_train.graph.adj.pk\n",
            "args.dev_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_dev.graph.adj.pk\n",
            "args.test_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_test.graph.adj.pk\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 356/356 [00:00<00:00, 918.30it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 1186.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_choice 4\n",
            "| ori_adj_len: mu 96.10 sigma 96.83 | adj_len: 85.07 | prune_rate： 0.10 | qc_num: 6.03 | ac_num: 2.34 |\n",
            "| ori_adj_len: mu 125.84 sigma 140.18 | adj_len: 94.26 | prune_rate： 0.20 | qc_num: 6.69 | ac_num: 2.72 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 96/96 [00:00<00:00, 1485.51it/s]\n",
            "loading adj matrices: 100%|██████████| 384/384 [00:00<00:00, 525.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ori_adj_len: mu 83.97 sigma 74.87 | adj_len: 78.50 | prune_rate： 0.09 | qc_num: 5.00 | ac_num: 2.15 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev_acc  0.8500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 48/48 [00:10<00:00,  4.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(wp_test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5hcdDS-Y1Cr",
        "outputId": "f89c5eb4-8c10-4531-f2cb-38fa03bc8dde"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XDOMm5UkZXg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WP_dataset_val = np.load('/content/drive/MyDrive/brain_teaser/datasets/WP_eval_data_for_practice.npy', allow_pickle=True,encoding='bytes')\n",
        "WP_dataset_val = np.load('/content/drive/MyDrive/brain_teaser/datasets/WP_new_test.npy', allow_pickle=True,encoding='bytes')\n",
        "\n",
        "print(len(WP_dataset_val))\n",
        "\n",
        "data_dict = {'question':[],\n",
        "             'choice_list':[]}\n",
        "for i in WP_dataset_val:\n",
        "  for k,v in i.items():\n",
        "    data_dict[k].append(v)\n",
        "\n",
        "WP_val_df = pd.DataFrame(data_dict, columns=['question', 'choice_list'])\n",
        "WP_val_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "gT5LwvToY77I",
        "outputId": "ebef6455-c9b1-45ef-e05c-671bc01b2a11"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  question  \\\n",
              "0  What kind of stock doesn't have shares?   \n",
              "1       What do you call a toothless bear?   \n",
              "\n",
              "                                         choice_list  \n",
              "0  [Small-cap stock., Livestock., Growth stock., ...  \n",
              "1  [A brown bear., A polar bear., A gummy bear., ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c33e4e00-a76b-44d5-84c4-08c9de406769\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What kind of stock doesn't have shares?</td>\n",
              "      <td>[Small-cap stock., Livestock., Growth stock., ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What do you call a toothless bear?</td>\n",
              "      <td>[A brown bear., A polar bear., A gummy bear., ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c33e4e00-a76b-44d5-84c4-08c9de406769')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c33e4e00-a76b-44d5-84c4-08c9de406769 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c33e4e00-a76b-44d5-84c4-08c9de406769');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e9fb24e8-2314-4b9b-9b72-bbbdbe845a15\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e9fb24e8-2314-4b9b-9b72-bbbdbe845a15')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e9fb24e8-2314-4b9b-9b72-bbbdbe845a15 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids=[]\n",
        "questions=[]\n",
        "choice_lists=[]\n",
        "predicted_labels=[]\n",
        "\n",
        "for i in tqdm(range(len(WP_val_df))):\n",
        "  sample=WP_val_df.iloc[i]\n",
        "  pred=wp_test_pred[i]\n",
        "  ids.append(i)\n",
        "  questions.append(sample['question'].strip())\n",
        "  predicted_labels.append(pred)\n",
        "  choice_lists.append(sample['choice_list'])\n",
        "\n",
        "temp_dict={'id':ids,\n",
        "'question':questions,\n",
        "'choice_list':choice_lists,\n",
        "'label':predicted_labels}\n",
        "\n",
        "WP_new_df=pd.DataFrame(data=temp_dict)\n",
        "WP_new_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "jH7BEA08Y74L",
        "outputId": "ef2e3a62-2969-4335-97b1-7e4d6c1bb84a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 96/96 [00:00<00:00, 20972.61it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id                                           question  \\\n",
              "0    0            What kind of stock doesn't have shares?   \n",
              "1    1                 What do you call a toothless bear?   \n",
              "2    2  Where will a computer technician keep all his ...   \n",
              "3    3             What do you call a bear with no teeth?   \n",
              "4    4  What was the result of the tiny lobster's math...   \n",
              "..  ..                                                ...   \n",
              "91  91         What can you find at the end of a rainbow?   \n",
              "92  92  Without using any R sounds, how do you say, \"P...   \n",
              "93  93               What kind of phone is most colorful?   \n",
              "94  94         What's the coolest letter in the alphabet?   \n",
              "95  95                    What is in the middle of Paris?   \n",
              "\n",
              "                                          choice_list  label  \n",
              "0   [Small-cap stock., Livestock., Growth stock., ...      1  \n",
              "1   [A brown bear., A polar bear., A gummy bear., ...      2  \n",
              "2   [A mouse., A monitor., A keyboard., None of ab...      0  \n",
              "3   [A brown bear., A gummy bear., A polar bear., ...      1  \n",
              "4   [Very-bad., Sea-plus., Very-Good., None of abo...      1  \n",
              "..                                                ...    ...  \n",
              "91  [The letter R., The letter W., The letter I., ...      1  \n",
              "92  [Bought a dog., Purchased A Rotweiler., Uchase...      2  \n",
              "93  [A cellphone., A smartphone., Chromophone., No...      0  \n",
              "94  [ 'Z', because it's the end of alphabet.,  'A'...      2  \n",
              "95  [The letter R., The letter S., The letter P., ...      1  \n",
              "\n",
              "[96 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-699a46b2-4c5d-4262-a409-764738e57ce6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What kind of stock doesn't have shares?</td>\n",
              "      <td>[Small-cap stock., Livestock., Growth stock., ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>What do you call a toothless bear?</td>\n",
              "      <td>[A brown bear., A polar bear., A gummy bear., ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Where will a computer technician keep all his ...</td>\n",
              "      <td>[A mouse., A monitor., A keyboard., None of ab...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>What do you call a bear with no teeth?</td>\n",
              "      <td>[A brown bear., A gummy bear., A polar bear., ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>What was the result of the tiny lobster's math...</td>\n",
              "      <td>[Very-bad., Sea-plus., Very-Good., None of abo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>91</td>\n",
              "      <td>What can you find at the end of a rainbow?</td>\n",
              "      <td>[The letter R., The letter W., The letter I., ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>92</td>\n",
              "      <td>Without using any R sounds, how do you say, \"P...</td>\n",
              "      <td>[Bought a dog., Purchased A Rotweiler., Uchase...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>93</td>\n",
              "      <td>What kind of phone is most colorful?</td>\n",
              "      <td>[A cellphone., A smartphone., Chromophone., No...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>What's the coolest letter in the alphabet?</td>\n",
              "      <td>[ 'Z', because it's the end of alphabet.,  'A'...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>What is in the middle of Paris?</td>\n",
              "      <td>[The letter R., The letter S., The letter P., ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-699a46b2-4c5d-4262-a409-764738e57ce6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-699a46b2-4c5d-4262-a409-764738e57ce6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-699a46b2-4c5d-4262-a409-764738e57ce6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c905601b-da3f-4d04-b7cf-3d4c26856cbb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c905601b-da3f-4d04-b7cf-3d4c26856cbb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c905601b-da3f-4d04-b7cf-3d4c26856cbb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d779e466-0c71-4982-a8cb-325c7b5ffe17\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('WP_new_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d779e466-0c71-4982-a8cb-325c7b5ffe17 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('WP_new_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = datetime.datetime.today().strftime('%Y_%m_%d')\n",
        "dt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "M0Vos0-wZGo0",
        "outputId": "bc2febd4-2ca2-4110-f91f-e03b229d9e58"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2024_01_21'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WP_new_df.to_csv(f\"/content/drive/MyDrive/brain_teaser/WP_qagnn_predictions_test_{dt}.csv\", index=False)"
      ],
      "metadata": {
        "id": "sPe0et9jZOVP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=[str(x) for x in WP_new_df['label'].values]\n",
        "with open('answer_word.txt', 'w') as f:\n",
        "    f.write('\\n'.join(res))"
      ],
      "metadata": {
        "id": "rfnNIcgRZGl3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8BxfzPCXZGiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "McegS308Y70c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U_xB-2f5Y0-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###training log"
      ],
      "metadata": {
        "id": "CgApkVrOTpWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WP"
      ],
      "metadata": {
        "id": "MqIFAWs1zSH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_5(args, global_step=0, best_dev_epoch=0, is_finetuning_on_new_ds=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "da08b250a2ae4ea88d26f4890973d381",
            "c53ccd7de8d347ce8080218924b9046d",
            "6563bb5b16c94edf8afec890787172d8",
            "d3947356e07c475b921a7cdc61bf2cb9",
            "b24149bdc2414cdb8051e43f63d9bd08",
            "55ca8bf5c45246d4b84e16114532cc3d",
            "e0208f60c5274d789155f574a96b2aff",
            "fd2f5a2c8e7c4829ad2bba28e0dfb981",
            "1aa378ecdefb446cbfb4570900e74326",
            "779c60e92fda4d55a31c1ed575ed1642",
            "2aee1fe75fd74598a59fc6128a2a5d59",
            "ad5e818866a04f938d87726fc749e928",
            "50dd4b9826364386ab7784bdcbc1899c",
            "03be80ee9a8e48c48747e465554ac286",
            "b7743c8000314f1e8faa840503a54676",
            "0140104ac9134182ae7ac7e261ead3a3",
            "184c38f22d3c4446a6bed8cf63aa3e46",
            "26bb1f91f5534810be04c8b6eea39a02",
            "ad7e58b260ce4de7b549903804e9cf79",
            "90c9f2bda4254b459f7d8db05eb50bbe",
            "0e1a328b48e34d5086cb368a507c0b72",
            "48e52f5125a745488a88ef2de80c0059",
            "39eb5f934f0645599398d18dac3d0963",
            "b57d6cd749c342199a7804e70578ad07",
            "55759c6bd8334e3586d64b7ad1dfa0e8",
            "bdba0d427e1340e9add0e455b0e87c28",
            "c590a6cb26c4455bb81c5455599b2819",
            "0d06c01da4a34464ba8eb874f6ccfd5b",
            "ebc765b0a8c642948daceb766449a24a",
            "3135ad0105f44fbe938c75b8a7bc9566",
            "b40fd335765f4d36b96a9041df049bf3",
            "44ceea0d9a1241ea8466259a5bff0496",
            "67ddaaa54f094efb9165448d7e169934",
            "e62a2ddd11df44a9b36ff5e9d91df555",
            "7e0db9fdf36846a19456e06008f45ae6",
            "00a8013a0d8a464b808154cde864da2d",
            "8114512a97fb4b159ec932410b621c67",
            "2ab0f53136624ff7a8873f215f314b53",
            "ba2b614ffe6145c5af3f5c2ec062c6a7",
            "3d5a11a0567e49e78a269819598a723b",
            "6c9fc7e9af8f4ceeac5f7ca996fc3187",
            "d2a8bd29e1b54ab3b755eb11d8e3f94d",
            "ccc367c6753d4d0a9094d3c83423e437",
            "3bb73f943e9948249dd6cf4038b84792",
            "d9a23ebef9c6424da52f864820f80fe2",
            "2b5fe1f08558497a88ecee62842a34bd",
            "cc6d067f377e4a46bbe8f28cbf96c08c",
            "4fe9a49d88bf4f13a37dabad77d90683",
            "123d05a3f05b4f63b2a89e234cf9ca83",
            "5cbc4b5cf49340b3ae615a4e2c886f74",
            "7c2cd7fea8bb4d8c8cca1c9973f7ce2e",
            "f39a22c9741f4c7ebeb3e9ed9cc86ccf",
            "fd9ddc994d18442a822948b13f7f384e",
            "b51218db8c414f63b4f3ad724ca8aba9",
            "b24ff947a28947ca89cecf6902ca8106"
          ]
        },
        "id": "PfSWIkwuzRCI",
        "outputId": "7e187fa5-fa04-45b2-a808-02506bdf836c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'enc': 'roberta-large', 'encoder': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_log_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 5, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'brain_teaser_ds', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/WP_inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'load_model_path': None, 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da08b250a2ae4ea88d26f4890973d381"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad5e818866a04f938d87726fc749e928"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39eb5f934f0645599398d18dac3d0963"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e62a2ddd11df44a9b36ff5e9d91df555"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 356/356 [00:00<00:00, 734.31it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 131.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_choice 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading adj matrices: 100%|██████████| 1424/1424 [00:03<00:00, 425.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ori_adj_len: mu 96.10 sigma 96.83 | adj_len: 85.07 | prune_rate： 0.10 | qc_num: 6.03 | ac_num: 2.34 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading adj matrices: 100%|██████████| 160/160 [00:00<00:00, 396.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ori_adj_len: mu 125.84 sigma 140.18 | adj_len: 94.26 | prune_rate： 0.20 | qc_num: 6.69 | ac_num: 2.72 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9a23ebef9c6424da52f864820f80fe2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-9-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "100%|██████████| 20/20 [00:04<00:00,  4.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   0 | step     3 | dev_acc  0.3500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.0.best_model\n",
            "epoch: 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| step     4 |  lr: 0.0002000 | loss  1.3827 | ms/batch 7162.25 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   1 | step     6 | dev_acc  0.3000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.1.temp_checkpoint\n",
            "epoch: 3/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   2 | step     9 | dev_acc  0.3000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.2.temp_checkpoint\n",
            "epoch: 4/100\n",
            "| step     9 |  lr: 0.0002000 | loss  1.3972 | ms/batch 3216.66 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   3 | step    12 | dev_acc  0.3250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.3.temp_checkpoint\n",
            "epoch: 5/100\n",
            "| step    14 |  lr: 0.0002000 | loss  1.3975 | ms/batch 21157.42 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   4 | step    15 | dev_acc  0.3500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.4.best_model\n",
            "epoch: 6/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   5 | step    18 | dev_acc  0.4000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.5.best_model\n",
            "epoch: 7/100\n",
            "| step    19 |  lr: 0.0002000 | loss  1.3851 | ms/batch 16768.43 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   6 | step    21 | dev_acc  0.4500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.6.best_model\n",
            "epoch: 8/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   7 | step    24 | dev_acc  0.3750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.7.temp_checkpoint\n",
            "epoch: 9/100\n",
            "| step    24 |  lr: 0.0002000 | loss  1.3558 | ms/batch 7610.88 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   8 | step    27 | dev_acc  0.5500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.8.best_model\n",
            "epoch: 10/100\n",
            "| step    29 |  lr: 0.0002000 | loss  1.2699 | ms/batch 22561.66 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   9 | step    30 | dev_acc  0.5250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.9.temp_checkpoint\n",
            "epoch: 11/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  10 | step    33 | dev_acc  0.6750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.10.best_model\n",
            "epoch: 12/100\n",
            "| step    34 |  lr: 0.0002000 | loss  1.1872 | ms/batch 16153.47 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  11 | step    36 | dev_acc  0.5500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.11.temp_checkpoint\n",
            "epoch: 13/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  12 | step    39 | dev_acc  0.6250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.12.temp_checkpoint\n",
            "epoch: 14/100\n",
            "| step    39 |  lr: 0.0002000 | loss  1.0961 | ms/batch 7556.55 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  13 | step    42 | dev_acc  0.5250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.13.temp_checkpoint\n",
            "epoch: 15/100\n",
            "| step    44 |  lr: 0.0002000 | loss  0.9754 | ms/batch 21631.47 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  14 | step    45 | dev_acc  0.5750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.14.temp_checkpoint\n",
            "epoch: 16/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  15 | step    48 | dev_acc  0.6250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.15.temp_checkpoint\n",
            "epoch: 17/100\n",
            "| step    49 |  lr: 0.0002000 | loss  0.9065 | ms/batch 15163.23 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  16 | step    51 | dev_acc  0.6500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.16.temp_checkpoint\n",
            "epoch: 18/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  17 | step    54 | dev_acc  0.6250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.17.temp_checkpoint\n",
            "epoch: 19/100\n",
            "| step    54 |  lr: 0.0002000 | loss  0.7782 | ms/batch 7389.65 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  18 | step    57 | dev_acc  0.6750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.18.best_model\n",
            "epoch: 20/100\n",
            "| step    59 |  lr: 0.0002000 | loss  0.6893 | ms/batch 22117.43 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  19 | step    60 | dev_acc  0.6500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.19.temp_checkpoint\n",
            "epoch: 21/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  20 | step    63 | dev_acc  0.7500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.20.best_model\n",
            "epoch: 22/100\n",
            "| step    64 |  lr: 0.0002000 | loss  0.6474 | ms/batch 15878.71 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:05<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  21 | step    66 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.21.best_model\n",
            "epoch: 23/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  22 | step    69 | dev_acc  0.7000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.22.temp_checkpoint\n",
            "epoch: 24/100\n",
            "| step    69 |  lr: 0.0002000 | loss  0.6076 | ms/batch 7881.98 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  23 | step    72 | dev_acc  0.6500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.23.temp_checkpoint\n",
            "epoch: 25/100\n",
            "| step    74 |  lr: 0.0002000 | loss  0.5705 | ms/batch 22000.06 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  24 | step    75 | dev_acc  0.7000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.24.temp_checkpoint\n",
            "epoch: 26/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  25 | step    78 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.25.best_model\n",
            "epoch: 27/100\n",
            "| step    79 |  lr: 0.0002000 | loss  0.5138 | ms/batch 16186.27 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  26 | step    81 | dev_acc  0.6750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.26.temp_checkpoint\n",
            "epoch: 28/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  27 | step    84 | dev_acc  0.8000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.27.best_model\n",
            "epoch: 29/100\n",
            "| step    84 |  lr: 0.0002000 | loss  0.4149 | ms/batch 8096.94 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  28 | step    87 | dev_acc  0.8500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.28.best_model\n",
            "epoch: 30/100\n",
            "| step    89 |  lr: 0.0002000 | loss  0.4161 | ms/batch 21993.22 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  29 | step    90 | dev_acc  0.8000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.29.temp_checkpoint\n",
            "epoch: 31/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  30 | step    93 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.30.temp_checkpoint\n",
            "epoch: 32/100\n",
            "| step    94 |  lr: 0.0002000 | loss  0.3647 | ms/batch 15238.64 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  31 | step    96 | dev_acc  0.6750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.31.temp_checkpoint\n",
            "epoch: 33/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  32 | step    99 | dev_acc  0.7000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.32.temp_checkpoint\n",
            "epoch: 34/100\n",
            "| step    99 |  lr: 0.0002000 | loss  0.3371 | ms/batch 7659.41 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  33 | step   102 | dev_acc  0.7500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.33.temp_checkpoint\n",
            "epoch: 35/100\n",
            "| step   104 |  lr: 0.0002000 | loss  0.3035 | ms/batch 21304.68 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  34 | step   105 | dev_acc  0.7000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.34.temp_checkpoint\n",
            "epoch: 36/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  35 | step   108 | dev_acc  0.8000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.35.temp_checkpoint\n",
            "epoch: 37/100\n",
            "| step   109 |  lr: 0.0002000 | loss  0.2890 | ms/batch 15592.68 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  36 | step   111 | dev_acc  0.8000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.36.temp_checkpoint\n",
            "epoch: 38/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  37 | step   114 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.37.temp_checkpoint\n",
            "epoch: 39/100\n",
            "| step   114 |  lr: 0.0002000 | loss  0.2458 | ms/batch 7551.11 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  38 | step   117 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.38.temp_checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hlw3He-TzXNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SP"
      ],
      "metadata": {
        "id": "y6DAQH-EYEFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_5(args, global_step=0, best_dev_epoch=0, is_finetuning_on_new_ds=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "335e2ade96b944afa78c08547f49424e",
            "b3287038fa03496cbdccd208b15e3aae",
            "bed0e4384b81410d9b2ed4bb9abfdc26",
            "7016007772b541879b219753b39b7ecb",
            "9f1dd37dada047a1995c9900ecefe95b",
            "1a99ae3a2e494e4c80cd2a71f3f9a6bf",
            "e8aa239127f34a80a9b0e28882325a6d",
            "f06082dbe7ec4188b2b5dbd26240748a",
            "a85eb15d779c4e64bd86a6d2f454df3f",
            "f1e9ea89cb3a4a4e927d05b319e45a93",
            "c8276523d6774d24a1d643f8d332647e",
            "d4cdd06b10b6478a8296185bfae7b253",
            "a4c013e3cfb643aaa583cfa6cd788751",
            "8a75358f71d041be8dfe50ff9039ca94",
            "4da880003fd64007bcde4dfcb0464188",
            "9495d47f80fd47c3ba95367a9aed3f48",
            "37cc5eb2914342eb8776bb5ef264c375",
            "9d48249ea94f45b0883fb16495ed2250",
            "1f605054b5fd44d3b090b4c37aca2852",
            "724c50bbc515459fa197d5d0d3a5ee8a",
            "c16887ff6e1a4c6f960cd5c111d63564",
            "e3e6b7c7157b4a9fae9bf578f12b7bb2",
            "6fa8e8195345486b941b2c88375a363a",
            "54f1ec5ca49f41cfa6c3ab7195d9253d",
            "8347f9a622d5408a97ac65ac3d5127b6",
            "926a3681c410457e94b8e3dc77c43201",
            "5eaf650332a34543b6cb30a36026d0ac",
            "2556bd77180e45dfa9fe05b724221ed9",
            "bf3917f00a9e479ea5a3814614e340da",
            "69c7e125d52a4bf29cad6c046cf9d978",
            "d11301ee310d42158d0e57fc3a192514",
            "311a6fd8c34a42158c10bf2bda483158",
            "d81c31f91e3d448c90c5b59277b5b0cb",
            "82c50447c1814fad890e5e0ba1b81ba4",
            "85449c3c33db4162b75a36c53edc5f93",
            "8f6839c793be4ea0bb0365a716aa0ddb",
            "7c13d49d519b4746934cd054cd31c31f",
            "c85162d9728a44419a10c0e797262665",
            "1c5b1686293c4139a5e32cb2f60faaff",
            "e0692b04da324e88a73f8d58df3c726f",
            "0a0a057bbcdc4d65b4152dd01dc7eff2",
            "87cc6a97c5194cdeba9df71edb0b2f4e",
            "5b8a5ace21b44a2990f04f358532049d",
            "4a134e7f56ee480c8516e42d78282d80",
            "37154188120e4a3da95063f785d67d4e",
            "4ac02d5286a64ad2ac1669ca843a4394",
            "206c0cd7957649de9ea966d0dfed363d",
            "604c4bf7f7c24cc4a213193382c88dd9",
            "ca2826857d9a42b6b8c9675c1576ebb2",
            "08c19d36fa5946f0b64c232eaa1f1cf0",
            "47f540779d514c51a54a309b5bc7dd6d",
            "c6eb666020b34beeae236d6af4ad0ae9",
            "c2b011c0179a4e43818140fdf0b21436",
            "bc3eaf073d8048aba01fc89ce151b5c2",
            "627dcba5f6074e27b8aef1122a131216"
          ]
        },
        "id": "2v5bJ7AIDAXi",
        "outputId": "048c6110-9cb3-4e34-b8fe-7cd4cb8d99d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'enc': 'roberta-large', 'encoder': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_log_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 5, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'brain_teaser_ds', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'load_model_path': None, 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "335e2ade96b944afa78c08547f49424e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4cdd06b10b6478a8296185bfae7b253",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fa8e8195345486b941b2c88375a363a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82c50447c1814fad890e5e0ba1b81ba4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 456/456 [00:01<00:00, 429.49it/s]\n",
            "100%|██████████| 51/51 [00:00<00:00, 962.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading adj matrices: 100%|██████████| 1824/1824 [00:09<00:00, 189.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ori_adj_len: mu 395.12 sigma 287.74 | adj_len: 177.72 | prune_rate： 0.73 | qc_num: 18.76 | ac_num: 5.46 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading adj matrices: 100%|██████████| 204/204 [00:01<00:00, 171.28it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ori_adj_len: mu 384.36 sigma 272.02 | adj_len: 175.26 | prune_rate： 0.69 | qc_num: 18.13 | ac_num: 5.17 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37154188120e4a3da95063f785d67d4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 1/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-6-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "100%|██████████| 26/26 [00:05<00:00,  4.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   0 | step     4 | dev_acc  0.2941 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.0.best_model\n",
            "epoch: 2/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     4 |  lr: 0.0002000 | loss  1.3886 | ms/batch 4270.95 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:05<00:00,  4.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   1 | step     8 | dev_acc  0.3333 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.1.best_model\n",
            "epoch: 3/100\n",
            "| step     9 |  lr: 0.0002000 | loss  1.3929 | ms/batch 8118.87 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:05<00:00,  4.34it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   2 | step    12 | dev_acc  0.3529 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.2.best_model\n",
            "epoch: 4/100\n",
            "| step    14 |  lr: 0.0002000 | loss  1.3864 | ms/batch 12416.27 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:05<00:00,  4.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   3 | step    16 | dev_acc  0.3725 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.3.best_model\n",
            "epoch: 5/100\n",
            "| step    19 |  lr: 0.0002000 | loss  1.3744 | ms/batch 30094.43 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   4 | step    20 | dev_acc  0.2941 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.4.temp_checkpoint\n",
            "epoch: 6/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   5 | step    24 | dev_acc  0.3137 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.5.temp_checkpoint\n",
            "epoch: 7/100\n",
            "| step    24 |  lr: 0.0002000 | loss  1.3555 | ms/batch 8520.36 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   6 | step    28 | dev_acc  0.3922 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.6.best_model\n",
            "epoch: 8/100\n",
            "| step    29 |  lr: 0.0002000 | loss  1.3122 | ms/batch 17221.87 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   7 | step    32 | dev_acc  0.5098 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.7.best_model\n",
            "epoch: 9/100\n",
            "| step    34 |  lr: 0.0002000 | loss  1.1865 | ms/batch 25619.06 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   8 | step    36 | dev_acc  0.5490 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.8.best_model\n",
            "epoch: 10/100\n",
            "| step    39 |  lr: 0.0002000 | loss  0.9460 | ms/batch 30305.18 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   9 | step    40 | dev_acc  0.7059 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.9.best_model\n",
            "epoch: 11/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  10 | step    44 | dev_acc  0.7255 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.10.best_model\n",
            "epoch: 12/100\n",
            "| step    44 |  lr: 0.0002000 | loss  0.6761 | ms/batch 8644.03 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  11 | step    48 | dev_acc  0.6471 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.11.temp_checkpoint\n",
            "epoch: 13/100\n",
            "| step    49 |  lr: 0.0002000 | loss  0.5054 | ms/batch 16882.62 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  12 | step    52 | dev_acc  0.6667 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.12.temp_checkpoint\n",
            "epoch: 14/100\n",
            "| step    54 |  lr: 0.0002000 | loss  0.3977 | ms/batch 25291.06 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  13 | step    56 | dev_acc  0.7059 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.13.temp_checkpoint\n",
            "epoch: 15/100\n",
            "| step    59 |  lr: 0.0002000 | loss  0.3301 | ms/batch 30072.13 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  14 | step    60 | dev_acc  0.7255 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.14.best_model\n",
            "epoch: 16/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  15 | step    64 | dev_acc  0.7451 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.15.best_model\n",
            "epoch: 17/100\n",
            "| step    64 |  lr: 0.0002000 | loss  0.3201 | ms/batch 8640.94 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  16 | step    68 | dev_acc  0.7647 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.16.best_model\n",
            "epoch: 18/100\n",
            "| step    69 |  lr: 0.0002000 | loss  0.2955 | ms/batch 17222.62 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  17 | step    72 | dev_acc  0.7843 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.17.best_model\n",
            "epoch: 19/100\n",
            "| step    74 |  lr: 0.0002000 | loss  0.2796 | ms/batch 25746.94 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  18 | step    76 | dev_acc  0.8039 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.18.best_model\n",
            "epoch: 20/100\n",
            "| step    79 |  lr: 0.0002000 | loss  0.2392 | ms/batch 30359.14 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  19 | step    80 | dev_acc  0.8039 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.19.best_model\n",
            "epoch: 21/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  20 | step    84 | dev_acc  0.8039 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.20.best_model\n",
            "epoch: 22/100\n",
            "| step    84 |  lr: 0.0002000 | loss  0.1968 | ms/batch 8727.34 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  21 | step    88 | dev_acc  0.8039 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.21.best_model\n",
            "epoch: 23/100\n",
            "| step    89 |  lr: 0.0002000 | loss  0.1624 | ms/batch 17135.65 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  22 | step    92 | dev_acc  0.8235 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.22.best_model\n",
            "epoch: 24/100\n",
            "| step    94 |  lr: 0.0002000 | loss  0.1574 | ms/batch 25558.63 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  23 | step    96 | dev_acc  0.8039 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.23.temp_checkpoint\n",
            "epoch: 25/100\n",
            "| step    99 |  lr: 0.0002000 | loss  0.1380 | ms/batch 30055.23 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  24 | step   100 | dev_acc  0.8039 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.24.temp_checkpoint\n",
            "epoch: 26/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  25 | step   104 | dev_acc  0.8235 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.25.best_model\n",
            "epoch: 27/100\n",
            "| step   104 |  lr: 0.0002000 | loss  0.1323 | ms/batch 8670.39 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  26 | step   108 | dev_acc  0.8039 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.26.temp_checkpoint\n",
            "epoch: 28/100\n",
            "| step   109 |  lr: 0.0002000 | loss  0.1363 | ms/batch 16916.75 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  27 | step   112 | dev_acc  0.8235 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.27.best_model\n",
            "epoch: 29/100\n",
            "| step   114 |  lr: 0.0002000 | loss  0.1433 | ms/batch 25528.02 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.13it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  28 | step   116 | dev_acc  0.8431 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.28.best_model\n",
            "epoch: 30/100\n",
            "| step   119 |  lr: 0.0002000 | loss  0.1096 | ms/batch 30326.40 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  29 | step   120 | dev_acc  0.7843 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.29.temp_checkpoint\n",
            "epoch: 31/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  30 | step   124 | dev_acc  0.8431 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.30.best_model\n",
            "epoch: 32/100\n",
            "| step   124 |  lr: 0.0002000 | loss  0.1010 | ms/batch 8723.30 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  31 | step   128 | dev_acc  0.8431 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.31.best_model\n",
            "epoch: 33/100\n",
            "| step   129 |  lr: 0.0002000 | loss  0.0768 | ms/batch 17341.00 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.22it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  32 | step   132 | dev_acc  0.8431 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.32.best_model\n",
            "epoch: 34/100\n",
            "| step   134 |  lr: 0.0002000 | loss  0.0683 | ms/batch 25684.14 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  33 | step   136 | dev_acc  0.9020 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/new_SP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.33.best_model\n",
            "epoch: 35/100\n",
            "| step   139 |  lr: 0.0002000 | loss  0.0645 | ms/batch 30239.02 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  34 | step   140 | dev_acc  0.8431 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.34.temp_checkpoint\n",
            "epoch: 36/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.20it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  35 | step   144 | dev_acc  0.8235 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.35.temp_checkpoint\n",
            "epoch: 37/100\n",
            "| step   144 |  lr: 0.0002000 | loss  0.0546 | ms/batch 8498.26 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  36 | step   148 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.36.temp_checkpoint\n",
            "epoch: 38/100\n",
            "| step   149 |  lr: 0.0002000 | loss  0.0596 | ms/batch 16863.40 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.23it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  37 | step   152 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.37.temp_checkpoint\n",
            "epoch: 39/100\n",
            "| step   154 |  lr: 0.0002000 | loss  0.0387 | ms/batch 25234.83 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  38 | step   156 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.38.temp_checkpoint\n",
            "epoch: 40/100\n",
            "| step   159 |  lr: 0.0002000 | loss  0.0344 | ms/batch 30047.69 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  39 | step   160 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.39.temp_checkpoint\n",
            "epoch: 41/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  40 | step   164 | dev_acc  0.8235 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.40.temp_checkpoint\n",
            "epoch: 42/100\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.40.temp_checkpoint\n",
            "epoch: 42/100\n",
            "| step   164 |  lr: 0.0002000 | loss  0.0547 | ms/batch 8480.43 |\n",
            "| step   164 |  lr: 0.0002000 | loss  0.0547 | ms/batch 8480.43 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.20it/s]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  41 | step   168 | dev_acc  0.8235 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            "| epoch  41 | step   168 | dev_acc  0.8235 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.41.temp_checkpoint\n",
            "epoch: 43/100\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.41.temp_checkpoint\n",
            "epoch: 43/100\n",
            "| step   169 |  lr: 0.0002000 | loss  0.0324 | ms/batch 16897.30 |\n",
            "| step   169 |  lr: 0.0002000 | loss  0.0324 | ms/batch 16897.30 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.23it/s]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  42 | step   172 | dev_acc  0.8039 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            "| epoch  42 | step   172 | dev_acc  0.8039 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.42.temp_checkpoint\n",
            "epoch: 44/100\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.42.temp_checkpoint\n",
            "epoch: 44/100\n",
            "| step   174 |  lr: 0.0002000 | loss  0.0210 | ms/batch 25295.92 |\n",
            "| step   174 |  lr: 0.0002000 | loss  0.0210 | ms/batch 25295.92 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.23it/s]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  43 | step   176 | dev_acc  0.8627 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------\n",
            "| epoch  43 | step   176 | dev_acc  0.8627 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.43.temp_checkpoint\n",
            "model saved to /content/new_SP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.43.temp_checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01V0oxp4DAUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PdIXtub9DAPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###predict"
      ],
      "metadata": {
        "id": "5LyLIwqsVzbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Ye96dUXerBI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SP_pred"
      ],
      "metadata": {
        "id": "Y7LaXhJ-rIqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args[\"save_test_preds\"]=True\n",
        "\n",
        "k=5 #num of gnn layers\n",
        "\n",
        "task_type=\"SP\"\n",
        "args[\"load_model_path\"]=f\"/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/{task_type}_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.21.best_model\"\n",
        "main_dir='/content/drive/MyDrive/brain_teaser'\n",
        "save_dir_pref=f\"{main_dir}/QA_GNN/saved_models\"\n",
        "dataset=\"brain_teaser_ds\"\n",
        "model='roberta-large'\n",
        "\n",
        "args[\"train_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_train.graph.adj.pk\"\n",
        "args[\"dev_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_dev.graph.adj.pk\"\n",
        "args[\"test_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_test.graph.adj.pk\"\n",
        "\n",
        "args[\"train_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_train.statement.jsonl\"\n",
        "args[\"dev_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_dev.statement.jsonl\"\n",
        "args[\"test_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_test.statement.jsonl\"\n",
        "\n",
        "args[\"best_model_save_dir\"]=f\"{save_dir_pref}/{task_type}_best_model_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"log_save_dir\"]=f\"{save_dir_pref}/{task_type}_log_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n"
      ],
      "metadata": {
        "id": "uSRpQnUtWAHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp_test_pred=predict(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549,
          "referenced_widgets": [
            "e36b6fe5fbb14f36b6568908738b85f1",
            "f6e6e42701b94af8af60cf011a25d253",
            "8e4935de4f664b308e28e15e9ab58607",
            "e00054ca95d44b3dab4123a233b8e40f",
            "5d728d028af84c159482ed6dd5f48167",
            "c1ec50d9822e416e9300b6f8dacf1d93",
            "6fb9b6d17efb4e36958ba27fa8fa196c",
            "95d0bf77cdc64b689f81af267b5af887",
            "4c778f96c446471ab439966bd8e649e4",
            "01fb165adc4e4438980fd14652d6be8d",
            "058001829eca48b18330b503178f71d5",
            "f0ee3880095041b5a9d80412f7a8e45f",
            "f9137528826542ffb365e5ca1065e785",
            "86a05d05cb8046618d69bc15edd41f36",
            "2b79b001a0044b16bfb582d28073495e",
            "ef4e1e75033f4625ad6a1088c0f4b880",
            "410a604a70e04407a867e5cf93ad828a",
            "4218a21fb11a4031be7d5ca3ac90572d",
            "5e820a3180ef42979b8400e3ab5c9c13",
            "e8553aa6a04b4e82a0f95541dc09f0c2",
            "6a626e3e19da47aeac31719a61157c50",
            "7da25e044e59453dbcf3fe17cc052957",
            "25716adacaae4424ace1712030178f0c",
            "15a180a9fe3645e8a4ba57044112ce61",
            "262cda27d8554e888f08741ceef1b1c3",
            "3b4fe7014c8c4b5ebc00cd2bf65e2260",
            "239a76d30aad4c0e83ed9b3d8c327ef6",
            "dd0dfa913df54c09aab19434c7c674ea",
            "d7f33d3cd07d439684427b04e18c85db",
            "69947ea716504a059028c992bbca6b48",
            "759a95ca398c49259d888ca2855178c1",
            "a29178650fef4bcbbf402c87a61ecf71",
            "76852921ecdc49fba4bac6a5861ff20c"
          ]
        },
        "id": "d-jlU_5EXwJF",
        "outputId": "fa2f7913-d6ea-4dec-83ed-4a7c7f79455f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| num_concepts: 799273 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inhouse? False\n",
            "args.train_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl\n",
            "args.dev_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_dev.statement.jsonl\n",
            "args.test_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_test.statement.jsonl\n",
            "args.train_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_train.graph.adj.pk\n",
            "args.dev_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_dev.graph.adj.pk\n",
            "args.test_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_test.graph.adj.pk\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e36b6fe5fbb14f36b6568908738b85f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0ee3880095041b5a9d80412f7a8e45f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25716adacaae4424ace1712030178f0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 456/456 [00:00<00:00, 886.06it/s]\n",
            "100%|██████████| 51/51 [00:00<00:00, 797.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_choice 4\n",
            "| ori_adj_len: mu 394.59 sigma 290.55 | adj_len: 177.47 | prune_rate： 0.72 | qc_num: 18.76 | ac_num: 5.36 |\n",
            "| ori_adj_len: mu 386.00 sigma 252.60 | adj_len: 180.20 | prune_rate： 0.80 | qc_num: 17.96 | ac_num: 6.38 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:00<00:00, 794.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ori_adj_len: mu 448.84 sigma 297.23 | adj_len: 183.54 | prune_rate： 0.78 | qc_num: 21.48 | ac_num: 5.64 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev_acc  0.9412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [00:13<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sp_test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tfmn5mTaj4w",
        "outputId": "bc6051ee-bed7-476b-ac95-a74505404077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SP_dataset_val = np.load('/content/drive/MyDrive/brain_teaser/datasets/SP_eval_data_for_practice.npy', allow_pickle=True,encoding='bytes')\n",
        "print(len(SP_dataset_val))\n",
        "\n",
        "data_dict = {'question':[],\n",
        "             'choice_list':[]}\n",
        "for i in SP_dataset_val:\n",
        "  for k,v in i.items():\n",
        "    data_dict[k].append(v)\n",
        "\n",
        "SP_val_df = pd.DataFrame(data_dict, columns=['question', 'choice_list'])\n",
        "SP_val_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "BOlH3ILBoZnn",
        "outputId": "34191742-b9ac-4ddc-be0a-8f06c3cc78f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  Everyone called him \"Batman,\" but he knew noth...   \n",
              "1  All of Mrs. Smith pets are dogs except one, an...   \n",
              "\n",
              "                                         choice_list  \n",
              "0  [He tries to be friendly., He is afraid others...  \n",
              "1  [Mrs.Smith has one additional pet that is neit...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2aefe198-f958-4ca8-9dc1-db3653065b9f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Everyone called him \"Batman,\" but he knew noth...</td>\n",
              "      <td>[He tries to be friendly., He is afraid others...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>All of Mrs. Smith pets are dogs except one, an...</td>\n",
              "      <td>[Mrs.Smith has one additional pet that is neit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2aefe198-f958-4ca8-9dc1-db3653065b9f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2aefe198-f958-4ca8-9dc1-db3653065b9f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2aefe198-f958-4ca8-9dc1-db3653065b9f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bf7202d6-8046-4346-b450-006d9d4a7b8c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf7202d6-8046-4346-b450-006d9d4a7b8c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bf7202d6-8046-4346-b450-006d9d4a7b8c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids=[]\n",
        "questions=[]\n",
        "choice_lists=[]\n",
        "predicted_labels=[]\n",
        "\n",
        "for i in tqdm(range(len(SP_val_df))):\n",
        "  sample=SP_val_df.iloc[i]\n",
        "  pred=sp_test_pred[i]\n",
        "  ids.append(i)\n",
        "  questions.append(sample['question'].strip())\n",
        "  predicted_labels.append(pred)\n",
        "  choice_lists.append(sample['choice_list'])\n",
        "\n",
        "temp_dict={'id':ids,\n",
        "'question':questions,\n",
        "'choice_list':choice_lists,\n",
        "'label':predicted_labels}\n",
        "\n",
        "sp_new_df=pd.DataFrame(data=temp_dict)\n",
        "sp_new_df"
      ],
      "metadata": {
        "id": "Ptneb8kNsaPv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "55225d2b-e609-4754-fde8-18a5b42fc50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:00<00:00, 17489.63it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                           question  \\\n",
              "0      0  Everyone called him \"Batman,\" but he knew noth...   \n",
              "1      1  All of Mrs. Smith pets are dogs except one, an...   \n",
              "2      2  Three doors are present. Every door has a way ...   \n",
              "3      3  Tom and his younger sister were fighting. Thei...   \n",
              "4      4  A woman sells a bottle of perfume to a man for...   \n",
              "..   ...                                                ...   \n",
              "115  115  How was it possible for a cowboy to arrive in ...   \n",
              "116  116  Natives of the Arctic will never eat a penguin...   \n",
              "117  117  A full water glass was in the hands of the mag...   \n",
              "118  118  Which could see the best in complete darkness?...   \n",
              "119  119  The ship was in the harbor on a beautiful sunn...   \n",
              "\n",
              "                                           choice_list  label  \n",
              "0    [He tries to be friendly., He is afraid others...      2  \n",
              "1    [Mrs.Smith has one additional pet that is neit...      2  \n",
              "2    [The third door, the alligator can be tierd an...      1  \n",
              "3    [Tom's mother slid a newspaper under a door, e...      1  \n",
              "4    [Fifteen dollars., Fifteen dollars plus the pe...      1  \n",
              "..                                                 ...    ...  \n",
              "115  [His horse is named Wednesday., Friday and Sat...      0  \n",
              "116  [Penguins only live in Antarctica., Penguins' ...      0  \n",
              "117  [Surface tension prevents water from spilling....      2  \n",
              "118               [Bat., Tiger., Owl., None of above.]      3  \n",
              "119  [There are too many fish around the ship., The...      2  \n",
              "\n",
              "[120 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17039faa-df5f-4987-819b-3dae8234a223\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Everyone called him \"Batman,\" but he knew noth...</td>\n",
              "      <td>[He tries to be friendly., He is afraid others...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>All of Mrs. Smith pets are dogs except one, an...</td>\n",
              "      <td>[Mrs.Smith has one additional pet that is neit...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Three doors are present. Every door has a way ...</td>\n",
              "      <td>[The third door, the alligator can be tierd an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Tom and his younger sister were fighting. Thei...</td>\n",
              "      <td>[Tom's mother slid a newspaper under a door, e...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>A woman sells a bottle of perfume to a man for...</td>\n",
              "      <td>[Fifteen dollars., Fifteen dollars plus the pe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>115</td>\n",
              "      <td>How was it possible for a cowboy to arrive in ...</td>\n",
              "      <td>[His horse is named Wednesday., Friday and Sat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>116</td>\n",
              "      <td>Natives of the Arctic will never eat a penguin...</td>\n",
              "      <td>[Penguins only live in Antarctica., Penguins' ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>117</td>\n",
              "      <td>A full water glass was in the hands of the mag...</td>\n",
              "      <td>[Surface tension prevents water from spilling....</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>118</td>\n",
              "      <td>Which could see the best in complete darkness?...</td>\n",
              "      <td>[Bat., Tiger., Owl., None of above.]</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>119</td>\n",
              "      <td>The ship was in the harbor on a beautiful sunn...</td>\n",
              "      <td>[There are too many fish around the ship., The...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17039faa-df5f-4987-819b-3dae8234a223')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17039faa-df5f-4987-819b-3dae8234a223 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17039faa-df5f-4987-819b-3dae8234a223');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0d4ec573-820c-4f5a-a201-fd28655b387e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d4ec573-820c-4f5a-a201-fd28655b387e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0d4ec573-820c-4f5a-a201-fd28655b387e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "dt = datetime.datetime.today().strftime('%Y_%m_%d')\n",
        "dt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YiZo0MO0FnB0",
        "outputId": "318db34e-9992-480c-c58b-ad51bd7c4a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2023_12_13'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp_new_df.to_csv(f\"/content/drive/MyDrive/brain_teaser/SP_qagnn_predictions_{dt}.csv\", index=False)"
      ],
      "metadata": {
        "id": "LmV68Uh2rFW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=[str(x) for x in sp_new_df['label'].values]\n",
        "with open('answer_sen.txt', 'w') as f:\n",
        "    f.write('\\n'.join(res))"
      ],
      "metadata": {
        "id": "xgDPtV_BRgum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yX6mFtDaLRyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WP_pred"
      ],
      "metadata": {
        "id": "vDuX6xyIrFtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args[\"save_test_preds\"]=True\n",
        "\n",
        "k=5 #num of gnn layers\n",
        "task_type=\"WP\"\n",
        "args[\"load_model_path\"]=f\"/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/{task_type}_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.26.best_model\"\n",
        "\n",
        "main_dir='/content/drive/MyDrive/brain_teaser'\n",
        "save_dir_pref=f\"{main_dir}/QA_GNN/saved_models\"\n",
        "dataset=\"brain_teaser_ds\"\n",
        "model='roberta-large'\n",
        "\n",
        "args[\"train_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_train.graph.adj.pk\"\n",
        "args[\"dev_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_dev.graph.adj.pk\"\n",
        "args[\"test_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/{task_type}_test.graph.adj.pk\"\n",
        "\n",
        "args[\"train_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_train.statement.jsonl\"\n",
        "args[\"dev_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_dev.statement.jsonl\"\n",
        "args[\"test_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/{task_type}_test.statement.jsonl\"\n",
        "\n",
        "args[\"best_model_save_dir\"]=f\"{save_dir_pref}/{task_type}_best_model_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"log_save_dir\"]=f\"{save_dir_pref}/{task_type}_log_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n"
      ],
      "metadata": {
        "id": "T6IY21pbc9kA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args[\"log_save_dir\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "o3QoGxSZHy5Q",
        "outputId": "0997fc80-9100-472e-cb11-3513f128e05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_log_brain_teaser_ds__enc-roberta-large_kchoice_list__gnndim200__bs128__seed0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wp_test_pred=predict(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZulWYrLdGNE",
        "outputId": "c3120944-cf27-46de-a413-446c6362515b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| num_concepts: 799273 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inhouse? False\n",
            "args.train_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl\n",
            "args.dev_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_dev.statement.jsonl\n",
            "args.test_statements /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_test.statement.jsonl\n",
            "args.train_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_train.graph.adj.pk\n",
            "args.dev_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_dev.graph.adj.pk\n",
            "args.test_adj /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_test.graph.adj.pk\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 356/356 [00:00<00:00, 1591.38it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 1627.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_choice 4\n",
            "| ori_adj_len: mu 98.33 sigma 98.79 | adj_len: 86.43 | prune_rate： 0.11 | qc_num: 6.04 | ac_num: 2.41 |\n",
            "| ori_adj_len: mu 82.68 sigma 82.56 | adj_len: 76.02 | prune_rate： 0.05 | qc_num: 5.01 | ac_num: 2.23 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:00<00:00, 1540.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ori_adj_len: mu 112.62 sigma 128.16 | adj_len: 91.44 | prune_rate： 0.14 | qc_num: 6.42 | ac_num: 3.11 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev_acc  0.8500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [00:14<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(wp_test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waHJwCEsV1wu",
        "outputId": "b2fda0e8-3b28-4879-9430-7890e30bbd84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WP_dataset_val = np.load('/content/drive/MyDrive/brain_teaser/datasets/WP_eval_data_for_practice.npy', allow_pickle=True,encoding='bytes')\n",
        "print(len(WP_dataset_val))\n",
        "\n",
        "data_dict = {'question':[],\n",
        "             'choice_list':[]}\n",
        "for i in WP_dataset_val:\n",
        "  for k,v in i.items():\n",
        "    data_dict[k].append(v)\n",
        "\n",
        "WP_val_df = pd.DataFrame(data_dict, columns=['question', 'choice_list'])\n",
        "WP_val_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "W-TMXQW9oZk-",
        "outputId": "7684fc4d-cc5a-4c15-fbfc-2ee1768e7ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          question  \\\n",
              "0   What kind of nut has no shell?   \n",
              "1  Which nut doesn't have a shell?   \n",
              "\n",
              "                                         choice_list  \n",
              "0  [A peanut., A Doughnut., A walnut., None of ab...  \n",
              "1  [A Doughnut., A walnut., A peanut., None of ab...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d02175b-e0bf-49da-beb3-5c0be4068889\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What kind of nut has no shell?</td>\n",
              "      <td>[A peanut., A Doughnut., A walnut., None of ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Which nut doesn't have a shell?</td>\n",
              "      <td>[A Doughnut., A walnut., A peanut., None of ab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d02175b-e0bf-49da-beb3-5c0be4068889')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d02175b-e0bf-49da-beb3-5c0be4068889 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d02175b-e0bf-49da-beb3-5c0be4068889');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-612c59cf-05e0-4770-98af-93b08e8bd97a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-612c59cf-05e0-4770-98af-93b08e8bd97a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-612c59cf-05e0-4770-98af-93b08e8bd97a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids=[]\n",
        "questions=[]\n",
        "choice_lists=[]\n",
        "predicted_labels=[]\n",
        "\n",
        "for i in tqdm(range(len(WP_val_df))):\n",
        "  sample=WP_val_df.iloc[i]\n",
        "  pred=wp_test_pred[i]\n",
        "  ids.append(i)\n",
        "  questions.append(sample['question'].strip())\n",
        "  predicted_labels.append(pred)\n",
        "  choice_lists.append(sample['choice_list'])\n",
        "\n",
        "temp_dict={'id':ids,\n",
        "'question':questions,\n",
        "'choice_list':choice_lists,\n",
        "'label':predicted_labels}\n",
        "\n",
        "WP_new_df=pd.DataFrame(data=temp_dict)\n",
        "WP_new_df"
      ],
      "metadata": {
        "id": "e7GSrllloibX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "69881038-3eeb-415b-eaac-edbb47f87ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:00<00:00, 17291.94it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                           question  \\\n",
              "0      0                     What kind of nut has no shell?   \n",
              "1      1                    Which nut doesn't have a shell?   \n",
              "2      2           Which type of bell doesn't make a sound?   \n",
              "3      3        What does a stone become when in the water?   \n",
              "4      4  What changes a stone makes when submerged in w...   \n",
              "..   ...                                                ...   \n",
              "115  115                  hijklmno' stands for what liquid?   \n",
              "116  116                acdfgnijkmn' stands for what award?   \n",
              "117  117  You are in a place called Wall's World and the...   \n",
              "118  118  You are in Wall's World, where there is only o...   \n",
              "119  119  You are in Wall's World, where there is only o...   \n",
              "\n",
              "                                           choice_list  label  \n",
              "0    [A peanut., A Doughnut., A walnut., None of ab...      1  \n",
              "1    [A Doughnut., A walnut., A peanut., None of ab...      0  \n",
              "2    [A fire bell., A cow bell., A Bluebell., None ...      2  \n",
              "3    [A whetstone., A limestone, A sandstone., None...      0  \n",
              "4    [A whetstone., A sandstone., A limestone, None...      0  \n",
              "..                                                 ...    ...  \n",
              "115  [Milk. \"H L M N O\" is similar as the nursery r...      2  \n",
              "116  [Nobel. \"Acdfgnijkmn\" is 'no B E L\" in the alp...      0  \n",
              "117  [Each word in Wall's World must contain less t...      2  \n",
              "118  [Each word in Wall's World must contain more t...      1  \n",
              "119  [Each word in Wall's World must contain more t...      1  \n",
              "\n",
              "[120 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f538d60-6f06-4569-acee-4592773b93e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>choice_list</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What kind of nut has no shell?</td>\n",
              "      <td>[A peanut., A Doughnut., A walnut., None of ab...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Which nut doesn't have a shell?</td>\n",
              "      <td>[A Doughnut., A walnut., A peanut., None of ab...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Which type of bell doesn't make a sound?</td>\n",
              "      <td>[A fire bell., A cow bell., A Bluebell., None ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>What does a stone become when in the water?</td>\n",
              "      <td>[A whetstone., A limestone, A sandstone., None...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>What changes a stone makes when submerged in w...</td>\n",
              "      <td>[A whetstone., A sandstone., A limestone, None...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>115</td>\n",
              "      <td>hijklmno' stands for what liquid?</td>\n",
              "      <td>[Milk. \"H L M N O\" is similar as the nursery r...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>116</td>\n",
              "      <td>acdfgnijkmn' stands for what award?</td>\n",
              "      <td>[Nobel. \"Acdfgnijkmn\" is 'no B E L\" in the alp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>117</td>\n",
              "      <td>You are in a place called Wall's World and the...</td>\n",
              "      <td>[Each word in Wall's World must contain less t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>118</td>\n",
              "      <td>You are in Wall's World, where there is only o...</td>\n",
              "      <td>[Each word in Wall's World must contain more t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>119</td>\n",
              "      <td>You are in Wall's World, where there is only o...</td>\n",
              "      <td>[Each word in Wall's World must contain more t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f538d60-6f06-4569-acee-4592773b93e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f538d60-6f06-4569-acee-4592773b93e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f538d60-6f06-4569-acee-4592773b93e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6450d014-fecb-4cf9-8876-abb804d19224\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6450d014-fecb-4cf9-8876-abb804d19224')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6450d014-fecb-4cf9-8876-abb804d19224 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = datetime.datetime.today().strftime('%Y_%m_%d')\n",
        "dt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aVeARnFkHLvE",
        "outputId": "65e30df7-306f-49e8-baaa-72dce61c7bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2023_12_13'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WP_new_df.to_csv(f\"/content/drive/MyDrive/brain_teaser/WP_qagnn_predictions_{dt}.csv\", index=False)"
      ],
      "metadata": {
        "id": "y5CGJOhatiVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=[str(x) for x in WP_new_df['label'].values]\n",
        "with open('answer_word.txt', 'w') as f:\n",
        "    f.write('\\n'.join(res))"
      ],
      "metadata": {
        "id": "HgeFCt04PpPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8KRxW6P7V1Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###training logs"
      ],
      "metadata": {
        "id": "HyI9aiAqVwKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12_11_2023"
      ],
      "metadata": {
        "id": "23dgDMr5Xloh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WP continue training, loading from best saved model (with new concept extraction code)"
      ],
      "metadata": {
        "id": "gdAuCK4q_Lhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elr=1e-5 #encoder learning rate\n",
        "args[\"encoder_lr\"]=elr\n",
        "\n",
        "args['log_interval']=2\n",
        "main_5(args, global_step=81, best_dev_epoch=26, is_finetuning_on_new_ds=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVoQ35RfDavU",
        "outputId": "b4502491-aa4b-4a62-becc-6d16c31963de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'enc': 'roberta-large', 'encoder': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_log_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 2, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'brain_teaser_ds', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 1e-05, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/WP_inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'load_model_path': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.26.best_model', 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 356/356 [00:00<00:00, 1597.64it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 1465.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_choice 4\n",
            "| ori_adj_len: mu 98.33 sigma 98.79 | adj_len: 86.43 | prune_rate： 0.11 | qc_num: 6.04 | ac_num: 2.41 |\n",
            "| ori_adj_len: mu 82.68 sigma 82.56 | adj_len: 76.02 | prune_rate： 0.05 | qc_num: 5.01 | ac_num: 2.23 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading and initializing model from /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.26.best_model\n",
            "previous best_dev_acc: 0.85\n",
            "current training epoch start from: 27\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 28/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-6-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| step    81 |  lr: 0.0000100 | loss  0.2313 | ms/batch 9479.55 |\n",
            "| step    83 |  lr: 0.0000100 | loss  0.4580 | ms/batch 14690.23 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  27 | step    84 | dev_acc  0.8250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.27.temp_checkpoint\n",
            "epoch: 29/100\n",
            "| step    85 |  lr: 0.0000100 | loss  0.4297 | ms/batch 16904.53 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  28 | step    87 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.28.temp_checkpoint\n",
            "epoch: 30/100\n",
            "| step    87 |  lr: 0.0000100 | loss  0.4338 | ms/batch 8297.87 |\n",
            "| step    89 |  lr: 0.0000100 | loss  0.3807 | ms/batch 15041.78 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  29 | step    90 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.29.temp_checkpoint\n",
            "epoch: 31/100\n",
            "| step    91 |  lr: 0.0000100 | loss  0.4229 | ms/batch 16711.30 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  30 | step    93 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.30.temp_checkpoint\n",
            "epoch: 32/100\n",
            "| step    93 |  lr: 0.0000100 | loss  0.3558 | ms/batch 8289.01 |\n",
            "| step    95 |  lr: 0.0000100 | loss  0.3743 | ms/batch 15046.70 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  31 | step    96 | dev_acc  0.7500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.31.temp_checkpoint\n",
            "epoch: 33/100\n",
            "| step    97 |  lr: 0.0000100 | loss  0.3810 | ms/batch 16717.29 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  32 | step    99 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.32.temp_checkpoint\n",
            "epoch: 34/100\n",
            "| step    99 |  lr: 0.0000100 | loss  0.3255 | ms/batch 8168.86 |\n",
            "| step   101 |  lr: 0.0000100 | loss  0.3777 | ms/batch 15166.52 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  33 | step   102 | dev_acc  0.7500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.33.temp_checkpoint\n",
            "epoch: 35/100\n",
            "| step   103 |  lr: 0.0000100 | loss  0.3469 | ms/batch 16632.39 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  34 | step   105 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.34.temp_checkpoint\n",
            "epoch: 36/100\n",
            "| step   105 |  lr: 0.0000100 | loss  0.3237 | ms/batch 8376.35 |\n",
            "| step   107 |  lr: 0.0000100 | loss  0.3535 | ms/batch 15004.57 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  35 | step   108 | dev_acc  0.7500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.35.temp_checkpoint\n",
            "epoch: 37/100\n",
            "| step   109 |  lr: 0.0000100 | loss  0.3179 | ms/batch 16780.31 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  36 | step   111 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.36.temp_checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yZYWKHSVDtSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elr=0.0002\n",
        "args[\"encoder_lr\"]=elr\n",
        "\n",
        "args['log_interval']=2\n",
        "main_5(args, global_step=81, best_dev_epoch=26, is_finetuning_on_new_ds=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0c6e8ad598aa4ee28179890eb8e83cc0",
            "cae5c2842d5d4688a571032c4ec244f4",
            "4652c8fec6874b979d92851329a854f9",
            "e62de9d2733e4d4f882b89f22eda012c",
            "b535a941aa0944d89e0bec62d3b22a8e",
            "42c7864fd4484e77962bc33b414b92eb",
            "41ab0b168d5a49fdb33a68634116a9b1",
            "a2b40293346146ed8c01c0047804fe38",
            "e9eff5a4cab849fbbf87214bd1f5593c",
            "27847845e4874c698970e709792c0326",
            "224ecab2401f44ba968a27a41cd4ddf1",
            "c047fe0871784ae3a632385a1fa4ca51",
            "498e502493dd45d090dce2b63fb49090",
            "9145cf6de4064f99858c6f9652d5fb2f",
            "f4ec57eb02c14dd5abd1f288426ca300",
            "14ad9701679d4578a7ad251c76c42add",
            "9a7fe027f120440a9d762fc9aa4822ee",
            "ca7fe3cce3844b528f74d8e843177c76",
            "c8a0d182737d46028659c4de48200f50",
            "6a787ee446eb4512959c344559c263e2",
            "4abea279858446b49b89dfe483fcdf28",
            "a4297614578b4394935551c29d150719",
            "ff15fac3674541da905860b4bd574aed",
            "e3613720c1f14570a12b7cc3d804336b",
            "d7c6be967a4e4c5e99d543c59b64eb35",
            "5495b73a280847faa0db93e5592a1425",
            "6a5b862847024c7cbadf8fe57bf77bb8",
            "1c06ef03262c48a0b56ab30184818e75",
            "3de34b30aae0496b85bde418b2b5e0f4",
            "69a8061a1537484ea6ddbc973280311b",
            "990b97a303fb457ebb79f01b4e503ff0",
            "9067d224fcd141258d9bc7297ade7367",
            "724f07ebfae647899d3255944b3663d4",
            "8f04028e9675451ba5def9db9c1c2a19",
            "5f99673a45d64768884d11efb813346b",
            "9fb9e15ce2864cc88ee393ee426c6553",
            "b0f4cd5ffdb34b25bdd8d7a28a9c9b0e",
            "79ee34ee8d6c4d9e9b5493f961e39d12",
            "18221d5549d248a1a0f2c6fbb86a4236",
            "a3add975034b4e7b96a1ee8ed996d9ff",
            "1db4e0b682d340e994eb51ae30af278a",
            "b01a7dd89e094d5f8163a72589f9a970",
            "0ca1633f98a84455b7294aaec75f649f",
            "0db9fa66d0164c42af93fe19d39238a8",
            "8446a3d9aba140c7b419f7810948d6de",
            "26c0d7ef738c49649504104c3d9fec87",
            "74753db77b724f128ccee61a2a559137",
            "f597a00c7dae46209dbc70130669e460",
            "44cee09826fc41c487b6525422cb4911",
            "287b83be07234d3b9489ef59ee45fbf7",
            "6385c270cd944eaf9769616d79ba2585",
            "95273a0e4d824837b0611aa532ab9ed3",
            "2c40884f5ca04dafa221931290fe7ecd",
            "dc33438de029473b8d162cee3d13e22d",
            "b17a1bf0280a4cde829dd71c5e5cfef8"
          ]
        },
        "id": "3IUbMCQU_KLd",
        "outputId": "0294a2d2-3c97-4c99-8136-ebac43bea5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'enc': 'roberta-large', 'encoder': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_log_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 2, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'brain_teaser_ds', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/WP_inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'load_model_path': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.26.best_model', 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c6e8ad598aa4ee28179890eb8e83cc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c047fe0871784ae3a632385a1fa4ca51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff15fac3674541da905860b4bd574aed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f04028e9675451ba5def9db9c1c2a19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 356/356 [00:00<00:00, 1458.07it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 1383.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_choice 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading adj matrices: 100%|██████████| 1424/1424 [00:03<00:00, 429.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ori_adj_len: mu 98.33 sigma 98.79 | adj_len: 86.43 | prune_rate： 0.11 | qc_num: 6.04 | ac_num: 2.41 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading adj matrices: 100%|██████████| 160/160 [00:00<00:00, 484.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| ori_adj_len: mu 82.68 sigma 82.56 | adj_len: 76.02 | prune_rate： 0.05 | qc_num: 5.01 | ac_num: 2.23 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8446a3d9aba140c7b419f7810948d6de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading and initializing model from /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.26.best_model\n",
            "previous best_dev_acc: 0.85\n",
            "current training epoch start from: 27\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 28/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-9-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| step    81 |  lr: 0.0002000 | loss  0.2313 | ms/batch 9019.99 |\n",
            "| step    83 |  lr: 0.0002000 | loss  0.4580 | ms/batch 14119.22 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  27 | step    84 | dev_acc  0.8250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.27.temp_checkpoint\n",
            "epoch: 29/100\n",
            "| step    85 |  lr: 0.0002000 | loss  0.4297 | ms/batch 16447.43 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  28 | step    87 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.28.temp_checkpoint\n",
            "epoch: 30/100\n",
            "| step    87 |  lr: 0.0002000 | loss  0.4338 | ms/batch 8357.83 |\n",
            "| step    89 |  lr: 0.0002000 | loss  0.3807 | ms/batch 15021.35 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  29 | step    90 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.29.temp_checkpoint\n",
            "epoch: 31/100\n",
            "| step    91 |  lr: 0.0002000 | loss  0.4229 | ms/batch 16689.87 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  30 | step    93 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.30.temp_checkpoint\n",
            "epoch: 32/100\n",
            "| step    93 |  lr: 0.0002000 | loss  0.3558 | ms/batch 8255.76 |\n",
            "| step    95 |  lr: 0.0002000 | loss  0.3743 | ms/batch 15046.26 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  31 | step    96 | dev_acc  0.7500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.31.temp_checkpoint\n",
            "epoch: 33/100\n",
            "| step    97 |  lr: 0.0002000 | loss  0.3810 | ms/batch 16696.88 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  32 | step    99 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.32.temp_checkpoint\n",
            "epoch: 34/100\n",
            "| step    99 |  lr: 0.0002000 | loss  0.3255 | ms/batch 8135.51 |\n",
            "| step   101 |  lr: 0.0002000 | loss  0.3780 | ms/batch 15187.86 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  33 | step   102 | dev_acc  0.7500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.33.temp_checkpoint\n",
            "epoch: 35/100\n",
            "| step   103 |  lr: 0.0002000 | loss  0.3464 | ms/batch 16598.95 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  34 | step   105 | dev_acc  0.7500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.34.temp_checkpoint\n",
            "epoch: 36/100\n",
            "| step   105 |  lr: 0.0002000 | loss  0.3235 | ms/batch 8382.24 |\n",
            "| step   107 |  lr: 0.0002000 | loss  0.3534 | ms/batch 14971.52 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  35 | step   108 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.35.temp_checkpoint\n",
            "epoch: 37/100\n",
            "| step   109 |  lr: 0.0002000 | loss  0.3182 | ms/batch 16841.73 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  36 | step   111 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.36.temp_checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BFHHMA2T_4Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WP"
      ],
      "metadata": {
        "id": "ipm2EiZ2KR3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args['log_interval']=2\n",
        "main_5(args, global_step=0, best_dev_epoch=0, is_finetuning_on_new_ds=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJJVAOjWXnG2",
        "outputId": "cffe6f60-2eda-4fff-c665-7f21a0f0e0ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'enc': 'roberta-large', 'encoder': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_log_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 2, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'brain_teaser_ds', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/WP_dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/WP_inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'load_model_path': None, 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/WP_train.statement.jsonl\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 356/356 [00:00<00:00, 801.34it/s]\n",
            "100%|██████████| 40/40 [00:00<00:00, 1424.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 4\n",
            "| ori_adj_len: mu 98.31 sigma 98.81 | adj_len: 86.41 | prune_rate： 0.11 | qc_num: 6.04 | ac_num: 2.41 |\n",
            "| ori_adj_len: mu 82.68 sigma 82.56 | adj_len: 76.02 | prune_rate： 0.05 | qc_num: 5.01 | ac_num: 2.23 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 1/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-6-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     1 |  lr: 0.0002000 | loss  1.4047 | ms/batch 16040.34 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.71it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   0 | step     3 | dev_acc  0.1750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.0.best_model\n",
            "epoch: 2/100\n",
            "| step     3 |  lr: 0.0002000 | loss  1.3708 | ms/batch 8359.61 |\n",
            "| step     5 |  lr: 0.0002000 | loss  1.3974 | ms/batch 15653.84 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.09it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   1 | step     6 | dev_acc  0.1500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.1.temp_checkpoint\n",
            "epoch: 3/100\n",
            "| step     7 |  lr: 0.0002000 | loss  1.3992 | ms/batch 16883.99 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   2 | step     9 | dev_acc  0.2250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.2.best_model\n",
            "epoch: 4/100\n",
            "| step     9 |  lr: 0.0002000 | loss  1.3914 | ms/batch 8423.04 |\n",
            "| step    11 |  lr: 0.0002000 | loss  1.3958 | ms/batch 16004.76 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   3 | step    12 | dev_acc  0.2750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.3.best_model\n",
            "epoch: 5/100\n",
            "| step    13 |  lr: 0.0002000 | loss  1.3795 | ms/batch 38794.59 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   4 | step    15 | dev_acc  0.2750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.4.best_model\n",
            "epoch: 6/100\n",
            "| step    15 |  lr: 0.0002000 | loss  1.3831 | ms/batch 18287.40 |\n",
            "| step    17 |  lr: 0.0002000 | loss  1.3890 | ms/batch 33810.85 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   5 | step    18 | dev_acc  0.3750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.5.best_model\n",
            "epoch: 7/100\n",
            "| step    19 |  lr: 0.0002000 | loss  1.3814 | ms/batch 36658.06 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.66it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   6 | step    21 | dev_acc  0.4750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.6.best_model\n",
            "epoch: 8/100\n",
            "| step    21 |  lr: 0.0002000 | loss  1.3566 | ms/batch 18106.94 |\n",
            "| step    23 |  lr: 0.0002000 | loss  1.3565 | ms/batch 33443.57 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.53it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   7 | step    24 | dev_acc  0.5500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.7.best_model\n",
            "epoch: 9/100\n",
            "| step    25 |  lr: 0.0002000 | loss  1.3147 | ms/batch 36582.14 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.66it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   8 | step    27 | dev_acc  0.6750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.8.best_model\n",
            "epoch: 10/100\n",
            "| step    27 |  lr: 0.0002000 | loss  1.2803 | ms/batch 18919.73 |\n",
            "| step    29 |  lr: 0.0002000 | loss  1.2350 | ms/batch 34752.41 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   9 | step    30 | dev_acc  0.6750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.9.best_model\n",
            "epoch: 11/100\n",
            "| step    31 |  lr: 0.0002000 | loss  1.2127 | ms/batch 38942.22 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.40it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  10 | step    33 | dev_acc  0.6250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.10.temp_checkpoint\n",
            "epoch: 12/100\n",
            "| step    33 |  lr: 0.0002000 | loss  1.1438 | ms/batch 19184.14 |\n",
            "| step    35 |  lr: 0.0002000 | loss  1.1027 | ms/batch 34021.50 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  11 | step    36 | dev_acc  0.5750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.11.temp_checkpoint\n",
            "epoch: 13/100\n",
            "| step    37 |  lr: 0.0002000 | loss  1.0544 | ms/batch 38341.13 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  12 | step    39 | dev_acc  0.6250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.12.temp_checkpoint\n",
            "epoch: 14/100\n",
            "| step    39 |  lr: 0.0002000 | loss  1.0421 | ms/batch 19114.37 |\n",
            "| step    41 |  lr: 0.0002000 | loss  1.0294 | ms/batch 34158.40 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  13 | step    42 | dev_acc  0.7000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.13.best_model\n",
            "epoch: 15/100\n",
            "| step    43 |  lr: 0.0002000 | loss  0.9276 | ms/batch 39090.49 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  14 | step    45 | dev_acc  0.7000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.14.best_model\n",
            "epoch: 16/100\n",
            "| step    45 |  lr: 0.0002000 | loss  0.9072 | ms/batch 19485.97 |\n",
            "| step    47 |  lr: 0.0002000 | loss  0.8118 | ms/batch 34426.44 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  15 | step    48 | dev_acc  0.6750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.15.temp_checkpoint\n",
            "epoch: 17/100\n",
            "| step    49 |  lr: 0.0002000 | loss  0.8425 | ms/batch 38357.96 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  16 | step    51 | dev_acc  0.6500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.16.temp_checkpoint\n",
            "epoch: 18/100\n",
            "| step    51 |  lr: 0.0002000 | loss  0.8018 | ms/batch 19116.99 |\n",
            "| step    53 |  lr: 0.0002000 | loss  0.7502 | ms/batch 34127.45 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  17 | step    54 | dev_acc  0.6750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.17.temp_checkpoint\n",
            "epoch: 19/100\n",
            "| step    55 |  lr: 0.0002000 | loss  0.6815 | ms/batch 38462.48 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  18 | step    57 | dev_acc  0.6750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.18.temp_checkpoint\n",
            "epoch: 20/100\n",
            "| step    57 |  lr: 0.0002000 | loss  0.7180 | ms/batch 19087.71 |\n",
            "| step    59 |  lr: 0.0002000 | loss  0.6082 | ms/batch 34078.47 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.52it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  19 | step    60 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.19.best_model\n",
            "epoch: 21/100\n",
            "| step    61 |  lr: 0.0002000 | loss  0.6367 | ms/batch 39118.11 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  20 | step    63 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.20.best_model\n",
            "epoch: 22/100\n",
            "| step    63 |  lr: 0.0002000 | loss  0.5054 | ms/batch 19843.44 |\n",
            "| step    65 |  lr: 0.0002000 | loss  0.5520 | ms/batch 34683.84 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  21 | step    66 | dev_acc  0.7500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.21.temp_checkpoint\n",
            "epoch: 23/100\n",
            "| step    67 |  lr: 0.0002000 | loss  0.4687 | ms/batch 38452.61 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  22 | step    69 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.22.temp_checkpoint\n",
            "epoch: 24/100\n",
            "| step    69 |  lr: 0.0002000 | loss  0.5109 | ms/batch 19170.58 |\n",
            "| step    71 |  lr: 0.0002000 | loss  0.5052 | ms/batch 34127.26 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  23 | step    72 | dev_acc  0.8000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.23.best_model\n",
            "epoch: 25/100\n",
            "| step    73 |  lr: 0.0002000 | loss  0.4746 | ms/batch 39001.47 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  24 | step    75 | dev_acc  0.7500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.24.temp_checkpoint\n",
            "epoch: 26/100\n",
            "| step    75 |  lr: 0.0002000 | loss  0.4605 | ms/batch 19321.25 |\n",
            "| step    77 |  lr: 0.0002000 | loss  0.4417 | ms/batch 34063.97 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  25 | step    78 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.25.temp_checkpoint\n",
            "epoch: 27/100\n",
            "| step    79 |  lr: 0.0002000 | loss  0.3945 | ms/batch 38298.16 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  26 | step    81 | dev_acc  0.8500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/WP_best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.26.best_model\n",
            "epoch: 28/100\n",
            "| step    81 |  lr: 0.0002000 | loss  0.4404 | ms/batch 19416.93 |\n",
            "| step    83 |  lr: 0.0002000 | loss  0.3919 | ms/batch 34673.66 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  27 | step    84 | dev_acc  0.7000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.27.temp_checkpoint\n",
            "epoch: 29/100\n",
            "| step    85 |  lr: 0.0002000 | loss  0.4504 | ms/batch 38621.97 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  28 | step    87 | dev_acc  0.7000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.28.temp_checkpoint\n",
            "epoch: 30/100\n",
            "| step    87 |  lr: 0.0002000 | loss  0.3339 | ms/batch 19263.49 |\n",
            "| step    89 |  lr: 0.0002000 | loss  0.3500 | ms/batch 34066.17 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.45it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  29 | step    90 | dev_acc  0.6500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.29.temp_checkpoint\n",
            "epoch: 31/100\n",
            "| step    91 |  lr: 0.0002000 | loss  0.4346 | ms/batch 38462.51 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  30 | step    93 | dev_acc  0.6250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.30.temp_checkpoint\n",
            "epoch: 32/100\n",
            "| step    93 |  lr: 0.0002000 | loss  0.3494 | ms/batch 19246.34 |\n",
            "| step    95 |  lr: 0.0002000 | loss  0.3282 | ms/batch 34014.87 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  31 | step    96 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.31.temp_checkpoint\n",
            "epoch: 33/100\n",
            "| step    97 |  lr: 0.0002000 | loss  0.2708 | ms/batch 38598.40 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  32 | step    99 | dev_acc  0.7750 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.32.temp_checkpoint\n",
            "epoch: 34/100\n",
            "| step    99 |  lr: 0.0002000 | loss  0.3058 | ms/batch 19596.62 |\n",
            "| step   101 |  lr: 0.0002000 | loss  0.2776 | ms/batch 33865.46 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  33 | step   102 | dev_acc  0.7250 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.33.temp_checkpoint\n",
            "epoch: 35/100\n",
            "| step   103 |  lr: 0.0002000 | loss  0.2648 | ms/batch 38558.86 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  34 | step   105 | dev_acc  0.7500 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.34.temp_checkpoint\n",
            "epoch: 36/100\n",
            "| step   105 |  lr: 0.0002000 | loss  0.2194 | ms/batch 19476.78 |\n",
            "| step   107 |  lr: 0.0002000 | loss  0.1683 | ms/batch 33957.90 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  35 | step   108 | dev_acc  0.7000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.35.temp_checkpoint\n",
            "epoch: 37/100\n",
            "| step   109 |  lr: 0.0002000 | loss  0.1767 | ms/batch 38653.55 |\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:04<00:00,  4.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  36 | step   111 | dev_acc  0.7000 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/WP_checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.36.temp_checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DNdnh5RnXlV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12-8-2023"
      ],
      "metadata": {
        "id": "YHWGroWZhhj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SP"
      ],
      "metadata": {
        "id": "s6RA2T8VKP8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "args[\"encoder_lr\"]=1e-5"
      ],
      "metadata": {
        "id": "8Q73fhLSxzeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_5(args, global_step=88, best_dev_epoch=21, is_finetuning_on_new_ds=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am6A4Xsfv2RP",
        "outputId": "94d2032f-e903-4e08-9c2a-e87c4689465a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'enc': 'roberta-large', 'encoder': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/log_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 5, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'brain_teaser_ds', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 1e-05, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'load_model_path': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.21.best_model', 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 456/456 [00:00<00:00, 648.70it/s]\n",
            "100%|██████████| 51/51 [00:00<00:00, 812.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_choice 4\n",
            "| ori_adj_len: mu 394.59 sigma 290.55 | adj_len: 177.47 | prune_rate： 0.72 | qc_num: 18.76 | ac_num: 5.36 |\n",
            "| ori_adj_len: mu 386.00 sigma 252.60 | adj_len: 180.20 | prune_rate： 0.80 | qc_num: 17.96 | ac_num: 6.38 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading and initializing model from /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.21.best_model\n",
            "previous best_dev_acc: 0.9411764705882353\n",
            "current training epoch start from: 22\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 23/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-6-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| step    89 |  lr: 0.0000100 | loss  0.0015 | ms/batch 7386.99 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:05<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  22 | step    92 | dev_acc  0.9216 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.22.temp_checkpoint\n",
            "epoch: 24/100\n",
            "| step    94 |  lr: 0.0000100 | loss  0.0007 | ms/batch 11511.70 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  23 | step    96 | dev_acc  0.9216 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.23.temp_checkpoint\n",
            "epoch: 25/100\n",
            "| step    99 |  lr: 0.0000100 | loss  0.0008 | ms/batch 14044.93 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  24 | step   100 | dev_acc  0.9216 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.24.temp_checkpoint\n",
            "epoch: 26/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  25 | step   104 | dev_acc  0.9216 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.25.temp_checkpoint\n",
            "epoch: 27/100\n",
            "| step   104 |  lr: 0.0000100 | loss  0.0006 | ms/batch 3940.74 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  26 | step   108 | dev_acc  0.9216 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.26.temp_checkpoint\n",
            "epoch: 28/100\n",
            "| step   109 |  lr: 0.0000100 | loss  0.0015 | ms/batch 7978.61 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  27 | step   112 | dev_acc  0.9216 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.27.temp_checkpoint\n",
            "epoch: 29/100\n",
            "| step   114 |  lr: 0.0000100 | loss  0.0006 | ms/batch 12175.71 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  28 | step   116 | dev_acc  0.9216 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.28.temp_checkpoint\n",
            "epoch: 30/100\n",
            "| step   119 |  lr: 0.0000100 | loss  0.0003 | ms/batch 14441.65 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  29 | step   120 | dev_acc  0.9216 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.29.temp_checkpoint\n",
            "epoch: 31/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  30 | step   124 | dev_acc  0.9216 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.30.temp_checkpoint\n",
            "epoch: 32/100\n",
            "| step   124 |  lr: 0.0000100 | loss  0.0004 | ms/batch 4005.60 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  31 | step   128 | dev_acc  0.9216 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.31.temp_checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SjpSkZ16yJfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "args[\"encoder_lr\"]=2e-4"
      ],
      "metadata": {
        "id": "tvBMlGJxxwDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_5(args, global_step=0, best_dev_epoch=0, is_finetuning_on_new_ds=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7d1ef1ab4b7044e7bb30fc1220cfabc1",
            "02a42df750404a52b344d82e539593cb",
            "e5f4269d160c4992867ec22572d53ff6",
            "180b38d300fe40c38406733a0730a9e3",
            "60a4458c6a35475ca4099513a48f2cd9",
            "e6774017cd7b49329753ea16238210ec",
            "25e0f9e2c8004ba0b2bbc147df456dc5",
            "8ef9f87db7f0462fa43fd5dd9fedded8",
            "04e6187984b141bcac5ba4423e69acc6",
            "c39185115e7c4e21baca2f629d4ad3c1",
            "aee591fab2f4460e8822480889069bf6",
            "4bf1c5d74c834b5d966ac45f063da84a",
            "46e8436773f042dda6182282aab5e72b",
            "0a5474597f0b4fb8b426d1f0af740101",
            "6383c58a588f411c82ca9047c2b6316c",
            "ea6ead3c919c4fdb853a593d919737e4",
            "d5710a7923ef4eefb223f0e3311d77f9",
            "09e2f56c14924edb9d212da9450d781c",
            "f2226551dc9d42079622cf9d63a918ef",
            "8c4c3037bf334566819a6ceb163fc050",
            "31e241ec496e425ca11b58b80e04b364",
            "d1f9784b31c64ab8b82abe83fda83718",
            "b9a7f2ab1cef4ad297a26d5c30756792",
            "7e6dc208c9494ca1924aebd1d859eb05",
            "19d727196a2041309196bd4eab475612",
            "9f74c31fa5d04d9aa5cf94cad4694540",
            "1df365a282aa40e494993fdcc8107ceb",
            "731e3e9e11854a89a0329201a006e877",
            "31aa170973b84fa3b85c4639cfd1b261",
            "ab4dbe13dd5a4dc58d003b6655da34cc",
            "9de54e63ad5646ffaf8885027beb875f",
            "834431fab85d4431b5d7e77b0e0106f3",
            "af4a92d3c415471a8b7d6dbda9eb9561",
            "44b3a7596ef640f587f8546676c6270a",
            "1de9e1a8fe4a4e57b3233b5e95e4373b",
            "508ff7efbe694603b475140cca709d88",
            "9011b17b72b649f69afb792dc0c40676",
            "a89d2a0ffd214caab48b986486ee4ded",
            "ece2afd37f1a4ea1bb68b6d6e2a548f1",
            "a8ddee9eb9c741d581fe03727009ed19",
            "03982097a9254bf1bbfb42ed13163f91",
            "593bb4587aeb4561ac0e8248ccf225a4",
            "9d045604f0cb452e8ae86deb32e7099c",
            "43310721377c4156b7e7632bd001fb29",
            "04a5bdcc1fc74b63a49805ce04867c07",
            "ff548bf675934feb8f17f5c0586d88c1",
            "5c2a12802cb1461f9cd86768b198e4ba",
            "af8dc41f0c114559a391cb09f3c9c211",
            "046e4bdee4e74509b8c61976fd1722f1",
            "9f69edadf5df40a3aedc7e4014e46120",
            "139a4b08045e4a7dab6cc7f3f48be434",
            "8b3e6d6e95f6424482c3f8367794fedc",
            "07b3206349bd42799a74aaa98c6f87ae",
            "7815ffa5acc74b62827afcb2ca3b06fe",
            "f7e6739175b849da820a565115931d1e"
          ]
        },
        "id": "e0Nvv142g1LZ",
        "outputId": "71e902a8-5dd3-430f-d08a-6f85f6b5cbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'enc': 'roberta-large', 'encoder': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/log_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 5, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'brain_teaser_ds', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/graph/SP_dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'load_model_path': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.16.best_model', 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/brain_teaser_ds/statement/SP_train.statement.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d1ef1ab4b7044e7bb30fc1220cfabc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bf1c5d74c834b5d966ac45f063da84a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9a7f2ab1cef4ad297a26d5c30756792"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44b3a7596ef640f587f8546676c6270a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 456/456 [00:00<00:00, 853.26it/s]\n",
            "100%|██████████| 51/51 [00:00<00:00, 823.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_choice 4\n",
            "| ori_adj_len: mu 394.59 sigma 290.55 | adj_len: 177.47 | prune_rate： 0.72 | qc_num: 18.76 | ac_num: 5.36 |\n",
            "| ori_adj_len: mu 386.00 sigma 252.60 | adj_len: 180.20 | prune_rate： 0.80 | qc_num: 17.96 | ac_num: 6.38 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04a5bdcc1fc74b63a49805ce04867c07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading and initializing model from /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.16.best_model\n",
            "previous best_dev_acc: None\n",
            "current training epoch start from: None\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-9-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "100%|██████████| 26/26 [00:05<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   0 | step     4 | dev_acc  0.4902 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.0.best_model\n",
            "epoch: 2/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| step     4 |  lr: 0.0002000 | loss  1.4676 | ms/batch 3781.09 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   1 | step     8 | dev_acc  0.5098 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.1.best_model\n",
            "epoch: 3/100\n",
            "| step     9 |  lr: 0.0002000 | loss  1.3736 | ms/batch 7760.60 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   2 | step    12 | dev_acc  0.6275 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.2.best_model\n",
            "epoch: 4/100\n",
            "| step    14 |  lr: 0.0002000 | loss  1.1772 | ms/batch 11881.46 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   3 | step    16 | dev_acc  0.6863 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.3.best_model\n",
            "epoch: 5/100\n",
            "| step    19 |  lr: 0.0002000 | loss  1.1403 | ms/batch 30309.04 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   4 | step    20 | dev_acc  0.6667 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.4.temp_checkpoint\n",
            "epoch: 6/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   5 | step    24 | dev_acc  0.6863 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.5.best_model\n",
            "epoch: 7/100\n",
            "| step    24 |  lr: 0.0002000 | loss  1.0658 | ms/batch 8472.60 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   6 | step    28 | dev_acc  0.7451 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.6.best_model\n",
            "epoch: 8/100\n",
            "| step    29 |  lr: 0.0002000 | loss  0.8713 | ms/batch 17128.69 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   7 | step    32 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.7.best_model\n",
            "epoch: 9/100\n",
            "| step    34 |  lr: 0.0002000 | loss  0.5321 | ms/batch 25744.00 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   8 | step    36 | dev_acc  0.8627 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.8.temp_checkpoint\n",
            "epoch: 10/100\n",
            "| step    39 |  lr: 0.0002000 | loss  0.2840 | ms/batch 30609.91 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   9 | step    40 | dev_acc  0.8235 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.9.temp_checkpoint\n",
            "epoch: 11/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  10 | step    44 | dev_acc  0.8235 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.10.temp_checkpoint\n",
            "epoch: 12/100\n",
            "| step    44 |  lr: 0.0002000 | loss  0.1714 | ms/batch 8476.78 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  11 | step    48 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.11.best_model\n",
            "epoch: 13/100\n",
            "| step    49 |  lr: 0.0002000 | loss  0.0939 | ms/batch 17196.33 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  12 | step    52 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.12.best_model\n",
            "epoch: 14/100\n",
            "| step    54 |  lr: 0.0002000 | loss  0.0451 | ms/batch 25724.95 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  13 | step    56 | dev_acc  0.8039 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.13.temp_checkpoint\n",
            "epoch: 15/100\n",
            "| step    59 |  lr: 0.0002000 | loss  0.0372 | ms/batch 30577.50 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  14 | step    60 | dev_acc  0.9020 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.14.best_model\n",
            "epoch: 16/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  15 | step    64 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.15.temp_checkpoint\n",
            "epoch: 17/100\n",
            "| step    64 |  lr: 0.0002000 | loss  0.0203 | ms/batch 8468.01 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  16 | step    68 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.16.temp_checkpoint\n",
            "epoch: 18/100\n",
            "| step    69 |  lr: 0.0002000 | loss  0.0085 | ms/batch 17159.22 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  17 | step    72 | dev_acc  0.9020 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.17.best_model\n",
            "epoch: 19/100\n",
            "| step    74 |  lr: 0.0002000 | loss  0.0044 | ms/batch 25687.87 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  18 | step    76 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.18.temp_checkpoint\n",
            "epoch: 20/100\n",
            "| step    79 |  lr: 0.0002000 | loss  0.0040 | ms/batch 30558.47 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  19 | step    80 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.19.temp_checkpoint\n",
            "epoch: 21/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  20 | step    84 | dev_acc  0.8824 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.20.temp_checkpoint\n",
            "epoch: 22/100\n",
            "| step    84 |  lr: 0.0002000 | loss  0.0012 | ms/batch 8475.37 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  21 | step    88 | dev_acc  0.9412 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.21.best_model\n",
            "epoch: 23/100\n",
            "| step    89 |  lr: 0.0002000 | loss  0.0008 | ms/batch 17157.95 |\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:06<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  22 | step    92 | dev_acc  0.8627 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_brain_teaser_ds__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.22.temp_checkpoint\n",
            "epoch: 24/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0a4fb7dbe8f9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_dev_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-54b0ff370d36>\u001b[0m in \u001b[0;36mmain_5\u001b[0;34m(args, global_step, best_dev_epoch)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_dev_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eval_detail'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;31m# raise NotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-54b0ff370d36>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, global_step, best_dev_epoch)\u001b[0m\n\u001b[1;32m    238\u001b[0m                         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m                     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_grad_norm\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PwrwLD4qiTnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vsKjNg9piTlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mzAzbejSiTie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KV3cn4jtiTe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eF7XKI_OiTZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ot7t0aCvUYp"
      },
      "source": [
        "##<font color=pink>Train Riddle_sense</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGSSRZcXvXjW",
        "outputId": "132202bd-dcea-4aad-e35e-212b0d15a1fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***** hyperparameters *****\n",
            "dataset: riddle_sense\n",
            "enc_name: roberta-large\n",
            "batch_size: 128\n",
            "learning_rate: elr 1e-05 dlr 0.001\n",
            "gnn: dim 200 layer 5\n",
            "Epochs: 100\n",
            "******************************\n"
          ]
        }
      ],
      "source": [
        "dataset=\"riddle_sense\"\n",
        "model='roberta-large'\n",
        "\n",
        "# elr=1e-5 #encoder learning rate\n",
        "elr=2e-4 #encoder learning rate\n",
        "dlr=1e-3  #decoder learing rate\n",
        "batch_size=128 #128 default\n",
        "mbs=2   #mini-batch-size\n",
        "n_epochs=100 #def 100\n",
        "num_relation=38 #(17 +2) * 2: originally 17, add 2 relation types (QA context -> Q node; QA context -> A node), and double because we add reverse edges\n",
        "seed=0\n",
        "\n",
        "k=5 #num of gnn layers\n",
        "gnndim=200    #dimension of the GNN layers def 200\n",
        "\n",
        "!echo \"***** hyperparameters *****\"\n",
        "!echo \"dataset: $dataset\"\n",
        "!echo \"enc_name: $model\"\n",
        "!echo \"batch_size: $batch_size\"\n",
        "!echo \"learning_rate: elr $elr dlr $dlr\"\n",
        "!echo \"gnn: dim $gnndim layer $k\"\n",
        "!echo \"Epochs: $n_epochs\"\n",
        "!echo \"******************************\"\n",
        "\n",
        "main_dir='/content/drive/MyDrive/brain_teaser'\n",
        "save_dir_pref=f\"{main_dir}/QA_GNN/saved_models\"\n",
        "\n",
        "if not os.path.exists(save_dir_pref):\n",
        "  %mkdir -p $save_dir_pref\n",
        "%mkdir -p logs\n",
        "\n",
        "args=dict()\n",
        "\n",
        "args['warmup_steps']=0\n",
        "\n",
        "args[\"encoder\"]=model\n",
        "args['enc']=model\n",
        "\n",
        "# args[\"save_dir\"]=f\"{save_dir_pref}/enc-{model}_dataset_{dataset}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"best_model_save_dir\"]=f\"{save_dir_pref}/best_model_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"checkpoint_save_dir\"]=f\"{save_dir_pref}/checkpoint_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"log_save_dir\"]=f\"{save_dir_pref}/log_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "\n",
        "args[\"save_best_model\"]=True\n",
        "args['save_test_preds']=False\n",
        "args[\"save_checkpoint\"]=True\n",
        "\n",
        "args['loss']='cross_entropy'\n",
        "args['lr_schedule']='fixed'\n",
        "args['bs']=batch_size\n",
        "args['batch_size']=batch_size\n",
        "\n",
        "\n",
        "args['max_grad_norm']=1.0\n",
        "args['me']=10\n",
        "args['log_interval']=5\n",
        "args['debug']=False\n",
        "args[\"optim\"]=\"radam\"\n",
        "\n",
        "args[\"mode\"]=\"train\"    #choices=['train', 'eval_detail'], help='run training or evaluation\n",
        "args[\"dataset\"]=dataset\n",
        "\n",
        "args[\"k\"]=k   #perform k-layer message passing\n",
        "args[\"gnn_dim\"]=gnndim\n",
        "args[\"encoder_lr\"]=elr\n",
        "args[\"decoder_lr\"]=dlr\n",
        "args[\"batch_size\"]=batch_size\n",
        "args[\"mini_batch_size\"]=mbs\n",
        "args[\"fp16\"]=False   #use fp16 training. this requires torch>=1.6.0\n",
        "args[\"seed\"]=seed\n",
        "args[\"num_relation\"]=num_relation\n",
        "args[\"n_epochs\"]=n_epochs\n",
        "args[\"max_epochs_before_stop\"]=10\n",
        "args[\"train_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/train.graph.adj.pk\"\n",
        "args[\"dev_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/dev.graph.adj.pk\"\n",
        "args[\"test_adj\"]=None\n",
        "\n",
        "args[\"train_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/train.statement.jsonl\"\n",
        "args[\"dev_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/dev.statement.jsonl\"\n",
        "args[\"test_statements\"]=None\n",
        "\n",
        "\n",
        "args[\"cuda\"]=True\n",
        "# args[\"ent_emb_paths\"]=['data/cpnet/tzw.ent.npy']\n",
        "args[\"ent_emb_paths\"]=['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy']\n",
        "args[\"max_seq_len\"]=128\n",
        "args[\"inhouse\"]=False\n",
        "args[\"inhouse_train_qids\"]=f'{main_dir}/datasets/{dataset}/inhouse_split_qids.txt'\n",
        "args[\"weight_decay\"]=1e-2\n",
        "\n",
        "args['encoder_layer']=-1\n",
        "# args['elr']=2e-4\n",
        "# args[\"encoder_lr\"]=2e-4\n",
        "\n",
        "\n",
        "# args[\"load_model_path\"]='/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.7.best_model'\n",
        "\n",
        "# args[\"load_model_path\"]=None\n",
        "args[\"load_model_path\"]='/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.12.best_model'\n",
        "# args[\"load_model_path\"]='/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.15.temp_checkpoint'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMxKHAvegptk"
      },
      "source": [
        "12_8_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC_dkZ2u3WIz",
        "outputId": "bbc00137-021b-42d0-f7e8-1ca425f6b3fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'warmup_steps': 0, 'encoder': 'roberta-large', 'enc': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/log_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 5, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'riddle_sense', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'elr': 0.0002, 'load_model_path': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.12.best_model', 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3503/3503 [00:03<00:00, 969.11it/s]\n",
            "100%|██████████| 1021/1021 [00:00<00:00, 1027.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 167.61 sigma 172.13 | adj_len: 115.70 | prune_rate： 0.30 | qc_num: 9.78 | ac_num: 1.64 |\n",
            "| ori_adj_len: mu 194.18 sigma 175.85 | adj_len: 131.31 | prune_rate： 0.36 | qc_num: 10.75 | ac_num: 1.49 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading and initializing model from /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.12.best_model\n",
            "previous best_dev_acc: 0.5974534769833496\n",
            "current training epoch start from: 13\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 14/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-6-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step   364 |  lr: 0.0002000 | loss  0.0138 | ms/batch 4208.62 |\n",
            "| step   369 |  lr: 0.0002000 | loss  0.0894 | ms/batch 20705.53 |\n",
            "| step   374 |  lr: 0.0002000 | loss  0.1123 | ms/batch 20972.75 |\n",
            "| step   379 |  lr: 0.0002000 | loss  0.1198 | ms/batch 21504.99 |\n",
            "| step   384 |  lr: 0.0002000 | loss  0.0957 | ms/batch 21245.28 |\n",
            "| step   389 |  lr: 0.0002000 | loss  0.1079 | ms/batch 21131.38 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:15<00:00,  3.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  13 | step   392 | dev_acc  0.6053 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.13.best_model\n",
            "epoch: 15/100\n",
            "| step   394 |  lr: 0.0002000 | loss  0.0667 | ms/batch 13093.28 |\n",
            "| step   399 |  lr: 0.0002000 | loss  0.1453 | ms/batch 20997.17 |\n",
            "| step   404 |  lr: 0.0002000 | loss  0.0789 | ms/batch 21456.75 |\n",
            "| step   409 |  lr: 0.0002000 | loss  0.0954 | ms/batch 21625.31 |\n",
            "| step   414 |  lr: 0.0002000 | loss  0.0862 | ms/batch 21164.54 |\n",
            "| step   419 |  lr: 0.0002000 | loss  0.0777 | ms/batch 18555.26 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:15<00:00,  3.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  14 | step   420 | dev_acc  0.6112 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.14.best_model\n",
            "epoch: 16/100\n",
            "| step   424 |  lr: 0.0002000 | loss  0.1124 | ms/batch 20967.72 |\n",
            "| step   429 |  lr: 0.0002000 | loss  0.0998 | ms/batch 21328.78 |\n",
            "| step   434 |  lr: 0.0002000 | loss  0.0833 | ms/batch 21441.13 |\n",
            "| step   439 |  lr: 0.0002000 | loss  0.0762 | ms/batch 21394.72 |\n",
            "| step   444 |  lr: 0.0002000 | loss  0.1173 | ms/batch 21302.66 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:15<00:00,  3.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  15 | step   448 | dev_acc  0.6033 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.15.temp_checkpoint\n",
            "epoch: 17/100\n",
            "| step   449 |  lr: 0.0002000 | loss  0.0978 | ms/batch 8710.55 |\n",
            "| step   454 |  lr: 0.0002000 | loss  0.0883 | ms/batch 21216.97 |\n",
            "| step   459 |  lr: 0.0002000 | loss  0.0984 | ms/batch 21090.97 |\n",
            "| step   464 |  lr: 0.0002000 | loss  0.0871 | ms/batch 21568.91 |\n",
            "| step   469 |  lr: 0.0002000 | loss  0.1006 | ms/batch 21270.89 |\n",
            "| step   474 |  lr: 0.0002000 | loss  0.0741 | ms/batch 21122.72 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:15<00:00,  3.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  16 | step   476 | dev_acc  0.6210 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.16.best_model\n",
            "epoch: 18/100\n",
            "| step   479 |  lr: 0.0002000 | loss  0.0987 | ms/batch 17273.49 |\n",
            "| step   484 |  lr: 0.0002000 | loss  0.0707 | ms/batch 21119.44 |\n",
            "| step   489 |  lr: 0.0002000 | loss  0.0854 | ms/batch 21160.69 |\n",
            "| step   494 |  lr: 0.0002000 | loss  0.0657 | ms/batch 21409.74 |\n",
            "| step   499 |  lr: 0.0002000 | loss  0.1029 | ms/batch 21301.84 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:15<00:00,  3.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  17 | step   504 | dev_acc  0.6141 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.17.temp_checkpoint\n",
            "epoch: 19/100\n",
            "| step   504 |  lr: 0.0002000 | loss  0.0838 | ms/batch 4343.33 |\n",
            "| step   509 |  lr: 0.0002000 | loss  0.0822 | ms/batch 21300.89 |\n",
            "| step   514 |  lr: 0.0002000 | loss  0.1003 | ms/batch 21373.39 |\n",
            "| step   519 |  lr: 0.0002000 | loss  0.1061 | ms/batch 21233.78 |\n",
            "| step   524 |  lr: 0.0002000 | loss  0.0747 | ms/batch 21190.92 |\n",
            "| step   529 |  lr: 0.0002000 | loss  0.0847 | ms/batch 21686.62 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:15<00:00,  3.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  18 | step   532 | dev_acc  0.6131 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.18.temp_checkpoint\n",
            "epoch: 20/100\n",
            "| step   534 |  lr: 0.0002000 | loss  0.0975 | ms/batch 13065.65 |\n",
            "| step   539 |  lr: 0.0002000 | loss  0.0911 | ms/batch 21350.86 |\n",
            "| step   544 |  lr: 0.0002000 | loss  0.0698 | ms/batch 21045.96 |\n",
            "| step   549 |  lr: 0.0002000 | loss  0.0843 | ms/batch 21502.84 |\n",
            "| step   554 |  lr: 0.0002000 | loss  0.0766 | ms/batch 21266.66 |\n",
            "| step   559 |  lr: 0.0002000 | loss  0.0515 | ms/batch 18806.92 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:15<00:00,  3.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  19 | step   560 | dev_acc  0.6082 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.19.temp_checkpoint\n",
            "epoch: 21/100\n",
            "| step   564 |  lr: 0.0002000 | loss  0.0628 | ms/batch 21458.95 |\n",
            "| step   569 |  lr: 0.0002000 | loss  0.0774 | ms/batch 21202.50 |\n",
            "| step   574 |  lr: 0.0002000 | loss  0.0714 | ms/batch 21307.69 |\n",
            "| step   579 |  lr: 0.0002000 | loss  0.0940 | ms/batch 21233.32 |\n",
            "| step   584 |  lr: 0.0002000 | loss  0.0739 | ms/batch 21366.74 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:14<00:00,  3.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  20 | step   588 | dev_acc  0.6151 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.20.temp_checkpoint\n",
            "epoch: 22/100\n",
            "| step   589 |  lr: 0.0002000 | loss  0.0682 | ms/batch 8729.31 |\n",
            "| step   594 |  lr: 0.0002000 | loss  0.0530 | ms/batch 21411.68 |\n",
            "| step   599 |  lr: 0.0002000 | loss  0.0402 | ms/batch 21331.92 |\n",
            "| step   604 |  lr: 0.0002000 | loss  0.0802 | ms/batch 21352.35 |\n",
            "| step   609 |  lr: 0.0002000 | loss  0.0750 | ms/batch 21147.64 |\n",
            "| step   614 |  lr: 0.0002000 | loss  0.0506 | ms/batch 21002.69 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:15<00:00,  3.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  21 | step   616 | dev_acc  0.6102 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.21.temp_checkpoint\n",
            "epoch: 23/100\n",
            "| step   619 |  lr: 0.0002000 | loss  0.0507 | ms/batch 17180.14 |\n",
            "| step   624 |  lr: 0.0002000 | loss  0.0621 | ms/batch 21202.27 |\n",
            "| step   629 |  lr: 0.0002000 | loss  0.0678 | ms/batch 21286.56 |\n",
            "| step   634 |  lr: 0.0002000 | loss  0.0718 | ms/batch 21373.93 |\n",
            "| step   639 |  lr: 0.0002000 | loss  0.0562 | ms/batch 21306.40 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:15<00:00,  3.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  22 | step   644 | dev_acc  0.6092 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.22.temp_checkpoint\n",
            "epoch: 24/100\n",
            "| step   644 |  lr: 0.0002000 | loss  0.0746 | ms/batch 4136.28 |\n",
            "| step   649 |  lr: 0.0002000 | loss  0.0528 | ms/batch 21733.76 |\n",
            "| step   654 |  lr: 0.0002000 | loss  0.0423 | ms/batch 21178.99 |\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e39dbbf71ac0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m364\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_dev_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-5a63b9a8dae3>\u001b[0m in \u001b[0;36mmain_5\u001b[0;34m(args, global_step, best_dev_epoch)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_dev_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eval_detail'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;31m# raise NotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-5a63b9a8dae3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, global_step, best_dev_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_layer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, layer_id, cache_output, detail, *inputs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0msent_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlm_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         logits, attn = self.decoder(sent_vecs.to(node_type_ids.device),\n\u001b[0m\u001b[1;32m    232\u001b[0m                                     \u001b[0mconcept_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                                     \u001b[0mnode_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_vecs, concept_ids, node_type_ids, node_scores, adj_lengths, adj, emb_data, cache_output)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mgnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mZ_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m#(batch_size, dim_node)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, H, A, node_type, node_score, cache_output)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#Embed type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_n_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mnode_type_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_node_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[batch_size, n_node, dim/2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mmake_one_hot\u001b[0;34m(labels, C)\u001b[0m\n\u001b[1;32m    363\u001b[0m     '''\n\u001b[1;32m    364\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "main_5(args, global_step=364, best_dev_epoch=12, is_finetuning_on_new_ds=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beVi8PGI3zUG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxpu56nigrt9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqeR2fmEirnJ"
      },
      "source": [
        "12_7_2023_  Loading from csqa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "47e63423b23f4c65b70b4dbc6d179675",
            "a5d9aba117484778bfffb9f1b4b6be6c",
            "cc2eeb93b0504598b497005acf4b2496",
            "4b199765011a443fa6107a49aef294f8",
            "feaa5655930c453b985c26051360230e",
            "76a9073e2fcc49368c366e9cae4c5cbd",
            "dd6691fc7b724d73b30560fc248a62da",
            "de3d7ba4f2d841a9a4fbe04b278d5445",
            "ec835bf8cc284d51a4ec243843003b06",
            "1738681fd75e4f019afdb860f022ba1b",
            "4857edd02066499fabae1b2a2123709b",
            "a663d38f915947f1a0cbad1b5ce01925",
            "175f032983f14d3d84d73f40086583d0",
            "c1334cf22480476ab22f9848743e334b",
            "b43a248e85214efdae985449d7d4f9fd",
            "9ac9407ffd85487aaca7cb420460f550",
            "67ea6863dcbb4b5f9bc9f1643ec75063",
            "2ddee989ac7a4bb18374a6b89cabe49c",
            "3125140a79084dcaa9ce3e665bc9853e",
            "96282002258d4254ad027348f6e32ba3",
            "f40737a9125a461e930de51ec3e49167",
            "c7cdc7af13c04fc7945ac971511db2ca",
            "5e83f5e96c1e4a5b89181c64f84b2b85",
            "b793fc09d80a4b359a56c28f119683dc",
            "718203cd7133449da33af5fa839dc479",
            "173775eb71e94bb7aedc322faa8a6f72",
            "434de5fd32a24f3dab8b335ddac525eb",
            "068b52189369439b8e7786802567ddaf",
            "43494ede53d84cfe85c8ddeef50ec526",
            "a6cade5a6900437f889eb2e018a581e3",
            "34af7818f7fa49c0a5e7362c5cea18e1",
            "c29e67631b1e43de8d8f1db49b3008d9",
            "3531b9252154431a8d5f4774abc1636a",
            "b20ce595da4a4ef69d161b55d87f2c5f",
            "a72404f819d4465c97f71fa626636a64",
            "9a1850fe21ea40a1ab2c483fb651de56",
            "19b99a08457c4ad7bafb5f680bd8f52f",
            "3de5f6ff765b44c19445a15229ddaca4",
            "f6c0322756534517a9e0b3d011146c4b",
            "a42731aa1ee04cb8bda9a346a28c9203",
            "a93756ab0c774bc6b847fd991c725e17",
            "36e31c596b5343f28dfa0869c378de01",
            "18e2574238f54a7c9eb405b43de5a521",
            "e3aaf4b6527c40f184555f5cd5f4cf3d",
            "9a228727bf3d4ae981dc910d5a4425db",
            "a486bcdae5a549a5a0a8d9bceb55f8b6",
            "9319ea6ab00940938f1518ccd140ac08",
            "c41305ec8c244605af457049afe2355a",
            "2318aa74cf45449d8302fd0607db55f4",
            "6884a3222be74617b51c8a91ac3585c2",
            "fc4d22c72f9d4297ab33014a1c39331e",
            "2519ee4c769a4d43a6457cff99208b16",
            "e6deadac49a54ca8b722519f5fd953a6",
            "05ab5d178a824081a0650be6abdd6c6a",
            "8beb94ea6ea24a3b9b1a8974062c9d44"
          ]
        },
        "id": "ffaeaq6XiW_V",
        "outputId": "abfc465f-a679-471d-fadb-c67c2c6c9b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'warmup_steps': 0, 'encoder': 'roberta-large', 'enc': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/log_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 5, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'riddle_sense', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'elr': 0.0002, 'load_model_path': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.7.best_model', 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47e63423b23f4c65b70b4dbc6d179675",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a663d38f915947f1a0cbad1b5ce01925",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e83f5e96c1e4a5b89181c64f84b2b85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b20ce595da4a4ef69d161b55d87f2c5f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3503/3503 [00:03<00:00, 1064.92it/s]\n",
            "100%|██████████| 1021/1021 [00:00<00:00, 1021.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 167.61 sigma 172.13 | adj_len: 115.70 | prune_rate： 0.30 | qc_num: 9.78 | ac_num: 1.64 |\n",
            "| ori_adj_len: mu 194.18 sigma 175.85 | adj_len: 131.31 | prune_rate： 0.36 | qc_num: 10.75 | ac_num: 1.49 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a228727bf3d4ae981dc910d5a4425db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading and initializing model from /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.7.best_model\n",
            "previous best_dev_acc: None\n",
            "current training epoch start from: None\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-9-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     4 |  lr: 0.0002000 | loss  2.0041 | ms/batch 21286.20 |\n",
            "| step     9 |  lr: 0.0002000 | loss  1.9068 | ms/batch 21459.62 |\n",
            "| step    14 |  lr: 0.0002000 | loss  1.6686 | ms/batch 21667.20 |\n",
            "| step    19 |  lr: 0.0002000 | loss  1.5554 | ms/batch 21497.12 |\n",
            "| step    24 |  lr: 0.0002000 | loss  1.5404 | ms/batch 21504.44 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:16<00:00,  3.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   0 | step    28 | dev_acc  0.2468 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.0.best_model\n",
            "epoch: 2/100\n",
            "| step    29 |  lr: 0.0002000 | loss  1.4928 | ms/batch 8849.86 |\n",
            "| step    34 |  lr: 0.0002000 | loss  1.4492 | ms/batch 21611.55 |\n",
            "| step    39 |  lr: 0.0002000 | loss  1.4524 | ms/batch 21480.84 |\n",
            "| step    44 |  lr: 0.0002000 | loss  1.4013 | ms/batch 21801.71 |\n",
            "| step    49 |  lr: 0.0002000 | loss  1.3837 | ms/batch 21611.43 |\n",
            "| step    54 |  lr: 0.0002000 | loss  1.3821 | ms/batch 21392.00 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:16<00:00,  3.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   1 | step    56 | dev_acc  0.2400 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.1.temp_checkpoint\n",
            "epoch: 3/100\n",
            "| step    59 |  lr: 0.0002000 | loss  1.3215 | ms/batch 17086.51 |\n",
            "| step    64 |  lr: 0.0002000 | loss  1.2859 | ms/batch 21448.20 |\n",
            "| step    69 |  lr: 0.0002000 | loss  1.2624 | ms/batch 21921.60 |\n",
            "| step    74 |  lr: 0.0002000 | loss  1.2476 | ms/batch 21553.08 |\n",
            "| step    79 |  lr: 0.0002000 | loss  1.2443 | ms/batch 21654.19 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:16<00:00,  3.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   2 | step    84 | dev_acc  0.2791 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.2.best_model\n",
            "epoch: 4/100\n",
            "| step    84 |  lr: 0.0002000 | loss  1.2004 | ms/batch 4532.51 |\n",
            "| step    89 |  lr: 0.0002000 | loss  1.1489 | ms/batch 21493.71 |\n",
            "| step    94 |  lr: 0.0002000 | loss  1.1918 | ms/batch 21454.85 |\n",
            "| step    99 |  lr: 0.0002000 | loss  1.1787 | ms/batch 21733.80 |\n",
            "| step   104 |  lr: 0.0002000 | loss  1.1282 | ms/batch 21609.60 |\n",
            "| step   109 |  lr: 0.0002000 | loss  1.1256 | ms/batch 21581.17 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:16<00:00,  3.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   3 | step   112 | dev_acc  0.2997 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.3.best_model\n",
            "epoch: 5/100\n",
            "| step   114 |  lr: 0.0002000 | loss  1.0679 | ms/batch 28601.69 |\n",
            "| step   119 |  lr: 0.0002000 | loss  1.0884 | ms/batch 47301.86 |\n",
            "| step   124 |  lr: 0.0002000 | loss  1.1489 | ms/batch 47189.20 |\n",
            "| step   129 |  lr: 0.0002000 | loss  1.0837 | ms/batch 47495.95 |\n",
            "| step   134 |  lr: 0.0002000 | loss  1.1005 | ms/batch 47384.97 |\n",
            "| step   139 |  lr: 0.0002000 | loss  1.0221 | ms/batch 41681.83 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:16<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   4 | step   140 | dev_acc  0.3056 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.4.best_model\n",
            "epoch: 6/100\n",
            "| step   144 |  lr: 0.0002000 | loss  1.0595 | ms/batch 47482.00 |\n",
            "| step   149 |  lr: 0.0002000 | loss  0.9723 | ms/batch 47364.61 |\n",
            "| step   154 |  lr: 0.0002000 | loss  0.8646 | ms/batch 47425.70 |\n",
            "| step   159 |  lr: 0.0002000 | loss  0.8455 | ms/batch 47259.08 |\n",
            "| step   164 |  lr: 0.0002000 | loss  0.8428 | ms/batch 47660.14 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:16<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   5 | step   168 | dev_acc  0.2948 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.5.temp_checkpoint\n",
            "epoch: 7/100\n",
            "| step   169 |  lr: 0.0002000 | loss  0.8753 | ms/batch 19220.09 |\n",
            "| step   174 |  lr: 0.0002000 | loss  0.7467 | ms/batch 47264.27 |\n",
            "| step   179 |  lr: 0.0002000 | loss  0.7212 | ms/batch 47233.43 |\n",
            "| step   184 |  lr: 0.0002000 | loss  0.6861 | ms/batch 47341.67 |\n",
            "| step   189 |  lr: 0.0002000 | loss  0.7457 | ms/batch 47294.10 |\n",
            "| step   194 |  lr: 0.0002000 | loss  0.6418 | ms/batch 47657.97 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:17<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   6 | step   196 | dev_acc  0.3526 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.6.best_model\n",
            "epoch: 8/100\n",
            "| step   199 |  lr: 0.0002000 | loss  0.6090 | ms/batch 38131.83 |\n",
            "| step   204 |  lr: 0.0002000 | loss  0.6162 | ms/batch 47494.03 |\n",
            "| step   209 |  lr: 0.0002000 | loss  0.6087 | ms/batch 47135.14 |\n",
            "| step   214 |  lr: 0.0002000 | loss  0.6405 | ms/batch 47362.75 |\n",
            "| step   219 |  lr: 0.0002000 | loss  0.6615 | ms/batch 47615.15 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:17<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   7 | step   224 | dev_acc  0.3663 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.7.best_model\n",
            "epoch: 9/100\n",
            "| step   224 |  lr: 0.0002000 | loss  0.5264 | ms/batch 9714.03 |\n",
            "| step   229 |  lr: 0.0002000 | loss  0.5192 | ms/batch 47504.86 |\n",
            "| step   234 |  lr: 0.0002000 | loss  0.5424 | ms/batch 47409.89 |\n",
            "| step   239 |  lr: 0.0002000 | loss  0.4939 | ms/batch 47767.83 |\n",
            "| step   244 |  lr: 0.0002000 | loss  0.5296 | ms/batch 47160.02 |\n",
            "| step   249 |  lr: 0.0002000 | loss  0.4520 | ms/batch 47172.86 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:17<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   8 | step   252 | dev_acc  0.4505 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.8.best_model\n",
            "epoch: 10/100\n",
            "| step   254 |  lr: 0.0002000 | loss  0.4506 | ms/batch 28668.24 |\n",
            "| step   259 |  lr: 0.0002000 | loss  0.4381 | ms/batch 47273.69 |\n",
            "| step   264 |  lr: 0.0002000 | loss  0.3447 | ms/batch 47569.79 |\n",
            "| step   269 |  lr: 0.0002000 | loss  0.3951 | ms/batch 47405.32 |\n",
            "| step   274 |  lr: 0.0002000 | loss  0.4349 | ms/batch 47493.01 |\n",
            "| step   279 |  lr: 0.0002000 | loss  0.4520 | ms/batch 41355.00 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:17<00:00,  3.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   9 | step   280 | dev_acc  0.4662 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.9.best_model\n",
            "epoch: 11/100\n",
            "| step   284 |  lr: 0.0002000 | loss  0.3527 | ms/batch 47673.60 |\n",
            "| step   289 |  lr: 0.0002000 | loss  0.3265 | ms/batch 47283.77 |\n",
            "| step   294 |  lr: 0.0002000 | loss  0.3331 | ms/batch 47635.40 |\n",
            "| step   299 |  lr: 0.0002000 | loss  0.2920 | ms/batch 47183.48 |\n",
            "| step   304 |  lr: 0.0002000 | loss  0.3480 | ms/batch 47320.25 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:16<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  10 | step   308 | dev_acc  0.5681 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.10.best_model\n",
            "epoch: 12/100\n",
            "| step   309 |  lr: 0.0002000 | loss  0.2779 | ms/batch 19129.25 |\n",
            "| step   314 |  lr: 0.0002000 | loss  0.2842 | ms/batch 47252.25 |\n",
            "| step   319 |  lr: 0.0002000 | loss  0.2517 | ms/batch 47569.12 |\n",
            "| step   324 |  lr: 0.0002000 | loss  0.2762 | ms/batch 47404.84 |\n",
            "| step   329 |  lr: 0.0002000 | loss  0.2516 | ms/batch 47246.57 |\n",
            "| step   334 |  lr: 0.0002000 | loss  0.2105 | ms/batch 47608.70 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:17<00:00,  3.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  11 | step   336 | dev_acc  0.5896 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.11.best_model\n",
            "epoch: 13/100\n",
            "| step   339 |  lr: 0.0002000 | loss  0.1219 | ms/batch 37932.93 |\n",
            "| step   344 |  lr: 0.0002000 | loss  0.1646 | ms/batch 47383.03 |\n",
            "| step   349 |  lr: 0.0002000 | loss  0.1524 | ms/batch 47190.76 |\n",
            "| step   354 |  lr: 0.0002000 | loss  0.1640 | ms/batch 47225.64 |\n",
            "| step   359 |  lr: 0.0002000 | loss  0.1559 | ms/batch 48031.70 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:16<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  12 | step   364 | dev_acc  0.5975 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.12.best_model\n",
            "epoch: 14/100\n",
            "| step   364 |  lr: 0.0002000 | loss  0.1631 | ms/batch 9561.59 |\n",
            "| step   369 |  lr: 0.0002000 | loss  0.1219 | ms/batch 47648.96 |\n",
            "| step   374 |  lr: 0.0002000 | loss  0.1014 | ms/batch 47558.87 |\n",
            "| step   379 |  lr: 0.0002000 | loss  0.1117 | ms/batch 47635.06 |\n",
            "| step   384 |  lr: 0.0002000 | loss  0.1141 | ms/batch 47313.62 |\n",
            "| step   389 |  lr: 0.0002000 | loss  0.1181 | ms/batch 47538.17 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:17<00:00,  3.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  13 | step   392 | dev_acc  0.5788 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.13.temp_checkpoint\n",
            "epoch: 15/100\n",
            "| step   394 |  lr: 0.0002000 | loss  0.1012 | ms/batch 28446.54 |\n",
            "| step   399 |  lr: 0.0002000 | loss  0.0627 | ms/batch 47545.48 |\n",
            "| step   404 |  lr: 0.0002000 | loss  0.0729 | ms/batch 47448.40 |\n",
            "| step   409 |  lr: 0.0002000 | loss  0.0865 | ms/batch 47490.79 |\n",
            "| step   414 |  lr: 0.0002000 | loss  0.0901 | ms/batch 47720.88 |\n",
            "| step   419 |  lr: 0.0002000 | loss  0.0962 | ms/batch 41499.37 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:17<00:00,  3.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  14 | step   420 | dev_acc  0.5426 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.14.temp_checkpoint\n",
            "epoch: 16/100\n",
            "| step   424 |  lr: 0.0002000 | loss  0.0940 | ms/batch 47975.36 |\n",
            "| step   429 |  lr: 0.0002000 | loss  0.0392 | ms/batch 47551.85 |\n",
            "| step   434 |  lr: 0.0002000 | loss  0.0479 | ms/batch 47380.80 |\n",
            "| step   439 |  lr: 0.0002000 | loss  0.0449 | ms/batch 47580.19 |\n",
            "| step   444 |  lr: 0.0002000 | loss  0.0420 | ms/batch 47044.22 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:16<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  15 | step   448 | dev_acc  0.5828 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.15.temp_checkpoint\n",
            "epoch: 17/100\n",
            "| step   449 |  lr: 0.0002000 | loss  0.0477 | ms/batch 19053.58 |\n"
          ]
        }
      ],
      "source": [
        "main_5(args, global_step=0, best_dev_epoch=0, is_finetuning_on_new_ds=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4SHADC7i2Yz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcU_O2P1i2SD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCwdu7Sgi2Ft"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb-d6d1U8nmt"
      },
      "source": [
        "###12_5_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "05c5ff6437a04d11951b23a7f3434c87",
            "4428c3ee8f79455ba5066cc0937de670",
            "28ef08c196b04f84bd701f2a2a7c2842",
            "78e550978be84dac93501e1dea84e0db",
            "ef735ce7ac5b421a8f6fb658d8ae1f24",
            "d54a4135a7164612b17a4c5198961c92",
            "b40148c4fe9e4b39b7f74710c471eea3",
            "68e8d6b6fa7c49bcb5d077937ecace97",
            "1b909814200c40dca6aa1770d5b16217",
            "a4dd9c4e890e4b55a12624e74dcb3839",
            "9c803485af954a2e9ecb4d9c704bbc99",
            "b45682f10ae5416cae55d1bafc811a56",
            "0a783c13998445aba947367704f6a1d4",
            "6b1b640237434e62a8bdcea7641fe3b6",
            "49b99b7bd73243cda135ff1ec0301d6b",
            "93293fed630240119e81fbdee35b0470",
            "f6aae10576a74343a13cb88cb8339d51",
            "cfb79a281c5f431286f645d5bdf6a498",
            "c73e4ce1c7574199941fa948f227c1b2",
            "86d781de6ae9458294a95229172fb68b",
            "2085af4e628748a9824c5e91e7490d4e",
            "86efd710dda44e63b26459377910ab99",
            "49cb2685d98047bcb9fd3f95f7dd20da",
            "887668167fac4cd3b127a8925d41d1d3",
            "3a7a50c1f70040c78932f8e5775c54e7",
            "c3d0493f32484d29b350c1c9f1fa4b54",
            "04ec4050bd9e42f28f207dbbd0009d6f",
            "53622d0462454b22a9bca33f485126d9",
            "b1862c326c6541949146f8647128fde8",
            "96fcd9f505454ee490de94e4864a4410",
            "bb7166fe00834c06ab4b3a63e712dd19",
            "bc988c676b6142b78a009a7da67fbc05",
            "59e7e5528504408c91dfe84d0fc0fa3f",
            "b326e9d81213487797f989598e0363b9",
            "4b9e173d962849fb892a4609e5ac30d9",
            "4f0dea01f6db4ce49dc47348e4d6a3a6",
            "041aea7ed89a41dd8cbabf58008955d4",
            "227a769daeff4569890489dfd71c97b6",
            "0fef5f46136b4ede921f9f5af49657eb",
            "b30432d1cfc947c5864f11382d337f89",
            "73a80398c84d4b76b180975a7962fd39",
            "752887d788f24465be7fc345ad3e94a1",
            "c8334f674d9945f4a117865dededfdbf",
            "826d0b9f5d16423c9ba55cd5fc4f8498",
            "ea886f2ba13642cfbe03c80c6dd651cf",
            "2bf9df005960449b81fb593a30de7764",
            "c59cb7dd90a24cd2b266e67d3cc4ea43",
            "ef71019daa6847a59da56501a4955fc5",
            "175dae5537da458f88798e706e35e7c8",
            "2124d2d5277f4b6aac4063089c824693",
            "8d9c6290951b4dd4beedfd4fa6f0fc6c",
            "ecf98edf5716448c8d81df119270e76a",
            "e21ba70e7890415d99bcb41b6b8e201e",
            "983125366ebc4609a51e9238268eaf73",
            "367d58a226294562b110d0f031b52e46"
          ]
        },
        "id": "FxL53IyKIT-H",
        "outputId": "b1d1bbf2-27fa-4434-8626-c459d691be77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'warmup_steps': 0, 'encoder': 'roberta-large', 'enc': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/log_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 5, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'riddle_sense', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'elr': 0.0002, 'load_model_path': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.18.temp_checkpoint', 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05c5ff6437a04d11951b23a7f3434c87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b45682f10ae5416cae55d1bafc811a56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49cb2685d98047bcb9fd3f95f7dd20da",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b326e9d81213487797f989598e0363b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3503/3503 [00:03<00:00, 915.67it/s] \n",
            "100%|██████████| 1021/1021 [00:01<00:00, 921.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 167.61 sigma 172.13 | adj_len: 115.70 | prune_rate： 0.30 | qc_num: 9.78 | ac_num: 1.64 |\n",
            "| ori_adj_len: mu 194.18 sigma 175.85 | adj_len: 131.31 | prune_rate： 0.36 | qc_num: 10.75 | ac_num: 1.49 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea886f2ba13642cfbe03c80c6dd651cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading and initializing model from /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.18.temp_checkpoint\n",
            "previous best_dev_acc: 0.604309500489716\n",
            "current training epoch start from: 19\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 20/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-9-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     4 |  lr: 0.0002000 | loss  0.1085 | ms/batch 21649.84 |\n",
            "| step     9 |  lr: 0.0002000 | loss  0.1172 | ms/batch 21968.65 |\n",
            "| step    14 |  lr: 0.0002000 | loss  0.1028 | ms/batch 22209.29 |\n",
            "| step    19 |  lr: 0.0002000 | loss  0.1071 | ms/batch 22187.86 |\n",
            "| step    24 |  lr: 0.0002000 | loss  0.1289 | ms/batch 22110.62 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:20<00:00,  3.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  19 | step    28 | dev_acc  0.5877 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.19.temp_checkpoint\n"
          ]
        }
      ],
      "source": [
        "main_5(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyGAULhPInIu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMz3S_mbanKf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDo6IVlKZY8Z"
      },
      "source": [
        "####previous training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4f2f28c0d09742b1b160830ab49b5f96",
            "d100bbc411ae4ce6a79e7f8f41dc2439",
            "f32ae9e091ae42e18e6595fff7f8bbd6",
            "a69656f8bf964ce8889df06c5ccac18c",
            "db343cee166c40a9871c7f74c65f9864",
            "331596856ff04a86a223eb78c66f897c",
            "fcad34dc82784222801b3289a6e2768b",
            "e7a7d50f071741278602f78c41160e20",
            "089bf456c9e544a4aeb8b8c02dd621f7",
            "c2d221d9ae204fe1b02dae8f9a811d82",
            "50045f2ce0bd490796a3d745f3b6d605",
            "c24d0b100a4148ab91cfdf1dd6977464",
            "aa53ecdfa9bd40888bf967666e1de0e4",
            "9798440f6a1d4ff7ac8706d888f47de4",
            "2fcef4e9a365414aa11731bc560051f5",
            "b7e31aca3bb14973b23128a19c05963e",
            "fe1169f5322a45bd80584fd5d34b4be6",
            "7a508d5ea00a4746a6e0a869628cc61e",
            "10e7e4ef5bfe42eca2be532ab59e75bc",
            "398a8fe2218242da85154dee81f9274c",
            "87e1dac952444071b2f5dd4aa697d194",
            "0ac22b52c7234e009239fcbfd7d6eaee",
            "92f37c86e17740238bf3d7c8d1b3a255",
            "bd8ce176966a43e2ab97dfb57c6008f1",
            "6d9af2a8f2844aaa83ffbfc00aa59948",
            "35984ebb24ee4b9ca8d7222748b18b52",
            "1979c0ec947d4c6fbe3bd975a088f7e5",
            "899aa9f35a0b4d6e867da2cb62f163a6",
            "079a672f9f244b5d91a05b5601320d99",
            "db23e606f67d4f478cf84ca9155adf57",
            "0e1ea22335ed4e84bc4dc837caeb07b2",
            "12034bd090834b45be34816d7afd4af1",
            "71d384ea1c534073909843badf4169ba",
            "98094b3c40864d3790fb639a7de74baa",
            "4155142ca6df49f394a56f4c8df1060c",
            "068c448caa5f45729c93ab6f5d4c0323",
            "45f7871720764afd818da0c6254f8216",
            "4bae712449dd442fb4cd2fc7473c37b4",
            "c9d3f83bfb7b433d9c41b499de79348d",
            "6e8325d208714eac98243896c232060c",
            "0b8eba20b74d406cafff2d83183c6fe5",
            "b4df5fb134a540ca886832f644a613ee",
            "1c72178fad984c0c8f172a0f5fb7706e",
            "56017c2723734c84aba96ef13cbc85b3",
            "438b1cb5984a4a51b77337573284f6d2",
            "188eafb67e75452eafbefdb2a6bff2b7",
            "fd70333d859741fe84645f53325b3c5c",
            "fd215d8777a946e4acab5ed77be48d6d",
            "0c9224a226b449859b023cf15c0e0f71",
            "7890614addb64ec49eb6f5470b05af5a",
            "7ce1362f02574e619239f5381f3fb6b8",
            "dc4d3150aeac433189d38455508431f5",
            "2857bcae75694427995f5f1ccf759afd",
            "63da9fc1903e42ad9f5c6e0c333d7221",
            "d5683069839347bc918f393d51a7d468"
          ]
        },
        "id": "bBb81ni-ZWAZ",
        "outputId": "b4ea2db1-50a7-4454-a99a-232703edf3c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'encoder': 'roberta-large', 'enc': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/log_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 150, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 5, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'riddle_sense', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'elr': 0.0002, 'load_model_path': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.8.temp_checkpoint', 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f2f28c0d09742b1b160830ab49b5f96",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c24d0b100a4148ab91cfdf1dd6977464",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92f37c86e17740238bf3d7c8d1b3a255",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98094b3c40864d3790fb639a7de74baa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3503/3503 [00:03<00:00, 966.13it/s] \n",
            "100%|██████████| 1021/1021 [00:01<00:00, 844.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 167.61 sigma 172.13 | adj_len: 115.70 | prune_rate： 0.30 | qc_num: 9.78 | ac_num: 1.64 |\n",
            "| ori_adj_len: mu 194.18 sigma 175.85 | adj_len: 131.31 | prune_rate： 0.36 | qc_num: 10.75 | ac_num: 1.49 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "438b1cb5984a4a51b77337573284f6d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading and initializing model from /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.8.temp_checkpoint\n",
            "previous best_dev_acc: 0.5886\n",
            "current training epoch start from: 8\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 9/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-9-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     4 |  lr: 0.0002000 | loss  0.2046 | ms/batch 20332.97 |\n",
            "| step     9 |  lr: 0.0002000 | loss  0.2042 | ms/batch 20107.77 |\n",
            "| step    14 |  lr: 0.0002000 | loss  0.1991 | ms/batch 20295.54 |\n",
            "| step    19 |  lr: 0.0002000 | loss  0.2132 | ms/batch 20187.20 |\n",
            "| step    24 |  lr: 0.0002000 | loss  0.2043 | ms/batch 20179.91 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   8 | step    28 | dev_acc  0.5837 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.8.temp_checkpoint\n",
            "epoch: 10/100\n",
            "| step    29 |  lr: 0.0002000 | loss  0.1817 | ms/batch 8151.85 |\n",
            "| step    34 |  lr: 0.0002000 | loss  0.2018 | ms/batch 20336.40 |\n",
            "| step    39 |  lr: 0.0002000 | loss  0.1766 | ms/batch 20115.28 |\n",
            "| step    44 |  lr: 0.0002000 | loss  0.1614 | ms/batch 20385.81 |\n",
            "| step    49 |  lr: 0.0002000 | loss  0.1919 | ms/batch 20262.32 |\n",
            "| step    54 |  lr: 0.0002000 | loss  0.1803 | ms/batch 20066.07 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   9 | step    56 | dev_acc  0.5798 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.9.temp_checkpoint\n",
            "epoch: 11/100\n",
            "| step    59 |  lr: 0.0002000 | loss  0.2137 | ms/batch 15929.52 |\n",
            "| step    64 |  lr: 0.0002000 | loss  0.1991 | ms/batch 20103.65 |\n",
            "| step    69 |  lr: 0.0002000 | loss  0.1950 | ms/batch 20471.43 |\n",
            "| step    74 |  lr: 0.0002000 | loss  0.1653 | ms/batch 20159.56 |\n",
            "| step    79 |  lr: 0.0002000 | loss  0.1696 | ms/batch 20267.15 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  10 | step    84 | dev_acc  0.5994 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.10.best_model\n",
            "epoch: 12/100\n",
            "| step    84 |  lr: 0.0002000 | loss  0.1718 | ms/batch 4194.17 |\n",
            "| step    89 |  lr: 0.0002000 | loss  0.1620 | ms/batch 20108.41 |\n",
            "| step    94 |  lr: 0.0002000 | loss  0.1878 | ms/batch 20089.25 |\n",
            "| step    99 |  lr: 0.0002000 | loss  0.1751 | ms/batch 20395.17 |\n",
            "| step   104 |  lr: 0.0002000 | loss  0.1325 | ms/batch 20284.31 |\n",
            "| step   109 |  lr: 0.0002000 | loss  0.1486 | ms/batch 20169.09 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  11 | step   112 | dev_acc  0.5798 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.11.temp_checkpoint\n",
            "epoch: 13/100\n",
            "| step   114 |  lr: 0.0002000 | loss  0.1444 | ms/batch 12232.66 |\n",
            "| step   119 |  lr: 0.0002000 | loss  0.1338 | ms/batch 20158.30 |\n",
            "| step   124 |  lr: 0.0002000 | loss  0.1721 | ms/batch 20001.29 |\n",
            "| step   129 |  lr: 0.0002000 | loss  0.1452 | ms/batch 20315.57 |\n",
            "| step   134 |  lr: 0.0002000 | loss  0.1654 | ms/batch 20212.89 |\n",
            "| step   139 |  lr: 0.0002000 | loss  0.1445 | ms/batch 17792.95 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  12 | step   140 | dev_acc  0.5896 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.12.temp_checkpoint\n",
            "epoch: 14/100\n",
            "| step   144 |  lr: 0.0002000 | loss  0.1175 | ms/batch 20240.16 |\n",
            "| step   149 |  lr: 0.0002000 | loss  0.1672 | ms/batch 20173.89 |\n",
            "| step   154 |  lr: 0.0002000 | loss  0.1430 | ms/batch 20213.51 |\n",
            "| step   159 |  lr: 0.0002000 | loss  0.1397 | ms/batch 19997.94 |\n",
            "| step   164 |  lr: 0.0002000 | loss  0.1502 | ms/batch 20452.39 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:08<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  13 | step   168 | dev_acc  0.5935 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.13.temp_checkpoint\n",
            "epoch: 15/100\n",
            "| step   169 |  lr: 0.0002000 | loss  0.1578 | ms/batch 8286.19 |\n",
            "| step   174 |  lr: 0.0002000 | loss  0.1646 | ms/batch 20137.75 |\n",
            "| step   179 |  lr: 0.0002000 | loss  0.1298 | ms/batch 19975.78 |\n",
            "| step   184 |  lr: 0.0002000 | loss  0.0939 | ms/batch 20191.17 |\n",
            "| step   189 |  lr: 0.0002000 | loss  0.1246 | ms/batch 20062.50 |\n",
            "| step   194 |  lr: 0.0002000 | loss  0.1054 | ms/batch 20360.53 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  14 | step   196 | dev_acc  0.5877 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.14.temp_checkpoint\n",
            "epoch: 16/100\n",
            "| step   199 |  lr: 0.0002000 | loss  0.0781 | ms/batch 16293.41 |\n",
            "| step   204 |  lr: 0.0002000 | loss  0.0801 | ms/batch 20260.16 |\n",
            "| step   209 |  lr: 0.0002000 | loss  0.1034 | ms/batch 20013.11 |\n",
            "| step   214 |  lr: 0.0002000 | loss  0.1091 | ms/batch 20188.04 |\n",
            "| step   219 |  lr: 0.0002000 | loss  0.0680 | ms/batch 20288.19 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  15 | step   224 | dev_acc  0.5749 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.15.temp_checkpoint\n",
            "epoch: 17/100\n",
            "| step   224 |  lr: 0.0002000 | loss  0.0513 | ms/batch 4077.99 |\n",
            "| step   229 |  lr: 0.0002000 | loss  0.0806 | ms/batch 20393.76 |\n",
            "| step   234 |  lr: 0.0002000 | loss  0.0491 | ms/batch 20185.78 |\n",
            "| step   239 |  lr: 0.0002000 | loss  0.0409 | ms/batch 20463.62 |\n",
            "| step   244 |  lr: 0.0002000 | loss  0.0544 | ms/batch 19943.09 |\n",
            "| step   249 |  lr: 0.0002000 | loss  0.0413 | ms/batch 19897.06 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  16 | step   252 | dev_acc  0.5916 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.16.temp_checkpoint\n",
            "epoch: 18/100\n",
            "| step   254 |  lr: 0.0002000 | loss  0.1085 | ms/batch 12285.01 |\n",
            "| step   259 |  lr: 0.0002000 | loss  0.1271 | ms/batch 19988.99 |\n",
            "| step   264 |  lr: 0.0002000 | loss  0.1671 | ms/batch 20327.63 |\n",
            "| step   269 |  lr: 0.0002000 | loss  0.1603 | ms/batch 20220.49 |\n",
            "| step   274 |  lr: 0.0002000 | loss  0.1439 | ms/batch 20349.11 |\n",
            "| step   279 |  lr: 0.0002000 | loss  0.1854 | ms/batch 17573.67 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  17 | step   280 | dev_acc  0.5857 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.17.temp_checkpoint\n",
            "epoch: 19/100\n",
            "| step   284 |  lr: 0.0002000 | loss  0.1379 | ms/batch 20438.75 |\n",
            "| step   289 |  lr: 0.0002000 | loss  0.1369 | ms/batch 20111.73 |\n",
            "| step   294 |  lr: 0.0002000 | loss  0.1484 | ms/batch 20374.31 |\n",
            "| step   299 |  lr: 0.0002000 | loss  0.1331 | ms/batch 19993.28 |\n",
            "| step   304 |  lr: 0.0002000 | loss  0.1649 | ms/batch 20140.83 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  18 | step   308 | dev_acc  0.5935 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.18.temp_checkpoint\n",
            "epoch: 20/100\n",
            "| step   309 |  lr: 0.0002000 | loss  0.1408 | ms/batch 8210.76 |\n",
            "| step   314 |  lr: 0.0002000 | loss  0.1495 | ms/batch 20112.61 |\n",
            "| step   319 |  lr: 0.0002000 | loss  0.1351 | ms/batch 20318.54 |\n",
            "| step   324 |  lr: 0.0002000 | loss  0.1608 | ms/batch 20221.87 |\n",
            "| step   329 |  lr: 0.0002000 | loss  0.1628 | ms/batch 20040.86 |\n",
            "| step   334 |  lr: 0.0002000 | loss  0.1374 | ms/batch 20301.88 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  19 | step   336 | dev_acc  0.5759 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.19.temp_checkpoint\n",
            "epoch: 21/100\n",
            "| step   339 |  lr: 0.0002000 | loss  0.1400 | ms/batch 16101.61 |\n",
            "| step   344 |  lr: 0.0002000 | loss  0.1328 | ms/batch 20124.45 |\n",
            "| step   349 |  lr: 0.0002000 | loss  0.1098 | ms/batch 19988.15 |\n",
            "| step   354 |  lr: 0.0002000 | loss  0.1333 | ms/batch 20016.34 |\n",
            "| step   359 |  lr: 0.0002000 | loss  0.0814 | ms/batch 20663.57 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:09<00:00,  3.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  20 | step   364 | dev_acc  0.5857 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_riddle_sense__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.20.temp_checkpoint\n"
          ]
        }
      ],
      "source": [
        "main_5(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRTYkl07eWU-",
        "outputId": "d9e186f4-f361-4626-96ce-f71c1d613d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/enc-roberta-large_dataset_riddle_sense_k5__gnndim200__bs128__seed0', 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 150, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 5, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'riddle_sense', 'encoder': 'roberta-large', 'enc': 'roberta-large', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/dev.statement.jsonl', 'test_statements': None, 'save_model': True, 'save_test_preds': False, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'elr': 0.0002, 'load_model_path': None, 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3503/3503 [00:04<00:00, 742.76it/s]\n",
            "100%|██████████| 1021/1021 [00:01<00:00, 983.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 167.61 sigma 172.13 | adj_len: 115.70 | prune_rate： 0.30 | qc_num: 9.78 | ac_num: 1.64 |\n",
            "| ori_adj_len: mu 194.18 sigma 175.85 | adj_len: 131.31 | prune_rate： 0.36 | qc_num: 10.75 | ac_num: 1.49 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-6-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     4 |  lr: 0.0002000 | loss  1.6168 | ms/batch 21699.65 |\n",
            "| step     9 |  lr: 0.0002000 | loss  1.6197 | ms/batch 21616.74 |\n",
            "| step    14 |  lr: 0.0002000 | loss  1.6153 | ms/batch 21966.07 |\n",
            "| step    19 |  lr: 0.0002000 | loss  1.6114 | ms/batch 21785.23 |\n",
            "| step    24 |  lr: 0.0002000 | loss  1.5989 | ms/batch 21825.15 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:18<00:00,  3.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   0 | step    28 | dev_acc  0.1763 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/enc-roberta-large_dataset_riddle_sense_k5__gnndim200__bs128__seed0/model.pt.0.best_model\n",
            "epoch: 2/100\n",
            "| step    29 |  lr: 0.0002000 | loss  1.5789 | ms/batch 9111.58 |\n",
            "| step    34 |  lr: 0.0002000 | loss  1.5220 | ms/batch 22023.51 |\n",
            "| step    39 |  lr: 0.0002000 | loss  1.4739 | ms/batch 21705.73 |\n",
            "| step    44 |  lr: 0.0002000 | loss  1.4839 | ms/batch 22023.76 |\n",
            "| step    49 |  lr: 0.0002000 | loss  1.4763 | ms/batch 21880.62 |\n",
            "| step    54 |  lr: 0.0002000 | loss  1.4648 | ms/batch 21651.96 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:18<00:00,  3.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   1 | step    56 | dev_acc  0.2174 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/enc-roberta-large_dataset_riddle_sense_k5__gnndim200__bs128__seed0/model.pt.1.best_model\n",
            "epoch: 3/100\n",
            "| step    59 |  lr: 0.0002000 | loss  1.4341 | ms/batch 17552.84 |\n",
            "| step    64 |  lr: 0.0002000 | loss  1.4107 | ms/batch 21671.62 |\n",
            "| step    69 |  lr: 0.0002000 | loss  1.4485 | ms/batch 22051.94 |\n",
            "| step    74 |  lr: 0.0002000 | loss  1.4657 | ms/batch 21696.14 |\n",
            "| step    79 |  lr: 0.0002000 | loss  1.4330 | ms/batch 21895.52 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:18<00:00,  3.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   2 | step    84 | dev_acc  0.2116 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/enc-roberta-large_dataset_riddle_sense_k5__gnndim200__bs128__seed0/model.pt.2.temp_checkpoint\n",
            "epoch: 4/100\n",
            "| step    84 |  lr: 0.0002000 | loss  1.4041 | ms/batch 4617.34 |\n",
            "| step    89 |  lr: 0.0002000 | loss  1.3514 | ms/batch 22074.55 |\n",
            "| step    94 |  lr: 0.0002000 | loss  1.4171 | ms/batch 21676.45 |\n",
            "| step    99 |  lr: 0.0002000 | loss  1.3695 | ms/batch 21940.79 |\n",
            "| step   104 |  lr: 0.0002000 | loss  1.3880 | ms/batch 21831.28 |\n",
            "| step   109 |  lr: 0.0002000 | loss  1.3818 | ms/batch 21757.07 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:18<00:00,  3.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   3 | step   112 | dev_acc  0.2360 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/enc-roberta-large_dataset_riddle_sense_k5__gnndim200__bs128__seed0/model.pt.3.best_model\n",
            "epoch: 5/100\n",
            "| step   114 |  lr: 0.0002000 | loss  1.3845 | ms/batch 29427.61 |\n",
            "| step   119 |  lr: 0.0002000 | loss  1.3041 | ms/batch 48769.79 |\n",
            "| step   124 |  lr: 0.0002000 | loss  1.3827 | ms/batch 48546.92 |\n",
            "| step   129 |  lr: 0.0002000 | loss  1.3279 | ms/batch 48918.27 |\n",
            "| step   134 |  lr: 0.0002000 | loss  1.2486 | ms/batch 48904.99 |\n",
            "| step   139 |  lr: 0.0002000 | loss  1.1225 | ms/batch 42936.50 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:22<00:00,  3.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   4 | step   140 | dev_acc  0.2419 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/enc-roberta-large_dataset_riddle_sense_k5__gnndim200__bs128__seed0/model.pt.4.best_model\n",
            "epoch: 6/100\n",
            "| step   144 |  lr: 0.0002000 | loss  1.0593 | ms/batch 49192.15 |\n",
            "| step   149 |  lr: 0.0002000 | loss  0.9206 | ms/batch 48790.31 |\n",
            "| step   154 |  lr: 0.0002000 | loss  0.9260 | ms/batch 48917.36 |\n",
            "| step   159 |  lr: 0.0002000 | loss  0.8912 | ms/batch 48564.57 |\n",
            "| step   164 |  lr: 0.0002000 | loss  0.8685 | ms/batch 49208.82 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:21<00:00,  3.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   5 | step   168 | dev_acc  0.3134 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/enc-roberta-large_dataset_riddle_sense_k5__gnndim200__bs128__seed0/model.pt.5.best_model\n",
            "epoch: 7/100\n",
            "| step   169 |  lr: 0.0002000 | loss  0.8229 | ms/batch 19998.34 |\n",
            "| step   174 |  lr: 0.0002000 | loss  0.7424 | ms/batch 48726.55 |\n",
            "| step   179 |  lr: 0.0002000 | loss  0.7118 | ms/batch 48687.96 |\n",
            "| step   184 |  lr: 0.0002000 | loss  0.7212 | ms/batch 48822.60 |\n",
            "| step   189 |  lr: 0.0002000 | loss  0.7539 | ms/batch 48777.19 |\n",
            "| step   194 |  lr: 0.0002000 | loss  0.7718 | ms/batch 49069.88 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:22<00:00,  3.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   6 | step   196 | dev_acc  0.4192 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/enc-roberta-large_dataset_riddle_sense_k5__gnndim200__bs128__seed0/model.pt.6.best_model\n",
            "epoch: 8/100\n",
            "| step   199 |  lr: 0.0002000 | loss  0.6125 | ms/batch 39363.81 |\n",
            "| step   204 |  lr: 0.0002000 | loss  0.4966 | ms/batch 48888.00 |\n",
            "| step   209 |  lr: 0.0002000 | loss  0.5219 | ms/batch 48681.96 |\n",
            "| step   214 |  lr: 0.0002000 | loss  0.5301 | ms/batch 48757.25 |\n",
            "| step   219 |  lr: 0.0002000 | loss  0.5100 | ms/batch 48969.34 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:22<00:00,  3.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   7 | step   224 | dev_acc  0.5886 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/enc-roberta-large_dataset_riddle_sense_k5__gnndim200__bs128__seed0/model.pt.7.best_model\n",
            "epoch: 9/100\n",
            "| step   224 |  lr: 0.0002000 | loss  0.4410 | ms/batch 10164.26 |\n",
            "| step   229 |  lr: 0.0002000 | loss  0.3228 | ms/batch 48993.60 |\n",
            "| step   234 |  lr: 0.0002000 | loss  0.2961 | ms/batch 48882.93 |\n",
            "| step   239 |  lr: 0.0002000 | loss  0.3039 | ms/batch 49257.75 |\n",
            "| step   244 |  lr: 0.0002000 | loss  0.4062 | ms/batch 48602.36 |\n",
            "| step   249 |  lr: 0.0002000 | loss  0.3589 | ms/batch 48626.07 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:22<00:00,  3.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   8 | step   252 | dev_acc  0.5828 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/enc-roberta-large_dataset_riddle_sense_k5__gnndim200__bs128__seed0/model.pt.8.temp_checkpoint\n",
            "epoch: 10/100\n",
            "| step   254 |  lr: 0.0002000 | loss  0.2691 | ms/batch 29805.56 |\n",
            "| step   259 |  lr: 0.0002000 | loss  0.1771 | ms/batch 48632.33 |\n"
          ]
        }
      ],
      "source": [
        "main_5(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rbcrykLnODk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmVDRrLnkW_6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY7w5vNbkf-G"
      },
      "source": [
        "####batch_size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CdHNOYqrvXIB",
        "outputId": "81bb9a79-aba8-4603-cb5b-eb2bf6a78c73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/enc-roberta-large_dataset_riddle_sense_k5__gnndim200__bs128__seed0', 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 150, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 5, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'riddle_sense', 'encoder': 'bert-large-uncased', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 5, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/graph/dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/dev.statement.jsonl', 'test_statements': None, 'save_model': False, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': False, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/riddle_sense/inhouse_split_qids.txt', 'weight_decay': 0.01, 'enc': 'bert-large-uncased', 'encoder_layer': -1, 'elr': 0.0002, 'load_model_path': None, 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/riddle_sense/statement/train.statement.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3503/3503 [00:06<00:00, 521.39it/s]\n",
            "100%|██████████| 1021/1021 [00:01<00:00, 1003.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 167.61 sigma 172.13 | adj_len: 115.70 | prune_rate： 0.30 | qc_num: 9.78 | ac_num: 1.64 |\n",
            "| ori_adj_len: mu 194.18 sigma 175.85 | adj_len: 131.31 | prune_rate： 0.36 | qc_num: 10.75 | ac_num: 1.49 |\n",
            "args.num_relation 38\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-6-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     4 |  lr: 0.0002000 | loss  1.6268 | ms/batch 21560.42 |\n",
            "| step     9 |  lr: 0.0002000 | loss  1.5908 | ms/batch 21041.02 |\n",
            "| step    14 |  lr: 0.0002000 | loss  1.4988 | ms/batch 20808.12 |\n",
            "| step    19 |  lr: 0.0002000 | loss  1.4786 | ms/batch 20767.71 |\n",
            "| step    24 |  lr: 0.0002000 | loss  1.4344 | ms/batch 20897.00 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:17<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   0 | step    28 | dev_acc  0.2693 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 2/5\n",
            "| step    29 |  lr: 0.0002000 | loss  1.3430 | ms/batch 8370.33 |\n",
            "| step    34 |  lr: 0.0002000 | loss  1.3710 | ms/batch 20812.29 |\n",
            "| step    39 |  lr: 0.0002000 | loss  1.3427 | ms/batch 20943.27 |\n",
            "| step    44 |  lr: 0.0002000 | loss  1.2496 | ms/batch 21130.59 |\n",
            "| step    49 |  lr: 0.0002000 | loss  1.2739 | ms/batch 20884.52 |\n",
            "| step    54 |  lr: 0.0002000 | loss  1.2549 | ms/batch 21021.53 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:17<00:00,  3.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   1 | step    56 | dev_acc  0.2674 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 3/5\n",
            "| step    59 |  lr: 0.0002000 | loss  1.2648 | ms/batch 16738.92 |\n",
            "| step    64 |  lr: 0.0002000 | loss  1.2587 | ms/batch 20827.85 |\n",
            "| step    69 |  lr: 0.0002000 | loss  1.2634 | ms/batch 20788.94 |\n",
            "| step    74 |  lr: 0.0002000 | loss  1.2352 | ms/batch 21340.64 |\n",
            "| step    79 |  lr: 0.0002000 | loss  1.2407 | ms/batch 22293.98 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 511/511 [02:28<00:00,  3.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   2 | step    84 | dev_acc  0.2684 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 4/5\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-52651c4fdb54>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-fb16ee537623>\u001b[0m in \u001b[0;36mmain_5\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eval_detail'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;31m# raise NotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-fb16ee537623>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    202\u001b[0m                             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_layer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, layer_id, cache_output, detail, *inputs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0msent_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlm_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         logits, attn = self.decoder(sent_vecs.to(node_type_ids.device),\n\u001b[0m\u001b[1;32m    232\u001b[0m                                     \u001b[0mconcept_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                                     \u001b[0mnode_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_vecs, concept_ids, node_type_ids, node_scores, adj_lengths, adj, emb_data, cache_output)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mgnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mZ_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m#(batch_size, dim_node)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, H, A, node_type, node_score, cache_output)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#Embed type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_n_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mnode_type_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_node_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[batch_size, n_node, dim/2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mmake_one_hot\u001b[0;34m(labels, C)\u001b[0m\n\u001b[1;32m    363\u001b[0m     '''\n\u001b[1;32m    364\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "main_5(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCJZ97JsFvj7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "appPFWkwFumo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn688v4c-wuP"
      },
      "source": [
        "##Train CSQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efceBq1OrysP"
      },
      "outputs": [],
      "source": [
        "# %cd \"/content/data\"\n",
        "\n",
        "# %cp -av /content/data/cpnet   /content/drive/MyDrive/brain_teaser/datasets/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D01WS8CadpdB",
        "outputId": "95b7663d-ec44-45ed-da7a-75a4f66e197f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***** hyperparameters *****\n",
            "dataset: csqa\n",
            "enc_name: roberta-large\n",
            "batch_size: 64\n",
            "learning_rate: elr 1e-05 dlr 0.001\n",
            "gnn: dim 200 layer 5\n",
            "Epochs: 100\n",
            "******************************\n"
          ]
        }
      ],
      "source": [
        "dataset=\"csqa\"\n",
        "model='roberta-large'\n",
        "\n",
        "elr=1e-5 #encoder learning rate\n",
        "dlr=1e-3  #decoder learing rate\n",
        "batch_size=64 #128 default\n",
        "mbs=2   #mini-batch-size\n",
        "n_epochs=100 #def 100\n",
        "num_relation=38 #(17 +2) * 2: originally 17, add 2 relation types (QA context -> Q node; QA context -> A node), and double because we add reverse edges\n",
        "seed=0\n",
        "\n",
        "k=5 #num of gnn layers\n",
        "gnndim=200    #dimension of the GNN layers def 200\n",
        "\n",
        "!echo \"***** hyperparameters *****\"\n",
        "!echo \"dataset: $dataset\"\n",
        "!echo \"enc_name: $model\"\n",
        "!echo \"batch_size: $batch_size\"\n",
        "!echo \"learning_rate: elr $elr dlr $dlr\"\n",
        "!echo \"gnn: dim $gnndim layer $k\"\n",
        "!echo \"Epochs: $n_epochs\"\n",
        "!echo \"******************************\"\n",
        "\n",
        "main_dir='/content/drive/MyDrive/brain_teaser'\n",
        "save_dir_pref=f\"{main_dir}/QA_GNN/saved_models\"\n",
        "\n",
        "if not os.path.exists(save_dir_pref):\n",
        "  %mkdir -p $save_dir_pref\n",
        "%mkdir -p logs\n",
        "\n",
        "args=dict()\n",
        "args[\"encoder\"]=model\n",
        "args['enc']=model\n",
        "\n",
        "# args[\"save_dir\"]=f\"{save_dir_pref}/enc-{model}_dataset_{dataset}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"best_model_save_dir\"]=f\"{save_dir_pref}/best_model_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"checkpoint_save_dir\"]=f\"{save_dir_pref}/checkpoint_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "args[\"log_save_dir\"]=f\"{save_dir_pref}/log_{dataset}__enc-{model}_k{k}__gnndim{gnndim}__bs{batch_size}__seed{seed}\"\n",
        "\n",
        "args[\"save_best_model\"]=True\n",
        "args['save_test_preds']=False\n",
        "args[\"save_checkpoint\"]=True\n",
        "\n",
        "args['loss']='cross_entropy'\n",
        "args['lr_schedule']='fixed'\n",
        "args['bs']=batch_size\n",
        "args['batch_size']=batch_size\n",
        "args['warmup_steps']=0\n",
        "args['max_grad_norm']=1.0\n",
        "args['me']=10\n",
        "args['log_interval']=10\n",
        "args['debug']=False\n",
        "args[\"optim\"]=\"radam\"\n",
        "\n",
        "args[\"mode\"]=\"train\"    #choices=['train', 'eval_detail'], help='run training or evaluation\n",
        "args[\"dataset\"]=dataset\n",
        "\n",
        "args[\"k\"]=k   #perform k-layer message passing\n",
        "args[\"gnn_dim\"]=gnndim\n",
        "args[\"encoder_lr\"]=elr\n",
        "args[\"decoder_lr\"]=dlr\n",
        "args[\"batch_size\"]=batch_size\n",
        "args[\"mini_batch_size\"]=mbs\n",
        "args[\"fp16\"]=False   #use fp16 training. this requires torch>=1.6.0\n",
        "args[\"seed\"]=seed\n",
        "args[\"num_relation\"]=num_relation\n",
        "args[\"n_epochs\"]=n_epochs\n",
        "args[\"max_epochs_before_stop\"]=10\n",
        "args[\"train_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/train.graph.adj.pk\"\n",
        "args[\"dev_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/dev.graph.adj.pk\"\n",
        "# args[\"test_adj\"]=f\"{main_dir}/datasets/{dataset}/graph/test.graph.adj.pk\"\n",
        "args[\"test_adj\"]=None\n",
        "\n",
        "args[\"train_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/train.statement.jsonl\"\n",
        "args[\"dev_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/dev.statement.jsonl\"\n",
        "# args[\"test_statements\"]=f\"{main_dir}/datasets/{dataset}/statement/test.statement.jsonl\"\n",
        "args[\"test_statements\"]=None\n",
        "\n",
        "\n",
        "args[\"cuda\"]=True\n",
        "# args[\"ent_emb_paths\"]=['data/cpnet/tzw.ent.npy']\n",
        "args[\"ent_emb_paths\"]=['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy']\n",
        "\n",
        "args[\"max_seq_len\"]=128\n",
        "args[\"inhouse\"]=True\n",
        "args[\"inhouse_train_qids\"]=f'{main_dir}/datasets/{dataset}/inhouse_split_qids.txt'\n",
        "args[\"weight_decay\"]=1e-2\n",
        "\n",
        "args['encoder_layer']=-1\n",
        "# args['elr']=2e-4\n",
        "# args[\"encoder_lr\"]=2e-4\n",
        "\n",
        "# args[\"load_model_path\"]=None\n",
        "# args[\"load_model_path\"]='/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.11.best_model'\n",
        "args[\"load_model_path\"]='/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.5.temp_checkpoint'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NgzKa3oVTWw"
      },
      "source": [
        "12_6_2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahxE8WypbFQu"
      },
      "source": [
        "bs 64 lr corrected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "599e4b1b889b45c9a65056ebcfc17ea2",
            "c1aecb7094ad43d291f1423c7f06e91c",
            "050eff1a4b9d47cb965ac5031fc7ad27",
            "2254cdc1388e460cbae57b9e6d27e0df",
            "36380c246d024dfe89fb0cbc0faf7e0c",
            "7ac47794443d40148385ea12e3eacfc3",
            "09374732818a4620ac7fc0e047782582",
            "1b543e822e1f486e839560c163620c65",
            "05b8005c6e8d471fb2cae39ad9d181c5",
            "b6f82153d8844bb0825b634fba9ee856",
            "2d4b418e8dd44657b08a02c4c2d339a8",
            "4361ada053e7403a9738cb2373c665a4",
            "7ea8c231d9d04206a2e3204ad4c53e3b",
            "6b4a884dac9b45fb8d826b84d29ecd38",
            "77c230f17fe3476b8c2cc6ac7f9b53d6",
            "d42ec097d1134e9ba79daa8058e82cf1",
            "9bda5cb17e3d4f00b8a302ffac4c93fb",
            "1866cef0486249c89781e74f155707c4",
            "78f8478731b94f4390236d25d30e13a6",
            "ee289b687b0d469483a5f07699f6f760",
            "4adaaade6d004c3c8edf805f7b775fef",
            "ccf85d8d81f14e8fbde7523b59027592",
            "9b4b2c2e47ad42b1b7412d97cd704450",
            "9dde42d94b4e475698662a423a293ccd",
            "ef33bea83b484f0da1932829d68b844f",
            "e03e3435b01140f599d76c028bde7866",
            "6e11852f304443588840577095f674bc",
            "15075843fc0649eda42e7f208ba9814c",
            "717000b19b614d6081cc21c28e4de156",
            "cf8d39dabfc44f19825946576572c977",
            "858fc0868aa5444c8b7da9fd98027610",
            "564822bb52f74e4797c4e3ff3671db50",
            "3521c762ec784931a948cdb4cc940a44",
            "3f9720733c4f4819a7f531a8f70bed99",
            "0aaba301ca034d06b73fa9d35a47e018",
            "6ef8ee747bf64c3bbce400d2acab274e",
            "ce05000fde2a4eba854f9c6dbfe24013",
            "f86e531a3b2d4d8eb605f3b3af6e833a",
            "b849dc7d01dd48a58be543e26c38eaf8",
            "1650689b0eb54ffbb94cf44e5197ac46",
            "8fef0a82427a46a3a373c716bf33c967",
            "8f15c2bc3bde4416bc93631e9c79cb7b",
            "6e086d1df1544d9eb2a05e620b827e03",
            "f8b0c19b35da4c73b88be2497c55596c",
            "ac55f62644ca46aba2b2c916980e90b7",
            "ee7ca923eb734254b1d8c7ea46132644",
            "2f9fa201216d46bbb3ed9734a0247d29",
            "14b16a63a0b04931a73868687fd51572",
            "330acb4c22274864abdef72b231ef9e9",
            "4a71f73c8c3e4500a2993a26c0e3c863",
            "3cd1135737474388ac2e8f7925c06d88",
            "f5ea2a6aa1294511bd78a11b1d442bad",
            "66bc3034b58a4ab89b0099760969fc63",
            "1678577a72dd49e1b3b85afef1d20678",
            "7f6ed8743ab442a7afa1fc511fc2d0a1"
          ]
        },
        "id": "iWyOR_3orBzx",
        "outputId": "f8e12f89-3eec-4fc2-e848-13bee643c1d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'encoder': 'roberta-large', 'enc': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0', 'checkpoint_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/log_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 64, 'batch_size': 64, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 10, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'csqa', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 1e-05, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': True, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/csqa/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'load_model_path': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.5.temp_checkpoint', 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/csqa/statement/train.statement.jsonl\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "599e4b1b889b45c9a65056ebcfc17ea2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4361ada053e7403a9738cb2373c665a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b4b2c2e47ad42b1b7412d97cd704450",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f9720733c4f4819a7f531a8f70bed99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9741/9741 [00:08<00:00, 1157.67it/s]\n",
            "100%|██████████| 1221/1221 [00:00<00:00, 1237.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 121.54 sigma 94.04 | adj_len: 107.96 | prune_rate： 0.17 | qc_num: 7.43 | ac_num: 2.07 |\n",
            "| ori_adj_len: mu 118.44 sigma 90.55 | adj_len: 106.55 | prune_rate： 0.15 | qc_num: 7.20 | ac_num: 2.05 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac55f62644ca46aba2b2c916980e90b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading and initializing model from /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.5.temp_checkpoint\n",
            "previous best_dev_acc: 0.46355446355446356\n",
            "current training epoch start from: 6\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 7/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-9-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     9 |  lr: 0.0000100 | loss  1.3387 | ms/batch 9891.80 |\n",
            "| step    19 |  lr: 0.0000100 | loss  1.3166 | ms/batch 9884.20 |\n",
            "| step    29 |  lr: 0.0000100 | loss  1.2754 | ms/batch 10300.54 |\n",
            "| step    39 |  lr: 0.0000100 | loss  1.3542 | ms/batch 10261.50 |\n",
            "| step    49 |  lr: 0.0000100 | loss  1.2638 | ms/batch 10402.89 |\n",
            "| step    59 |  lr: 0.0000100 | loss  1.3248 | ms/batch 10421.96 |\n",
            "| step    69 |  lr: 0.0000100 | loss  1.3536 | ms/batch 10378.94 |\n",
            "| step    79 |  lr: 0.0000100 | loss  1.2388 | ms/batch 10273.31 |\n",
            "| step    89 |  lr: 0.0000100 | loss  1.2894 | ms/batch 10482.65 |\n",
            "| step    99 |  lr: 0.0000100 | loss  1.3169 | ms/batch 10432.82 |\n",
            "| step   109 |  lr: 0.0000100 | loss  1.2568 | ms/batch 10507.19 |\n",
            "| step   119 |  lr: 0.0000100 | loss  1.3206 | ms/batch 10275.67 |\n",
            "| step   129 |  lr: 0.0000100 | loss  1.2953 | ms/batch 10551.39 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:35<00:00,  3.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   6 | step   133 | dev_acc  0.4447 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.6.temp_checkpoint\n",
            "epoch: 8/100\n",
            "| step   139 |  lr: 0.0000100 | loss  1.2570 | ms/batch 7284.30 |\n",
            "| step   149 |  lr: 0.0000100 | loss  1.2927 | ms/batch 10351.27 |\n",
            "| step   159 |  lr: 0.0000100 | loss  1.2947 | ms/batch 10409.26 |\n",
            "| step   169 |  lr: 0.0000100 | loss  1.3034 | ms/batch 10456.52 |\n",
            "| step   179 |  lr: 0.0000100 | loss  1.2254 | ms/batch 10347.60 |\n",
            "| step   189 |  lr: 0.0000100 | loss  1.3117 | ms/batch 10295.37 |\n",
            "| step   199 |  lr: 0.0000100 | loss  1.2715 | ms/batch 10352.63 |\n",
            "| step   209 |  lr: 0.0000100 | loss  1.2646 | ms/batch 10408.71 |\n",
            "| step   219 |  lr: 0.0000100 | loss  1.2684 | ms/batch 10560.96 |\n",
            "| step   229 |  lr: 0.0000100 | loss  1.3043 | ms/batch 10327.04 |\n",
            "| step   239 |  lr: 0.0000100 | loss  1.2502 | ms/batch 10365.49 |\n",
            "| step   249 |  lr: 0.0000100 | loss  1.2762 | ms/batch 10434.14 |\n",
            "| step   259 |  lr: 0.0000100 | loss  1.2797 | ms/batch 10409.41 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:34<00:00,  3.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   7 | step   266 | dev_acc  0.4636 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.7.best_model\n",
            "epoch: 9/100\n",
            "| step   269 |  lr: 0.0000100 | loss  1.2749 | ms/batch 4323.70 |\n",
            "| step   279 |  lr: 0.0000100 | loss  1.2471 | ms/batch 10343.75 |\n",
            "| step   289 |  lr: 0.0000100 | loss  1.2502 | ms/batch 10419.99 |\n",
            "| step   299 |  lr: 0.0000100 | loss  1.2816 | ms/batch 10400.18 |\n",
            "| step   309 |  lr: 0.0000100 | loss  1.2928 | ms/batch 10375.97 |\n",
            "| step   319 |  lr: 0.0000100 | loss  1.2789 | ms/batch 10489.82 |\n",
            "| step   329 |  lr: 0.0000100 | loss  1.2987 | ms/batch 10515.48 |\n",
            "| step   339 |  lr: 0.0000100 | loss  1.2975 | ms/batch 10308.94 |\n",
            "| step   349 |  lr: 0.0000100 | loss  1.2464 | ms/batch 10400.14 |\n",
            "| step   359 |  lr: 0.0000100 | loss  1.2722 | ms/batch 10238.29 |\n",
            "| step   369 |  lr: 0.0000100 | loss  1.3091 | ms/batch 10444.88 |\n",
            "| step   379 |  lr: 0.0000100 | loss  1.2758 | ms/batch 10336.64 |\n",
            "| step   389 |  lr: 0.0000100 | loss  1.2702 | ms/batch 10348.45 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:34<00:00,  3.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   8 | step   399 | dev_acc  0.4505 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.8.temp_checkpoint\n",
            "epoch: 10/100\n",
            "| step   399 |  lr: 0.0000100 | loss  1.2229 | ms/batch  975.30 |\n",
            "| step   409 |  lr: 0.0000100 | loss  1.2597 | ms/batch 10158.79 |\n"
          ]
        }
      ],
      "source": [
        "main_5(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Kh4sywsrTBR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "glxrEH6vaOyk",
        "outputId": "ad3f62f1-400f-4465-e4fe-9f4bb9b2d34b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'encoder': 'roberta-large', 'enc': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0', 'checkpoint_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/log_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 64, 'batch_size': 64, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 10, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'csqa', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 1e-05, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': True, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/csqa/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'load_model_path': None, 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/csqa/statement/train.statement.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9741/9741 [00:08<00:00, 1177.59it/s]\n",
            "100%|██████████| 1221/1221 [00:01<00:00, 1211.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 121.54 sigma 94.04 | adj_len: 107.96 | prune_rate： 0.17 | qc_num: 7.43 | ac_num: 2.07 |\n",
            "| ori_adj_len: mu 118.44 sigma 90.55 | adj_len: 106.55 | prune_rate： 0.15 | qc_num: 7.20 | ac_num: 2.05 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-6-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     9 |  lr: 0.0000100 | loss  1.6148 | ms/batch 9489.88 |\n",
            "| step    19 |  lr: 0.0000100 | loss  1.6119 | ms/batch 9739.61 |\n",
            "| step    29 |  lr: 0.0000100 | loss  1.6118 | ms/batch 9768.78 |\n",
            "| step    39 |  lr: 0.0000100 | loss  1.5669 | ms/batch 9701.37 |\n",
            "| step    49 |  lr: 0.0000100 | loss  1.5287 | ms/batch 9800.87 |\n",
            "| step    59 |  lr: 0.0000100 | loss  1.5243 | ms/batch 9802.52 |\n",
            "| step    69 |  lr: 0.0000100 | loss  1.5547 | ms/batch 9771.50 |\n",
            "| step    79 |  lr: 0.0000100 | loss  1.5006 | ms/batch 9696.78 |\n",
            "| step    89 |  lr: 0.0000100 | loss  1.5260 | ms/batch 9868.48 |\n",
            "| step    99 |  lr: 0.0000100 | loss  1.4887 | ms/batch 9822.44 |\n",
            "| step   109 |  lr: 0.0000100 | loss  1.4976 | ms/batch 9877.50 |\n",
            "| step   119 |  lr: 0.0000100 | loss  1.5032 | ms/batch 9667.84 |\n",
            "| step   129 |  lr: 0.0000100 | loss  1.4868 | ms/batch 9938.30 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:25<00:00,  4.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   0 | step   133 | dev_acc  0.3620 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.0.best_model\n",
            "epoch: 2/100\n",
            "| step   139 |  lr: 0.0000100 | loss  1.4837 | ms/batch 6804.16 |\n",
            "| step   149 |  lr: 0.0000100 | loss  1.4796 | ms/batch 9763.37 |\n",
            "| step   159 |  lr: 0.0000100 | loss  1.4725 | ms/batch 9800.68 |\n",
            "| step   169 |  lr: 0.0000100 | loss  1.4330 | ms/batch 9834.75 |\n",
            "| step   179 |  lr: 0.0000100 | loss  1.3750 | ms/batch 9766.05 |\n",
            "| step   189 |  lr: 0.0000100 | loss  1.4285 | ms/batch 9700.12 |\n",
            "| step   199 |  lr: 0.0000100 | loss  1.3969 | ms/batch 9774.67 |\n",
            "| step   209 |  lr: 0.0000100 | loss  1.3828 | ms/batch 9828.04 |\n",
            "| step   219 |  lr: 0.0000100 | loss  1.4142 | ms/batch 9947.11 |\n",
            "| step   229 |  lr: 0.0000100 | loss  1.3934 | ms/batch 9745.38 |\n",
            "| step   239 |  lr: 0.0000100 | loss  1.3638 | ms/batch 9774.69 |\n",
            "| step   249 |  lr: 0.0000100 | loss  1.3828 | ms/batch 9807.87 |\n",
            "| step   259 |  lr: 0.0000100 | loss  1.3834 | ms/batch 9803.28 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:25<00:00,  4.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   1 | step   266 | dev_acc  0.4406 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.1.best_model\n",
            "epoch: 3/100\n",
            "| step   269 |  lr: 0.0000100 | loss  1.3855 | ms/batch 3998.66 |\n",
            "| step   279 |  lr: 0.0000100 | loss  1.3718 | ms/batch 9777.49 |\n",
            "| step   289 |  lr: 0.0000100 | loss  1.3668 | ms/batch 9795.42 |\n",
            "| step   299 |  lr: 0.0000100 | loss  1.3763 | ms/batch 9785.24 |\n",
            "| step   309 |  lr: 0.0000100 | loss  1.3910 | ms/batch 9774.84 |\n",
            "| step   319 |  lr: 0.0000100 | loss  1.3652 | ms/batch 9855.82 |\n",
            "| step   329 |  lr: 0.0000100 | loss  1.3874 | ms/batch 9896.89 |\n",
            "| step   339 |  lr: 0.0000100 | loss  1.3867 | ms/batch 9716.40 |\n",
            "| step   349 |  lr: 0.0000100 | loss  1.3363 | ms/batch 9847.12 |\n",
            "| step   359 |  lr: 0.0000100 | loss  1.3763 | ms/batch 9668.34 |\n",
            "| step   369 |  lr: 0.0000100 | loss  1.3809 | ms/batch 9853.17 |\n",
            "| step   379 |  lr: 0.0000100 | loss  1.3922 | ms/batch 9788.05 |\n",
            "| step   389 |  lr: 0.0000100 | loss  1.3700 | ms/batch 9822.52 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:25<00:00,  4.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   2 | step   399 | dev_acc  0.4447 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.2.best_model\n",
            "epoch: 4/100\n",
            "| step   399 |  lr: 0.0000100 | loss  1.2987 | ms/batch  951.03 |\n",
            "| step   409 |  lr: 0.0000100 | loss  1.3351 | ms/batch 9845.72 |\n",
            "| step   419 |  lr: 0.0000100 | loss  1.3672 | ms/batch 9857.23 |\n",
            "| step   429 |  lr: 0.0000100 | loss  1.3349 | ms/batch 9742.11 |\n",
            "| step   439 |  lr: 0.0000100 | loss  1.3395 | ms/batch 9948.38 |\n",
            "| step   449 |  lr: 0.0000100 | loss  1.3570 | ms/batch 9722.86 |\n",
            "| step   459 |  lr: 0.0000100 | loss  1.4009 | ms/batch 9786.19 |\n",
            "| step   469 |  lr: 0.0000100 | loss  1.3859 | ms/batch 9841.21 |\n",
            "| step   479 |  lr: 0.0000100 | loss  1.4076 | ms/batch 9705.10 |\n",
            "| step   489 |  lr: 0.0000100 | loss  1.3772 | ms/batch 9691.94 |\n",
            "| step   499 |  lr: 0.0000100 | loss  1.3950 | ms/batch 9745.50 |\n",
            "| step   509 |  lr: 0.0000100 | loss  1.3792 | ms/batch 9781.36 |\n",
            "| step   519 |  lr: 0.0000100 | loss  1.3737 | ms/batch 9754.42 |\n",
            "| step   529 |  lr: 0.0000100 | loss  1.3663 | ms/batch 9845.34 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:26<00:00,  4.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   3 | step   532 | dev_acc  0.4169 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.3.temp_checkpoint\n",
            "epoch: 5/100\n",
            "| step   539 |  lr: 0.0000100 | loss  1.3265 | ms/batch 17670.78 |\n",
            "| step   549 |  lr: 0.0000100 | loss  1.3980 | ms/batch 22070.23 |\n",
            "| step   559 |  lr: 0.0000100 | loss  1.3349 | ms/batch 22057.27 |\n",
            "| step   569 |  lr: 0.0000100 | loss  1.3643 | ms/batch 22062.89 |\n",
            "| step   579 |  lr: 0.0000100 | loss  1.3122 | ms/batch 22159.40 |\n",
            "| step   589 |  lr: 0.0000100 | loss  1.4029 | ms/batch 22142.90 |\n",
            "| step   599 |  lr: 0.0000100 | loss  1.3193 | ms/batch 22159.55 |\n",
            "| step   609 |  lr: 0.0000100 | loss  1.3425 | ms/batch 22208.17 |\n",
            "| step   619 |  lr: 0.0000100 | loss  1.2995 | ms/batch 22099.31 |\n",
            "| step   629 |  lr: 0.0000100 | loss  1.2996 | ms/batch 22159.86 |\n",
            "| step   639 |  lr: 0.0000100 | loss  1.2924 | ms/batch 22164.00 |\n",
            "| step   649 |  lr: 0.0000100 | loss  1.3432 | ms/batch 22057.75 |\n",
            "| step   659 |  lr: 0.0000100 | loss  1.3497 | ms/batch 22145.52 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:28<00:00,  4.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   4 | step   665 | dev_acc  0.4636 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.4.best_model\n",
            "epoch: 6/100\n",
            "| step   669 |  lr: 0.0000100 | loss  1.3272 | ms/batch 11165.60 |\n",
            "| step   679 |  lr: 0.0000100 | loss  1.3244 | ms/batch 22093.74 |\n",
            "| step   689 |  lr: 0.0000100 | loss  1.2879 | ms/batch 22096.13 |\n",
            "| step   699 |  lr: 0.0000100 | loss  1.3315 | ms/batch 22026.27 |\n",
            "| step   709 |  lr: 0.0000100 | loss  1.3419 | ms/batch 22021.71 |\n",
            "| step   719 |  lr: 0.0000100 | loss  1.3272 | ms/batch 22182.72 |\n",
            "| step   729 |  lr: 0.0000100 | loss  1.3525 | ms/batch 22135.32 |\n",
            "| step   739 |  lr: 0.0000100 | loss  1.3348 | ms/batch 22041.18 |\n",
            "| step   749 |  lr: 0.0000100 | loss  1.3403 | ms/batch 22150.84 |\n",
            "| step   759 |  lr: 0.0000100 | loss  1.3704 | ms/batch 22141.86 |\n",
            "| step   769 |  lr: 0.0000100 | loss  1.3318 | ms/batch 22236.45 |\n",
            "| step   779 |  lr: 0.0000100 | loss  1.3930 | ms/batch 22144.96 |\n",
            "| step   789 |  lr: 0.0000100 | loss  1.4025 | ms/batch 22063.84 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:28<00:00,  4.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   5 | step   798 | dev_acc  0.4365 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs64__seed0/model.pt.5.temp_checkpoint\n",
            "epoch: 7/100\n",
            "| step   799 |  lr: 0.0000100 | loss  1.3417 | ms/batch 4466.51 |\n"
          ]
        }
      ],
      "source": [
        "main_5(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeCDG8c2-OIQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m0ZzTH-npcw7",
        "outputId": "fe14c413-4043-4e58-abfb-fae4de4fd56e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'encoder': 'roberta-large', 'enc': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/log_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 10, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'csqa', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/dev.graph.adj.pk', 'test_adj': None, 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/dev.statement.jsonl', 'test_statements': None, 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': True, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/csqa/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'elr': 0.0002, 'load_model_path': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.4.best_model', 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/csqa/statement/train.statement.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9741/9741 [00:08<00:00, 1212.62it/s]\n",
            "100%|██████████| 1221/1221 [00:00<00:00, 1263.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 121.54 sigma 94.04 | adj_len: 107.96 | prune_rate： 0.17 | qc_num: 7.43 | ac_num: 2.07 |\n",
            "| ori_adj_len: mu 118.44 sigma 90.55 | adj_len: 106.55 | prune_rate： 0.15 | qc_num: 7.20 | ac_num: 2.05 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading and initializing model from /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.4.best_model\n",
            "previous best_dev_acc: 0.44471744471744473\n",
            "current training epoch start from: 5\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 6/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-6-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     9 |  lr: 0.0002000 | loss  1.3002 | ms/batch 20022.85 |\n",
            "| step    19 |  lr: 0.0002000 | loss  1.2773 | ms/batch 19633.00 |\n",
            "| step    29 |  lr: 0.0002000 | loss  1.2647 | ms/batch 19784.90 |\n",
            "| step    39 |  lr: 0.0002000 | loss  1.2628 | ms/batch 19653.65 |\n",
            "| step    49 |  lr: 0.0002000 | loss  1.2812 | ms/batch 19881.45 |\n",
            "| step    59 |  lr: 0.0002000 | loss  1.2453 | ms/batch 19719.10 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:28<00:00,  4.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   5 | step    67 | dev_acc  0.4398 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.5.temp_checkpoint\n",
            "epoch: 7/100\n",
            "| step    69 |  lr: 0.0002000 | loss  1.2357 | ms/batch 5921.55 |\n",
            "| step    79 |  lr: 0.0002000 | loss  1.2654 | ms/batch 19856.34 |\n",
            "| step    89 |  lr: 0.0002000 | loss  1.2454 | ms/batch 19824.65 |\n",
            "| step    99 |  lr: 0.0002000 | loss  1.2071 | ms/batch 19677.83 |\n",
            "| step   109 |  lr: 0.0002000 | loss  1.2111 | ms/batch 20010.03 |\n",
            "| step   119 |  lr: 0.0002000 | loss  1.1972 | ms/batch 19743.77 |\n",
            "| step   129 |  lr: 0.0002000 | loss  1.2258 | ms/batch 19858.90 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:28<00:00,  4.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   6 | step   134 | dev_acc  0.4545 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.6.best_model\n",
            "epoch: 8/100\n",
            "| step   139 |  lr: 0.0002000 | loss  1.2513 | ms/batch 11897.17 |\n",
            "| step   149 |  lr: 0.0002000 | loss  1.2574 | ms/batch 19849.59 |\n",
            "| step   159 |  lr: 0.0002000 | loss  1.2653 | ms/batch 19863.49 |\n",
            "| step   169 |  lr: 0.0002000 | loss  1.2476 | ms/batch 19833.47 |\n",
            "| step   179 |  lr: 0.0002000 | loss  1.2408 | ms/batch 19723.26 |\n",
            "| step   189 |  lr: 0.0002000 | loss  1.2922 | ms/batch 19848.26 |\n",
            "| step   199 |  lr: 0.0002000 | loss  1.2434 | ms/batch 19697.58 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:27<00:00,  4.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   7 | step   201 | dev_acc  0.4578 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.7.best_model\n",
            "epoch: 9/100\n",
            "| step   209 |  lr: 0.0002000 | loss  1.2762 | ms/batch 17845.89 |\n",
            "| step   219 |  lr: 0.0002000 | loss  1.2751 | ms/batch 19941.48 |\n",
            "| step   229 |  lr: 0.0002000 | loss  1.3112 | ms/batch 19800.05 |\n",
            "| step   239 |  lr: 0.0002000 | loss  1.3115 | ms/batch 19837.72 |\n",
            "| step   249 |  lr: 0.0002000 | loss  1.2927 | ms/batch 19696.51 |\n",
            "| step   259 |  lr: 0.0002000 | loss  1.2997 | ms/batch 19795.22 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:28<00:00,  4.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   8 | step   268 | dev_acc  0.4414 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.8.temp_checkpoint\n",
            "epoch: 10/100\n",
            "| step   269 |  lr: 0.0002000 | loss  1.2753 | ms/batch 4025.85 |\n",
            "| step   279 |  lr: 0.0002000 | loss  1.3305 | ms/batch 19736.76 |\n",
            "| step   289 |  lr: 0.0002000 | loss  1.3007 | ms/batch 19885.78 |\n",
            "| step   299 |  lr: 0.0002000 | loss  1.2850 | ms/batch 19976.05 |\n",
            "| step   309 |  lr: 0.0002000 | loss  1.2545 | ms/batch 19924.34 |\n",
            "| step   319 |  lr: 0.0002000 | loss  1.2652 | ms/batch 20127.92 |\n",
            "| step   329 |  lr: 0.0002000 | loss  1.2740 | ms/batch 19831.26 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:29<00:00,  4.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   9 | step   335 | dev_acc  0.4447 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.9.temp_checkpoint\n",
            "epoch: 11/100\n",
            "| step   339 |  lr: 0.0002000 | loss  1.2929 | ms/batch 10071.15 |\n",
            "| step   349 |  lr: 0.0002000 | loss  1.2332 | ms/batch 19870.62 |\n",
            "| step   359 |  lr: 0.0002000 | loss  1.2890 | ms/batch 19864.37 |\n",
            "| step   369 |  lr: 0.0002000 | loss  1.2588 | ms/batch 19938.58 |\n",
            "| step   379 |  lr: 0.0002000 | loss  1.2939 | ms/batch 19949.33 |\n",
            "| step   389 |  lr: 0.0002000 | loss  1.2893 | ms/batch 20052.92 |\n",
            "| step   399 |  lr: 0.0002000 | loss  1.3039 | ms/batch 19964.72 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:29<00:00,  4.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  10 | step   402 | dev_acc  0.4373 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.10.temp_checkpoint\n",
            "epoch: 12/100\n",
            "| step   409 |  lr: 0.0002000 | loss  1.2792 | ms/batch 15936.48 |\n",
            "| step   419 |  lr: 0.0002000 | loss  1.2747 | ms/batch 19884.67 |\n",
            "| step   429 |  lr: 0.0002000 | loss  1.2799 | ms/batch 20074.27 |\n",
            "| step   439 |  lr: 0.0002000 | loss  1.3064 | ms/batch 19817.46 |\n",
            "| step   449 |  lr: 0.0002000 | loss  1.2572 | ms/batch 19980.38 |\n",
            "| step   459 |  lr: 0.0002000 | loss  1.2350 | ms/batch 19876.73 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:29<00:00,  4.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  11 | step   469 | dev_acc  0.4627 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.11.best_model\n",
            "epoch: 13/100\n",
            "| step   469 |  lr: 0.0002000 | loss  1.2714 | ms/batch 1984.12 |\n",
            "| step   479 |  lr: 0.0002000 | loss  1.2300 | ms/batch 20022.81 |\n",
            "| step   489 |  lr: 0.0002000 | loss  1.2290 | ms/batch 20021.18 |\n",
            "| step   499 |  lr: 0.0002000 | loss  1.2455 | ms/batch 19873.35 |\n",
            "| step   509 |  lr: 0.0002000 | loss  1.2771 | ms/batch 20042.16 |\n",
            "| step   519 |  lr: 0.0002000 | loss  1.2641 | ms/batch 19948.56 |\n",
            "| step   529 |  lr: 0.0002000 | loss  1.2370 | ms/batch 19909.10 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:28<00:00,  4.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch  12 | step   536 | dev_acc  0.4423 | test_acc  0.0000 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.12.temp_checkpoint\n",
            "epoch: 14/100\n",
            "| step   539 |  lr: 0.0002000 | loss  1.2387 | ms/batch 7964.93 |\n",
            "| step   549 |  lr: 0.0002000 | loss  1.3072 | ms/batch 19859.10 |\n",
            "| step   559 |  lr: 0.0002000 | loss  1.3086 | ms/batch 20040.47 |\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-52651c4fdb54>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-bbaedfa62511>\u001b[0m in \u001b[0;36mmain_5\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eval_detail'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# raise NotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-bbaedfa62511>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_grad_norm\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fp16\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "main_5(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnLb9jqBaXx1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a42bed8c0614ad1b992a78902602ede",
            "a7f94fa5f24e4d68ae44d8c599aefd71",
            "e54bea3ca5cc400881d7c866137cfed2",
            "9023fc4d35ad4f4ebd0e5e47e84e5032",
            "36c6a68e64104b44803be140cf177f02",
            "3f2135f8496b4dbba32ff755b0b6295e",
            "44edc79b6f54460ea66005ad78e0cdb4",
            "8fe789acb1bc48bf9a07a1c34f4199c5",
            "8a6973ecfe89488c9487703f20f0306f",
            "d2ff9a7632d54429b9cbb28e0575431e",
            "1f19718ce6d14e739fd0e206a6b75137",
            "3a938e7985624a2985286f8fb35e5105",
            "2170b27a44bf47cd824a0255e78b3ee5",
            "d116a5a50efb49e7adb3ece153f629c8",
            "10ce5b37d7aa4cbabed2bc21f82ae36c",
            "ec695c2195a84148ac97c7d34e9490b3",
            "0024c6d4d0304803b086e7df15b783e8",
            "cdbd796c94a84398a9a55b38b746226f",
            "052127d3e7774ce0b5855ddc45519cfe",
            "d1bce12bcbce40759194126a83e76445",
            "de5936f228a84f5483db3431fdefd765",
            "23b1a887ad0643d0a327ab9605935670",
            "814c6a6a69914d1f9a1b5a088f8a7a6c",
            "df7b05271e28476fa939b0844617b987",
            "a69b8f5064704444a723616dd71ccc90",
            "5558b8409cdc4434aec82b2955820a75",
            "180a6ce7a4554755b10b32c3d1aa6466",
            "e59d50d4f70945b191e9d07346ac381d",
            "41d9a6d81a0c4c509cd2e9f300dd0ab4",
            "f0d2b6d33c484ae09e6a4dde1123a721",
            "2ac1ac315e75448db313dbf925b89a99",
            "d3370d718ff34f32be8a07d96831c95f",
            "dcf8e3f6a9074332860ad1d11fdb0e1b",
            "10ec34e6deb34074934cc1fb49e41f59",
            "6740d07292ae492aa72d2cee02e3f02e",
            "8103ba6080ff42e5a5135373e6b4a01b",
            "fda016da076e4a44ac05d80ad7863e05",
            "28a36948c80f44a1a57d8dc4fb2c4c52",
            "2dca73ed24764b1f9335bd59d16be1bd",
            "54f7d7ced3a54cda8329aae549a887f0",
            "debe941c643345379bc1e1ffeb646afe",
            "d39ddfed77d345e1a54d3586242dedc3",
            "b76fac24ee804e5c81ace9f8f504ceb1",
            "94781a3d5bc84fa2ae652792259f523b",
            "b4aa2c41de0c4774ae829a04f4486843",
            "4706281b6d4c45bfa55dd05ee26bda3c",
            "0606a000ba7c4db6a98b4a8e48bab815",
            "2fef69957f3743a2a4d2b6f0cdeecfb6",
            "c1741c3f390741e19fd17f7f17db0e69",
            "93b5a81251cd4e4296c5137617f5042a",
            "e9fbd1aefc144995951e463c94688600",
            "aeab8a0b49ab438ba40c628659477052",
            "835a09cb70d543d7a94cff4eaa662042",
            "083b688ab01f46948b263aba05f7a559",
            "88b8ab889656435089542a9574731e41"
          ]
        },
        "id": "435Tb0pmVVPC",
        "outputId": "648c5ba7-b2ec-4a6a-fe8c-40b95a565273"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'encoder': 'roberta-large', 'enc': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/log_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'warmup_steps': 0, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 10, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'csqa', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/dev.graph.adj.pk', 'test_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/test.graph.adj.pk', 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/dev.statement.jsonl', 'test_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/test.statement.jsonl', 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': True, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/csqa/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'elr': 0.0002, 'load_model_path': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.2.best_model', 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/csqa/statement/train.statement.jsonl\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a42bed8c0614ad1b992a78902602ede",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a938e7985624a2985286f8fb35e5105",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "814c6a6a69914d1f9a1b5a088f8a7a6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10ec34e6deb34074934cc1fb49e41f59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9741/9741 [00:08<00:00, 1178.01it/s]\n",
            "100%|██████████| 1221/1221 [00:00<00:00, 1249.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 121.54 sigma 94.04 | adj_len: 107.96 | prune_rate： 0.17 | qc_num: 7.43 | ac_num: 2.07 |\n",
            "| ori_adj_len: mu 118.44 sigma 90.55 | adj_len: 106.55 | prune_rate： 0.15 | qc_num: 7.20 | ac_num: 2.05 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1140/1140 [00:00<00:00, 1169.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ori_adj_len: mu 119.20 sigma 93.49 | adj_len: 106.22 | prune_rate： 0.16 | qc_num: 7.38 | ac_num: 2.05 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4aa2c41de0c4774ae829a04f4486843",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading and initializing model from /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.2.best_model\n",
            "previous best_dev_acc: 0.44471744471744473\n",
            "current training epoch start from: 3\n",
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 4/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-9-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     9 |  lr: 0.0002000 | loss  1.3477 | ms/batch 19443.30 |\n",
            "| step    19 |  lr: 0.0002000 | loss  1.3336 | ms/batch 19423.32 |\n",
            "| step    29 |  lr: 0.0002000 | loss  1.3143 | ms/batch 19583.90 |\n",
            "| step    39 |  lr: 0.0002000 | loss  1.3219 | ms/batch 19438.83 |\n",
            "| step    49 |  lr: 0.0002000 | loss  1.3608 | ms/batch 19654.43 |\n",
            "| step    59 |  lr: 0.0002000 | loss  1.3241 | ms/batch 19536.26 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:25<00:00,  4.19it/s]\n",
            "100%|██████████| 621/621 [02:28<00:00,  4.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   3 | step    67 | dev_acc  0.4275 | test_acc  0.4376 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.3.temp_checkpoint\n",
            "epoch: 5/100\n",
            "| step    69 |  lr: 0.0002000 | loss  1.3064 | ms/batch 13105.31 |\n",
            "| step    79 |  lr: 0.0002000 | loss  1.3283 | ms/batch 44166.02 |\n",
            "| step    89 |  lr: 0.0002000 | loss  1.2848 | ms/batch 44123.61 |\n",
            "| step    99 |  lr: 0.0002000 | loss  1.2910 | ms/batch 43936.02 |\n",
            "| step   109 |  lr: 0.0002000 | loss  1.2889 | ms/batch 44295.09 |\n",
            "| step   119 |  lr: 0.0002000 | loss  1.2789 | ms/batch 44029.61 |\n",
            "| step   129 |  lr: 0.0002000 | loss  1.3053 | ms/batch 44153.52 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:27<00:00,  4.13it/s]\n",
            "100%|██████████| 621/621 [02:30<00:00,  4.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   4 | step   134 | dev_acc  0.4447 | test_acc  0.4343 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.4.best_model\n",
            "epoch: 6/100\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-52651c4fdb54>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-bbaedfa62511>\u001b[0m in \u001b[0;36mmain_5\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eval_detail'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# raise NotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-bbaedfa62511>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    234\u001b[0m                         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m                     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_grad_norm\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "main_5(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJXC1fMEVczp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gis206p1Vcul"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRIrDGIPOFGl"
      },
      "source": [
        "12_5_2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "COxI_uzlN5tm",
        "outputId": "d0a106ca-6930-458e-fe7f-1f3039384742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'warmup_steps': 150, 'encoder': 'roberta-large', 'enc': 'roberta-large', 'best_model_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0', 'checkpoint_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/checkpoint_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0', 'log_save_dir': '/content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/log_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0', 'save_best_model': True, 'save_test_preds': False, 'save_checkpoint': True, 'loss': 'cross_entropy', 'lr_schedule': 'fixed', 'bs': 128, 'batch_size': 128, 'max_grad_norm': 1.0, 'me': 10, 'log_interval': 10, 'debug': False, 'optim': 'radam', 'mode': 'train', 'dataset': 'csqa', 'k': 5, 'gnn_dim': 200, 'encoder_lr': 0.0002, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'fp16': False, 'seed': 0, 'num_relation': 38, 'n_epochs': 100, 'max_epochs_before_stop': 10, 'train_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/train.graph.adj.pk', 'dev_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/dev.graph.adj.pk', 'test_adj': '/content/drive/MyDrive/brain_teaser/datasets/csqa/graph/test.graph.adj.pk', 'train_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/train.statement.jsonl', 'dev_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/dev.statement.jsonl', 'test_statements': '/content/drive/MyDrive/brain_teaser/datasets/csqa/statement/test.statement.jsonl', 'cuda': True, 'ent_emb_paths': ['/content/drive/MyDrive/brain_teaser/datasets/cpnet/tzw.ent.npy'], 'max_seq_len': 128, 'inhouse': True, 'inhouse_train_qids': '/content/drive/MyDrive/brain_teaser/datasets/csqa/inhouse_split_qids.txt', 'weight_decay': 0.01, 'encoder_layer': -1, 'elr': 0.0002, 'load_model_path': None, 'use_cache': True, 'att_head_num': 2, 'fc_dim': 200, 'fc_layer_num': 1, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'mbs': 1, 'ebs': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'drop_partial_batch': False, 'fill_partial_batch': False}\n",
            "| num_concepts: 799273 |\n",
            "| concept_dim: 1024 |\n",
            "train_statement_path /content/drive/MyDrive/brain_teaser/datasets/csqa/statement/train.statement.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9741/9741 [00:10<00:00, 970.32it/s] \n",
            "100%|██████████| 1221/1221 [00:01<00:00, 1009.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 121.54 sigma 94.04 | adj_len: 107.96 | prune_rate： 0.17 | qc_num: 7.43 | ac_num: 2.07 |\n",
            "| ori_adj_len: mu 118.44 sigma 90.55 | adj_len: 106.55 | prune_rate： 0.15 | qc_num: 7.20 | ac_num: 2.05 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1140/1140 [00:01<00:00, 1092.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ori_adj_len: mu 119.20 sigma 93.49 | adj_len: 106.22 | prune_rate： 0.16 | qc_num: 7.38 | ac_num: 2.05 |\n",
            "args.num_relation 38\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "parameters:\n",
            "\tconcept_emb.emb.weight                       \tfixed\ttorch.Size([799273, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.weight             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tconcept_emb.cpt_transform.bias               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tsvec2nvec.weight                             \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tsvec2nvec.bias                               \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.weight                     \ttrainable\ttorch.Size([100, 4])\tdevice:cuda:0\n",
            "\tgnn.emb_node_type.bias                       \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.weight                         \ttrainable\ttorch.Size([100, 100])\tdevice:cuda:0\n",
            "\tgnn.emb_score.bias                           \ttrainable\ttorch.Size([100])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.weight                    \ttrainable\ttorch.Size([200, 47])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.0.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.weight                    \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.1.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.weight                    \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.edge_encoder.3.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.0.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.1.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.2.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.3.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_key.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.weight           \ttrainable\ttorch.Size([200, 600])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_msg.bias             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.weight         \ttrainable\ttorch.Size([200, 400])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.linear_query.bias           \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.0.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.weight                \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.1.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.weight                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.gnn_layers.4.mlp.3.bias                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vh.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vh.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tgnn.Vx.weight                                \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tgnn.Vx.bias                                  \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_qs.weight                           \ttrainable\ttorch.Size([200, 1024])\tdevice:cuda:0\n",
            "\tpooler.w_qs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_ks.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.weight                           \ttrainable\ttorch.Size([200, 200])\tdevice:cuda:0\n",
            "\tpooler.w_vs.bias                             \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.weight                    \ttrainable\ttorch.Size([200, 1424])\tdevice:cuda:0\n",
            "\tfc.layers.0-Linear.bias                      \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.weight                 \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.0-LayerNorm.bias                   \ttrainable\ttorch.Size([200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.weight                    \ttrainable\ttorch.Size([1, 200])\tdevice:cuda:0\n",
            "\tfc.layers.1-Linear.bias                      \ttrainable\ttorch.Size([1])\tdevice:cuda:0\n",
            "\ttotal: 3129201\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "epoch: 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "<ipython-input-6-267d489110eb>:61: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1519.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:261: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| step     9 |  lr: 0.0002000 | loss  1.6139 | ms/batch 20497.63 |\n",
            "| step    19 |  lr: 0.0002000 | loss  1.6175 | ms/batch 20509.08 |\n",
            "| step    29 |  lr: 0.0002000 | loss  1.5985 | ms/batch 20707.41 |\n",
            "| step    39 |  lr: 0.0002000 | loss  1.5458 | ms/batch 20545.30 |\n",
            "| step    49 |  lr: 0.0002000 | loss  1.5458 | ms/batch 20809.47 |\n",
            "| step    59 |  lr: 0.0002000 | loss  1.5303 | ms/batch 20667.66 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:33<00:00,  3.99it/s]\n",
            "100%|██████████| 621/621 [02:35<00:00,  3.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   0 | step    67 | dev_acc  0.3579 | test_acc  0.3537 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.0.best_model\n",
            "epoch: 2/100\n",
            "| step    69 |  lr: 0.0002000 | loss  1.5166 | ms/batch 6184.46 |\n",
            "| step    79 |  lr: 0.0002000 | loss  1.5041 | ms/batch 20695.47 |\n",
            "| step    89 |  lr: 0.0002000 | loss  1.4691 | ms/batch 20653.85 |\n",
            "| step    99 |  lr: 0.0002000 | loss  1.4672 | ms/batch 20522.04 |\n",
            "| step   109 |  lr: 0.0002000 | loss  1.4685 | ms/batch 20907.25 |\n",
            "| step   119 |  lr: 0.0002000 | loss  1.4366 | ms/batch 20628.91 |\n",
            "| step   129 |  lr: 0.0002000 | loss  1.4347 | ms/batch 20743.53 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:33<00:00,  3.98it/s]\n",
            "100%|██████████| 621/621 [02:35<00:00,  3.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   1 | step   134 | dev_acc  0.4128 | test_acc  0.4037 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.1.best_model\n",
            "epoch: 3/100\n",
            "| step   139 |  lr: 0.0002000 | loss  1.4026 | ms/batch 12431.32 |\n",
            "| step   149 |  lr: 0.0002000 | loss  1.4133 | ms/batch 20723.68 |\n",
            "| step   159 |  lr: 0.0002000 | loss  1.4051 | ms/batch 20733.92 |\n",
            "| step   169 |  lr: 0.0002000 | loss  1.3773 | ms/batch 20727.97 |\n",
            "| step   179 |  lr: 0.0002000 | loss  1.3584 | ms/batch 20597.03 |\n",
            "| step   189 |  lr: 0.0002000 | loss  1.3836 | ms/batch 20720.01 |\n",
            "| step   199 |  lr: 0.0002000 | loss  1.3330 | ms/batch 20529.39 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:33<00:00,  3.99it/s]\n",
            "100%|██████████| 621/621 [02:35<00:00,  3.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "| epoch   2 | step   201 | dev_acc  0.4447 | test_acc  0.4150 |\n",
            "-----------------------------------------------------------------------\n",
            "model saved to /content/drive/MyDrive/brain_teaser/QA_GNN/saved_models/best_model_csqa__enc-roberta-large_k5__gnndim200__bs128__seed0/model.pt.2.best_model\n",
            "epoch: 4/100\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-52651c4fdb54>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-bbaedfa62511>\u001b[0m in \u001b[0;36mmain_5\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'eval_detail'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# raise NotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-bbaedfa62511>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    228\u001b[0m                             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_layer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, layer_id, cache_output, detail, *inputs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0msent_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlm_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         logits, attn = self.decoder(sent_vecs.to(node_type_ids.device),\n\u001b[0m\u001b[1;32m    232\u001b[0m                                     \u001b[0mconcept_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                                     \u001b[0mnode_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_vecs, concept_ids, node_type_ids, node_scores, adj_lengths, adj, emb_data, cache_output)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mgnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mZ_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgnn_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m#(batch_size, dim_node)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, H, A, node_type, node_score, cache_output)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#Embed type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_one_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_n_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ntype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mnode_type_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_node_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#[batch_size, n_node, dim/2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-fe053a8ef34d>\u001b[0m in \u001b[0;36mmake_one_hot\u001b[0;34m(labels, C)\u001b[0m\n\u001b[1;32m    363\u001b[0m     '''\n\u001b[1;32m    364\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m     \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "main_5(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxSOE2iUOICc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iORyPJz7OH9P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwSZ6lFyOpqf"
      },
      "source": [
        "###previous trainings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI5ZwFzJzISE"
      },
      "source": [
        "batch size 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwzPYPU9t3fF"
      },
      "outputs": [],
      "source": [
        "# main_5(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F57zTpFp4pM"
      },
      "outputs": [],
      "source": [
        "'| epoch   0 | step  1063 | dev_acc  0.4201 | test_acc  0.4061 |'\n",
        "'| epoch   1 | step  2126 | dev_acc  0.4242 | test_acc  0.4102 |'\n",
        "'| epoch   2 | step  3189 | dev_acc  0.4177 | test_acc  0.4198 |'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPrZ6y8tzFBm"
      },
      "source": [
        "bartch size 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5umXKN_Ln73A"
      },
      "outputs": [],
      "source": [
        "'| epoch   0 | step   266 | dev_acc  0.4341 | test_acc  0.4303 |'\n",
        "'| epoch   1 | step   532 | dev_acc  0.4267 | test_acc  0.4376 |'\n",
        "'| epoch   2 | step   798 | dev_acc  0.4365 | test_acc  0.4569 |'\n",
        "'| epoch   3 | step  1064 | dev_acc  0.4292 | test_acc  0.4319 |'\n",
        "'| epoch   4 | step  1330 | dev_acc  0.3374 | test_acc  0.3642 |'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syCf2ZXPU7pr"
      },
      "outputs": [],
      "source": [
        "# /content/drive/Shareddrives/Gdrive/My_Thesis/QA_GNN/saved_models/csqa/enc-roberta-large__k5__gnndim100__bs8__seed0/model.pt.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppt8fGxZU7nf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPDIYZgY_IKa"
      },
      "source": [
        "#Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCVXMpsp_Xz7"
      },
      "source": [
        "##CSQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUo2c8e9NNps",
        "outputId": "b200fc30-c2aa-44cd-83c8-8e750c7e7618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***** hyperparameters *****\n",
            "dataset: csqa\n",
            "enc_name: roberta-large\n",
            "batch_size: 32\n",
            "learning_rate: elr 1e-05 dlr 0.001\n",
            "gnn: dim 100 layer 5\n",
            "******************************\n",
            "| num_concepts: 799273 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inhouse? True\n",
            "args.train_statements data/csqa/statement/train.statement.jsonl\n",
            "args.dev_statements data/csqa/statement/dev.statement.jsonl\n",
            "args.test_statements data/csqa/statement/test.statement.jsonl\n",
            "args.train_adj data/csqa/graph/train.graph.adj.pk\n",
            "args.dev_adj data/csqa/graph/dev.graph.adj.pk\n",
            "args.test_adj data/csqa/graph/test.graph.adj.pk\n",
            "train_statement_path data/csqa/statement/train.statement.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9741/9741 [00:09<00:00, 1080.38it/s]\n",
            "100%|██████████| 1221/1221 [00:00<00:00, 1232.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_choice 5\n",
            "| ori_adj_len: mu 121.54 sigma 94.04 | adj_len: 107.96 | prune_rate： 0.17 | qc_num: 7.43 | ac_num: 2.07 |\n",
            "| ori_adj_len: mu 118.44 sigma 90.55 | adj_len: 106.55 | prune_rate： 0.15 | qc_num: 7.20 | ac_num: 2.05 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1140/1140 [00:01<00:00, 1021.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| ori_adj_len: mu 119.20 sigma 93.49 | adj_len: 106.22 | prune_rate： 0.16 | qc_num: 7.38 | ac_num: 2.05 |\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 611/611 [02:34<00:00,  3.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dev_acc  0.4357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 621/621 [02:44<00:00,  3.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------\n",
            "test_acc  0.4561\n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "dataset=\"csqa\"\n",
        "model='roberta-large'\n",
        "\n",
        "elr=1e-5 #encoder learning rate\n",
        "dlr=1e-3  #decoder learing rate\n",
        "bs=32\n",
        "mbs=2   #mini-batch-size\n",
        "n_epochs=5 #def 100\n",
        "num_relation=38 #(17 +2) * 2: originally 17, add 2 relation types (QA context -> Q node; QA context -> A node), and double because we add reverse edges\n",
        "seed=0\n",
        "\n",
        "k=5 #num of gnn layers\n",
        "gnndim=100    #dimension of the GNN layers def 200\n",
        "\n",
        "!echo \"***** hyperparameters *****\"\n",
        "!echo \"dataset: $dataset\"\n",
        "!echo \"enc_name: $model\"\n",
        "!echo \"batch_size: $bs\"\n",
        "!echo \"learning_rate: elr $elr dlr $dlr\"\n",
        "!echo \"gnn: dim $gnndim layer $k\"\n",
        "!echo \"******************************\"\n",
        "\n",
        "save_dir_pref='/content/drive/Shareddrives/Gdrive/My_Thesis/QA_GNN/saved_models'\n",
        "%mkdir -p $save_dir_pref\n",
        "%mkdir -p logs\n",
        "\n",
        "args=dict()\n",
        "\n",
        "args['loss']='cross_entropy'\n",
        "args['lr_schedule']='fixed'\n",
        "args['bs']=32\n",
        "args['batch_size']=32\n",
        "args['warmup_steps']=150\n",
        "args['max_grad_norm']=1.0\n",
        "args['me']=10\n",
        "args['log_interval']=10\n",
        "args['debug']=False\n",
        "args[\"optim\"]=\"radam\"\n",
        "\n",
        "args[\"mode\"]=\"eval_detail\"    #choices=['train', 'eval_detail'], help='run training or evaluation\n",
        "args[\"dataset\"]=dataset\n",
        "args[\"encoder\"]=model\n",
        "args[\"k\"]=k   #perform k-layer message passing\n",
        "args[\"gnn_dim\"]=gnndim\n",
        "args[\"encoder_lr\"]=elr\n",
        "args[\"decoder_lr\"]=dlr\n",
        "args[\"batch_size\"]=bs\n",
        "args[\"mini_batch_size\"]=mbs\n",
        "args[\"fp16\"]=False   #use fp16 training. this requires torch>=1.6.0\n",
        "args[\"seed\"]=seed\n",
        "args[\"num_relation\"]=num_relation\n",
        "args[\"n_epochs\"]=n_epochs\n",
        "args[\"max_epochs_before_stop\"]=10\n",
        "args[\"train_adj\"]=f\"data/{dataset}/graph/train.graph.adj.pk\"\n",
        "args[\"dev_adj\"]=f\"data/{dataset}/graph/dev.graph.adj.pk\"\n",
        "args[\"test_adj\"]=f\"data/{dataset}/graph/test.graph.adj.pk\"\n",
        "args[\"train_statements\"]=f\"data/{dataset}/statement/train.statement.jsonl\"\n",
        "args[\"dev_statements\"]=f\"data/{dataset}/statement/dev.statement.jsonl\"\n",
        "args[\"test_statements\"]=f\"data/{dataset}/statement/test.statement.jsonl\"\n",
        "args[\"save_model\"]=True\n",
        "args[\"save_dir\"]=f\"{save_dir_pref}/{dataset}/enc-{model}__k{k}__gnndim{gnndim}__bs{bs}__seed{seed}\"\n",
        "args[\"cuda\"]=True\n",
        "args[\"ent_emb_paths\"]=['data/cpnet/tzw.ent.npy']\n",
        "args[\"max_seq_len\"]=128\n",
        "args[\"inhouse\"]=True\n",
        "args[\"inhouse_train_qids\"]=f'data/{dataset}/inhouse_split_qids.txt'\n",
        "args[\"weight_decay\"]=1e-2\n",
        "\n",
        "args['enc']=\"bert-large-uncased\"\n",
        "args['encoder']=\"bert-large-uncased\"\n",
        "args['encoder_layer']=-1\n",
        "args['elr']=2e-4\n",
        "args[\"encoder_lr\"]=2e-4\n",
        "args[\"ent_emb\"]='tzw'\n",
        "args[\"load_model_path\"]='/content/drive/Shareddrives/Gdrive/My_Thesis/QA_GNN/saved_models/csqa/enc-roberta-large__k5__gnndim100__bs32__seed0/model.pt.2'\n",
        "\n",
        "main_5(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs_8KQes-29I"
      },
      "outputs": [],
      "source": [
        "# #!/bin/bash\n",
        "\n",
        "# export CUDA_VISIBLE_DEVICES=0\n",
        "# dt=`date '+%Y%m%d_%H%M%S'`\n",
        "\n",
        "\n",
        "# dataset=\"csqa\"\n",
        "# model='roberta-large'\n",
        "# shift\n",
        "# shift\n",
        "# args=$@\n",
        "\n",
        "\n",
        "# echo \"******************************\"\n",
        "# echo \"dataset: $dataset\"\n",
        "# echo \"******************************\"\n",
        "\n",
        "# save_dir_pref='saved_models'\n",
        "# mkdir -p $save_dir_pref\n",
        "\n",
        "# ###### Eval ######\n",
        "# python3 -u qagnn.py --dataset $dataset \\\n",
        "#       --train_adj data/${dataset}/graph/train.graph.adj.pk \\\n",
        "#       --dev_adj   data/${dataset}/graph/dev.graph.adj.pk \\\n",
        "#       --test_adj  data/${dataset}/graph/test.graph.adj.pk \\\n",
        "#       --train_statements data/${dataset}/statement/train.statement.jsonl \\\n",
        "#       --dev_statements   data/${dataset}/statement/dev.statement.jsonl \\\n",
        "#       --test_statements  data/${dataset}/statement/test.statement.jsonl \\\n",
        "#       --save_model \\\n",
        "#       --save_dir saved_models \\\n",
        "#       --mode eval_detail \\\n",
        "#       --load_model_path saved_models/csqa_model_hf3.4.0.pt \\\n",
        "#       $args\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TZJL1sB6iBD1",
        "6GNJ4gJNiSvg",
        "N3OESkpwSnZo",
        "VBidYjbXkACn",
        "tHFKwLTQzoCE",
        "lEkPdryQz2Bp",
        "zzWaS2419YSv",
        "OvkQQajd9jE4",
        "lPhvEjtb9uUL",
        "UuA8Vzig9ZtW",
        "vvPbRU_Yv7AP",
        "PVjdHIbbv-yn",
        "Q4OI9lggSpvW",
        "EgUHf2vgSt8E",
        "q0U3ichgSwkS",
        "J48ndOxbU72V",
        "QlhHUUUfU-ai",
        "PCXov-G7g24j",
        "yfhWt9ggPKjY",
        "Hcvm3ykzPNRG",
        "1jAJCOTyUx9w",
        "r8eHOoO9UjqJ",
        "l728-RTPUsGF",
        "dwzojUKPldDT",
        "j87C4256oM1N",
        "kX1RANkUoVcm",
        "t-Tm0jETk-Kv",
        "ngD1X0kf_owV",
        "SkF95Fcx_4K0",
        "hE4BK3BXyP0Y",
        "0bhxD-gFDg8S",
        "l7CgbSN0DmIS",
        "wFEd4QpWvN6e",
        "ynkYiLtLp8hL",
        "tmHPbVpCacmn",
        "yyGBxbhnae8d",
        "c5bPbKdVrC6z",
        "48YJR6gju2VW",
        "ti71TzHFu0wD",
        "VG-3JX23L7wz",
        "DeTAphGUL-Ra",
        "iyAN0PhVKxG1",
        "AtgNN9PVNIXX",
        "PgP-Vziweewm",
        "YYK__uSSwAe2",
        "ApSWZUPeU_js",
        "jnjMGgv_U199",
        "uoNvZ9axVKqI",
        "T_T8Sa4xUooQ",
        "wjH6fwkBVWlj",
        "gvKvsTHxVobU",
        "QeVNdraXVya7",
        "CgApkVrOTpWW",
        "5LyLIwqsVzbv",
        "HyI9aiAqVwKz",
        "9Ot7t0aCvUYp",
        "gb-d6d1U8nmt",
        "EDo6IVlKZY8Z",
        "fY7w5vNbkf-G",
        "Tn688v4c-wuP",
        "IwSZ6lFyOpqf",
        "VPDIYZgY_IKa"
      ],
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0024c6d4d0304803b086e7df15b783e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "041aea7ed89a41dd8cbabf58008955d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8334f674d9945f4a117865dededfdbf",
            "placeholder": "​",
            "style": "IPY_MODEL_826d0b9f5d16423c9ba55cd5fc4f8498",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 34.1MB/s]"
          }
        },
        "04ec4050bd9e42f28f207dbbd0009d6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "050eff1a4b9d47cb965ac5031fc7ad27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b543e822e1f486e839560c163620c65",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05b8005c6e8d471fb2cae39ad9d181c5",
            "value": 482
          }
        },
        "052127d3e7774ce0b5855ddc45519cfe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ab5d178a824081a0650be6abdd6c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05b8005c6e8d471fb2cae39ad9d181c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05c5ff6437a04d11951b23a7f3434c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4428c3ee8f79455ba5066cc0937de670",
              "IPY_MODEL_28ef08c196b04f84bd701f2a2a7c2842",
              "IPY_MODEL_78e550978be84dac93501e1dea84e0db"
            ],
            "layout": "IPY_MODEL_ef735ce7ac5b421a8f6fb658d8ae1f24"
          }
        },
        "0606a000ba7c4db6a98b4a8e48bab815": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeab8a0b49ab438ba40c628659477052",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_835a09cb70d543d7a94cff4eaa662042",
            "value": 1421700479
          }
        },
        "068b52189369439b8e7786802567ddaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "068c448caa5f45729c93ab6f5d4c0323": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b8eba20b74d406cafff2d83183c6fe5",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4df5fb134a540ca886832f644a613ee",
            "value": 1355863
          }
        },
        "079a672f9f244b5d91a05b5601320d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "083b688ab01f46948b263aba05f7a559": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "089bf456c9e544a4aeb8b8c02dd621f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09374732818a4620ac7fc0e047782582": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a783c13998445aba947367704f6a1d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6aae10576a74343a13cb88cb8339d51",
            "placeholder": "​",
            "style": "IPY_MODEL_cfb79a281c5f431286f645d5bdf6a498",
            "value": "vocab.json: 100%"
          }
        },
        "0aaba301ca034d06b73fa9d35a47e018": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b849dc7d01dd48a58be543e26c38eaf8",
            "placeholder": "​",
            "style": "IPY_MODEL_1650689b0eb54ffbb94cf44e5197ac46",
            "value": "tokenizer.json: 100%"
          }
        },
        "0ac22b52c7234e009239fcbfd7d6eaee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b8eba20b74d406cafff2d83183c6fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c9224a226b449859b023cf15c0e0f71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e1ea22335ed4e84bc4dc837caeb07b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fef5f46136b4ede921f9f5af49657eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ce5b37d7aa4cbabed2bc21f82ae36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de5936f228a84f5483db3431fdefd765",
            "placeholder": "​",
            "style": "IPY_MODEL_23b1a887ad0643d0a327ab9605935670",
            "value": " 899k/899k [00:00&lt;00:00, 1.90MB/s]"
          }
        },
        "10e7e4ef5bfe42eca2be532ab59e75bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ec34e6deb34074934cc1fb49e41f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6740d07292ae492aa72d2cee02e3f02e",
              "IPY_MODEL_8103ba6080ff42e5a5135373e6b4a01b",
              "IPY_MODEL_fda016da076e4a44ac05d80ad7863e05"
            ],
            "layout": "IPY_MODEL_28a36948c80f44a1a57d8dc4fb2c4c52"
          }
        },
        "12034bd090834b45be34816d7afd4af1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14b16a63a0b04931a73868687fd51572": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1678577a72dd49e1b3b85afef1d20678",
            "placeholder": "​",
            "style": "IPY_MODEL_7f6ed8743ab442a7afa1fc511fc2d0a1",
            "value": " 1.42G/1.42G [00:13&lt;00:00, 87.8MB/s]"
          }
        },
        "15075843fc0649eda42e7f208ba9814c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1650689b0eb54ffbb94cf44e5197ac46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1678577a72dd49e1b3b85afef1d20678": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "173775eb71e94bb7aedc322faa8a6f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c29e67631b1e43de8d8f1db49b3008d9",
            "placeholder": "​",
            "style": "IPY_MODEL_3531b9252154431a8d5f4774abc1636a",
            "value": " 456k/456k [00:00&lt;00:00, 18.1MB/s]"
          }
        },
        "1738681fd75e4f019afdb860f022ba1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175dae5537da458f88798e706e35e7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175f032983f14d3d84d73f40086583d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ea6863dcbb4b5f9bc9f1643ec75063",
            "placeholder": "​",
            "style": "IPY_MODEL_2ddee989ac7a4bb18374a6b89cabe49c",
            "value": "vocab.json: 100%"
          }
        },
        "180a6ce7a4554755b10b32c3d1aa6466": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1866cef0486249c89781e74f155707c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "188eafb67e75452eafbefdb2a6bff2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7890614addb64ec49eb6f5470b05af5a",
            "placeholder": "​",
            "style": "IPY_MODEL_7ce1362f02574e619239f5381f3fb6b8",
            "value": "model.safetensors: 100%"
          }
        },
        "18e2574238f54a7c9eb405b43de5a521": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1979c0ec947d4c6fbe3bd975a088f7e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19b99a08457c4ad7bafb5f680bd8f52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18e2574238f54a7c9eb405b43de5a521",
            "placeholder": "​",
            "style": "IPY_MODEL_e3aaf4b6527c40f184555f5cd5f4cf3d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 10.8MB/s]"
          }
        },
        "1b543e822e1f486e839560c163620c65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b909814200c40dca6aa1770d5b16217": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c72178fad984c0c8f172a0f5fb7706e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f19718ce6d14e739fd0e206a6b75137": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2085af4e628748a9824c5e91e7490d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2124d2d5277f4b6aac4063089c824693": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2170b27a44bf47cd824a0255e78b3ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0024c6d4d0304803b086e7df15b783e8",
            "placeholder": "​",
            "style": "IPY_MODEL_cdbd796c94a84398a9a55b38b746226f",
            "value": "vocab.json: 100%"
          }
        },
        "2254cdc1388e460cbae57b9e6d27e0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6f82153d8844bb0825b634fba9ee856",
            "placeholder": "​",
            "style": "IPY_MODEL_2d4b418e8dd44657b08a02c4c2d339a8",
            "value": " 482/482 [00:00&lt;00:00, 36.0kB/s]"
          }
        },
        "227a769daeff4569890489dfd71c97b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2318aa74cf45449d8302fd0607db55f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23b1a887ad0643d0a327ab9605935670": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2519ee4c769a4d43a6457cff99208b16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2857bcae75694427995f5f1ccf759afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28a36948c80f44a1a57d8dc4fb2c4c52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ef08c196b04f84bd701f2a2a7c2842": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68e8d6b6fa7c49bcb5d077937ecace97",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b909814200c40dca6aa1770d5b16217",
            "value": 482
          }
        },
        "2ac1ac315e75448db313dbf925b89a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bf9df005960449b81fb593a30de7764": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2124d2d5277f4b6aac4063089c824693",
            "placeholder": "​",
            "style": "IPY_MODEL_8d9c6290951b4dd4beedfd4fa6f0fc6c",
            "value": "model.safetensors: 100%"
          }
        },
        "2d4b418e8dd44657b08a02c4c2d339a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dca73ed24764b1f9335bd59d16be1bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ddee989ac7a4bb18374a6b89cabe49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f9fa201216d46bbb3ed9734a0247d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5ea2a6aa1294511bd78a11b1d442bad",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66bc3034b58a4ab89b0099760969fc63",
            "value": 1421700479
          }
        },
        "2fcef4e9a365414aa11731bc560051f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87e1dac952444071b2f5dd4aa697d194",
            "placeholder": "​",
            "style": "IPY_MODEL_0ac22b52c7234e009239fcbfd7d6eaee",
            "value": " 899k/899k [00:00&lt;00:00, 2.31MB/s]"
          }
        },
        "2fef69957f3743a2a4d2b6f0cdeecfb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_083b688ab01f46948b263aba05f7a559",
            "placeholder": "​",
            "style": "IPY_MODEL_88b8ab889656435089542a9574731e41",
            "value": " 1.42G/1.42G [00:04&lt;00:00, 328MB/s]"
          }
        },
        "3125140a79084dcaa9ce3e665bc9853e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "330acb4c22274864abdef72b231ef9e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331596856ff04a86a223eb78c66f897c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34af7818f7fa49c0a5e7362c5cea18e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3521c762ec784931a948cdb4cc940a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3531b9252154431a8d5f4774abc1636a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35984ebb24ee4b9ca8d7222748b18b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12034bd090834b45be34816d7afd4af1",
            "placeholder": "​",
            "style": "IPY_MODEL_71d384ea1c534073909843badf4169ba",
            "value": " 456k/456k [00:00&lt;00:00, 779kB/s]"
          }
        },
        "36380c246d024dfe89fb0cbc0faf7e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "367d58a226294562b110d0f031b52e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36c6a68e64104b44803be140cf177f02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e31c596b5343f28dfa0869c378de01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "398a8fe2218242da85154dee81f9274c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a7a50c1f70040c78932f8e5775c54e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96fcd9f505454ee490de94e4864a4410",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb7166fe00834c06ab4b3a63e712dd19",
            "value": 456318
          }
        },
        "3a938e7985624a2985286f8fb35e5105": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2170b27a44bf47cd824a0255e78b3ee5",
              "IPY_MODEL_d116a5a50efb49e7adb3ece153f629c8",
              "IPY_MODEL_10ce5b37d7aa4cbabed2bc21f82ae36c"
            ],
            "layout": "IPY_MODEL_ec695c2195a84148ac97c7d34e9490b3"
          }
        },
        "3cd1135737474388ac2e8f7925c06d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3de5f6ff765b44c19445a15229ddaca4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f2135f8496b4dbba32ff755b0b6295e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f9720733c4f4819a7f531a8f70bed99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0aaba301ca034d06b73fa9d35a47e018",
              "IPY_MODEL_6ef8ee747bf64c3bbce400d2acab274e",
              "IPY_MODEL_ce05000fde2a4eba854f9c6dbfe24013"
            ],
            "layout": "IPY_MODEL_f86e531a3b2d4d8eb605f3b3af6e833a"
          }
        },
        "4155142ca6df49f394a56f4c8df1060c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9d3f83bfb7b433d9c41b499de79348d",
            "placeholder": "​",
            "style": "IPY_MODEL_6e8325d208714eac98243896c232060c",
            "value": "tokenizer.json: 100%"
          }
        },
        "41d9a6d81a0c4c509cd2e9f300dd0ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43494ede53d84cfe85c8ddeef50ec526": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "434de5fd32a24f3dab8b335ddac525eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4361ada053e7403a9738cb2373c665a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ea8c231d9d04206a2e3204ad4c53e3b",
              "IPY_MODEL_6b4a884dac9b45fb8d826b84d29ecd38",
              "IPY_MODEL_77c230f17fe3476b8c2cc6ac7f9b53d6"
            ],
            "layout": "IPY_MODEL_d42ec097d1134e9ba79daa8058e82cf1"
          }
        },
        "438b1cb5984a4a51b77337573284f6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_188eafb67e75452eafbefdb2a6bff2b7",
              "IPY_MODEL_fd70333d859741fe84645f53325b3c5c",
              "IPY_MODEL_fd215d8777a946e4acab5ed77be48d6d"
            ],
            "layout": "IPY_MODEL_0c9224a226b449859b023cf15c0e0f71"
          }
        },
        "4428c3ee8f79455ba5066cc0937de670": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d54a4135a7164612b17a4c5198961c92",
            "placeholder": "​",
            "style": "IPY_MODEL_b40148c4fe9e4b39b7f74710c471eea3",
            "value": "config.json: 100%"
          }
        },
        "44edc79b6f54460ea66005ad78e0cdb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45f7871720764afd818da0c6254f8216": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c72178fad984c0c8f172a0f5fb7706e",
            "placeholder": "​",
            "style": "IPY_MODEL_56017c2723734c84aba96ef13cbc85b3",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.39MB/s]"
          }
        },
        "4706281b6d4c45bfa55dd05ee26bda3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93b5a81251cd4e4296c5137617f5042a",
            "placeholder": "​",
            "style": "IPY_MODEL_e9fbd1aefc144995951e463c94688600",
            "value": "model.safetensors: 100%"
          }
        },
        "47e63423b23f4c65b70b4dbc6d179675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5d9aba117484778bfffb9f1b4b6be6c",
              "IPY_MODEL_cc2eeb93b0504598b497005acf4b2496",
              "IPY_MODEL_4b199765011a443fa6107a49aef294f8"
            ],
            "layout": "IPY_MODEL_feaa5655930c453b985c26051360230e"
          }
        },
        "4857edd02066499fabae1b2a2123709b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49b99b7bd73243cda135ff1ec0301d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2085af4e628748a9824c5e91e7490d4e",
            "placeholder": "​",
            "style": "IPY_MODEL_86efd710dda44e63b26459377910ab99",
            "value": " 899k/899k [00:00&lt;00:00, 15.0MB/s]"
          }
        },
        "49cb2685d98047bcb9fd3f95f7dd20da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_887668167fac4cd3b127a8925d41d1d3",
              "IPY_MODEL_3a7a50c1f70040c78932f8e5775c54e7",
              "IPY_MODEL_c3d0493f32484d29b350c1c9f1fa4b54"
            ],
            "layout": "IPY_MODEL_04ec4050bd9e42f28f207dbbd0009d6f"
          }
        },
        "4a71f73c8c3e4500a2993a26c0e3c863": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4adaaade6d004c3c8edf805f7b775fef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b199765011a443fa6107a49aef294f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1738681fd75e4f019afdb860f022ba1b",
            "placeholder": "​",
            "style": "IPY_MODEL_4857edd02066499fabae1b2a2123709b",
            "value": " 482/482 [00:00&lt;00:00, 42.3kB/s]"
          }
        },
        "4b9e173d962849fb892a4609e5ac30d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fef5f46136b4ede921f9f5af49657eb",
            "placeholder": "​",
            "style": "IPY_MODEL_b30432d1cfc947c5864f11382d337f89",
            "value": "tokenizer.json: 100%"
          }
        },
        "4bae712449dd442fb4cd2fc7473c37b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f0dea01f6db4ce49dc47348e4d6a3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73a80398c84d4b76b180975a7962fd39",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_752887d788f24465be7fc345ad3e94a1",
            "value": 1355863
          }
        },
        "4f2f28c0d09742b1b160830ab49b5f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d100bbc411ae4ce6a79e7f8f41dc2439",
              "IPY_MODEL_f32ae9e091ae42e18e6595fff7f8bbd6",
              "IPY_MODEL_a69656f8bf964ce8889df06c5ccac18c"
            ],
            "layout": "IPY_MODEL_db343cee166c40a9871c7f74c65f9864"
          }
        },
        "50045f2ce0bd490796a3d745f3b6d605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53622d0462454b22a9bca33f485126d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f7d7ced3a54cda8329aae549a887f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5558b8409cdc4434aec82b2955820a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3370d718ff34f32be8a07d96831c95f",
            "placeholder": "​",
            "style": "IPY_MODEL_dcf8e3f6a9074332860ad1d11fdb0e1b",
            "value": " 456k/456k [00:00&lt;00:00, 35.8MB/s]"
          }
        },
        "56017c2723734c84aba96ef13cbc85b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "564822bb52f74e4797c4e3ff3671db50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "599e4b1b889b45c9a65056ebcfc17ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1aecb7094ad43d291f1423c7f06e91c",
              "IPY_MODEL_050eff1a4b9d47cb965ac5031fc7ad27",
              "IPY_MODEL_2254cdc1388e460cbae57b9e6d27e0df"
            ],
            "layout": "IPY_MODEL_36380c246d024dfe89fb0cbc0faf7e0c"
          }
        },
        "59e7e5528504408c91dfe84d0fc0fa3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e83f5e96c1e4a5b89181c64f84b2b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b793fc09d80a4b359a56c28f119683dc",
              "IPY_MODEL_718203cd7133449da33af5fa839dc479",
              "IPY_MODEL_173775eb71e94bb7aedc322faa8a6f72"
            ],
            "layout": "IPY_MODEL_434de5fd32a24f3dab8b335ddac525eb"
          }
        },
        "63da9fc1903e42ad9f5c6e0c333d7221": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66bc3034b58a4ab89b0099760969fc63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6740d07292ae492aa72d2cee02e3f02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dca73ed24764b1f9335bd59d16be1bd",
            "placeholder": "​",
            "style": "IPY_MODEL_54f7d7ced3a54cda8329aae549a887f0",
            "value": "tokenizer.json: 100%"
          }
        },
        "67ea6863dcbb4b5f9bc9f1643ec75063": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6884a3222be74617b51c8a91ac3585c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68e8d6b6fa7c49bcb5d077937ecace97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b1b640237434e62a8bdcea7641fe3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c73e4ce1c7574199941fa948f227c1b2",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86d781de6ae9458294a95229172fb68b",
            "value": 898823
          }
        },
        "6b4a884dac9b45fb8d826b84d29ecd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f8478731b94f4390236d25d30e13a6",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee289b687b0d469483a5f07699f6f760",
            "value": 898823
          }
        },
        "6d9af2a8f2844aaa83ffbfc00aa59948": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db23e606f67d4f478cf84ca9155adf57",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e1ea22335ed4e84bc4dc837caeb07b2",
            "value": 456318
          }
        },
        "6e086d1df1544d9eb2a05e620b827e03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e11852f304443588840577095f674bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e8325d208714eac98243896c232060c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ef8ee747bf64c3bbce400d2acab274e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fef0a82427a46a3a373c716bf33c967",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f15c2bc3bde4416bc93631e9c79cb7b",
            "value": 1355863
          }
        },
        "717000b19b614d6081cc21c28e4de156": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "718203cd7133449da33af5fa839dc479": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6cade5a6900437f889eb2e018a581e3",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34af7818f7fa49c0a5e7362c5cea18e1",
            "value": 456318
          }
        },
        "71d384ea1c534073909843badf4169ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73a80398c84d4b76b180975a7962fd39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752887d788f24465be7fc345ad3e94a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76a9073e2fcc49368c366e9cae4c5cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77c230f17fe3476b8c2cc6ac7f9b53d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4adaaade6d004c3c8edf805f7b775fef",
            "placeholder": "​",
            "style": "IPY_MODEL_ccf85d8d81f14e8fbde7523b59027592",
            "value": " 899k/899k [00:00&lt;00:00, 6.71MB/s]"
          }
        },
        "7890614addb64ec49eb6f5470b05af5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e550978be84dac93501e1dea84e0db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4dd9c4e890e4b55a12624e74dcb3839",
            "placeholder": "​",
            "style": "IPY_MODEL_9c803485af954a2e9ecb4d9c704bbc99",
            "value": " 482/482 [00:00&lt;00:00, 37.3kB/s]"
          }
        },
        "78f8478731b94f4390236d25d30e13a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a508d5ea00a4746a6e0a869628cc61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ac47794443d40148385ea12e3eacfc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ce1362f02574e619239f5381f3fb6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ea8c231d9d04206a2e3204ad4c53e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bda5cb17e3d4f00b8a302ffac4c93fb",
            "placeholder": "​",
            "style": "IPY_MODEL_1866cef0486249c89781e74f155707c4",
            "value": "vocab.json: 100%"
          }
        },
        "7f6ed8743ab442a7afa1fc511fc2d0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8103ba6080ff42e5a5135373e6b4a01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_debe941c643345379bc1e1ffeb646afe",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d39ddfed77d345e1a54d3586242dedc3",
            "value": 1355863
          }
        },
        "814c6a6a69914d1f9a1b5a088f8a7a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df7b05271e28476fa939b0844617b987",
              "IPY_MODEL_a69b8f5064704444a723616dd71ccc90",
              "IPY_MODEL_5558b8409cdc4434aec82b2955820a75"
            ],
            "layout": "IPY_MODEL_180a6ce7a4554755b10b32c3d1aa6466"
          }
        },
        "826d0b9f5d16423c9ba55cd5fc4f8498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "835a09cb70d543d7a94cff4eaa662042": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "858fc0868aa5444c8b7da9fd98027610": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86d781de6ae9458294a95229172fb68b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86efd710dda44e63b26459377910ab99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87e1dac952444071b2f5dd4aa697d194": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "887668167fac4cd3b127a8925d41d1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53622d0462454b22a9bca33f485126d9",
            "placeholder": "​",
            "style": "IPY_MODEL_b1862c326c6541949146f8647128fde8",
            "value": "merges.txt: 100%"
          }
        },
        "88b8ab889656435089542a9574731e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "899aa9f35a0b4d6e867da2cb62f163a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6973ecfe89488c9487703f20f0306f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8beb94ea6ea24a3b9b1a8974062c9d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d9c6290951b4dd4beedfd4fa6f0fc6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f15c2bc3bde4416bc93631e9c79cb7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8fe789acb1bc48bf9a07a1c34f4199c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fef0a82427a46a3a373c716bf33c967": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9023fc4d35ad4f4ebd0e5e47e84e5032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ff9a7632d54429b9cbb28e0575431e",
            "placeholder": "​",
            "style": "IPY_MODEL_1f19718ce6d14e739fd0e206a6b75137",
            "value": " 482/482 [00:00&lt;00:00, 40.8kB/s]"
          }
        },
        "92f37c86e17740238bf3d7c8d1b3a255": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd8ce176966a43e2ab97dfb57c6008f1",
              "IPY_MODEL_6d9af2a8f2844aaa83ffbfc00aa59948",
              "IPY_MODEL_35984ebb24ee4b9ca8d7222748b18b52"
            ],
            "layout": "IPY_MODEL_1979c0ec947d4c6fbe3bd975a088f7e5"
          }
        },
        "9319ea6ab00940938f1518ccd140ac08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2519ee4c769a4d43a6457cff99208b16",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6deadac49a54ca8b722519f5fd953a6",
            "value": 1421700479
          }
        },
        "93293fed630240119e81fbdee35b0470": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93b5a81251cd4e4296c5137617f5042a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94781a3d5bc84fa2ae652792259f523b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96282002258d4254ad027348f6e32ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96fcd9f505454ee490de94e4864a4410": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9798440f6a1d4ff7ac8706d888f47de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10e7e4ef5bfe42eca2be532ab59e75bc",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_398a8fe2218242da85154dee81f9274c",
            "value": 898823
          }
        },
        "98094b3c40864d3790fb639a7de74baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4155142ca6df49f394a56f4c8df1060c",
              "IPY_MODEL_068c448caa5f45729c93ab6f5d4c0323",
              "IPY_MODEL_45f7871720764afd818da0c6254f8216"
            ],
            "layout": "IPY_MODEL_4bae712449dd442fb4cd2fc7473c37b4"
          }
        },
        "983125366ebc4609a51e9238268eaf73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a1850fe21ea40a1ab2c483fb651de56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a93756ab0c774bc6b847fd991c725e17",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36e31c596b5343f28dfa0869c378de01",
            "value": 1355863
          }
        },
        "9a228727bf3d4ae981dc910d5a4425db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a486bcdae5a549a5a0a8d9bceb55f8b6",
              "IPY_MODEL_9319ea6ab00940938f1518ccd140ac08",
              "IPY_MODEL_c41305ec8c244605af457049afe2355a"
            ],
            "layout": "IPY_MODEL_2318aa74cf45449d8302fd0607db55f4"
          }
        },
        "9a42bed8c0614ad1b992a78902602ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7f94fa5f24e4d68ae44d8c599aefd71",
              "IPY_MODEL_e54bea3ca5cc400881d7c866137cfed2",
              "IPY_MODEL_9023fc4d35ad4f4ebd0e5e47e84e5032"
            ],
            "layout": "IPY_MODEL_36c6a68e64104b44803be140cf177f02"
          }
        },
        "9ac9407ffd85487aaca7cb420460f550": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b4b2c2e47ad42b1b7412d97cd704450": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9dde42d94b4e475698662a423a293ccd",
              "IPY_MODEL_ef33bea83b484f0da1932829d68b844f",
              "IPY_MODEL_e03e3435b01140f599d76c028bde7866"
            ],
            "layout": "IPY_MODEL_6e11852f304443588840577095f674bc"
          }
        },
        "9bda5cb17e3d4f00b8a302ffac4c93fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c803485af954a2e9ecb4d9c704bbc99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dde42d94b4e475698662a423a293ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15075843fc0649eda42e7f208ba9814c",
            "placeholder": "​",
            "style": "IPY_MODEL_717000b19b614d6081cc21c28e4de156",
            "value": "merges.txt: 100%"
          }
        },
        "a42731aa1ee04cb8bda9a346a28c9203": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a486bcdae5a549a5a0a8d9bceb55f8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6884a3222be74617b51c8a91ac3585c2",
            "placeholder": "​",
            "style": "IPY_MODEL_fc4d22c72f9d4297ab33014a1c39331e",
            "value": "model.safetensors: 100%"
          }
        },
        "a4dd9c4e890e4b55a12624e74dcb3839": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5d9aba117484778bfffb9f1b4b6be6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76a9073e2fcc49368c366e9cae4c5cbd",
            "placeholder": "​",
            "style": "IPY_MODEL_dd6691fc7b724d73b30560fc248a62da",
            "value": "config.json: 100%"
          }
        },
        "a663d38f915947f1a0cbad1b5ce01925": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_175f032983f14d3d84d73f40086583d0",
              "IPY_MODEL_c1334cf22480476ab22f9848743e334b",
              "IPY_MODEL_b43a248e85214efdae985449d7d4f9fd"
            ],
            "layout": "IPY_MODEL_9ac9407ffd85487aaca7cb420460f550"
          }
        },
        "a69656f8bf964ce8889df06c5ccac18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2d221d9ae204fe1b02dae8f9a811d82",
            "placeholder": "​",
            "style": "IPY_MODEL_50045f2ce0bd490796a3d745f3b6d605",
            "value": " 482/482 [00:00&lt;00:00, 36.8kB/s]"
          }
        },
        "a69b8f5064704444a723616dd71ccc90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0d2b6d33c484ae09e6a4dde1123a721",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ac1ac315e75448db313dbf925b89a99",
            "value": 456318
          }
        },
        "a6cade5a6900437f889eb2e018a581e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a72404f819d4465c97f71fa626636a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6c0322756534517a9e0b3d011146c4b",
            "placeholder": "​",
            "style": "IPY_MODEL_a42731aa1ee04cb8bda9a346a28c9203",
            "value": "tokenizer.json: 100%"
          }
        },
        "a7f94fa5f24e4d68ae44d8c599aefd71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f2135f8496b4dbba32ff755b0b6295e",
            "placeholder": "​",
            "style": "IPY_MODEL_44edc79b6f54460ea66005ad78e0cdb4",
            "value": "config.json: 100%"
          }
        },
        "a93756ab0c774bc6b847fd991c725e17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa53ecdfa9bd40888bf967666e1de0e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe1169f5322a45bd80584fd5d34b4be6",
            "placeholder": "​",
            "style": "IPY_MODEL_7a508d5ea00a4746a6e0a869628cc61e",
            "value": "vocab.json: 100%"
          }
        },
        "ac55f62644ca46aba2b2c916980e90b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee7ca923eb734254b1d8c7ea46132644",
              "IPY_MODEL_2f9fa201216d46bbb3ed9734a0247d29",
              "IPY_MODEL_14b16a63a0b04931a73868687fd51572"
            ],
            "layout": "IPY_MODEL_330acb4c22274864abdef72b231ef9e9"
          }
        },
        "aeab8a0b49ab438ba40c628659477052": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1862c326c6541949146f8647128fde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b20ce595da4a4ef69d161b55d87f2c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a72404f819d4465c97f71fa626636a64",
              "IPY_MODEL_9a1850fe21ea40a1ab2c483fb651de56",
              "IPY_MODEL_19b99a08457c4ad7bafb5f680bd8f52f"
            ],
            "layout": "IPY_MODEL_3de5f6ff765b44c19445a15229ddaca4"
          }
        },
        "b30432d1cfc947c5864f11382d337f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b326e9d81213487797f989598e0363b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b9e173d962849fb892a4609e5ac30d9",
              "IPY_MODEL_4f0dea01f6db4ce49dc47348e4d6a3a6",
              "IPY_MODEL_041aea7ed89a41dd8cbabf58008955d4"
            ],
            "layout": "IPY_MODEL_227a769daeff4569890489dfd71c97b6"
          }
        },
        "b40148c4fe9e4b39b7f74710c471eea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b43a248e85214efdae985449d7d4f9fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f40737a9125a461e930de51ec3e49167",
            "placeholder": "​",
            "style": "IPY_MODEL_c7cdc7af13c04fc7945ac971511db2ca",
            "value": " 899k/899k [00:00&lt;00:00, 6.63MB/s]"
          }
        },
        "b45682f10ae5416cae55d1bafc811a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a783c13998445aba947367704f6a1d4",
              "IPY_MODEL_6b1b640237434e62a8bdcea7641fe3b6",
              "IPY_MODEL_49b99b7bd73243cda135ff1ec0301d6b"
            ],
            "layout": "IPY_MODEL_93293fed630240119e81fbdee35b0470"
          }
        },
        "b4aa2c41de0c4774ae829a04f4486843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4706281b6d4c45bfa55dd05ee26bda3c",
              "IPY_MODEL_0606a000ba7c4db6a98b4a8e48bab815",
              "IPY_MODEL_2fef69957f3743a2a4d2b6f0cdeecfb6"
            ],
            "layout": "IPY_MODEL_c1741c3f390741e19fd17f7f17db0e69"
          }
        },
        "b4df5fb134a540ca886832f644a613ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6f82153d8844bb0825b634fba9ee856": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76fac24ee804e5c81ace9f8f504ceb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b793fc09d80a4b359a56c28f119683dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_068b52189369439b8e7786802567ddaf",
            "placeholder": "​",
            "style": "IPY_MODEL_43494ede53d84cfe85c8ddeef50ec526",
            "value": "merges.txt: 100%"
          }
        },
        "b7e31aca3bb14973b23128a19c05963e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b849dc7d01dd48a58be543e26c38eaf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb7166fe00834c06ab4b3a63e712dd19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc988c676b6142b78a009a7da67fbc05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8ce176966a43e2ab97dfb57c6008f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_899aa9f35a0b4d6e867da2cb62f163a6",
            "placeholder": "​",
            "style": "IPY_MODEL_079a672f9f244b5d91a05b5601320d99",
            "value": "merges.txt: 100%"
          }
        },
        "c1334cf22480476ab22f9848743e334b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3125140a79084dcaa9ce3e665bc9853e",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96282002258d4254ad027348f6e32ba3",
            "value": 898823
          }
        },
        "c1741c3f390741e19fd17f7f17db0e69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1aecb7094ad43d291f1423c7f06e91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ac47794443d40148385ea12e3eacfc3",
            "placeholder": "​",
            "style": "IPY_MODEL_09374732818a4620ac7fc0e047782582",
            "value": "config.json: 100%"
          }
        },
        "c24d0b100a4148ab91cfdf1dd6977464": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa53ecdfa9bd40888bf967666e1de0e4",
              "IPY_MODEL_9798440f6a1d4ff7ac8706d888f47de4",
              "IPY_MODEL_2fcef4e9a365414aa11731bc560051f5"
            ],
            "layout": "IPY_MODEL_b7e31aca3bb14973b23128a19c05963e"
          }
        },
        "c29e67631b1e43de8d8f1db49b3008d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d221d9ae204fe1b02dae8f9a811d82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d0493f32484d29b350c1c9f1fa4b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc988c676b6142b78a009a7da67fbc05",
            "placeholder": "​",
            "style": "IPY_MODEL_59e7e5528504408c91dfe84d0fc0fa3f",
            "value": " 456k/456k [00:00&lt;00:00, 28.6MB/s]"
          }
        },
        "c41305ec8c244605af457049afe2355a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ab5d178a824081a0650be6abdd6c6a",
            "placeholder": "​",
            "style": "IPY_MODEL_8beb94ea6ea24a3b9b1a8974062c9d44",
            "value": " 1.42G/1.42G [00:19&lt;00:00, 84.8MB/s]"
          }
        },
        "c59cb7dd90a24cd2b266e67d3cc4ea43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecf98edf5716448c8d81df119270e76a",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e21ba70e7890415d99bcb41b6b8e201e",
            "value": 1421700479
          }
        },
        "c73e4ce1c7574199941fa948f227c1b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7cdc7af13c04fc7945ac971511db2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8334f674d9945f4a117865dededfdbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9d3f83bfb7b433d9c41b499de79348d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc2eeb93b0504598b497005acf4b2496": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de3d7ba4f2d841a9a4fbe04b278d5445",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec835bf8cc284d51a4ec243843003b06",
            "value": 482
          }
        },
        "ccf85d8d81f14e8fbde7523b59027592": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdbd796c94a84398a9a55b38b746226f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce05000fde2a4eba854f9c6dbfe24013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e086d1df1544d9eb2a05e620b827e03",
            "placeholder": "​",
            "style": "IPY_MODEL_f8b0c19b35da4c73b88be2497c55596c",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 25.2MB/s]"
          }
        },
        "cf8d39dabfc44f19825946576572c977": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfb79a281c5f431286f645d5bdf6a498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d100bbc411ae4ce6a79e7f8f41dc2439": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_331596856ff04a86a223eb78c66f897c",
            "placeholder": "​",
            "style": "IPY_MODEL_fcad34dc82784222801b3289a6e2768b",
            "value": "config.json: 100%"
          }
        },
        "d116a5a50efb49e7adb3ece153f629c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_052127d3e7774ce0b5855ddc45519cfe",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1bce12bcbce40759194126a83e76445",
            "value": 898823
          }
        },
        "d1bce12bcbce40759194126a83e76445": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2ff9a7632d54429b9cbb28e0575431e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3370d718ff34f32be8a07d96831c95f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d39ddfed77d345e1a54d3586242dedc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d42ec097d1134e9ba79daa8058e82cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d54a4135a7164612b17a4c5198961c92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5683069839347bc918f393d51a7d468": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db23e606f67d4f478cf84ca9155adf57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db343cee166c40a9871c7f74c65f9864": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc4d3150aeac433189d38455508431f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf8e3f6a9074332860ad1d11fdb0e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd6691fc7b724d73b30560fc248a62da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de3d7ba4f2d841a9a4fbe04b278d5445": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de5936f228a84f5483db3431fdefd765": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "debe941c643345379bc1e1ffeb646afe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df7b05271e28476fa939b0844617b987": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e59d50d4f70945b191e9d07346ac381d",
            "placeholder": "​",
            "style": "IPY_MODEL_41d9a6d81a0c4c509cd2e9f300dd0ab4",
            "value": "merges.txt: 100%"
          }
        },
        "e03e3435b01140f599d76c028bde7866": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_564822bb52f74e4797c4e3ff3671db50",
            "placeholder": "​",
            "style": "IPY_MODEL_3521c762ec784931a948cdb4cc940a44",
            "value": " 456k/456k [00:00&lt;00:00, 29.8MB/s]"
          }
        },
        "e21ba70e7890415d99bcb41b6b8e201e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3aaf4b6527c40f184555f5cd5f4cf3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e54bea3ca5cc400881d7c866137cfed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fe789acb1bc48bf9a07a1c34f4199c5",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a6973ecfe89488c9487703f20f0306f",
            "value": 482
          }
        },
        "e59d50d4f70945b191e9d07346ac381d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6deadac49a54ca8b722519f5fd953a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7a7d50f071741278602f78c41160e20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9fbd1aefc144995951e463c94688600": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea886f2ba13642cfbe03c80c6dd651cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bf9df005960449b81fb593a30de7764",
              "IPY_MODEL_c59cb7dd90a24cd2b266e67d3cc4ea43",
              "IPY_MODEL_ef71019daa6847a59da56501a4955fc5"
            ],
            "layout": "IPY_MODEL_175dae5537da458f88798e706e35e7c8"
          }
        },
        "ec695c2195a84148ac97c7d34e9490b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec835bf8cc284d51a4ec243843003b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecf98edf5716448c8d81df119270e76a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee289b687b0d469483a5f07699f6f760": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee7ca923eb734254b1d8c7ea46132644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a71f73c8c3e4500a2993a26c0e3c863",
            "placeholder": "​",
            "style": "IPY_MODEL_3cd1135737474388ac2e8f7925c06d88",
            "value": "model.safetensors: 100%"
          }
        },
        "ef33bea83b484f0da1932829d68b844f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf8d39dabfc44f19825946576572c977",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_858fc0868aa5444c8b7da9fd98027610",
            "value": 456318
          }
        },
        "ef71019daa6847a59da56501a4955fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_983125366ebc4609a51e9238268eaf73",
            "placeholder": "​",
            "style": "IPY_MODEL_367d58a226294562b110d0f031b52e46",
            "value": " 1.42G/1.42G [00:04&lt;00:00, 302MB/s]"
          }
        },
        "ef735ce7ac5b421a8f6fb658d8ae1f24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0d2b6d33c484ae09e6a4dde1123a721": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f32ae9e091ae42e18e6595fff7f8bbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a7d50f071741278602f78c41160e20",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_089bf456c9e544a4aeb8b8c02dd621f7",
            "value": 482
          }
        },
        "f40737a9125a461e930de51ec3e49167": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5ea2a6aa1294511bd78a11b1d442bad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6aae10576a74343a13cb88cb8339d51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6c0322756534517a9e0b3d011146c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f86e531a3b2d4d8eb605f3b3af6e833a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8b0c19b35da4c73b88be2497c55596c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc4d22c72f9d4297ab33014a1c39331e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcad34dc82784222801b3289a6e2768b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd215d8777a946e4acab5ed77be48d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63da9fc1903e42ad9f5c6e0c333d7221",
            "placeholder": "​",
            "style": "IPY_MODEL_d5683069839347bc918f393d51a7d468",
            "value": " 1.42G/1.42G [00:47&lt;00:00, 29.3MB/s]"
          }
        },
        "fd70333d859741fe84645f53325b3c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc4d3150aeac433189d38455508431f5",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2857bcae75694427995f5f1ccf759afd",
            "value": 1421700479
          }
        },
        "fda016da076e4a44ac05d80ad7863e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b76fac24ee804e5c81ace9f8f504ceb1",
            "placeholder": "​",
            "style": "IPY_MODEL_94781a3d5bc84fa2ae652792259f523b",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 5.67MB/s]"
          }
        },
        "fe1169f5322a45bd80584fd5d34b4be6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feaa5655930c453b985c26051360230e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d1ef1ab4b7044e7bb30fc1220cfabc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02a42df750404a52b344d82e539593cb",
              "IPY_MODEL_e5f4269d160c4992867ec22572d53ff6",
              "IPY_MODEL_180b38d300fe40c38406733a0730a9e3"
            ],
            "layout": "IPY_MODEL_60a4458c6a35475ca4099513a48f2cd9"
          }
        },
        "02a42df750404a52b344d82e539593cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6774017cd7b49329753ea16238210ec",
            "placeholder": "​",
            "style": "IPY_MODEL_25e0f9e2c8004ba0b2bbc147df456dc5",
            "value": "config.json: 100%"
          }
        },
        "e5f4269d160c4992867ec22572d53ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ef9f87db7f0462fa43fd5dd9fedded8",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04e6187984b141bcac5ba4423e69acc6",
            "value": 482
          }
        },
        "180b38d300fe40c38406733a0730a9e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c39185115e7c4e21baca2f629d4ad3c1",
            "placeholder": "​",
            "style": "IPY_MODEL_aee591fab2f4460e8822480889069bf6",
            "value": " 482/482 [00:00&lt;00:00, 39.5kB/s]"
          }
        },
        "60a4458c6a35475ca4099513a48f2cd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6774017cd7b49329753ea16238210ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e0f9e2c8004ba0b2bbc147df456dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ef9f87db7f0462fa43fd5dd9fedded8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04e6187984b141bcac5ba4423e69acc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c39185115e7c4e21baca2f629d4ad3c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aee591fab2f4460e8822480889069bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bf1c5d74c834b5d966ac45f063da84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46e8436773f042dda6182282aab5e72b",
              "IPY_MODEL_0a5474597f0b4fb8b426d1f0af740101",
              "IPY_MODEL_6383c58a588f411c82ca9047c2b6316c"
            ],
            "layout": "IPY_MODEL_ea6ead3c919c4fdb853a593d919737e4"
          }
        },
        "46e8436773f042dda6182282aab5e72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5710a7923ef4eefb223f0e3311d77f9",
            "placeholder": "​",
            "style": "IPY_MODEL_09e2f56c14924edb9d212da9450d781c",
            "value": "vocab.json: 100%"
          }
        },
        "0a5474597f0b4fb8b426d1f0af740101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2226551dc9d42079622cf9d63a918ef",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c4c3037bf334566819a6ceb163fc050",
            "value": 898823
          }
        },
        "6383c58a588f411c82ca9047c2b6316c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31e241ec496e425ca11b58b80e04b364",
            "placeholder": "​",
            "style": "IPY_MODEL_d1f9784b31c64ab8b82abe83fda83718",
            "value": " 899k/899k [00:00&lt;00:00, 1.14MB/s]"
          }
        },
        "ea6ead3c919c4fdb853a593d919737e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5710a7923ef4eefb223f0e3311d77f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09e2f56c14924edb9d212da9450d781c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2226551dc9d42079622cf9d63a918ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c4c3037bf334566819a6ceb163fc050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31e241ec496e425ca11b58b80e04b364": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f9784b31c64ab8b82abe83fda83718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9a7f2ab1cef4ad297a26d5c30756792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e6dc208c9494ca1924aebd1d859eb05",
              "IPY_MODEL_19d727196a2041309196bd4eab475612",
              "IPY_MODEL_9f74c31fa5d04d9aa5cf94cad4694540"
            ],
            "layout": "IPY_MODEL_1df365a282aa40e494993fdcc8107ceb"
          }
        },
        "7e6dc208c9494ca1924aebd1d859eb05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_731e3e9e11854a89a0329201a006e877",
            "placeholder": "​",
            "style": "IPY_MODEL_31aa170973b84fa3b85c4639cfd1b261",
            "value": "merges.txt: 100%"
          }
        },
        "19d727196a2041309196bd4eab475612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab4dbe13dd5a4dc58d003b6655da34cc",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9de54e63ad5646ffaf8885027beb875f",
            "value": 456318
          }
        },
        "9f74c31fa5d04d9aa5cf94cad4694540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_834431fab85d4431b5d7e77b0e0106f3",
            "placeholder": "​",
            "style": "IPY_MODEL_af4a92d3c415471a8b7d6dbda9eb9561",
            "value": " 456k/456k [00:00&lt;00:00, 755kB/s]"
          }
        },
        "1df365a282aa40e494993fdcc8107ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "731e3e9e11854a89a0329201a006e877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31aa170973b84fa3b85c4639cfd1b261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab4dbe13dd5a4dc58d003b6655da34cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9de54e63ad5646ffaf8885027beb875f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "834431fab85d4431b5d7e77b0e0106f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4a92d3c415471a8b7d6dbda9eb9561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44b3a7596ef640f587f8546676c6270a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1de9e1a8fe4a4e57b3233b5e95e4373b",
              "IPY_MODEL_508ff7efbe694603b475140cca709d88",
              "IPY_MODEL_9011b17b72b649f69afb792dc0c40676"
            ],
            "layout": "IPY_MODEL_a89d2a0ffd214caab48b986486ee4ded"
          }
        },
        "1de9e1a8fe4a4e57b3233b5e95e4373b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece2afd37f1a4ea1bb68b6d6e2a548f1",
            "placeholder": "​",
            "style": "IPY_MODEL_a8ddee9eb9c741d581fe03727009ed19",
            "value": "tokenizer.json: 100%"
          }
        },
        "508ff7efbe694603b475140cca709d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03982097a9254bf1bbfb42ed13163f91",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_593bb4587aeb4561ac0e8248ccf225a4",
            "value": 1355863
          }
        },
        "9011b17b72b649f69afb792dc0c40676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d045604f0cb452e8ae86deb32e7099c",
            "placeholder": "​",
            "style": "IPY_MODEL_43310721377c4156b7e7632bd001fb29",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.62MB/s]"
          }
        },
        "a89d2a0ffd214caab48b986486ee4ded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece2afd37f1a4ea1bb68b6d6e2a548f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8ddee9eb9c741d581fe03727009ed19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03982097a9254bf1bbfb42ed13163f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593bb4587aeb4561ac0e8248ccf225a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d045604f0cb452e8ae86deb32e7099c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43310721377c4156b7e7632bd001fb29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04a5bdcc1fc74b63a49805ce04867c07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff548bf675934feb8f17f5c0586d88c1",
              "IPY_MODEL_5c2a12802cb1461f9cd86768b198e4ba",
              "IPY_MODEL_af8dc41f0c114559a391cb09f3c9c211"
            ],
            "layout": "IPY_MODEL_046e4bdee4e74509b8c61976fd1722f1"
          }
        },
        "ff548bf675934feb8f17f5c0586d88c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f69edadf5df40a3aedc7e4014e46120",
            "placeholder": "​",
            "style": "IPY_MODEL_139a4b08045e4a7dab6cc7f3f48be434",
            "value": "model.safetensors: 100%"
          }
        },
        "5c2a12802cb1461f9cd86768b198e4ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b3e6d6e95f6424482c3f8367794fedc",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07b3206349bd42799a74aaa98c6f87ae",
            "value": 1421700479
          }
        },
        "af8dc41f0c114559a391cb09f3c9c211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7815ffa5acc74b62827afcb2ca3b06fe",
            "placeholder": "​",
            "style": "IPY_MODEL_f7e6739175b849da820a565115931d1e",
            "value": " 1.42G/1.42G [00:45&lt;00:00, 29.8MB/s]"
          }
        },
        "046e4bdee4e74509b8c61976fd1722f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f69edadf5df40a3aedc7e4014e46120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "139a4b08045e4a7dab6cc7f3f48be434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b3e6d6e95f6424482c3f8367794fedc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07b3206349bd42799a74aaa98c6f87ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7815ffa5acc74b62827afcb2ca3b06fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7e6739175b849da820a565115931d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d32b2a401d4e4c0b9496948a027c8fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_596645eda20f4b91a8323de570854203",
              "IPY_MODEL_f6730ce233fd4b3aa9833c02fa0e86e1",
              "IPY_MODEL_c69e1d273d694ba5a912da20eece5b10"
            ],
            "layout": "IPY_MODEL_22098da9de01452c9a114eaba2460fa4"
          }
        },
        "596645eda20f4b91a8323de570854203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_403ce0e6f0dd4d1f8f9943fcac101032",
            "placeholder": "​",
            "style": "IPY_MODEL_942dd3f6fd754b18956f9424be66ce51",
            "value": "vocab.json: 100%"
          }
        },
        "f6730ce233fd4b3aa9833c02fa0e86e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a568a5851fba4fe7bd0998b8f7919e9f",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7093cabbcbc3455b977c6902e974c949",
            "value": 898823
          }
        },
        "c69e1d273d694ba5a912da20eece5b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86221f9c690f4e7089db3db12994cc65",
            "placeholder": "​",
            "style": "IPY_MODEL_27239faf493841c1994c7ee70eaae5e5",
            "value": " 899k/899k [00:00&lt;00:00, 4.68MB/s]"
          }
        },
        "22098da9de01452c9a114eaba2460fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "403ce0e6f0dd4d1f8f9943fcac101032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942dd3f6fd754b18956f9424be66ce51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a568a5851fba4fe7bd0998b8f7919e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7093cabbcbc3455b977c6902e974c949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86221f9c690f4e7089db3db12994cc65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27239faf493841c1994c7ee70eaae5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13b189ebc05a425398c90e14290bb2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aeb32f54f0464262b77937675b00c95a",
              "IPY_MODEL_75c978ddaf48488e8fccab426aff11ef",
              "IPY_MODEL_fc694e117e8241c6a13d16cf4b9c33f6"
            ],
            "layout": "IPY_MODEL_92d4d0d7ed45448f91c891c2692eeded"
          }
        },
        "aeb32f54f0464262b77937675b00c95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e02e5d622b140959818e6e23f482e0e",
            "placeholder": "​",
            "style": "IPY_MODEL_73ced5e57db54217a51c0ec93f2db19d",
            "value": "merges.txt: 100%"
          }
        },
        "75c978ddaf48488e8fccab426aff11ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c642e70ae7045b7a73527a72ba31e24",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66085a2ab1964bc1a0a7e8716c740ae8",
            "value": 456318
          }
        },
        "fc694e117e8241c6a13d16cf4b9c33f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a56f44e83d5e4df49533d9d2e8990550",
            "placeholder": "​",
            "style": "IPY_MODEL_9161e72b7c524b2385206123913153a3",
            "value": " 456k/456k [00:00&lt;00:00, 13.6MB/s]"
          }
        },
        "92d4d0d7ed45448f91c891c2692eeded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e02e5d622b140959818e6e23f482e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ced5e57db54217a51c0ec93f2db19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c642e70ae7045b7a73527a72ba31e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66085a2ab1964bc1a0a7e8716c740ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a56f44e83d5e4df49533d9d2e8990550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9161e72b7c524b2385206123913153a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48e421f7f8414bc4b7e8dbd79ad50fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0bc5ba7e16e4818a998137066c1d6ef",
              "IPY_MODEL_97eb08aed9b042f68d73e65e24a00e08",
              "IPY_MODEL_0cda20db7de64c0ca7844afde465d77b"
            ],
            "layout": "IPY_MODEL_b42932735b6b494f8b27f3cb745333c2"
          }
        },
        "d0bc5ba7e16e4818a998137066c1d6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4df4c5cc0a494a57a41c4616c97dc42d",
            "placeholder": "​",
            "style": "IPY_MODEL_4a5f86ff185c4cfba33ff2998a82d2e3",
            "value": "tokenizer.json: 100%"
          }
        },
        "97eb08aed9b042f68d73e65e24a00e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49b91dfd059645cca58b1b4177991aff",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfaa6cb5d31046d4957c4253d2b61c7c",
            "value": 1355863
          }
        },
        "0cda20db7de64c0ca7844afde465d77b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c060951707a48b1a4682a5f5445a30f",
            "placeholder": "​",
            "style": "IPY_MODEL_525d925ac8a84b3587136a96edcada6a",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 17.9MB/s]"
          }
        },
        "b42932735b6b494f8b27f3cb745333c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df4c5cc0a494a57a41c4616c97dc42d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a5f86ff185c4cfba33ff2998a82d2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49b91dfd059645cca58b1b4177991aff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfaa6cb5d31046d4957c4253d2b61c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c060951707a48b1a4682a5f5445a30f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525d925ac8a84b3587136a96edcada6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39d16970b4994b42802dff8a739149b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cca53dec484449b58ec184e205f9808c",
              "IPY_MODEL_df9892c7bf804e1c884eeccece200a78",
              "IPY_MODEL_ee03d39fca184c98b884f49bdf7e7a83"
            ],
            "layout": "IPY_MODEL_e5b2545485014a6393d06a07fa9988ad"
          }
        },
        "cca53dec484449b58ec184e205f9808c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc6949948cd74909b1d530f48ad94c31",
            "placeholder": "​",
            "style": "IPY_MODEL_ff057385f27f47d9adf0b5c3cd8adba8",
            "value": "config.json: 100%"
          }
        },
        "df9892c7bf804e1c884eeccece200a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_772df8c2cd0447619ced3acdd0046c24",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00ea5426180f4abdab48246b35b91b0d",
            "value": 482
          }
        },
        "ee03d39fca184c98b884f49bdf7e7a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7ce631d8d8f42a9b950673d21eb503b",
            "placeholder": "​",
            "style": "IPY_MODEL_37e5d8ad303f42a6b73492ce6226f59d",
            "value": " 482/482 [00:00&lt;00:00, 8.38kB/s]"
          }
        },
        "e5b2545485014a6393d06a07fa9988ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc6949948cd74909b1d530f48ad94c31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff057385f27f47d9adf0b5c3cd8adba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "772df8c2cd0447619ced3acdd0046c24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00ea5426180f4abdab48246b35b91b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7ce631d8d8f42a9b950673d21eb503b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37e5d8ad303f42a6b73492ce6226f59d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c929dc3239114c479ecd9ff450092cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45f084d7edfa4f989aad34a64dd9b2b8",
              "IPY_MODEL_438284f546864d6dbcb55c54a8d97275",
              "IPY_MODEL_7999b7ab4bc54326ae6ffa736e52712b"
            ],
            "layout": "IPY_MODEL_3d57d8934c914660a6e5973ae97f8bce"
          }
        },
        "45f084d7edfa4f989aad34a64dd9b2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa9a2d6c33b64504bdc0b31f964787e1",
            "placeholder": "​",
            "style": "IPY_MODEL_452172f204f44b299a4277ee99b4d6a7",
            "value": "model.safetensors: 100%"
          }
        },
        "438284f546864d6dbcb55c54a8d97275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e0e04ea663643998c2bdd9efd2ba4c6",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2254211f20c144caa95f4074072981a4",
            "value": 1421700479
          }
        },
        "7999b7ab4bc54326ae6ffa736e52712b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c499589d90fc45619f656fb10a5bf962",
            "placeholder": "​",
            "style": "IPY_MODEL_fb685baeaf9643309fe48a61c5c06fcc",
            "value": " 1.42G/1.42G [00:15&lt;00:00, 143MB/s]"
          }
        },
        "3d57d8934c914660a6e5973ae97f8bce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa9a2d6c33b64504bdc0b31f964787e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "452172f204f44b299a4277ee99b4d6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e0e04ea663643998c2bdd9efd2ba4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2254211f20c144caa95f4074072981a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c499589d90fc45619f656fb10a5bf962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb685baeaf9643309fe48a61c5c06fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c6e8ad598aa4ee28179890eb8e83cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cae5c2842d5d4688a571032c4ec244f4",
              "IPY_MODEL_4652c8fec6874b979d92851329a854f9",
              "IPY_MODEL_e62de9d2733e4d4f882b89f22eda012c"
            ],
            "layout": "IPY_MODEL_b535a941aa0944d89e0bec62d3b22a8e"
          }
        },
        "cae5c2842d5d4688a571032c4ec244f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42c7864fd4484e77962bc33b414b92eb",
            "placeholder": "​",
            "style": "IPY_MODEL_41ab0b168d5a49fdb33a68634116a9b1",
            "value": "config.json: 100%"
          }
        },
        "4652c8fec6874b979d92851329a854f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2b40293346146ed8c01c0047804fe38",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9eff5a4cab849fbbf87214bd1f5593c",
            "value": 482
          }
        },
        "e62de9d2733e4d4f882b89f22eda012c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27847845e4874c698970e709792c0326",
            "placeholder": "​",
            "style": "IPY_MODEL_224ecab2401f44ba968a27a41cd4ddf1",
            "value": " 482/482 [00:00&lt;00:00, 40.9kB/s]"
          }
        },
        "b535a941aa0944d89e0bec62d3b22a8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c7864fd4484e77962bc33b414b92eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ab0b168d5a49fdb33a68634116a9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2b40293346146ed8c01c0047804fe38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9eff5a4cab849fbbf87214bd1f5593c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27847845e4874c698970e709792c0326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "224ecab2401f44ba968a27a41cd4ddf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c047fe0871784ae3a632385a1fa4ca51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_498e502493dd45d090dce2b63fb49090",
              "IPY_MODEL_9145cf6de4064f99858c6f9652d5fb2f",
              "IPY_MODEL_f4ec57eb02c14dd5abd1f288426ca300"
            ],
            "layout": "IPY_MODEL_14ad9701679d4578a7ad251c76c42add"
          }
        },
        "498e502493dd45d090dce2b63fb49090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a7fe027f120440a9d762fc9aa4822ee",
            "placeholder": "​",
            "style": "IPY_MODEL_ca7fe3cce3844b528f74d8e843177c76",
            "value": "vocab.json: 100%"
          }
        },
        "9145cf6de4064f99858c6f9652d5fb2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8a0d182737d46028659c4de48200f50",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a787ee446eb4512959c344559c263e2",
            "value": 898823
          }
        },
        "f4ec57eb02c14dd5abd1f288426ca300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4abea279858446b49b89dfe483fcdf28",
            "placeholder": "​",
            "style": "IPY_MODEL_a4297614578b4394935551c29d150719",
            "value": " 899k/899k [00:00&lt;00:00, 3.64MB/s]"
          }
        },
        "14ad9701679d4578a7ad251c76c42add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a7fe027f120440a9d762fc9aa4822ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7fe3cce3844b528f74d8e843177c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8a0d182737d46028659c4de48200f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a787ee446eb4512959c344559c263e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4abea279858446b49b89dfe483fcdf28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4297614578b4394935551c29d150719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff15fac3674541da905860b4bd574aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3613720c1f14570a12b7cc3d804336b",
              "IPY_MODEL_d7c6be967a4e4c5e99d543c59b64eb35",
              "IPY_MODEL_5495b73a280847faa0db93e5592a1425"
            ],
            "layout": "IPY_MODEL_6a5b862847024c7cbadf8fe57bf77bb8"
          }
        },
        "e3613720c1f14570a12b7cc3d804336b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c06ef03262c48a0b56ab30184818e75",
            "placeholder": "​",
            "style": "IPY_MODEL_3de34b30aae0496b85bde418b2b5e0f4",
            "value": "merges.txt: 100%"
          }
        },
        "d7c6be967a4e4c5e99d543c59b64eb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69a8061a1537484ea6ddbc973280311b",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_990b97a303fb457ebb79f01b4e503ff0",
            "value": 456318
          }
        },
        "5495b73a280847faa0db93e5592a1425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9067d224fcd141258d9bc7297ade7367",
            "placeholder": "​",
            "style": "IPY_MODEL_724f07ebfae647899d3255944b3663d4",
            "value": " 456k/456k [00:00&lt;00:00, 621kB/s]"
          }
        },
        "6a5b862847024c7cbadf8fe57bf77bb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c06ef03262c48a0b56ab30184818e75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3de34b30aae0496b85bde418b2b5e0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69a8061a1537484ea6ddbc973280311b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "990b97a303fb457ebb79f01b4e503ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9067d224fcd141258d9bc7297ade7367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "724f07ebfae647899d3255944b3663d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f04028e9675451ba5def9db9c1c2a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f99673a45d64768884d11efb813346b",
              "IPY_MODEL_9fb9e15ce2864cc88ee393ee426c6553",
              "IPY_MODEL_b0f4cd5ffdb34b25bdd8d7a28a9c9b0e"
            ],
            "layout": "IPY_MODEL_79ee34ee8d6c4d9e9b5493f961e39d12"
          }
        },
        "5f99673a45d64768884d11efb813346b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18221d5549d248a1a0f2c6fbb86a4236",
            "placeholder": "​",
            "style": "IPY_MODEL_a3add975034b4e7b96a1ee8ed996d9ff",
            "value": "tokenizer.json: 100%"
          }
        },
        "9fb9e15ce2864cc88ee393ee426c6553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1db4e0b682d340e994eb51ae30af278a",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b01a7dd89e094d5f8163a72589f9a970",
            "value": 1355863
          }
        },
        "b0f4cd5ffdb34b25bdd8d7a28a9c9b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca1633f98a84455b7294aaec75f649f",
            "placeholder": "​",
            "style": "IPY_MODEL_0db9fa66d0164c42af93fe19d39238a8",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.89MB/s]"
          }
        },
        "79ee34ee8d6c4d9e9b5493f961e39d12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18221d5549d248a1a0f2c6fbb86a4236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3add975034b4e7b96a1ee8ed996d9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1db4e0b682d340e994eb51ae30af278a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b01a7dd89e094d5f8163a72589f9a970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ca1633f98a84455b7294aaec75f649f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db9fa66d0164c42af93fe19d39238a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8446a3d9aba140c7b419f7810948d6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26c0d7ef738c49649504104c3d9fec87",
              "IPY_MODEL_74753db77b724f128ccee61a2a559137",
              "IPY_MODEL_f597a00c7dae46209dbc70130669e460"
            ],
            "layout": "IPY_MODEL_44cee09826fc41c487b6525422cb4911"
          }
        },
        "26c0d7ef738c49649504104c3d9fec87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_287b83be07234d3b9489ef59ee45fbf7",
            "placeholder": "​",
            "style": "IPY_MODEL_6385c270cd944eaf9769616d79ba2585",
            "value": "model.safetensors: 100%"
          }
        },
        "74753db77b724f128ccee61a2a559137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95273a0e4d824837b0611aa532ab9ed3",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c40884f5ca04dafa221931290fe7ecd",
            "value": 1421700479
          }
        },
        "f597a00c7dae46209dbc70130669e460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc33438de029473b8d162cee3d13e22d",
            "placeholder": "​",
            "style": "IPY_MODEL_b17a1bf0280a4cde829dd71c5e5cfef8",
            "value": " 1.42G/1.42G [00:03&lt;00:00, 367MB/s]"
          }
        },
        "44cee09826fc41c487b6525422cb4911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "287b83be07234d3b9489ef59ee45fbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6385c270cd944eaf9769616d79ba2585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95273a0e4d824837b0611aa532ab9ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c40884f5ca04dafa221931290fe7ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc33438de029473b8d162cee3d13e22d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17a1bf0280a4cde829dd71c5e5cfef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e36b6fe5fbb14f36b6568908738b85f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6e6e42701b94af8af60cf011a25d253",
              "IPY_MODEL_8e4935de4f664b308e28e15e9ab58607",
              "IPY_MODEL_e00054ca95d44b3dab4123a233b8e40f"
            ],
            "layout": "IPY_MODEL_5d728d028af84c159482ed6dd5f48167"
          }
        },
        "f6e6e42701b94af8af60cf011a25d253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1ec50d9822e416e9300b6f8dacf1d93",
            "placeholder": "​",
            "style": "IPY_MODEL_6fb9b6d17efb4e36958ba27fa8fa196c",
            "value": "vocab.json: 100%"
          }
        },
        "8e4935de4f664b308e28e15e9ab58607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95d0bf77cdc64b689f81af267b5af887",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c778f96c446471ab439966bd8e649e4",
            "value": 898823
          }
        },
        "e00054ca95d44b3dab4123a233b8e40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01fb165adc4e4438980fd14652d6be8d",
            "placeholder": "​",
            "style": "IPY_MODEL_058001829eca48b18330b503178f71d5",
            "value": " 899k/899k [00:00&lt;00:00, 5.99MB/s]"
          }
        },
        "5d728d028af84c159482ed6dd5f48167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1ec50d9822e416e9300b6f8dacf1d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb9b6d17efb4e36958ba27fa8fa196c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95d0bf77cdc64b689f81af267b5af887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c778f96c446471ab439966bd8e649e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01fb165adc4e4438980fd14652d6be8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058001829eca48b18330b503178f71d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0ee3880095041b5a9d80412f7a8e45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9137528826542ffb365e5ca1065e785",
              "IPY_MODEL_86a05d05cb8046618d69bc15edd41f36",
              "IPY_MODEL_2b79b001a0044b16bfb582d28073495e"
            ],
            "layout": "IPY_MODEL_ef4e1e75033f4625ad6a1088c0f4b880"
          }
        },
        "f9137528826542ffb365e5ca1065e785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_410a604a70e04407a867e5cf93ad828a",
            "placeholder": "​",
            "style": "IPY_MODEL_4218a21fb11a4031be7d5ca3ac90572d",
            "value": "merges.txt: 100%"
          }
        },
        "86a05d05cb8046618d69bc15edd41f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e820a3180ef42979b8400e3ab5c9c13",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8553aa6a04b4e82a0f95541dc09f0c2",
            "value": 456318
          }
        },
        "2b79b001a0044b16bfb582d28073495e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a626e3e19da47aeac31719a61157c50",
            "placeholder": "​",
            "style": "IPY_MODEL_7da25e044e59453dbcf3fe17cc052957",
            "value": " 456k/456k [00:00&lt;00:00, 9.18MB/s]"
          }
        },
        "ef4e1e75033f4625ad6a1088c0f4b880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "410a604a70e04407a867e5cf93ad828a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4218a21fb11a4031be7d5ca3ac90572d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e820a3180ef42979b8400e3ab5c9c13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8553aa6a04b4e82a0f95541dc09f0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a626e3e19da47aeac31719a61157c50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da25e044e59453dbcf3fe17cc052957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25716adacaae4424ace1712030178f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15a180a9fe3645e8a4ba57044112ce61",
              "IPY_MODEL_262cda27d8554e888f08741ceef1b1c3",
              "IPY_MODEL_3b4fe7014c8c4b5ebc00cd2bf65e2260"
            ],
            "layout": "IPY_MODEL_239a76d30aad4c0e83ed9b3d8c327ef6"
          }
        },
        "15a180a9fe3645e8a4ba57044112ce61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd0dfa913df54c09aab19434c7c674ea",
            "placeholder": "​",
            "style": "IPY_MODEL_d7f33d3cd07d439684427b04e18c85db",
            "value": "tokenizer.json: 100%"
          }
        },
        "262cda27d8554e888f08741ceef1b1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69947ea716504a059028c992bbca6b48",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_759a95ca398c49259d888ca2855178c1",
            "value": 1355863
          }
        },
        "3b4fe7014c8c4b5ebc00cd2bf65e2260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a29178650fef4bcbbf402c87a61ecf71",
            "placeholder": "​",
            "style": "IPY_MODEL_76852921ecdc49fba4bac6a5861ff20c",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 16.9MB/s]"
          }
        },
        "239a76d30aad4c0e83ed9b3d8c327ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd0dfa913df54c09aab19434c7c674ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7f33d3cd07d439684427b04e18c85db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69947ea716504a059028c992bbca6b48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "759a95ca398c49259d888ca2855178c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a29178650fef4bcbbf402c87a61ecf71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76852921ecdc49fba4bac6a5861ff20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "335e2ade96b944afa78c08547f49424e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3287038fa03496cbdccd208b15e3aae",
              "IPY_MODEL_bed0e4384b81410d9b2ed4bb9abfdc26",
              "IPY_MODEL_7016007772b541879b219753b39b7ecb"
            ],
            "layout": "IPY_MODEL_9f1dd37dada047a1995c9900ecefe95b"
          }
        },
        "b3287038fa03496cbdccd208b15e3aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a99ae3a2e494e4c80cd2a71f3f9a6bf",
            "placeholder": "​",
            "style": "IPY_MODEL_e8aa239127f34a80a9b0e28882325a6d",
            "value": "config.json: 100%"
          }
        },
        "bed0e4384b81410d9b2ed4bb9abfdc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f06082dbe7ec4188b2b5dbd26240748a",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a85eb15d779c4e64bd86a6d2f454df3f",
            "value": 482
          }
        },
        "7016007772b541879b219753b39b7ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1e9ea89cb3a4a4e927d05b319e45a93",
            "placeholder": "​",
            "style": "IPY_MODEL_c8276523d6774d24a1d643f8d332647e",
            "value": " 482/482 [00:00&lt;00:00, 21.4kB/s]"
          }
        },
        "9f1dd37dada047a1995c9900ecefe95b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a99ae3a2e494e4c80cd2a71f3f9a6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8aa239127f34a80a9b0e28882325a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f06082dbe7ec4188b2b5dbd26240748a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85eb15d779c4e64bd86a6d2f454df3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1e9ea89cb3a4a4e927d05b319e45a93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8276523d6774d24a1d643f8d332647e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4cdd06b10b6478a8296185bfae7b253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4c013e3cfb643aaa583cfa6cd788751",
              "IPY_MODEL_8a75358f71d041be8dfe50ff9039ca94",
              "IPY_MODEL_4da880003fd64007bcde4dfcb0464188"
            ],
            "layout": "IPY_MODEL_9495d47f80fd47c3ba95367a9aed3f48"
          }
        },
        "a4c013e3cfb643aaa583cfa6cd788751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37cc5eb2914342eb8776bb5ef264c375",
            "placeholder": "​",
            "style": "IPY_MODEL_9d48249ea94f45b0883fb16495ed2250",
            "value": "vocab.json: 100%"
          }
        },
        "8a75358f71d041be8dfe50ff9039ca94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f605054b5fd44d3b090b4c37aca2852",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_724c50bbc515459fa197d5d0d3a5ee8a",
            "value": 898823
          }
        },
        "4da880003fd64007bcde4dfcb0464188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c16887ff6e1a4c6f960cd5c111d63564",
            "placeholder": "​",
            "style": "IPY_MODEL_e3e6b7c7157b4a9fae9bf578f12b7bb2",
            "value": " 899k/899k [00:00&lt;00:00, 12.3MB/s]"
          }
        },
        "9495d47f80fd47c3ba95367a9aed3f48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37cc5eb2914342eb8776bb5ef264c375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d48249ea94f45b0883fb16495ed2250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f605054b5fd44d3b090b4c37aca2852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "724c50bbc515459fa197d5d0d3a5ee8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c16887ff6e1a4c6f960cd5c111d63564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e6b7c7157b4a9fae9bf578f12b7bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fa8e8195345486b941b2c88375a363a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54f1ec5ca49f41cfa6c3ab7195d9253d",
              "IPY_MODEL_8347f9a622d5408a97ac65ac3d5127b6",
              "IPY_MODEL_926a3681c410457e94b8e3dc77c43201"
            ],
            "layout": "IPY_MODEL_5eaf650332a34543b6cb30a36026d0ac"
          }
        },
        "54f1ec5ca49f41cfa6c3ab7195d9253d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2556bd77180e45dfa9fe05b724221ed9",
            "placeholder": "​",
            "style": "IPY_MODEL_bf3917f00a9e479ea5a3814614e340da",
            "value": "merges.txt: 100%"
          }
        },
        "8347f9a622d5408a97ac65ac3d5127b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69c7e125d52a4bf29cad6c046cf9d978",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d11301ee310d42158d0e57fc3a192514",
            "value": 456318
          }
        },
        "926a3681c410457e94b8e3dc77c43201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_311a6fd8c34a42158c10bf2bda483158",
            "placeholder": "​",
            "style": "IPY_MODEL_d81c31f91e3d448c90c5b59277b5b0cb",
            "value": " 456k/456k [00:00&lt;00:00, 17.7MB/s]"
          }
        },
        "5eaf650332a34543b6cb30a36026d0ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2556bd77180e45dfa9fe05b724221ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf3917f00a9e479ea5a3814614e340da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69c7e125d52a4bf29cad6c046cf9d978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d11301ee310d42158d0e57fc3a192514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "311a6fd8c34a42158c10bf2bda483158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d81c31f91e3d448c90c5b59277b5b0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82c50447c1814fad890e5e0ba1b81ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85449c3c33db4162b75a36c53edc5f93",
              "IPY_MODEL_8f6839c793be4ea0bb0365a716aa0ddb",
              "IPY_MODEL_7c13d49d519b4746934cd054cd31c31f"
            ],
            "layout": "IPY_MODEL_c85162d9728a44419a10c0e797262665"
          }
        },
        "85449c3c33db4162b75a36c53edc5f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c5b1686293c4139a5e32cb2f60faaff",
            "placeholder": "​",
            "style": "IPY_MODEL_e0692b04da324e88a73f8d58df3c726f",
            "value": "tokenizer.json: 100%"
          }
        },
        "8f6839c793be4ea0bb0365a716aa0ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a0a057bbcdc4d65b4152dd01dc7eff2",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87cc6a97c5194cdeba9df71edb0b2f4e",
            "value": 1355863
          }
        },
        "7c13d49d519b4746934cd054cd31c31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b8a5ace21b44a2990f04f358532049d",
            "placeholder": "​",
            "style": "IPY_MODEL_4a134e7f56ee480c8516e42d78282d80",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 37.2MB/s]"
          }
        },
        "c85162d9728a44419a10c0e797262665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c5b1686293c4139a5e32cb2f60faaff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0692b04da324e88a73f8d58df3c726f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a0a057bbcdc4d65b4152dd01dc7eff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87cc6a97c5194cdeba9df71edb0b2f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b8a5ace21b44a2990f04f358532049d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a134e7f56ee480c8516e42d78282d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37154188120e4a3da95063f785d67d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ac02d5286a64ad2ac1669ca843a4394",
              "IPY_MODEL_206c0cd7957649de9ea966d0dfed363d",
              "IPY_MODEL_604c4bf7f7c24cc4a213193382c88dd9"
            ],
            "layout": "IPY_MODEL_ca2826857d9a42b6b8c9675c1576ebb2"
          }
        },
        "4ac02d5286a64ad2ac1669ca843a4394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c19d36fa5946f0b64c232eaa1f1cf0",
            "placeholder": "​",
            "style": "IPY_MODEL_47f540779d514c51a54a309b5bc7dd6d",
            "value": "model.safetensors: 100%"
          }
        },
        "206c0cd7957649de9ea966d0dfed363d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6eb666020b34beeae236d6af4ad0ae9",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2b011c0179a4e43818140fdf0b21436",
            "value": 1421700479
          }
        },
        "604c4bf7f7c24cc4a213193382c88dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc3eaf073d8048aba01fc89ce151b5c2",
            "placeholder": "​",
            "style": "IPY_MODEL_627dcba5f6074e27b8aef1122a131216",
            "value": " 1.42G/1.42G [00:14&lt;00:00, 190MB/s]"
          }
        },
        "ca2826857d9a42b6b8c9675c1576ebb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08c19d36fa5946f0b64c232eaa1f1cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f540779d514c51a54a309b5bc7dd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6eb666020b34beeae236d6af4ad0ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2b011c0179a4e43818140fdf0b21436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc3eaf073d8048aba01fc89ce151b5c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627dcba5f6074e27b8aef1122a131216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da08b250a2ae4ea88d26f4890973d381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c53ccd7de8d347ce8080218924b9046d",
              "IPY_MODEL_6563bb5b16c94edf8afec890787172d8",
              "IPY_MODEL_d3947356e07c475b921a7cdc61bf2cb9"
            ],
            "layout": "IPY_MODEL_b24149bdc2414cdb8051e43f63d9bd08"
          }
        },
        "c53ccd7de8d347ce8080218924b9046d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55ca8bf5c45246d4b84e16114532cc3d",
            "placeholder": "​",
            "style": "IPY_MODEL_e0208f60c5274d789155f574a96b2aff",
            "value": "config.json: 100%"
          }
        },
        "6563bb5b16c94edf8afec890787172d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd2f5a2c8e7c4829ad2bba28e0dfb981",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1aa378ecdefb446cbfb4570900e74326",
            "value": 482
          }
        },
        "d3947356e07c475b921a7cdc61bf2cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_779c60e92fda4d55a31c1ed575ed1642",
            "placeholder": "​",
            "style": "IPY_MODEL_2aee1fe75fd74598a59fc6128a2a5d59",
            "value": " 482/482 [00:00&lt;00:00, 13.1kB/s]"
          }
        },
        "b24149bdc2414cdb8051e43f63d9bd08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ca8bf5c45246d4b84e16114532cc3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0208f60c5274d789155f574a96b2aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd2f5a2c8e7c4829ad2bba28e0dfb981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa378ecdefb446cbfb4570900e74326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "779c60e92fda4d55a31c1ed575ed1642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aee1fe75fd74598a59fc6128a2a5d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad5e818866a04f938d87726fc749e928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50dd4b9826364386ab7784bdcbc1899c",
              "IPY_MODEL_03be80ee9a8e48c48747e465554ac286",
              "IPY_MODEL_b7743c8000314f1e8faa840503a54676"
            ],
            "layout": "IPY_MODEL_0140104ac9134182ae7ac7e261ead3a3"
          }
        },
        "50dd4b9826364386ab7784bdcbc1899c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_184c38f22d3c4446a6bed8cf63aa3e46",
            "placeholder": "​",
            "style": "IPY_MODEL_26bb1f91f5534810be04c8b6eea39a02",
            "value": "vocab.json: 100%"
          }
        },
        "03be80ee9a8e48c48747e465554ac286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad7e58b260ce4de7b549903804e9cf79",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90c9f2bda4254b459f7d8db05eb50bbe",
            "value": 898823
          }
        },
        "b7743c8000314f1e8faa840503a54676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e1a328b48e34d5086cb368a507c0b72",
            "placeholder": "​",
            "style": "IPY_MODEL_48e52f5125a745488a88ef2de80c0059",
            "value": " 899k/899k [00:00&lt;00:00, 5.77MB/s]"
          }
        },
        "0140104ac9134182ae7ac7e261ead3a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "184c38f22d3c4446a6bed8cf63aa3e46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26bb1f91f5534810be04c8b6eea39a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad7e58b260ce4de7b549903804e9cf79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c9f2bda4254b459f7d8db05eb50bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e1a328b48e34d5086cb368a507c0b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e52f5125a745488a88ef2de80c0059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39eb5f934f0645599398d18dac3d0963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b57d6cd749c342199a7804e70578ad07",
              "IPY_MODEL_55759c6bd8334e3586d64b7ad1dfa0e8",
              "IPY_MODEL_bdba0d427e1340e9add0e455b0e87c28"
            ],
            "layout": "IPY_MODEL_c590a6cb26c4455bb81c5455599b2819"
          }
        },
        "b57d6cd749c342199a7804e70578ad07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d06c01da4a34464ba8eb874f6ccfd5b",
            "placeholder": "​",
            "style": "IPY_MODEL_ebc765b0a8c642948daceb766449a24a",
            "value": "merges.txt: 100%"
          }
        },
        "55759c6bd8334e3586d64b7ad1dfa0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3135ad0105f44fbe938c75b8a7bc9566",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b40fd335765f4d36b96a9041df049bf3",
            "value": 456318
          }
        },
        "bdba0d427e1340e9add0e455b0e87c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44ceea0d9a1241ea8466259a5bff0496",
            "placeholder": "​",
            "style": "IPY_MODEL_67ddaaa54f094efb9165448d7e169934",
            "value": " 456k/456k [00:00&lt;00:00, 13.0MB/s]"
          }
        },
        "c590a6cb26c4455bb81c5455599b2819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d06c01da4a34464ba8eb874f6ccfd5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebc765b0a8c642948daceb766449a24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3135ad0105f44fbe938c75b8a7bc9566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b40fd335765f4d36b96a9041df049bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44ceea0d9a1241ea8466259a5bff0496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ddaaa54f094efb9165448d7e169934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e62a2ddd11df44a9b36ff5e9d91df555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e0db9fdf36846a19456e06008f45ae6",
              "IPY_MODEL_00a8013a0d8a464b808154cde864da2d",
              "IPY_MODEL_8114512a97fb4b159ec932410b621c67"
            ],
            "layout": "IPY_MODEL_2ab0f53136624ff7a8873f215f314b53"
          }
        },
        "7e0db9fdf36846a19456e06008f45ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba2b614ffe6145c5af3f5c2ec062c6a7",
            "placeholder": "​",
            "style": "IPY_MODEL_3d5a11a0567e49e78a269819598a723b",
            "value": "tokenizer.json: 100%"
          }
        },
        "00a8013a0d8a464b808154cde864da2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c9fc7e9af8f4ceeac5f7ca996fc3187",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2a8bd29e1b54ab3b755eb11d8e3f94d",
            "value": 1355863
          }
        },
        "8114512a97fb4b159ec932410b621c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc367c6753d4d0a9094d3c83423e437",
            "placeholder": "​",
            "style": "IPY_MODEL_3bb73f943e9948249dd6cf4038b84792",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 23.8MB/s]"
          }
        },
        "2ab0f53136624ff7a8873f215f314b53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba2b614ffe6145c5af3f5c2ec062c6a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d5a11a0567e49e78a269819598a723b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c9fc7e9af8f4ceeac5f7ca996fc3187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a8bd29e1b54ab3b755eb11d8e3f94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccc367c6753d4d0a9094d3c83423e437": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bb73f943e9948249dd6cf4038b84792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9a23ebef9c6424da52f864820f80fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b5fe1f08558497a88ecee62842a34bd",
              "IPY_MODEL_cc6d067f377e4a46bbe8f28cbf96c08c",
              "IPY_MODEL_4fe9a49d88bf4f13a37dabad77d90683"
            ],
            "layout": "IPY_MODEL_123d05a3f05b4f63b2a89e234cf9ca83"
          }
        },
        "2b5fe1f08558497a88ecee62842a34bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cbc4b5cf49340b3ae615a4e2c886f74",
            "placeholder": "​",
            "style": "IPY_MODEL_7c2cd7fea8bb4d8c8cca1c9973f7ce2e",
            "value": "model.safetensors: 100%"
          }
        },
        "cc6d067f377e4a46bbe8f28cbf96c08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f39a22c9741f4c7ebeb3e9ed9cc86ccf",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd9ddc994d18442a822948b13f7f384e",
            "value": 1421700479
          }
        },
        "4fe9a49d88bf4f13a37dabad77d90683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b51218db8c414f63b4f3ad724ca8aba9",
            "placeholder": "​",
            "style": "IPY_MODEL_b24ff947a28947ca89cecf6902ca8106",
            "value": " 1.42G/1.42G [00:16&lt;00:00, 118MB/s]"
          }
        },
        "123d05a3f05b4f63b2a89e234cf9ca83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cbc4b5cf49340b3ae615a4e2c886f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c2cd7fea8bb4d8c8cca1c9973f7ce2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f39a22c9741f4c7ebeb3e9ed9cc86ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9ddc994d18442a822948b13f7f384e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b51218db8c414f63b4f3ad724ca8aba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24ff947a28947ca89cecf6902ca8106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b21316c9d624080a39b71567b137fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3eb3884b7c5142faa0fd1fc626680564",
              "IPY_MODEL_34ca28d4626f43efa6adf4ba838c443d",
              "IPY_MODEL_e4bab30c46f84bde915fcb9f486e0be6"
            ],
            "layout": "IPY_MODEL_5756f82d73a249ea9a8db88920a48ede"
          }
        },
        "3eb3884b7c5142faa0fd1fc626680564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29b76ca112b14487a7884a7c3e6effaa",
            "placeholder": "​",
            "style": "IPY_MODEL_d7b64afac4284c8782a81be37281eab1",
            "value": "config.json: 100%"
          }
        },
        "34ca28d4626f43efa6adf4ba838c443d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3007747147c49628e977705c639961b",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05835ea718ec4f33aebd4b6edce9bdf2",
            "value": 482
          }
        },
        "e4bab30c46f84bde915fcb9f486e0be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6842aa0e6d38477b849a1877d4465bc0",
            "placeholder": "​",
            "style": "IPY_MODEL_2a608f59847e490082648355e94b5090",
            "value": " 482/482 [00:00&lt;00:00, 36.7kB/s]"
          }
        },
        "5756f82d73a249ea9a8db88920a48ede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29b76ca112b14487a7884a7c3e6effaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7b64afac4284c8782a81be37281eab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3007747147c49628e977705c639961b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05835ea718ec4f33aebd4b6edce9bdf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6842aa0e6d38477b849a1877d4465bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a608f59847e490082648355e94b5090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9fbc27ae7c34bebbcf8859efa3bc6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0be1dfbcaaa4817a3109f7140975252",
              "IPY_MODEL_f5418179275d41afada48581a87730ca",
              "IPY_MODEL_086ecd5d73284ef7b111f216eeb15703"
            ],
            "layout": "IPY_MODEL_1471aa6f1cce4531a7eda9ad22ff5c95"
          }
        },
        "e0be1dfbcaaa4817a3109f7140975252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f7973970ffb47c89de7c2d67995abc8",
            "placeholder": "​",
            "style": "IPY_MODEL_e0b7083aea5c478093fa4986b0cfd261",
            "value": "model.safetensors: 100%"
          }
        },
        "f5418179275d41afada48581a87730ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c26bdeec290848eba5c1dec59180d5bf",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d92550066df743f096294f5a832f4a27",
            "value": 1421700479
          }
        },
        "086ecd5d73284ef7b111f216eeb15703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d518865e90854b47ba721c2a5d8c6d1f",
            "placeholder": "​",
            "style": "IPY_MODEL_46b5ff9d83a84f6fb8654cdfb1e4b360",
            "value": " 1.42G/1.42G [00:04&lt;00:00, 347MB/s]"
          }
        },
        "1471aa6f1cce4531a7eda9ad22ff5c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f7973970ffb47c89de7c2d67995abc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0b7083aea5c478093fa4986b0cfd261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c26bdeec290848eba5c1dec59180d5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d92550066df743f096294f5a832f4a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d518865e90854b47ba721c2a5d8c6d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46b5ff9d83a84f6fb8654cdfb1e4b360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77b387e66a78495788777dbf7d0b6667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_834d98911d4a473d8b2a46439c2c5ea9",
              "IPY_MODEL_c6dedce0790b4383acef74e5c2cbd89a",
              "IPY_MODEL_0b91449d5bac4a7e9f5e35ec3f427a94"
            ],
            "layout": "IPY_MODEL_7fe043b046c24eb7a3c1dba8bfca4445"
          }
        },
        "834d98911d4a473d8b2a46439c2c5ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78459338634e4989b871b87667ba7653",
            "placeholder": "​",
            "style": "IPY_MODEL_7d0106726065476780f72187ae3f6d58",
            "value": "vocab.json: 100%"
          }
        },
        "c6dedce0790b4383acef74e5c2cbd89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d865548c544a4a62ad1d152c46ad4ca1",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_777dcc47065640b8bc51d692840c7154",
            "value": 898823
          }
        },
        "0b91449d5bac4a7e9f5e35ec3f427a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5268d0c349ba430f8cc489737a88ab43",
            "placeholder": "​",
            "style": "IPY_MODEL_000017bdcc9d47c197ed028450f3ddb4",
            "value": " 899k/899k [00:00&lt;00:00, 39.9MB/s]"
          }
        },
        "7fe043b046c24eb7a3c1dba8bfca4445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78459338634e4989b871b87667ba7653": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0106726065476780f72187ae3f6d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d865548c544a4a62ad1d152c46ad4ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777dcc47065640b8bc51d692840c7154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5268d0c349ba430f8cc489737a88ab43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "000017bdcc9d47c197ed028450f3ddb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c500209e24be43e3ba24c3e36d868275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c211156905fc4522a7b0a9dc661d85e4",
              "IPY_MODEL_d56c52ead86d400db1be250755272aca",
              "IPY_MODEL_d8650c1019574638b8baeecb80fe0ac7"
            ],
            "layout": "IPY_MODEL_7fc31c83750b4c0fa32cd5075162af2d"
          }
        },
        "c211156905fc4522a7b0a9dc661d85e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0404a5727b91485eadf3af9104d53223",
            "placeholder": "​",
            "style": "IPY_MODEL_5acc0096591e4c99a41769b8fe6056ab",
            "value": "merges.txt: 100%"
          }
        },
        "d56c52ead86d400db1be250755272aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e09a5d3cf486495ba34f9f008a0c1681",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3352ed4957534ecdb91a288fc9dd8821",
            "value": 456318
          }
        },
        "d8650c1019574638b8baeecb80fe0ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_462300d4cff4451e8a042d35f5e121b3",
            "placeholder": "​",
            "style": "IPY_MODEL_20ecacdae30c45b69d1b54bc50bbc3f2",
            "value": " 456k/456k [00:00&lt;00:00, 34.9MB/s]"
          }
        },
        "7fc31c83750b4c0fa32cd5075162af2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0404a5727b91485eadf3af9104d53223": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5acc0096591e4c99a41769b8fe6056ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e09a5d3cf486495ba34f9f008a0c1681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3352ed4957534ecdb91a288fc9dd8821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "462300d4cff4451e8a042d35f5e121b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20ecacdae30c45b69d1b54bc50bbc3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fb4e841728d4dd5909d4d740047d72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2faacd41c0394407b88d7a354d40ebd3",
              "IPY_MODEL_f905256e0e94468b85a4f09497e27bd1",
              "IPY_MODEL_ba0d18c7ad3643d58183678c79ebecf5"
            ],
            "layout": "IPY_MODEL_7e21d20a56b149d2a9a082a3563c4f2c"
          }
        },
        "2faacd41c0394407b88d7a354d40ebd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d7d3f9e1f21400a84504d197795d4d7",
            "placeholder": "​",
            "style": "IPY_MODEL_53f5c29f48644191baadf672e2d7433f",
            "value": "tokenizer.json: 100%"
          }
        },
        "f905256e0e94468b85a4f09497e27bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17f3d169001940f0ac2e4854bc4b853e",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e948b265a524a29a5c043a22b18d8a1",
            "value": 1355863
          }
        },
        "ba0d18c7ad3643d58183678c79ebecf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8854f06b063c4864ad280d41cc605b87",
            "placeholder": "​",
            "style": "IPY_MODEL_a7496c19abac467f81e839663f2d9bc5",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 5.42MB/s]"
          }
        },
        "7e21d20a56b149d2a9a082a3563c4f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d7d3f9e1f21400a84504d197795d4d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f5c29f48644191baadf672e2d7433f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17f3d169001940f0ac2e4854bc4b853e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e948b265a524a29a5c043a22b18d8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8854f06b063c4864ad280d41cc605b87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7496c19abac467f81e839663f2d9bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}